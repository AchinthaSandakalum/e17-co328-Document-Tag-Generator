{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cepdnaclk.github.io/e15-3yp-A-GUI-for-controlling-and-supervising-multiple-robots-remotely\n",
      "https://cepdnaclk.github.io/e15-3yp-An-Efficient-System-For-Waste-Collection\n",
      "https://cepdnaclk.github.io/e15-3yp-An-automated-system-for-monitoring-and-controlling-the-water-supply-to-a-large-farmland\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Bike-Sharing-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Book-Management-System-Automated-Book-Carrying-Robot\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Vehicle-Parking-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Water-Quality-Monitoring-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Automatic-Door-Lock-System\n",
      "https://cepdnaclk.github.io/e15-3yp-E-Checkup\n",
      "https://cepdnaclk.github.io/e15-3yp-Embedded-system-for-detecting-adverse-gases\n",
      "https://cepdnaclk.github.io/e15-3yp-Fire-Detection-and-Alert-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Health-Watch\n",
      "https://cepdnaclk.github.io/e15-3yp-Hydroponics-Automation-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Intelligent-Road-Traffic-Control-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Monitoring-and-Tracking-System-for-Transportation-of-Pharmaceuticals\n",
      "https://cepdnaclk.github.io/e15-3yp-Personal-Physical-Trainer-PPT\n",
      "https://cepdnaclk.github.io/e15-3yp-Safer-Travel-Utility-SaVy\n",
      "https://cepdnaclk.github.io/e15-3yp-Smart-Educational-Management-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Smart-Mirror\n",
      "https://cepdnaclk.github.io/e15-3yp-Smart-Monitoring-and-Automated-Controlling-System-for-an-Aquarium\n",
      "https://cepdnaclk.github.io/e14-3yp-Air-Quality-Monitoring-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Attendance-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Bike-Sharing-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Electricity-Billing-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Fishing-Bot\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Greenhouse-Fertilizing-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Monitoring-of-Hospital-Patients\n",
      "https://cepdnaclk.github.io/e14-3yp-Automatic-Speed-Trap\n",
      "https://cepdnaclk.github.io/e14-3yp-Bus-tracking-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Control-System-for-Heliostat-Solar-Power-Plants\n",
      "https://cepdnaclk.github.io/e14-3yp-Networked-and-Automated-Weather-Monitoring-and-Alerting-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Real-Time-Water-Qualtiy-Measurement-System\n",
      "https://cepdnaclk.github.io/e14-3yp-River-water-level-and-speed-monitoring-and-alert-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Breathalyzer-Test\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Shopping-Cart\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Warehouse-Monitoring-for-Paddy-Storage\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Waste-Disposal-Monitoring-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Telepresence-Robot\n",
      "https://cepdnaclk.github.io/e14-3yp-Train-Movement-Tracking-and-Level-Crossing-Safety-Control\n",
      "https://cepdnaclk.github.io/e14-3yp-sleep-apnea-detection\n",
      "https://cepdnaclk.github.io/e17-3yp-Covid-Tracer\n",
      "https://cepdnaclk.github.io/e17-3yp-E-Parking-System\n",
      "https://cepdnaclk.github.io/e17-3yp-Landmine-Detector\n",
      "https://cepdnaclk.github.io/e17-3yp-Milk-Testing-and-Collecting-System\n",
      "https://cepdnaclk.github.io/e17-3yp-Remote-Gatekeeping-System\n",
      "https://cepdnaclk.github.io/e17-3yp-Secure-Food-Delivery\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Cradle\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Locker\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Pet-Feeder\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Pour\n",
      "https://cepdnaclk.github.io/e17-3yp-Wild-Life-Tracker\n",
      "https://cepdnaclk.github.io/e17-3yp-maker-mate\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-billiard\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-keyboard-tutoring-system\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-medical-diagnostics\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-proctoring-system\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-apartment-security-system\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-garbage-collection\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-home\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-shopping-cart\n",
      "https://cepdnaclk.github.io/e16-3yp-agribot\n",
      "https://cepdnaclk.github.io/e16-3yp-automated-railway-ticketing-system\n",
      "https://cepdnaclk.github.io/e16-3yp-automatic-fish-tank-control-system\n",
      "https://cepdnaclk.github.io/e16-3yp-chessMATE\n",
      "https://cepdnaclk.github.io/e16-3yp-computerized-timetabling-and-attendance-marking-system\n",
      "https://cepdnaclk.github.io/e16-3yp-digital-signage-based-user-targeted-advertising\n",
      "https://cepdnaclk.github.io/e16-3yp-full-body-motion-tracking-system\n",
      "https://cepdnaclk.github.io/e16-3yp-gas-level-indicator-and-leakage-detector\n",
      "https://cepdnaclk.github.io/e16-3yp-obstacle-bots-for-swarm-robots\n",
      "https://cepdnaclk.github.io/e16-3yp-qurantine-tracker\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-door-lock\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-infared-shooting-sport\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-meeting-automaton\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-payment-system\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-pharmaceutical-warehousing\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-pill-manager\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-shopping-cart-with-automatic-bill-system\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-vending-machine\n",
      "https://cepdnaclk.github.io/e16-3yp-waiterbot-system\n",
      "https://cepdnaclk.github.io/e16-3yp-water-quality-monitoring-and-usage-monitoring-system\n",
      "https://cepdnaclk.github.io/e15-4yp-Accelerating-Adaptive-Banded-Event-Alignment-Algorithm-with-OpenCL-on-FPGA\n",
      "https://cepdnaclk.github.io/e15-4yp-Brain-Computer-Interface-for-controlling-virtual-objects\n",
      "https://cepdnaclk.github.io/e15-4yp-Doppelganger-Cartoon\n",
      "https://cepdnaclk.github.io/e15-4yp-Explainable-Machine-Learning-for-Real-World-Resource-Constrained-Problems\n",
      "https://cepdnaclk.github.io/e15-4yp-Hand-Gesture-Recognition-using-sEMG\n",
      "https://cepdnaclk.github.io/e15-4yp-Identifying-keywords-in-legal-articles-using-ML-techniques\n",
      "https://cepdnaclk.github.io/e15-4yp-Microservice-Based-Edge-Computing-Architecture\n",
      "https://cepdnaclk.github.io/e15-4yp-Mixed-Reality-based-Simulation-Platform-for-Swarm-Robotics\n",
      "https://cepdnaclk.github.io/e15-4yp-Optimizing-Mitochondria-Genome-Assembly-And-Annotation-With-Skim-Sequencing-Data\n",
      "https://cepdnaclk.github.io/e15-4yp-Optimizing-chloroplast-genome-assembly-and-annotation-with-skim-sequencing-data\n",
      "https://cepdnaclk.github.io/e15-4yp-Pipeline-for-Isolation-of-Fast-evolving-ITS-Regions-from-Skim-Sequencing-Data\n",
      "https://cepdnaclk.github.io/e15-4yp-Real-Time-Data-processing-and-AI-for-Distributed-IoT\n",
      "https://cepdnaclk.github.io/e15-4yp-Real-Time-Emotion-Recognition-using-Electrocardiogram-Analysis\n",
      "https://cepdnaclk.github.io/e15-4yp-Revealing-miRNA-Biomarkers-for-Alzheimer-s-Disease-using-NGS\n",
      "https://cepdnaclk.github.io/e15-4yp-anonymous-authentication\n",
      "https://cepdnaclk.github.io/e15-4yp-cricket-analysis\n",
      "https://cepdnaclk.github.io/e15-4yp-human-behavior-prediction-using-cctv\n",
      "https://cepdnaclk.github.io/e15-4yp-nearIR-spectroscopy\n",
      "https://cepdnaclk.github.io/e15-4yp-online-proctoring-system\n",
      "https://cepdnaclk.github.io/e15-4yp-sports-action-recognition\n",
      "https://cepdnaclk.github.io/e14-4yp-ipb\n",
      "https://cepdnaclk.github.io/e15-co326-Remotely-Controlled-CNC-Robot\n",
      "https://cepdnaclk.github.io/e17-co328-Analysis-Tool-for-Industrial-Images\n",
      "https://cepdnaclk.github.io/e17-co328-ContactTracingApp\n",
      "https://cepdnaclk.github.io/e17-co328-Flood-Forecasting-System\n",
      "https://cepdnaclk.github.io/e17-co328-Greenhouse-Monitoring-System\n",
      "https://cepdnaclk.github.io/e17-co328-Greenhouse-monitoring-and-controlling-based-on-IOT-sensor-data\n",
      "https://cepdnaclk.github.io/e17-co328-History-of-Music\n",
      "https://cepdnaclk.github.io/e17-co328-Host-Pathogen-Interaction\n",
      "https://cepdnaclk.github.io/e17-co328-NGS-Data-AnalysingToolkit\n",
      "https://cepdnaclk.github.io/e17-co328-Oral-Cavity-Region-Detection\n",
      "https://cepdnaclk.github.io/e17-co328-Prediction-of-risks-associated-with-mass-corona-vaccination\n",
      "https://cepdnaclk.github.io/e17-co328-Skim-Sequencing-Analysis\n",
      "https://cepdnaclk.github.io/e16-co328-Movie-Review-System\n",
      "https://cepdnaclk.github.io/e16-co328-Project-Publication-Platform\n",
      "https://cepdnaclk.github.io/e16-co328-Student-Management-System\n",
      "https://cepdnaclk.github.io/e15-co328-Zero-Trash\n",
      "https://cepdnaclk.github.io/e17-co543-SL-Number-Plate-Detection-Group-A\n",
      "https://cepdnaclk.github.io/e15-2yp-Pera-Knowledge-Portal\n",
      "https://cepdnaclk.github.io/e15-2yp-finite-element-based-structural-non-linear-analysis\n",
      "https://cepdnaclk.github.io/e14-2yp-dynamic-background-cancellation-in-videos\n",
      "https://cepdnaclk.github.io/e16-co502-RISCV-Pipeline-CPU-Implimentation-Group2\n",
      "https://cepdnaclk.github.io/e16-co502-RISCV-pipeline-cpu-implementation-group04\n",
      "https://cepdnaclk.github.io/e16-co502-RV32IM-NoC-implementation\n",
      "https://cepdnaclk.github.io/e16-co502-RV32IM-pipeline-implementation-group1\n",
      "https://cepdnaclk.github.io/e16-co502-RV32IM-pipeline-implementation-group3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "projects = pd.read_csv(\"data/projects_details.csv\")\n",
    "\n",
    "for url in projects['page_url']:\n",
    "    url = url.strip()\n",
    "    if url == \"#\":\n",
    "        continue\n",
    "\n",
    "    print(url)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_7996\\356083747.py:17: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\"><head>\n",
      "\n",
      "  <meta charset=\"utf-8\">\n",
      "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\">\n",
      "\n",
      "  <title>Covid Tracer</title>\n",
      "  <meta content=\"\" name=\"description\">\n",
      "  <meta content=\"\" name=\"keywords\">\n",
      "\n",
      "  <!-- Favicons -->\n",
      "  <link href=\"assets/img/favicon.png\" rel=\"icon\">\n",
      "\n",
      "  <!-- Google Fonts -->\n",
      "  <link href=\"https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,600,700|Raleway:300,400,400i,500,500i,700,800,900\" rel=\"stylesheet\">\n",
      "\n",
      "  <!-- Vendor CSS Files -->\n",
      "  <link href=\"assets/vendor/animate.css/animate.min.css\" rel=\"stylesheet\">\n",
      "  <link href=\"assets/vendor/bootstrap/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
      "  <link href=\"assets/vendor/bootstrap-icons/bootstrap-icons.css\" rel=\"stylesheet\">\n",
      "  <link href=\"assets/vendor/boxicons/css/boxicons.min.css\" rel=\"stylesheet\">\n",
      "  <link href=\"assets/vendor/glightbox/css/glightbox.min.css\" rel=\"stylesheet\">\n",
      "  <link href=\"assets/vendor/swiper/swiper-bundle.min.css\" rel=\"stylesheet\">\n",
      "\n",
      "  <!-- Template Main CSS File -->\n",
      "  <link href=\"assets/css/style.css\" rel=\"stylesheet\">\n",
      "\n",
      "</head>\n",
      "\n",
      "\n",
      "<body>\n",
      "\n",
      "  <!-- ======= Header ======= -->\n",
      "  <header id=\"header\" class=\"fixed-top d-flex align-items-center\">\n",
      "    <div class=\"container d-flex justify-content-between\">\n",
      "\n",
      "      <div class=\"logo\">\n",
      "        <h1><a href=\"index.html\"><span></span>Covid Tracer</a></h1>\n",
      "        <!-- Uncomment below if you prefer to use an image logo\n",
      "        <a href=\"index.html\"><img src=\"assets/img/favicon.png\" alt=\"\" class=\"img-fluid\"></a> -->\n",
      "      </div>\n",
      "\n",
      "      <nav id=\"navbar\" class=\"navbar\">\n",
      "        <ul>\n",
      "          <li><a class=\"nav-link scrollto active\" href=\"#hero\">Home</a></li>\n",
      "          <li><a class=\"nav-link scrollto\" href=\"#about\">About</a></li>\n",
      "          <li><a class=\"nav-link scrollto\" href=\"#system\">Features</a></li>  \n",
      "          <li class=\"dropdown\"><a href=\"#\"><span>Solution Architecture\n",
      "          </span> <i class=\"bi bi-chevron-down\"></i></a>\n",
      "            <ul>\n",
      "              <li><a href=\"#high-level\">High Level</a></li>\n",
      "              <li><a href=\"#hardware\">Hardware</a></li>\n",
      "              <li><a href=\"#security\">Security</a></li>\n",
      "              <li><a href=\"#pricing\">Budget</a></li>\n",
      "              <li><a href=\"#timeline\">Timeline</a></li>  \n",
      "            </ul>\n",
      "          </li>\n",
      "          <li class=\"dropdown\"><a href=\"#\"><span>Development\n",
      "          </span> <i class=\"bi bi-chevron-down\"></i></a>\n",
      "            <ul>\n",
      "              <li><a href=\"development.html\">Software</a></li>\n",
      "              <!--<li><a href=\"#\">1</a></li>\n",
      "              <li><a href=\"#\">2</a></li>-->\n",
      "              <li><a href=\"hardware.html\">Hardware</a></li>\n",
      "            </ul>\n",
      "          </li> \n",
      "          <li><a href=\"test.html\">Testing</a></li>\n",
      "          <!--<li><a class=\"nav-link scrollto\" href=\"#blog\">Conclusion</a></li>-->\n",
      "          <li><a class=\"nav-link scrollto\" href=\"#team\">Team</a></li>\n",
      "        </ul>\n",
      "        <i class=\"bi bi-list mobile-nav-toggle\"></i>\n",
      "      </nav><!-- .navbar -->\n",
      "\n",
      "    </div>\n",
      "  </header><!-- End Header -->\n",
      "\n",
      "  <!-- ======= hero Section ======= -->\n",
      "  <section id=\"hero\">\n",
      "    <div class=\"hero-container\">\n",
      "      <div id=\"heroCarousel\" class=\"carousel slide carousel-fade\" data-bs-ride=\"carousel\" data-bs-interval=\"5000\">\n",
      "\n",
      "        <ol id=\"hero-carousel-indicators\" class=\"carousel-indicators\"><li data-bs-target=\"#heroCarousel\" data-bs-slide-to=\"0\" class=\"active\"></li><li data-bs-target=\"#heroCarousel\" data-bs-slide-to=\"1\"></li><li data-bs-target=\"#heroCarousel\" data-bs-slide-to=\"2\"></li></ol>\n",
      "\n",
      "        <div class=\"carousel-inner\" role=\"listbox\">\n",
      "\n",
      "          <div class=\"carousel-item active\" style=\"background-image: url(assets/img/hero-carousel/covid.jpg)\">\n",
      "            <div class=\"carousel-container\">\n",
      "              <div class=\"container\">\n",
      "                <h2 class=\"animate__animated animate__fadeInDown\">Autonomous Covid-19 Tracking System</h2>\n",
      "                <p class=\"animate__animated animate__fadeInUp\">For a Well Aware and Safe Sri Lanka</p>\n",
      "                <a href=\"https://github.com/cepdnaclk/e17-3yp-Covid-Tracer\" target=\"_blank\" class=\"btn-get-started scrollto animate__animated animate__fadeInUp\">Project Repo</a>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "\n",
      "          <div class=\"carousel-item\" style=\"background-image: url(assets/img/hero-carousel/overview.jpg)\">\n",
      "            <div class=\"carousel-container\">\n",
      "              <div class=\"container\">\n",
      "                <h2 class=\"animate__animated animate__fadeInDown\">Covid-19</h2>\n",
      "                <p class=\"animate__animated animate__fadeInUp\">New Normal Situation due to the Pandemic</p>\n",
      "                <a href=\"#about\" class=\"btn-get-started scrollto animate__animated animate__fadeInUp\">Get Started</a>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "\n",
      "          <div class=\"carousel-item\" style=\"background-image: url(assets/img/hero-carousel/product_video.mp4)\">\n",
      "            <div class=\"carousel-container\">\n",
      "              <div class=\"container\">\n",
      "                <video controls=\"autoplay\" width=\"100%\" height=\"500\" preload=\"true\">\n",
      "                  <source src=\"assets/img/hero-carousel/product_video.mp4\" type=\"video/mp4\">\n",
      "                </video>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "\n",
      "        </div>\n",
      "\n",
      "        <a class=\"carousel-control-prev\" href=\"#heroCarousel\" role=\"button\" data-bs-slide=\"prev\">\n",
      "          <span class=\"carousel-control-prev-icon bi bi-chevron-left\" aria-hidden=\"true\"></span>\n",
      "        </a>\n",
      "\n",
      "        <a class=\"carousel-control-next\" href=\"#heroCarousel\" role=\"button\" data-bs-slide=\"next\">\n",
      "          <span class=\"carousel-control-next-icon bi bi-chevron-right\" aria-hidden=\"true\"></span>\n",
      "        </a>\n",
      "\n",
      "      </div>\n",
      "    </div>\n",
      "  </section><!-- End Hero Section -->\n",
      "\n",
      "  <main id=\"main\">\n",
      "\n",
      "    <!-- ======= About Section ======= -->\n",
      "    <div id=\"about\" class=\"about-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline text-center\">\n",
      "              <h2>Introduction</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row\">\n",
      "          <!-- single-well start-->\n",
      "          <div class=\"col-md-6 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-left\">\n",
      "              <div class=\"single-well\">\n",
      "                <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                  <img src=\"assets/img/about/new-normal.jpg\" alt=\"world due to covid\">\n",
      "                </div>\n",
      "              </div>\n",
      "            </div> \n",
      "          </div>\n",
      "          <!-- single-well end-->\n",
      "          <div class=\"col-md-6 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-middle\">\n",
      "              <div class=\"single-well\">\n",
      "                <h4 class=\"sec-head\">Overview</h4>\n",
      "                <p>\n",
      "                  <strong>The Covid-19 Pandemic</strong> is the defining Global Health Crisis of the contemporary society. Since its emergence in late\n",
      "                        2019, the virus has spread across the entire world and led to a dramatic loss of human life. The economic and social \n",
      "                        disruption caused by the pandemic is devastating. Almost every sector is affected by this pandemic. In addition,\n",
      "                        this prevailing situation has raised unprecedented challenges to the daily routines of the people. While taking\n",
      "                        immense measures on infect diagnosis, Corona Virus treatments and controlling the spread of the disease a reasonable\n",
      "                        focus should be given to how we adjust to this new normal situation.<br>\n",
      "                        <i>When will the world be free of Covid? </i>is an unanswered question. Our focus is to make the new normal situation due \n",
      "                        to Covid easily adjustable for the people while making their lives safe.\n",
      "                </p>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>    \n",
      "        <div class=\"row\">\n",
      "          <div class=\"well-middle\">\n",
      "            <h4 class=\"sec-head\"><br>Real World Problem</h4>\n",
      "            <p>\n",
      "              Due to the prevailing pandemic situation people have a responsibility of providing accurate details of themselves at \n",
      "              entrances of various commercial places like shopping malls, banks etc. and get their temperatures checked and accepted \n",
      "              before entering. This situation is currently handled manually by people writing details on a book at entrances of various places. \n",
      "              <br><br>\n",
      "              Some major issues with this system includes:\n",
      "              </p><ul>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> Inefficient thus time consuming\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> Risk of getting infected by everyone touching same stationary is high\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> Details get blot by touching with wet hands after washing or sanitizing\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> Personal details of people are publicly made available\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> High probability for the guard at the entrance checking temperatures to get in contact with infects\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> People providing inaccurate data, neglecting providing details and getting the temperature checked\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> Inability to detect people under quarantine\n",
      "                </li>\n",
      "                <li>\n",
      "                  <i class=\"bi bi-check\"></i> Inability to keep track of infected percentages of the locations visited\n",
      "                </li>\n",
      "              </ul>\n",
      "              <br>\n",
      "              Adhering to workplace safety and health practices and ensuring access to decent work and the protection of labour rights \n",
      "              in all industries will be crucial in addressing the human dimension of the crisis.\n",
      "            <p></p>  \n",
      "          </div>      \n",
      "        </div>\n",
      "      </div>\n",
      "    </div><!-- End About Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= features Section ======= -->\n",
      "    <div id=\"system\" class=\"services-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline services-head text-center\">\n",
      "              <h2>Features of our system</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row text-center\">\n",
      "          <!-- Start Left services -->\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "            <div class=\"about-move\">\n",
      "              <div class=\"services-details\">\n",
      "                <div class=\"single-services\">\n",
      "                  <div class=\"services-icon\">\n",
      "                    <i class=\"bi bi-menu-button-wide\"></i>\n",
      "                  </div>\n",
      "                  <h4>Computerized system</h4>\n",
      "                  <p>\n",
      "                    Covid-19 management software with computerized database system for the Government. This is also mainly used for demonstrating how over system gets latest\n",
      "                    covid information from the Government Authorities through a REST API\n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "              <!-- end about-details -->\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "            <div class=\"about-move\">\n",
      "              <div class=\"services-details\">\n",
      "                <div class=\"single-services\">\n",
      "                  <div class=\"services-icon\">\n",
      "                    <i class=\"bi bi-card-checklist\"></i>\n",
      "                  </div>\n",
      "                  <h4>Autonomous detail entering and temperature checking</h4>\n",
      "                  <p>\n",
      "                    Details about the person will be entered to the system by scanning the barcode of NIC/ QR scanning, system will detect if the \n",
      "                    person is under quarantine. The temperature will be measured using sensors. These temperature measurements along \n",
      "                    with the visited location will be sent to the server and stored for a 2 weeks period. Your privacy will be highly protected\n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "              <!-- end about-details -->\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "            <!-- end col-md-4 -->\n",
      "            <div class=\" about-move\">\n",
      "              <div class=\"services-details\">\n",
      "                <div class=\"single-services\">\n",
      "                  <div class=\"services-icon\">\n",
      "                    <i class=\"bi bi-door-open\"></i>\n",
      "                  </div>\n",
      "                  <h4>Automated door opening</h4>\n",
      "                  <p>\n",
      "                    This comes as an optional feature of our system. If certain satisfactory conditions are met like quarantine status, max \n",
      "                    temperature level then the doors will be opened automatically\n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "              <!-- end about-details -->\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "            <!-- end col-md-4 -->\n",
      "            <div class=\" about-move\">\n",
      "              <div class=\"services-details\">\n",
      "                <div class=\"single-services\">\n",
      "                  <div class=\"services-icon\">\n",
      "                    <i class=\"bi bi-geo-alt\"></i>\n",
      "                  </div>\n",
      "                  <h4>Covid tracking</h4>\n",
      "                  <p>\n",
      "                    Check about reported infects of a particular location as a percentage before visiting.\n",
      "                    Our system will also keep records about the visited locations of a person for a period of 2 weeks. Infect percentages \n",
      "                    of these locations reported later will be tracked\n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "              <!-- end about-details -->\n",
      "            </div>\n",
      "          </div>\n",
      "          <!-- End Left services -->\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "            <!-- end col-md-4 -->\n",
      "            <div class=\" about-move\">\n",
      "              <div class=\"services-details\">\n",
      "                <div class=\"single-services\">\n",
      "                  <div class=\"services-icon\">\n",
      "                    <i class=\"bi bi-laptop\"></i>\n",
      "                  </div>\n",
      "                  <h4>Website</h4>\n",
      "                  <p>\n",
      "                    Local community can visit our website to view covid related information like daily/cumulative cases and deaths, infect percentages \n",
      "                    of areas. A seperate user login will be provided to view personal details like temperate fluctuations using data obtained \n",
      "                    at entrances, infect percentages of the locations visited for a period of 2 weeks \n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "              <!-- end about-details -->\n",
      "            </div>\n",
      "          </div>\n",
      "          <!-- End Left services -->\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "            <!-- end col-md-4 -->\n",
      "            <div class=\" about-move\">\n",
      "              <div class=\"services-details\">\n",
      "                <div class=\"single-services\">\n",
      "                  <div class=\"services-icon\">\n",
      "                    <i class=\"bi bi-phone\"></i>\n",
      "                  </div>\n",
      "                  <h4>Mobile app</h4>\n",
      "                  <p>\n",
      "                    Similar interface as the website. This is designed for the easy use at the comfort of a mobile phone.\n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "              <!-- end about-details -->\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div><!-- End Services Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= High Level Section ======= -->\n",
      "    <div id=\"high-level\" class=\"about-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline text-center\">\n",
      "              <h2>High Level System</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row\">\n",
      "          <!-- single-well start-->\n",
      "          <div class=\"col-md-12 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-middle\">\n",
      "              <div class=\"single-well\">\n",
      "                <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                  <img src=\"assets/img/solution/highlevel.png\" alt=\"world due to covid\" class=\"center-highlevel\">\n",
      "                </div>\n",
      "              </div>\n",
      "            </div> \n",
      "          </div>\n",
      "          <!-- single-well end-->\n",
      "        </div>    \n",
      "        <div class=\"row\">\n",
      "          <div class=\"well-middle\">\n",
      "            <h4 class=\"sec-head\"><br>Description</h4>\n",
      "            <p>\n",
      "              Our system can be described in four segments. \n",
      "            </p>\n",
      "            <p>\n",
      "              <i class=\"bi bi-dot\"></i>A software for data entering, data representing along with a computerized database system will be provided to the\n",
      "              Government Authorities. They maintain detailed Covid related information like infects, pcr test reports,people under quarantine etc. in their \n",
      "              server system. Our database system will be updated on certain intervals with the Government Server through a REST API.\n",
      "            </p>\n",
      "            <p>\n",
      "              <i class=\"bi bi-dot\"></i>Our server system will be deployed in the cloud. We will keep information about people's NIC numbers, \n",
      "              addresses, contact numbers, visited locations, temperature readings obtained at various entrances etc. Various calculations on data \n",
      "              for example infect percentages will be done on a cloud virtual environment\n",
      "            </p>    \n",
      "            <p>\n",
      "              <i class=\"bi bi-dot\"></i>Commercial Merchants including shopping malls, banks etc. will be provided with an embedded system \n",
      "              device based on a micro-controller. People can scan their IDs before entering and the system will check with the servers if the \n",
      "              person's under quarantine. The temperature will be measured by contact-less sensors and checked if satisfactory. Whether the person \n",
      "              is allowed to enter or not will be notified using LED displays and buzzers. ID number along with the temperature and location will be stored \n",
      "              in our servers for a 2 week period. Therefore merchants don't have the burden of handling customer details. At the same time \n",
      "              people don't have to provide their details publicly. Commercial merchants have the choice of implementing our door system which will \n",
      "              be opened automatically based on the customer's conditions\n",
      "            </p>  \n",
      "            <p>\n",
      "              <i class=\"bi bi-dot\"></i>The local community will be provided with a website as well as a mobile app. They can visit our website/app to\n",
      "              view general Covid related information in the country eg: daily/cumulative cases and deaths, infect persentages of different areas. A seperate\n",
      "              user login is provided to view personal data eg: infect percentage reported later of visited locations, temperature fluctuations, \n",
      "              general health alerts released by Government eg: vaccinating dates in different areas as well as user specific health alerts\n",
      "            </p> \n",
      "          </div>      \n",
      "        </div>\n",
      "      </div>\n",
      "    </div><!-- End High Level Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= Hardware Section ======= -->\n",
      " \n",
      "    <div id=\"hardware\" class=\"services-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline services-head text-center\">\n",
      "              <h2>Embedded Hardware Device</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <br>\n",
      "            <video width=\"100%\" height=\"550px\" controls=\"controls\" preload=\"true\">\n",
      "              <source src=\"assets/img/hardware/covid tracer v19.mp4\" type=\"video/mp4\">\n",
      "            </video>\n",
      "          </div>\n",
      "\n",
      "          <!-- single-well start\n",
      "          <div class= \"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <h5><br><br><br>\n",
      "              Main Components of the Device<br></h5>\n",
      "          </div>-->\n",
      "          <br>\n",
      "\n",
      "          <div class=\"col-md-6 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-left\">\n",
      "              <div class=\"single-well\">\n",
      "                <div>\n",
      "                  <h4 class=\"sec-head\"><br>Microcontroller</h4>\n",
      "                  <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                    <img src=\"assets/img/hardware/esp32 board.jpg\" alt=\"esp32 board\">\n",
      "                  </div>-->\n",
      "                  <div>\n",
      "                    <p>\n",
      "                      <br>Microcontroller is the base of our device and it should accomplish several task at the same time. \n",
      "                      Hence, having a dual core processor in the microcontroller will be efficient to handle those tasks\n",
      "                      seperately. Low power consuption is a major concern as it is active 24x7 mostly.\n",
      "                    </p>\n",
      "                  </div> \n",
      "                </div>                \n",
      "              </div>\n",
      "            </div> \n",
      "\n",
      "            <div class=\"well-left\">\n",
      "              <div class=\"single-well\">\n",
      "                <div>\n",
      "                  <h4 class=\"sec-head\"><br><br>Modules</h4>\n",
      "                  <div>\n",
      "                    \n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\"><br>GSM module</h5>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/sim module.jpg\" alt=\"sim module\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                        <br>GSM module(SIM 800L) supports a sim card to connect with server using 2G mobile data as a backup option when \n",
      "                        wifi is not available.  \n",
      "                      </p>\n",
      "                    </div>\n",
      "                    <div> \n",
      "                      <h4 class=\"sec-subhead\">External Flash Memory</h4>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/flash memory.jpg\" alt=\"flash memory\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                          <br>W25Q32(4MB) model is used as the external flash memory to increase the scalability of the device. As the system has to check with\n",
      "                          the cloud server whether the person is quarantined or not for each person, and since the server gets such requests from\n",
      "                          all over the country, the efficiency and scalability will be less. Therefore a local caching system will keep a list of quarantined people in there are,\n",
      "                          Thus only the information that is not available to the device can be requested from the server.\n",
      "                      </p>\n",
      "                    </div>\n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\"><br>Battery</h5>\n",
      "                    </div>\n",
      "\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/battery.jpg\" alt=\"battery\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                        <br>The device contains an internal rechargeable battery to keep the device active in case of \n",
      "                        power failures.   \n",
      "                      </p>\n",
      "                    </div>\n",
      "\n",
      "                  </div> \n",
      "                </div>                \n",
      "              </div>\n",
      "            </div> \n",
      "\n",
      "          </div>\n",
      "          \n",
      "          <!-- single-well end-->\n",
      "          <div class=\"col-md-6 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-middle\">\n",
      "                <div>\n",
      "                  <h4 class=\"sec-head\"><br>Sensors</h4>\n",
      "                  <div>\n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\">IR Sensor </h5>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/ir sensor.jpg\" alt=\"ir sensor\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                        <br>Contactless IR sensor is used to detect the body temperature.\n",
      "                      </p>\n",
      "                    </div>\n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\"><br>Ultrasonic Sensor</h5>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/ultrasonic sensor.jpg\" alt=\"ultrasonic sensor\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                        <br>This sensor is used to detect the distance from IR sensor to hand and to the execution of sanitizing unit.\n",
      "                      </p>\n",
      "                    </div>\n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\"><br>Barcode Scanner</h5>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/barcode scanner.jpg\" alt=\"Barcode scanner\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                          <br>Gm66 model 2D barcode reader is used to read the barcode in the ID card.   \n",
      "                      </p>\n",
      "                    </div>\n",
      "                  </div> \n",
      "                </div>                \n",
      "            </div>\n",
      "\n",
      "            <div class=\"well-middle\">\n",
      "                <div>\n",
      "                  <h4 class=\"sec-head\"><br><br>Actuators</h4>\n",
      "                  <div>\n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\">Piezo Buzzer</h5>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/buzzer.jpg\" alt=\"piezo buzzer\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                        <br>A piezo buzzer is used to indicate that certain process is successfully done or not.\n",
      "                      </p>\n",
      "                    </div>\n",
      "                    <div> \n",
      "                      <h5 class=\"sec-subhead\"><br>LCD Display</h5>\n",
      "                    </div>\n",
      "                    <!--<div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                      <img src=\"assets/img/hardware/lcd.jpg\" alt=\"lcd display\">\n",
      "                    </div>-->\n",
      "                    <div>\n",
      "                      <p>\n",
      "                          <br>The result of each process is dispalyed on the LCD.\n",
      "                      </p>\n",
      "                    </div>\n",
      "                  </div> \n",
      "                </div>                \n",
      "            </div> \n",
      "            \n",
      "\n",
      "          </div>\n",
      "        </div>    \n",
      "      </div>\n",
      "    </div><!-- End Hardware Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= Security Section ======= -->\n",
      "    <div id=\"security\" class=\"about-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline text-center\">\n",
      "              <h2>Security Aspects</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row\">\n",
      "          <!-- single-well start-->\n",
      "          <div class=\"col-md-6 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-left\">\n",
      "              <div class=\"single-well\">\n",
      "                <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "                  <img src=\"assets/img/solution/cia.jpg\" style=\"width: 70%;\" alt=\"cia\">\n",
      "                </div>\n",
      "              </div>\n",
      "            </div> \n",
      "          </div>\n",
      "          <!-- single-well end-->\n",
      "          <div class=\"col-md-6 col-sm-6 col-xs-12\">\n",
      "            <div class=\"well-middle\">\n",
      "              <div class=\"single-well\">\n",
      "                <h4 class=\"sec-head\">Why is it important?</h4>\n",
      "                <p>\n",
      "                  For any system it's crucial to pay attention to the security aspects. No system can be automatically immune. \n",
      "                  If we don’t consider this seriously, the impact and recoveries can be very expensive. <br><br>Looking from the perspective of the CIA triad,\n",
      "                  <br><br><strong>Availability</strong> is necessary because the system mostly works 24/7 and the whole entrace system of the country depends on it.\n",
      "                  If the system is not available the effects can be very significant.\n",
      "                  <br><br><strong>Confidentiality </strong>also plays a major role as we handle sensitive data. Only the authorized people should be able to see the data.\n",
      "                  <br><br><strong>Integrity</strong> is necessary because if the data is modified without the knowledge of authorized people, it can break trust of people\n",
      "                  towards the system. Imagine providing inaccurate health details to people!\n",
      "                </p>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>   \n",
      "        <div class=\"row\">\n",
      "          <div class=\"well-middle\">\n",
      "            <h4 class=\"sec-head\"><br><br>what are the sensitive data that needs to be secured?</h4>\n",
      "            <img src=\"assets/img/solution/security.png\" style=\"width: 60%;\" alt=\"sensitive data\" class=\"center-highlevel\">\n",
      "            <p>\n",
      "              Any system that handles <strong>PII(Personally Identifiable Information) or SPII(Sensitive Personally Identifiable Information)</strong> or any <strong>Health Care data</strong>, are legally obligated to protect these data.\n",
      "              If these information are compromised it can lead to devastating consequences like identity theft incidents, high risk of damage to a individual, loss of  trust on the system and many more.\n",
      "              There are many international guidlines such a system needs to adhere to. For example GDPR(General Data Protection Regulation), HIPAA(Health Insurance Portability and Accountability Act)\n",
      "            </p>\n",
      "            <p>\n",
      "              Our system keeps personal details about people like full name, NIC, address, contact details, locations they have visited, health details like temperatures and oxygen levels. These data have high criticality. When such system is deployed,\n",
      "              many attackers try to play with the data since the data can be of interest to many. For example if a person can access to someone else's mobile app, he can checkin to places pretending to be someone else.\n",
      "              If our database is compromised it can lead to a data breach which will expose all the PII details of the community.\n",
      "              This can even result in Ransomware attacks.\n",
      "            </p>\n",
      "          </div>      \n",
      "        </div>    \n",
      "      </div>\n",
      "    </div><!-- End Security Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= Pricing Section ======= -->\n",
      "    <div id=\"pricing\" class=\"pricing-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline text-center\">\n",
      "              <h2>Budget</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-4 col-sm-4 col-xs-12 padding-0\">\n",
      "            <div class=\"pri_table_list active\">\n",
      "              <h3>Item</h3>\n",
      "              <ol>\n",
      "                <li class=\"check\"><span>ESP32 30-pin DOIT Board</span></li>\n",
      "                <li class=\"check\"><span>External Flash(W25Q32)</span></li>                \n",
      "                <li class=\"check\"><span>Ultrasonic sensor(HC-SR04)</span></li>\n",
      "                <li class=\"check\"><span>Barcode reader(GM66)</span></li>\n",
      "                <li class=\"check\"><span>IR temperature sensor(MLX90614)</span></li>  \n",
      "                <li class=\"check\"><span>Piezo buzzer</span></li>\n",
      "                <li class=\"check\"><span>16x2 LCD</span></li>\n",
      "                <li class=\"check\"><span>Power Supply Module</span></li>\n",
      "                <li class=\"check\"><span>9V AC/DC Adapter</span></li>\n",
      "                <li class=\"check\"><span>Transistor</span></li>\n",
      "                <li class=\"check\"><span>Water Pump</span></li>\n",
      "                <li class=\"check\"><span>Nozzle</span></li>\n",
      "                <li class=\"check\"><span>ESP32 Antena</span></li>\n",
      "                <li class=\"check\"><span>Rechargable battery</span></li>\n",
      "\n",
      "              </ol>\n",
      "              <span class=\"inv\">***</span>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-2 col-sm-4 col-xs-12 padding-0\">\n",
      "            <div class=\"pri_table_list active\">\n",
      "              <h3>Quantity</h3>\n",
      "              <ol>\n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>2</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>  \n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>  \n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>  \n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "                <li class=\"check\"><span>2</span></li>\n",
      "                <li class=\"check\"><span>1</span></li>  \n",
      "                <li class=\"check\"><span>1</span></li>\n",
      "              </ol>\n",
      "              <span class=\"inv\">***</span>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-3 col-sm-4 col-xs-12 padding-0\">\n",
      "            <div class=\"pri_table_list active\">\n",
      "              <h3>Unit Cost</h3>\n",
      "              <ol>\n",
      "                <li class=\"check\"><span>2400.00</span></li>\n",
      "                <li class=\"check\"><span>300.00</span></li>\n",
      "                <li class=\"check\"><span>200.00</span></li>\n",
      "                <li class=\"check\"><span>5000.00</span></li>  \n",
      "                <li class=\"check\"><span>3000.00</span></li>\n",
      "                <li class=\"check\"><span>30.00</span></li>\n",
      "                <li class=\"check\"><span>320.00</span></li>\n",
      "                <li class=\"check\"><span>1100.00</span></li>  \n",
      "                <li class=\"check\"><span>750.00</span></li>\n",
      "                <li class=\"check\"><span>130.00</span></li>\n",
      "                <li class=\"check\"><span>300.00</span></li>\n",
      "                <li class=\"check\"><span>180.00</span></li>\n",
      "                <li class=\"check\"><span>220.00</span></li>\n",
      "                <li class=\"check\"><span>1200.00</span></li>\n",
      "\n",
      "              </ol>\n",
      "              <span class=\"inv\">Total</span>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-3 col-sm-4 col-xs-12 padding-0\">\n",
      "            <div class=\"pri_table_list active\">\n",
      "              <h3>Total</h3>\n",
      "              <ol>\n",
      "                <li class=\"check\"><span>2400.00</span></li>\n",
      "                <li class=\"check\"><span>300.00</span></li>\n",
      "                <li class=\"check\"><span>400.00</span></li>\n",
      "                <li class=\"check\"><span>5000.00</span></li>  \n",
      "                <li class=\"check\"><span>3000.00</span></li>\n",
      "                <li class=\"check\"><span>30.00</span></li>\n",
      "                <li class=\"check\"><span>320.00</span></li>\n",
      "                <li class=\"check\"><span>1100.00</span></li>  \n",
      "                <li class=\"check\"><span>750.00</span></li>\n",
      "                <li class=\"check\"><span>130.00</span></li>\n",
      "                <li class=\"check\"><span>300.00</span></li>\n",
      "                <li class=\"check\"><span>360.00</span></li>\n",
      "                <li class=\"check\"><span>220.00</span></li>\n",
      "                <li class=\"check\"><span>1200.00</span></li>\n",
      "              </ol>\n",
      "              <span class=\"inv\">15510</span>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div><!-- End Pricing Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= Timeline Section ======= -->\n",
      "    <div id=\"timeline\" class=\"about-area area-padding\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"section-headline text-center\">\n",
      "              <h2>Timeline</h2>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <img src=\"assets/img/solution/timeline.PNG\" alt=\"Timeline\" class=\"center-timeline\"> \n",
      "          </div> \n",
      "        </div>        \n",
      "      </div>\n",
      "    </div><!-- End Timeline Section -->\n",
      "\n",
      "\n",
      "    <!-- ======= Blog Section ======= -->\n",
      "    <!--\n",
      "    <div id=\"blog\" class=\"blog-area\">\n",
      "      <div class=\"blog-inner area-padding\">\n",
      "        <div class=\"blog-overly\"></div>\n",
      "        <div class=\"container \">\n",
      "          <div class=\"row\">\n",
      "            <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "              <div class=\"section-headline text-center\">\n",
      "                <h2>Conclusion</h2>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"row\">\n",
      "            <div class=\"col-md-8 col-sm-4 col-xs-12\">\n",
      "              <div class=\"single-blog\">\n",
      "                <div class=\"blog-meta\">\n",
      "                  <span class=\"comments-type\">\n",
      "                    <i class=\"fa fa-comment-o\"></i>\n",
      "                    <a>Project End</a>\n",
      "                  </span>\n",
      "                  <span class=\"date-type\">\n",
      "                    <i class=\"fa fa-calendar\"></i>2021-09-17\n",
      "                  </span>\n",
      "                </div>\n",
      "                <div class=\"blog-text\">\n",
      "                  <h4>\n",
      "                    What we achieved\n",
      "                  </h4>\n",
      "                  <p>\n",
      "                    Contents to be updated\n",
      "                  </p>\n",
      "                </div>\n",
      "              </div>\n",
      "            </div>\n",
      "            <div class=\"col-md-4 col-sm-4 col-xs-12\">\n",
      "              <div class=\"single-blog\">\n",
      "                <div class=\"single-blog-img\">\n",
      "                  <div>\n",
      "                    <img src=\"assets/img/blog/3.jpg\" alt=\"\">\n",
      "                  </div>\n",
      "                </div>\n",
      "                <div class=\"blog-text\">\n",
      "                  <h4>\n",
      "                    <br>Our potential product\n",
      "                  </h4>\n",
      "                  <p>\n",
      "                    Contents to be updated\n",
      "                  </p>\n",
      "                </div>\n",
      "                <span>\n",
      "                  <a href=\"blog.html\" class=\"ready-btn\">Read more</a>\n",
      "                </span>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div>\n",
      "    -->\n",
      "\n",
      "  </main><!-- End #main -->\n",
      "\n",
      "  <!-- ======= Team Section ======= -->\n",
      "  <div id=\"team\" class=\"our-team-area area-padding\">\n",
      "    <div class=\"container\">\n",
      "      <div class=\"row\">\n",
      "        <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "          <div class=\"section-headline text-center\">\n",
      "            <h2>Our Team</h2>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "      <div class=\"row\">\n",
      "        <div class=\"col-md-4 col-sm-3 col-xs-12\">\n",
      "          <div class=\"single-team-member\">\n",
      "            <div class=\"team-img padding-img1\">\n",
      "              <div>\n",
      "                <img src=\"assets/img/team/kenath.jpg\" alt=\"\">\n",
      "              </div>\n",
      "              <div class=\"team-social-icon text-center\">\n",
      "                <ul>\n",
      "                  <li>\n",
      "                    <a href=\"mailto:kenathkp@gmail.com\">\n",
      "                      <i class=\"bi bi-envelope\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://github.com/Kenath252\">\n",
      "                      <i class=\"bi bi-github\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"#\">\n",
      "                      <i class=\"bi bi-linkedin\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                </ul>\n",
      "              </div>\n",
      "            </div>\n",
      "            <div class=\"team-content text-center\">\n",
      "              <h4>Kenath Perera</h4>\n",
      "              <h5>E/17/252</h5>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <!-- End column -->\n",
      "        <div class=\"col-md-4 col-sm-3 col-xs-12\">\n",
      "          <div class=\"single-team-member\">\n",
      "            <div class=\"team-img padding-img1\">\n",
      "              <div>\n",
      "                <img src=\"assets/img/team/deanna.jpg\" alt=\"\">\n",
      "              </div>\n",
      "              <div class=\"team-social-icon text-center\">\n",
      "                <ul>\n",
      "                  <li>\n",
      "                    <a href=\"mailto:deannatscoralage@gmail.com\">\n",
      "                      <i class=\"bi bi-envelope\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://github.com/Deanna-Coralage\">\n",
      "                      <i class=\"bi bi-github\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://www.linkedin.com/in/deanna-coralage-996308158/\">\n",
      "                      <i class=\"bi bi-linkedin\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                </ul>\n",
      "              </div>\n",
      "            </div>\n",
      "            <div class=\"team-content text-center\">\n",
      "              <h4>Deanna Coralage</h4>\n",
      "              <h5>E/17/044</h5>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <!-- End column -->\n",
      "        <div class=\"col-md-4 col-sm-3 col-xs-12\">\n",
      "          <div class=\"single-team-member\">\n",
      "            <div class=\"team-img padding-img1\">\n",
      "              <div>\n",
      "                <img src=\"assets/img/team/ruchika.jpg\" alt=\"\">\n",
      "              </div>\n",
      "              <div class=\"team-social-icon text-center\">\n",
      "                <ul>\n",
      "                  <li>\n",
      "                    <a href=\"mailto:e17242@eng.pdn.ac.lk\">\n",
      "                      <i class=\"bi bi-envelope\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://github.com/Ruchika-Perera\">\n",
      "                      <i class=\"bi bi-github\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://www.linkedin.com/in/ruchika-perera-449487196/\">\n",
      "                      <i class=\"bi bi-linkedin\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                </ul>\n",
      "              </div>\n",
      "            </div>\n",
      "            <div class=\"team-content text-center\">\n",
      "              <h4>Ruchika Perera</h4>\n",
      "              <h5>E/17/242</h5>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "      <div class=\"row\">\n",
      "        <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "          <div class=\"section-headline text-center\">\n",
      "            <h2><br>Our Supervisors</h2>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "      <div class=\"row\">\n",
      "        <div class=\"col-md-6 col-sm-3 col-xs-12\">\n",
      "          <div class=\"single-team-member\">\n",
      "            <div class=\"team-img padding-img2\">\n",
      "              <div>\n",
      "                <img src=\"assets/img/team/drisuru.PNG\" alt=\"\">\n",
      "              </div>\n",
      "              <div class=\"team-social-icon text-center\">\n",
      "                <ul>\n",
      "                  <li>\n",
      "                    <a href=\"mailto:isurunawinne@eng.pdn.ac.lk\">\n",
      "                      <i class=\"bi bi-envelope\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://lk.linkedin.com/in/isuru-nawinne-73302833\">\n",
      "                      <i class=\"bi bi-linkedin\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                </ul>\n",
      "              </div>\n",
      "            </div>\n",
      "            <div class=\"team-content text-center\">\n",
      "              <h4>Dr. Isuru Nawinne</h4>\n",
      "              <h5>Senior Lecturer</h5>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <!-- End column -->\n",
      "        <div class=\"col-md-6 col-sm-3 col-xs-12\">\n",
      "          <div class=\"single-team-member\">\n",
      "            <div class=\"team-img padding-img2\">\n",
      "              <div>\n",
      "                <img src=\"assets/img/team/drmahanama.PNG\" alt=\"\">\n",
      "              </div>\n",
      "              <div class=\"team-social-icon text-center\">\n",
      "                <ul>\n",
      "                  <li>\n",
      "                    <a href=\"mailto:mahanamaw@eng.pdn.ac.lk\">\n",
      "                      <i class=\"bi bi-envelope\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                  <li>\n",
      "                    <a href=\"https://www.linkedin.com/in/mahanama\">\n",
      "                      <i class=\"bi bi-linkedin\"></i>\n",
      "                    </a>\n",
      "                  </li>\n",
      "                </ul>\n",
      "              </div>\n",
      "            </div>\n",
      "            <div class=\"team-content text-center\">\n",
      "              <h4>Dr. Mahanama Wickramasinghe</h4>\n",
      "              <h5>Senior Lecturer</h5>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "    </div>\n",
      "  </div><!-- End Team Section -->\n",
      "\n",
      "\n",
      "  <!-- ======= Footer ======= -->\n",
      "  <footer>\n",
      "    <div class=\"footer-area\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-4\">\n",
      "            <div class=\"footer-content\">\n",
      "              <div class=\"footer-head\">\n",
      "                <div class=\"footer-logo\">\n",
      "                  <h2>Covid Tracer</h2>\n",
      "                </div>\n",
      "                <p>We are a group of undergraduates from Department of Computer Engineering, University of Peradeniya. \n",
      "                  This system was implemented as our third year project</p>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "          <!-- end single footer -->\n",
      "          <div class=\"col-md-4 padding-0\">\n",
      "            <div class=\"footer-content\">\n",
      "              <div class=\"footer-head\">\n",
      "                <h4>----------------------------------- Links</h4>\n",
      "                <div class=\"footer-contacts\">\n",
      "                  <p><a href=\"https://github.com/cepdnaclk/e17-3yp-Covid-Tracer\">Project Repo</a></p>\n",
      "                  <p><a href=\"https://projects.ce.pdn.ac.lk\">Department Projects</a></p>\n",
      "                  <p><a href=\"http://www.ce.pdn.ac.lk\">Department of Computer Engineering</a></p>\n",
      "                  <p></p>\n",
      "                </div>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"col-md-4 padding-0\">\n",
      "            <div class=\"footer-content\">\n",
      "              <div class=\"footer-head\">\n",
      "                <h4>-----------------------------------</h4>\n",
      "                <div class=\"footer-contacts\">\n",
      "                  <p><a href=\"http://eng.pdn.ac.lk\">Faculty of Engineering</a></p>\n",
      "                  <p><a href=\"https://www.pdn.ac.lk/academics/academics.php\">University of Peradeniya</a></p>\n",
      "                  <p></p>\n",
      "                </div>\n",
      "              </div>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div>\n",
      "    <div class=\"footer-area-bottom\">\n",
      "      <div class=\"container\">\n",
      "        <div class=\"row\">\n",
      "          <div class=\"col-md-12 col-sm-12 col-xs-12\">\n",
      "            <div class=\"copyright text-center\">\n",
      "              <p>\n",
      "                © Copyright <strong>eBusiness</strong>. All Rights Reserved\n",
      "              </p>\n",
      "            </div>\n",
      "            <div class=\"credits\">\n",
      "              <!--\n",
      "              All the links in the footer should remain intact.\n",
      "              You can delete the links only if you purchased the pro version.\n",
      "              Licensing information: https://bootstrapmade.com/license/\n",
      "              Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=eBusiness\n",
      "            -->\n",
      "              Designed by <a href=\"https://bootstrapmade.com/\">BootstrapMade</a>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div>\n",
      "  </footer><!-- End  Footer -->\n",
      "\n",
      "  \n",
      "  <a href=\"#\" class=\"back-to-top d-flex align-items-center justify-content-center\"><i class=\"bi bi-arrow-up-short\"></i></a>\n",
      "\n",
      "  <!-- Vendor JS Files -->\n",
      "  <script src=\"assets/vendor/bootstrap/js/bootstrap.bundle.min.js\"></script>\n",
      "  <script src=\"assets/vendor/glightbox/js/glightbox.min.js\"></script>\n",
      "  <script src=\"assets/vendor/isotope-layout/isotope.pkgd.min.js\"></script>\n",
      "  <script src=\"assets/vendor/php-email-form/validate.js\"></script>\n",
      "  <script src=\"assets/vendor/swiper/swiper-bundle.min.js\"></script>\n",
      "\n",
      "  <!-- Template Main JS File -->\n",
      "  <script src=\"assets/js/main.js\"></script>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from shutil import which\n",
    "from selenium.webdriver.chrome import options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Import options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Create Options object\n",
    "chrome_options = Options()\n",
    "# Add argument to Options to use headless browser\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "chrome_path = which(\"chromedriver\")\n",
    "\n",
    "# Add options argument to Chrome driver to use headless browser\n",
    "driver = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)\n",
    "\n",
    "driver.get(\"https://cepdnaclk.github.io/e17-3yp-Covid-Tracer/\")\n",
    "\n",
    "# search_input = driver.find_element_by_id(\"search_form_input_homepage\")\n",
    "# search_input.send_keys(\"My User Agent\")\n",
    "# search_input.send_keys(Keys.ENTER)\n",
    "\n",
    "# Print the html markup\n",
    "print(driver.page_source)\n",
    "\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Close the driver\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid Tracer\n",
      "Covid Tracer\n",
      "Home\n",
      "About\n",
      "Features\n",
      "Solution Architecture\n",
      "High Level\n",
      "Hardware\n",
      "Security\n",
      "Budget\n",
      "Timeline\n",
      "Development\n",
      "Software\n",
      "Hardware\n",
      "Testing\n",
      "Team\n",
      "Autonomous Covid-19 Tracking System\n",
      "For a Well Aware and Safe Sri Lanka\n",
      "Project Repo\n",
      "Covid-19\n",
      "New Normal Situation due to the Pandemic\n",
      "Get Started\n",
      "Introduction\n",
      "Overview\n",
      "The Covid-19 Pandemic is the defining Global Health Crisis of the contemporary society. Since its emergence in late\n",
      "2019, the virus has spread across the entire world and led to a dramatic loss of human life. The economic and social\n",
      "disruption caused by the pandemic is devastating. Almost every sector is affected by this pandemic. In addition,\n",
      "this prevailing situation has raised unprecedented challenges to the daily routines of the people. While taking\n",
      "immense measures on infect diagnosis, Corona Virus treatments and controlling the spread of the disease a reasonable\n",
      "focus should be given to how we adjust to this new normal situation.\n",
      "When will the world be free of Covid? is an unanswered question. Our focus is to make the new normal situation due\n",
      "to Covid easily adjustable for the people while making their lives safe.\n",
      "Real World Problem\n",
      "Due to the prevailing pandemic situation people have a responsibility of providing accurate details of themselves at\n",
      "entrances of various commercial places like shopping malls, banks etc. and get their temperatures checked and accepted\n",
      "before entering. This situation is currently handled manually by people writing details on a book at entrances of various places.\n",
      "Some major issues with this system includes:\n",
      "Inefficient thus time consuming\n",
      "Risk of getting infected by everyone touching same stationary is high\n",
      "Details get blot by touching with wet hands after washing or sanitizing\n",
      "Personal details of people are publicly made available\n",
      "High probability for the guard at the entrance checking temperatures to get in contact with infects\n",
      "People providing inaccurate data, neglecting providing details and getting the temperature checked\n",
      "Inability to detect people under quarantine\n",
      "Inability to keep track of infected percentages of the locations visited\n",
      "Adhering to workplace safety and health practices and ensuring access to decent work and the protection of labour rights\n",
      "in all industries will be crucial in addressing the human dimension of the crisis.\n",
      "Features of our system\n",
      "Computerized system\n",
      "Covid-19 management software with computerized database system for the Government. This is also mainly used for demonstrating how over system gets latest\n",
      "covid information from the Government Authorities through a REST API\n",
      "Autonomous detail entering and temperature checking\n",
      "Details about the person will be entered to the system by scanning the barcode of NIC/ QR scanning, system will detect if the\n",
      "person is under quarantine. The temperature will be measured using sensors. These temperature measurements along\n",
      "with the visited location will be sent to the server and stored for a 2 weeks period. Your privacy will be highly protected\n",
      "Automated door opening\n",
      "This comes as an optional feature of our system. If certain satisfactory conditions are met like quarantine status, max\n",
      "temperature level then the doors will be opened automatically\n",
      "Covid tracking\n",
      "Check about reported infects of a particular location as a percentage before visiting.\n",
      "Our system will also keep records about the visited locations of a person for a period of 2 weeks. Infect percentages\n",
      "of these locations reported later will be tracked\n",
      "Website\n",
      "Local community can visit our website to view covid related information like daily/cumulative cases and deaths, infect percentages\n",
      "of areas. A seperate user login will be provided to view personal details like temperate fluctuations using data obtained\n",
      "at entrances, infect percentages of the locations visited for a period of 2 weeks\n",
      "Mobile app\n",
      "Similar interface as the website. This is designed for the easy use at the comfort of a mobile phone.\n",
      "High Level System\n",
      "Description\n",
      "Our system can be described in four segments.\n",
      "A software for data entering, data representing along with a computerized database system will be provided to the\n",
      "Government Authorities. They maintain detailed Covid related information like infects, pcr test reports,people under quarantine etc. in their\n",
      "server system. Our database system will be updated on certain intervals with the Government Server through a REST API.\n",
      "Our server system will be deployed in the cloud. We will keep information about people's NIC numbers,\n",
      "addresses, contact numbers, visited locations, temperature readings obtained at various entrances etc. Various calculations on data\n",
      "for example infect percentages will be done on a cloud virtual environment\n",
      "Commercial Merchants including shopping malls, banks etc. will be provided with an embedded system\n",
      "device based on a micro-controller. People can scan their IDs before entering and the system will check with the servers if the\n",
      "person's under quarantine. The temperature will be measured by contact-less sensors and checked if satisfactory. Whether the person\n",
      "is allowed to enter or not will be notified using LED displays and buzzers. ID number along with the temperature and location will be stored\n",
      "in our servers for a 2 week period. Therefore merchants don't have the burden of handling customer details. At the same time\n",
      "people don't have to provide their details publicly. Commercial merchants have the choice of implementing our door system which will\n",
      "be opened automatically based on the customer's conditions\n",
      "The local community will be provided with a website as well as a mobile app. They can visit our website/app to\n",
      "view general Covid related information in the country eg: daily/cumulative cases and deaths, infect persentages of different areas. A seperate\n",
      "user login is provided to view personal data eg: infect percentage reported later of visited locations, temperature fluctuations,\n",
      "general health alerts released by Government eg: vaccinating dates in different areas as well as user specific health alerts\n",
      "Embedded Hardware Device\n",
      "Microcontroller\n",
      "Microcontroller is the base of our device and it should accomplish several task at the same time.\n",
      "Hence, having a dual core processor in the microcontroller will be efficient to handle those tasks\n",
      "seperately. Low power consuption is a major concern as it is active 24x7 mostly.\n",
      "Modules\n",
      "GSM module\n",
      "GSM module(SIM 800L) supports a sim card to connect with server using 2G mobile data as a backup option when\n",
      "wifi is not available.\n",
      "External Flash Memory\n",
      "W25Q32(4MB) model is used as the external flash memory to increase the scalability of the device. As the system has to check with\n",
      "the cloud server whether the person is quarantined or not for each person, and since the server gets such requests from\n",
      "all over the country, the efficiency and scalability will be less. Therefore a local caching system will keep a list of quarantined people in there are,\n",
      "Thus only the information that is not available to the device can be requested from the server.\n",
      "Battery\n",
      "The device contains an internal rechargeable battery to keep the device active in case of\n",
      "power failures.\n",
      "Sensors\n",
      "IR Sensor\n",
      "Contactless IR sensor is used to detect the body temperature.\n",
      "Ultrasonic Sensor\n",
      "This sensor is used to detect the distance from IR sensor to hand and to the execution of sanitizing unit.\n",
      "Barcode Scanner\n",
      "Gm66 model 2D barcode reader is used to read the barcode in the ID card.\n",
      "Actuators\n",
      "Piezo Buzzer\n",
      "A piezo buzzer is used to indicate that certain process is successfully done or not.\n",
      "LCD Display\n",
      "The result of each process is dispalyed on the LCD.\n",
      "Security Aspects\n",
      "Why is it important?\n",
      "For any system it's crucial to pay attention to the security aspects. No system can be automatically immune.\n",
      "If we don’t consider this seriously, the impact and recoveries can be very expensive. Looking from the perspective of the CIA triad,\n",
      "Availability is necessary because the system mostly works 24/7 and the whole entrace system of the country depends on it.\n",
      "If the system is not available the effects can be very significant.\n",
      "Confidentiality also plays a major role as we handle sensitive data. Only the authorized people should be able to see the data.\n",
      "Integrity is necessary because if the data is modified without the knowledge of authorized people, it can break trust of people\n",
      "towards the system. Imagine providing inaccurate health details to people!\n",
      "what are the sensitive data that needs to be secured?\n",
      "Any system that handles PII(Personally Identifiable Information) or SPII(Sensitive Personally Identifiable Information) or any Health Care data, are legally obligated to protect these data.\n",
      "If these information are compromised it can lead to devastating consequences like identity theft incidents, high risk of damage to a individual, loss of\n",
      "trust on the system and many more.\n",
      "There are many international guidlines such a system needs to adhere to. For example GDPR(General Data Protection Regulation), HIPAA(Health Insurance Portability and Accountability Act)\n",
      "Our system keeps personal details about people like full name, NIC, address, contact details, locations they have visited, health details like temperatures and oxygen levels. These data have high criticality. When such system is deployed,\n",
      "many attackers try to play with the data since the data can be of interest to many. For example if a person can access to someone else's mobile app, he can checkin to places pretending to be someone else.\n",
      "If our database is compromised it can lead to a data breach which will expose all the PII details of the community.\n",
      "This can even result in Ransomware attacks.\n",
      "Budget\n",
      "Item\n",
      "ESP32 30-pin DOIT Board\n",
      "External Flash(W25Q32)\n",
      "Ultrasonic sensor(HC-SR04)\n",
      "Barcode reader(GM66)\n",
      "IR temperature sensor(MLX90614)\n",
      "Piezo buzzer\n",
      "16x2 LCD\n",
      "Power Supply Module\n",
      "9V AC/DC Adapter\n",
      "Transistor\n",
      "Water Pump\n",
      "Nozzle\n",
      "ESP32 Antena\n",
      "Rechargable battery\n",
      "***\n",
      "Quantity\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "***\n",
      "Unit Cost\n",
      "2400.00\n",
      "300.00\n",
      "200.00\n",
      "5000.00\n",
      "3000.00\n",
      "30.00\n",
      "320.00\n",
      "1100.00\n",
      "750.00\n",
      "130.00\n",
      "300.00\n",
      "180.00\n",
      "220.00\n",
      "1200.00\n",
      "Total\n",
      "Total\n",
      "2400.00\n",
      "300.00\n",
      "400.00\n",
      "5000.00\n",
      "3000.00\n",
      "30.00\n",
      "320.00\n",
      "1100.00\n",
      "750.00\n",
      "130.00\n",
      "300.00\n",
      "360.00\n",
      "220.00\n",
      "1200.00\n",
      "15510\n",
      "Timeline\n",
      "Our Team\n",
      "Kenath Perera\n",
      "E/17/252\n",
      "Deanna Coralage\n",
      "E/17/044\n",
      "Ruchika Perera\n",
      "E/17/242\n",
      "Our Supervisors\n",
      "Dr. Isuru Nawinne\n",
      "Senior Lecturer\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Senior Lecturer\n",
      "Covid Tracer\n",
      "We are a group of undergraduates from Department of Computer Engineering, University of Peradeniya.\n",
      "This system was implemented as our third year project\n",
      "----------------------------------- Links\n",
      "Project Repo\n",
      "Department Projects\n",
      "Department of Computer Engineering\n",
      "-----------------------------------\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "© Copyright eBusiness. All Rights Reserved\n",
      "Designed by BootstrapMade\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "\n",
    "# break into lines and remove leading and trailing space on each\n",
    "lines = (line.strip() for line in text.splitlines())\n",
    "# break multi-headlines into a line each\n",
    "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# drop blank lines\n",
    "text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "# selectedElements = ['p', re.compile('^h[1-6]$'), 'li', 'ul']\n",
    "#\n",
    "# text = \"\"\n",
    "# for el in selectedElements:\n",
    "#     paragraphs = soup.findAll(el)\n",
    "#\n",
    "#     for paragraph in paragraphs:\n",
    "#         text += paragraph.get_text() + \". \"\n",
    "\n",
    "print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp/ipykernel_3476/374995474.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Extracting A GUI for controlling and supervising multiple robots remotely https://cepdnaclk.github.io/e15-3yp-A-GUI-for-controlling-and-supervising-multiple-robots-remotely\n",
      "\n",
      "\n",
      "A GUI for control & supervising multiple robots remotely\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "A GUI for control & supervising multiple robots remotely\n",
      "Team\n",
      "E/15/140, Jaliyagoda A.J.N.M., nuwanjaliyagoda@eng.pdn.ac.lk\n",
      "E/15/173, Karunarathne S.D.D.D, dinelkadilshani95@gmail.com\n",
      "E/15/350, Tennakoon T.M.P.B., pasan96tennakoon@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "This idea came from a project that is related to swarm intelligence. According to the definition, “Swarm intelligence is the collective behavior of decentralized, self-organized systems”\n",
      "Swarm robotics is applying swarm intelligence to accomplish a bigger task. And it also similar to the behavior of animals like bees, ants, birds, etc.\n",
      "One of the greatest fallbacks of swarm intelligence-related research is that it is difficult to simulate the algorithms in the real world unless you have a large number of robots to test these algorithms. Building a group of robots takes a lot of time and it is very expensive. As a solution to this problem, we can design or buy general purpose robots which have hardware capabilities to run basic swarm intelligence related algorithms. But buying a set of pre-built robots doesn’t solve the whole problem since it is too expensive yet.\n",
      "The final goal of this project is not only to design a general-purpose swarm robot unit but designing the simulation platform too. This simulation platform will be able to control basic functionalities of the robots such as assign a robot into a defined place, recharge the robot’s battery when it is draining out, program the robots with giving algorithms, etc… This simulation arena can be accessed from a remote location and these remote users can upload their own algorithms into the robots which are placed in the arena. After upload, they can run it on robots and see the response of the robots using Data and Video feedbacks. Research teams who are working in the field of Swarm Robotics can test their algorithms without taking much effort into hardware. So it saves their time and money.\n",
      "Introduction Video: youtu.be/40D3IqbQy5A\n",
      "Solution Architecture\n",
      "Identifying the scope\n",
      "Since this whole project is beyond our scope for this unified project we are planning to do only a part of the main project. We hope to create a simulation platform for these robots and control and monitor a few parameters using a remote GUI (Graphical User Interface).\n",
      "Our goal is to develop a GUI that a user can select robots and specify locations for them in the simulation arena. Then robots will be moved to these specified locations within the smallest possible time by avoiding collisions with other robots.\n",
      "This project is not only limited to swarm intelligence based problems. We can use what we will develop to increase the efficiency of the real world problems like Search and Rescue Missions, Bomb detection, Planetary exploration, etc. Common facts of these problems are that there is a group or robots which are located in a geographical area and the person who needs controls them from a remote location.\n",
      "Identifying the requirements\n",
      "Since we need to remotely monitor and control robots, it is required to establish a communication link between the simulation arena and the end user in real time. This communication link should be able to send and receive messages in both directions\n",
      "Another requirement is that robots should be able to move into a specified location of the arena. In this case, the robot should be able to identify its current coordinates and the distance of the travel precisely.\n",
      "When a large number of robots moving in a limited area, there is a high probability to be collisions between robots. We need to find a suitable mechanism to avoid such kind of situations.\n",
      "We are allowing remote users (through the internet) to control and monitor the robots, so it is compulsory to think about the security of the network.\n",
      "Suggested Data Communication Flow\n",
      "Hardware and Software Designs\n",
      "Communication Protocol between Robot Server and End User\n",
      "When finding a solution for our project, we found a few challenging points. Since we hope to remotely monitor and control ‘multiple’ robots, we wanted to have a real-time communication method between our end nodes (in this case, robots) and the client (in this case, human users) The connection should be able to send control signals from user to robots as\n",
      "well as response messages from the robots.\n",
      "We first considered RESTful API based server-client architecture, but it was rejected due to it doesn’t support full duplex communication. Next, we looked into use a MQTT Broker between our robots and end user. MQTT (Message Queue Telemetry Transport) was originally developed for low power IoT devices. It is a topic based on communication. Nodes can subscribe to topics, and publish into topics. When a device published data into a topic, MQTT broker will inform it to all the devices/nodes which were subscribed into that topic.\n",
      "We found another communication protocol known as WebRTC. It is a free and open source project which is developed for communication between browsers and mobile applications in real time. WebRTC is a plugin-free API that most of the modern web browsers support. It has multiple standards and protocols, including STUN/TURN servers, signaling, JSEP, ICE, SIP, SDP, NAT, UDP/TCP, network sockets, and more.\n",
      "Generally, WebRTC is designed for stream Video and Audio, but there is a channel for data/media stream too. One of our requirements is to remotely monitor the robots and that includes both video and data. So we finally decided to use WebRTC as our communication method.\n",
      "You can learn more about WebRTC from following links.\n",
      "WebRTC : Official Page\n",
      "What Is WebRTC and How Does It Work?\n",
      "Data Communication between Robots and Robot Server\n",
      "We decided to use WiFi as the default communication method between our robots and the robot server. The main reason to choose WiFi is that we can implement two-way communication for multiple channels with the minimum hardware cost. And can be used in various communication protocols, which are developed on top of the basic WiFi protocols such as IEEE 802.11\n",
      "Robot Navigation Control\n",
      "Since our robots will be controlled remotely, robots should be able to handle incoming commands while navigating. Due to the practical hardware problems, robots can’t move on straight directions and take precise turns without feedback loop based control structures. Most of the available sensors that measure the distance have errors and when we continually taking measurements, it will add cumulative errors. So we decided to avoid this by doing a small modification to our platform.\n",
      "We decided to use a black color grid on the arena, so robots can follow the lines and correct the cumulating errors from the junctions when it is passing them. Not only that, it can use this grid system to take 90 degree turns using floor color sensors and a simple feedback loop.\n",
      "To identify the black lines from the white background, we decided to use IR Transmitter Receiver pairs. Principle of this sensor is that white color background reflects the IR beam emitted by the IR diode, but not by the black color background. The voltage output of the Photodiode will depend on the amount of reflection. Currently, we hope to feed this digital signal into our microcontroller as an external hardware interrupt, rather than polling digital inputs. So we decided to use an Op-amp circuit with Voltage comparator arrangement to convert this analog reading into a digital signal.\n",
      "The comparator is an electronic decision-making circuit that makes use of an operational amplifier very high gain in its open-loop state, that is, there is no feedback resistor. The Op-amp comparator compares one analog voltage level with another analog voltage level, or some preset reference voltage, VREF and produces an output signal based on this voltage comparison. In other words, the op-amp voltage comparator compares the magnitudes of two voltage inputs and determines which is the largest of the two.\n",
      "We have designed the comparator circuit using the IC named, LM324. The operational amplifier LM324 IC can work like a normal comparator, and it comprises four independent op-amps internally. This IC has designed with low-power, bandwidth and high stability for operating with single power supply over extensive voltage ranges. The range of operating voltages of this IC includes 3.0 V for low and 32 V for high. The range of common mode input mainly comprises the negative voltage supply, thus removing the requirement of outside biasing components in several applications. The range of output voltage also comprises the negative voltage supply.\n",
      "Voltage Reference for the comparator circuit is provided by a Multi-turn trimming resistor because it can be configured as a voltage divider more precisely than a usual Preset Resistor.\n",
      "Here are the Schematic Diagram and the PCB layout of the comparator circuit we have designed. We used an open-source software called Fritzing to design the PCB. Circuit board was fabricated using the PCB milling method, which engraves and isolate the circuit paths on copper plate.\n",
      "Overview of the PCB Design\n",
      "To design the PCB, we used free and open-source software named Fritzing. The PCB is a single layer design and we used jumper cables to avoid crossed signal paths. To fabricate the PCB, the design was exported as a Gerber file and processed with the software named dipTrace.\n",
      "After processing the Gerber file, it was imported into a software named, FlatCAM to convert the PCB design into a toolpath for machinery. The G-Code files which exported from the FlatCam were sent to the CNC milling machine, and the machine fabricated the PCB by few isolating milling and drilling cycles.\n",
      "After two and a half hours of soldering, we were able to completely assemble the PCB as shown below. (We used a ready-made power supply known as a\n",
      "DC to DC Buck converter to reduce the battery voltage of 8.4v to 5v and it is the green color module you can see in below image)\n",
      "Overview of the Robot Design\n",
      "We have used SolidWorks for designing the structure of the robot. After a few design revisions, we came up with the following design. We decided to use a round shape for the robot.\n",
      "We used a black 3mm Cladding Board as the raw material of the base. The design was fabricated by CNC milling, using a 1.5mm end milling bit with a contour milling operation. Wheels also manufactured using the same material and using the same method.\n",
      "We used 5mm x 60mm Hex bolts, M5 nuts, and M5 washers as the spacers between two base plates and the PCB layer.\n",
      "Links\n",
      "Pages\n",
      "Local Controller\n",
      "Control Panel\n",
      "Documents\n",
      "Technical Design\n",
      "User Manual\n",
      "Other Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting An Efficient System For Waste Collection https://cepdnaclk.github.io/e15-3yp-An-Efficient-System-For-Waste-Collection\n",
      "\n",
      "\n",
      "An Efficient System For Waste Collection\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "An Efficient System For Waste Collection\n",
      "I.U. Sudasinghe\tE/15/347\n",
      "K.A.R.L. Alwis\tE/15/010\n",
      "U.L.R.R. Perera\tE/15/265\n",
      "Team\n",
      "E/15/347, I.U. Sudasinghe, isuru.sudasinghe@eng.pdn.ac.lk\n",
      "E/15/010, K.A.R.L. Alwis, alwisruchika@gmail.com\n",
      "E/15/265, U.L.R.R. Perera, risithperera@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "This Project aims to implement an Efficient Waste\n",
      "Collection System in urban areas. Its is a very well known fact to the public that the waste collection in our country is done in a very primitive manner. Since the waste collecting vehicles has no awareness regarding the content level of the garbage cans, everyday they follow the same routine even though sometimes they arrives at garbage cans which are basically empty. This waste a considerable amount of time, money and fuel regardless to the traffic created by those vehicles. Since the use of garbage cans separately for basic types of waste (food, paper, plastic & polythene) has already began in our country, the process of collection of waste could be make very effective if there’s a method to notify the shortest route that covers all the completely filled garbage cans to the driver of the waste collection vehicle. Our goal will be to implement the above solution using Embedded Systems, the knowledge of Networking and web application design.\n",
      "Solution Architecture\n",
      "Client Side\n",
      "Server Side\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting An automated system for monitoring and controlling the water supply to a large farmland https://cepdnaclk.github.io/e15-3yp-An-automated-system-for-monitoring-and-controlling-the-water-supply-to-a-large-farmland\n",
      "\n",
      "\n",
      "An automated system for monitoring and controlling the water supply to a large farmland\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "An automated system for monitoring and controlling the water supply to a large farmland\n",
      "Team\n",
      "E/15/138, M.M.M. Irfan, irfanmm96@gmail.com\n",
      "E/15/209, H.K. Madhushani, kithmamadushani1@gmail.com\n",
      "E/15/307, L. Rishikeshan, work@ris.fi\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "This is a system for automatically controlling the amount of water flow in a soil field for maintaining the correct amount of water over it. The idea is to sense the amount of water using a device with an embedded system. The device has sensing elements where it measures the electrical conductivity and those results are used to estimate the amount of water the soil has. The system could be controlled by a controller/supervisor or it can be done in an automated way. The device will automatically switch off the water supplier when the highest level is reached and switch on the motor when the lowest level is reached.\n",
      "Solution Architecture\n",
      "Our solution for the above mentioned problem is to develop a system for automatically controlling the amount of water flow in a soil field for maintaining the correct amount of water over it. The idea is to sense the amount of water using a device with an embedded system. The device has sensing elements where it measures the electrical conductivity and those results are used to estimate the amount of water the soil has. The system could be controlled by a controller/supervisor or it can be done in an automated way. The device will automatically switch off the water supplier when the highest level is reached and switch on the motor when the lowest level is reached.\n",
      "Hardware and Software Designs\n",
      "WiFi coverage area of a device\n",
      "Sprinkler\n",
      "The whole idea\n",
      "Testing\n",
      "Results for hardware load testing\n",
      "Conclusion\n",
      "You can see our final product and how the water supplying process works by this link.\n",
      "CLICK TO WATCH\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Bike Sharing System https://cepdnaclk.github.io/e15-3yp-Automated-Bike-Sharing-System\n",
      "\n",
      "\n",
      "Automated Bike Sharing System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Bike Sharing System\n",
      "Team\n",
      "E/15/179, KARUNARATNE S.M.A.K., anandi.karunaratne@gmail.com\n",
      "E/15/092, EKANAYAKE I.U., imeshuek@eng.pdn.ac.lk\n",
      "E/15/325, SANKALPANA W.A.P.C., chalanisweerarathna@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Intro\n",
      "Today vehicles are a huge problem in the world, starting from the environment pollution arranging parking space causes deforestation. Moreover, people don’t have enough time to workout and to attend a gym. Therefore Today, more than 600 cities and more than 200 universities around the globe have their own bike-share systems, and more programs are starting every year. The largest systems are in China, in cities such as Hangzhou and Shanghai. In Paris, London, and Washington, D.C. highly successful systems have helped to promote cycling as a viable and valued transport option. Bike-share has taken many forms over the course of its development, from free bikes left for a community to use at will to more technologically advanced and secure systems.\n",
      "As the most of the universities have a wide area of land, transportation within the university causes the time to waste, accidents, congestion because of using the private vehicles, parking problems and the energy consumption related to the mobility of workers and students of the universities. The bicycle sharing programs have received increasing attention in recent years with initiatives to increase bike usage, better meet the demand of a more mobile public and lessen the environmental impacts of our transportation activities. So, the project aims to introduce automated bike sharing system to minimize the above impacts while evaluating the mobility patterns of academic campuses and assessing the energy consumption and pollutant emissions produced by the universities. This system provides the users to unlock the chosen bicycle in the substations via a mobile app and start riding, check the availability of bicycles and authorized people to track the path of rides of all users.\n",
      "Mainly targeting universities with a wide area of land to have a proper transportation system for inter-travel other than using private vehicles or taxis. This can be categorized into a few clusters.\n",
      "Mobility for employees – providing transportation options that assist University employees to conduct their duties and responsibilities in an efficient, environmentally-friendly manner\n",
      "Safety through reduced motor vehicle traffic – reducing the amount of motor vehicle traffic in areas with complicated infrastructure or high pedestrian volumes\n",
      "Health through increased physical activity – providing methods for employees and students to add more movement into their daily routine, thus impacting alertness, health, longevity, and more\n",
      "Environmental benefits of reduced motor vehicle traffic – reducing greenhouse-gas emissions, decreasing impervious surfaces for parking lots, decreasing the need for road maintenance\n",
      "Social benefits through enhancement of bicycling culture – supporting a culture that sees cycling as a preferred transportation mode choice, and a community that respects and works with the different transportation options\n",
      "Convenience factor – providing efficient transportation choices to aid users in arriving at destinations quickly and safely by reducing the need to always be in search of a bicycle or car parking area as well as the need to have to do own maintenance on bicycles\n",
      "Economically self-sustaining – implement a system that will pay for itself and reduce transportation costs for the campus community\n",
      "Research opportunities – provide the potential for research in urban planning, kinesiology and community health, marketing, environment, engineering, and more, with opportunities to publicize findings internationally\n",
      "Education campaign – participate with the campus-wide bicycle education campaign, by creating a platform for information sharing\n",
      "Enhanced Image of the Campus – Implementing a bicycle sharing program would improve the campus’ standing as a preferred employer and be an attractive feature for prospective students. This could positively impact recruitment and retention.\n",
      "Hardware and Software Designs\n",
      "Network and Web Application\n",
      "First to handle the whole system, a web application will be implemented for the administrative purposes. Basic features will be registering the riders, monitor the bike usage and to track the picks and docks.\n",
      "Next, for the users, an mobile application will be implemented in android platform which helps to find the nearest docks using the google maps, and to unlock it via the QR scanner by scanning the QR code in the lock.\n",
      "For these applications HTML, CSS, JavaScript and PHP will be used for the front end.\n",
      "HARDWARE DESIGN\n",
      "Implementation of smart locks for bike dock stations is the main task under hardware design. Smart lock is going to be designed using a linear actuator (solenoid) which triggered when the current flows. The smart lock unlocks when the rider reads the QR code and locks when the rider returns the bike.\n",
      "Each lock in dock station contains RFID reader and lock components which are connected to an Arduino Nano board. Those Arduino Nano boards are connected to an Arduino mega board using I2C communication bus. GSM/GPRS module is used for the wireless communication between the hardware components and the server. In between the server and the hardware components, there is a MQTT broker which is primarily responsible for receiving all messages, filtering them, decide who is interested in it and then sending the message to all subscribed clients.\n",
      "Video animations and Demonstration\n",
      "The Locking Mechanism Simulation\n",
      "Locking Mechanism Design Animation\n",
      "Demonstration Video\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Book Management System Automated Book Carrying Robot https://cepdnaclk.github.io/e15-3yp-Automated-Book-Management-System-Automated-Book-Carrying-Robot\n",
      "\n",
      "\n",
      "Automated Book Management System - Automated Book Carrying Robot\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Book Management System - Automated Book Carrying Robot\n",
      "Team\n",
      "E/15/016, ANOJAN S., e15016@eng.pdn.ac.lk\n",
      "E/15/171, KAPILRAJH R., svkapilvs@gmail.com\n",
      "E/15/351, THAKSHAJINI S., tsuhumar8@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "In libraries, We have planned to implement a book carrying robot to help the workers.Our embedded system will have Arduino,IR sensors,DC motors,power batteries and voltage regulator etc.It will work as a line following robot.Wi-fi module is used to communicate with a robot.We use RFID tag for books to use a web application,a database and a server to store the book details as well as the location details about the book shelfs for each and every book.\n",
      "Solution Architecture\n",
      "Making an automated book picking robot to help the workers in the library.\n",
      "The robot saves time and reduces human effort.\n",
      "It reduces human error and manages the books in an efficient and effective way.\n",
      "It is always available in the library.\n",
      "It is reliable.\n",
      "It ensures the security of the library and keeps the book safe.\n",
      "Hardware and Software Designs\n",
      "#### Basic Circuit Design for the Line Following Robot.\n",
      "#### Final Product\n",
      "Links\n",
      "Documents\n",
      "Project Report\n",
      "Project Proposal\n",
      "Other Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Vehicle Parking System https://cepdnaclk.github.io/e15-3yp-Automated-Vehicle-Parking-System\n",
      "\n",
      "\n",
      "Automated Vehicle Parking System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Vehicle Parking System\n",
      "Team\n",
      "E/15/076, DILEKA J.H.S., sandushidileka2@gmail.com\n",
      "E/15/065, DE SILVA K.G.P.M., prasadmadusankadasilva@gmail.com\n",
      "E/15/220, MALITHTHA K.H.H., maliththamax@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Vehicle Parking areas usually have people who give printed tickets for parking. This consumes a lot of time and which causes a lot of traffic. Along with causing traffic and commotion, there is also a lot of paper litter outside the vehicle parking areas.As the number of vehicles are increasing, the problems faced by manual parking management system are also increasing. Such problems can be eliminated to some extent by implementing an intelligent parking system where the entry and exit of cars is monitored and payment is made easy with sensor technology.In order to avoid all of these, Automated Vehicle Parking System can be used. This project uses an RFID which can be swiped at the entrance.\n",
      "Solution Architecture\n",
      "RFID Card for registered users\n",
      "Tag for unregistered users\n",
      "No paper tickets\n",
      "No waitings and checkings at the gate\n",
      "Time informed by a message\n",
      "Automated payments\n",
      "Hardware and Software Designs\n",
      "Data Flow and Infrastructure\n",
      "Overall Process\n",
      "PCB Design for the Vehicle Parking System\n",
      "Links\n",
      "Document\n",
      "Project Proposal\n",
      "Testing\n",
      "Progress\n",
      "Other Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Water Quality Monitoring System https://cepdnaclk.github.io/e15-3yp-Automated-Water-Quality-Monitoring-System\n",
      "\n",
      "\n",
      "Automated Water Quality Monitoring System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Water Quality Monitoring System\n",
      "Team\n",
      "E/15/077, K.P.W.A.K.K. Dilhani, kshithija.dilhani@gmail.com\n",
      "E/15/279, L.S.W.S. Premathilaka, wathsaripremathilaka@gmail.com\n",
      "E/15/211, S.A.I. Maduwanthi, ishmadhuwanthi@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "Fresh water is finite resource need for agriculture,industry and human existence. Therefore the quality of water is very important.The objective of this project is to develop automated water quality monitoring system by using continues measurements of pH and turbidity measurement.Normal process is water samples are normally collected at regular period and do the analysis and this ask for larger time consumption.But in this project we hope to offer fast and easy monitoring of pH and turbidity levels with IoT applications for continues maintenance of clean water.\n",
      "The process carried out water treatment plant.\n",
      "Solution Architecture\n",
      "Hardware and Software Designs\n",
      "Circuit Diagram\n",
      "Flow Chart\n",
      "Front-End Technologies\n",
      "UI Design\n",
      "Back-End Technologies\n",
      "ER Diagran\n",
      "Testing\n",
      "Test Plan\n",
      "Following are the test plan that is to be tested.\n",
      "Integration Testing\n",
      "Focus – pH sensor, web site\n",
      "Inputs and expected output are like below.\n",
      "PH <6.5 –> Alert\n",
      "PH\n",
      "6.5 – 7. 5 –> Normal\n",
      "PH >7.5 –> Alert\n",
      "Assumption – temperature 25(C)\n",
      "Testing Environment – wifi connection,pH sensor along with the embedded device and web interface\n",
      "Testing Process - In our system we are designing it to give alert when the variation of pH and turbidity values occurred. We can give some sort of boundary values to the system and check whether it gives expected output to the clients.\n",
      "Normally pH value of treated water should be in the range of 6.5 – 7.5.Then we are going to test our system using this case.\n",
      "By using soap water ,normal water and leman water it can be tested.\n",
      "Unit Testing\n",
      "Test whether sensors are working properly.Test both pH and Turbidity sensors with known solutions to verify whether it gives expected values.\n",
      "Focus – pH sensor\n",
      "Inputs and expected outputs –pH value of water is going to be changed by using pH known chemical and expecting their exact pH values using our pH sensor\n",
      "2.2 – Vinegar\n",
      "10.5 - Milk of Magnesia\n",
      "14.0 - Sodium Hydroxide (NaOH)\n",
      "Assumption – temperature 25(C)\n",
      "Testing Environment – pH sensor is needed\n",
      "Load Testing\n",
      "Focus –whole system\n",
      "Inputs – increase the number of nodes up to 30 nodes for the system using\n",
      "dummy values\n",
      "Expected output –system should operate properly as before\n",
      "Assumption - temperature 25(C)\n",
      "Testing Environment – pH sensor ,Turbidy sensors,wifi connection and web site\n",
      "Conclusion\n",
      "Now we have completed\n",
      "two nodes in the system. We can measure pH values and Turbidity values in real time of those two water treatment stages. But we still doing it in using two water samples(pure water and muddy water). And the Database also updating at the same time when sensor values are\n",
      "updated. And when considering the web application,\n",
      "the data can be retrieved easily. And tables in the web application also real-time updated with the database.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automatic Door Lock System https://cepdnaclk.github.io/e15-3yp-Automatic-Door-Lock-System\n",
      "\n",
      "\n",
      "Automatic Door Lock System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automatic Door Lock System\n",
      "Team\n",
      "E/15/119, D.L. D. Hasanika, dinithiliyanage.95@gmail.com\n",
      "E/15/202, D.P. Liyanage, preethi.du1995@gmail.com\n",
      "E/15/208, G.G.R. D. Madhushani, roshanidilhara7@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Detailed budget\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "Today, security has become the most important thing to be considered. People need a security system to prohibit unauthorized access to their property. Our target is to implement an automatic door lock system which allows the access only for authorized people. It helps to safeguard property from unauthorized people.\n",
      "Solution Architecture\n",
      "Data Flow and Infrastructure\n",
      "RFID Door Lock System\n",
      "Mechanism of RFID Reader\n",
      "Fingerprint Sensor\n",
      "Face Recognition\n",
      "Hardware and Software Designs\n",
      "Node 1 : RFID Door Lock System PCB design\n",
      "Node 2 : Completed PCB Design\n",
      "Testing\n",
      "PDF document Group_4_Automatic_Door_Lock_System_test_plan.pdf\n",
      "Conclusion\n",
      "Special Note:\n",
      "We decided to use IR sensors instead of PIR sensors. Because PIR sensors detect all the motions in a wide range. So it was difficult to use in this project.\n",
      "We removed the face recognition part from our node 2. Because for the high security, recognizing only the fingerprint is sufficient.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting E Checkup https://cepdnaclk.github.io/e15-3yp-E-Checkup\n",
      "\n",
      "\n",
      "E Checkup\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "E Checkup\n",
      "Team\n",
      "E/15/366, THINESH S., sathathinesh@gmail.com\n",
      "E/15/373, VAHEESAN R., waga950924@gmail.com\n",
      "E/15/330, SATHURSAN K., wdeva22@gmail.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "This project is about making an online interface for routine medical checkups. Usually people are not happy with standing in a queue or waiting a long time in the hospital to see the doctor as well as doctors also need a most efficient and effective way to examine their patients. Mostly in routine medical checkups doctor needs a data of several biometric parameters of patient’s body. These data can be measured by some sensors and stored through our system.\n",
      "Intro\n",
      "Solution Architecture\n",
      "This system allows you to measure biometric parameters such as pulse, breath rate, oxygen in blood, electrocardiogram signals, blood pressure, glucose levels. This information is used to monitor in real time the state of a user or to get sensitive data in order to be subsequently analyzed for medical diagnosis. Biometric information gathered can be wirelessly sent to the server and stored there , the data can be visualized in a tablet or smart phone by the patient thereafter the patient can send those data to doctor. The doctors can analyze those data and provide feedback to patients.\n",
      "Hardware and Software Designs\n",
      "Data Flow of System\n",
      "Web Application Demonstration\n",
      "Links\n",
      "Documents\n",
      "Project Report\n",
      "Project Proposal\n",
      "Other Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Embedded system for detecting adverse gases https://cepdnaclk.github.io/e15-3yp-Embedded-system-for-detecting-adverse-gases\n",
      "\n",
      "\n",
      "Embedded system for detecting adverse gases\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Embedded system for detecting adverse gases\n",
      "Team\n",
      "E/15/243, NISANSALA R.M.B.S., sewwanis@gmail.com\n",
      "E/15/271, PRASADIKA L.B.S., sonaliprasadika077@gmail.com\n",
      "E/15/180, KARUNATHILAKA V.M.B.S.S.V., supipivirajini@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Links\n",
      "Introduction\n",
      "Intro Video\n",
      "As we all know, air pollution is a growing problem in Sri Lanka. This is mainly due to motorization and industrialization. Among those two sections, we concentrate on industrialization with a hope of providing solution to that problem from our decided embedded system.\n",
      "Basically, authorities who are responsible for air pollution controlling our country,tend to regulate air pollution due to toxic gasses leaving from factories only at the beginning of them. But,with the time, that process is not longer continued by the authorities.Then, the factories are feel free to discharge air pollutants to the environment by exceeding the limit identified by the authorities. This is because regularly, authorities do not have proper system to detect whether a factory is discharging air pollutants with a control.\n",
      "Solution Architecture\n",
      "Therefore, our plan is to implement an embedded system for the use of government, from which authorities can anytime come and check whether factories are discharging toxic gasses exceeding the limitation. Actually this is just like a meter reading at our home. On the display of the system, the percentage of CO, SO2, NO2, Humidity, Temperature will be shown.\n",
      "Hardware and Software Designs\n",
      "In the server side we wish to analyze and filter the row of sensors and will display them on the web site graphically.\n",
      "For our project, we are going to use sensors; MQ9 (CO sensor), AM2301(Temperature and humidity sensor), SO2 alpha-sensors and NO2 sensor. Initially, sensor details were studied by referring datasheet of each sensor . After that, the sensors are connected to the arduino UNO board and arduino codes were written to all of those sensors in order to read voltage values of the sensors’ outputs. Calibration is done for measuring temperature and humidity. Meanwhile, php and mysql were studied in order to create a database to website.\n",
      "As we decided at very first of that project, CO, SO2, Temperature and Humidity can be measured through the developed device. Furthermore, to measure CH4 gasses which are discharged from the factories, another sensor also was added. For that, MQ-2 Gas sensor module smoke was used. So at Milestone 3, successfully,\n",
      "we could show that the device was taking data from that sensor.\n",
      "Up to now, data from sensors were retrieved using a WiFi-shield. But when WiFi is not available around corresponding factory, device will not work. Therefore, for the ability to use the device by any of the factories, we decided to add a GPRS. Up to now, performance of the project run under local server, but for the ability to work with GPRS, we need a public server. Then, after milestone 3, we expected to get a public server and do the coding for GPRS. From that, we hope to present our embedded system at next milestone with GPRS module.\n",
      "Furthermore, our Air Quality Monitor con be met with Two nodes\n",
      "Testing\n",
      "The Test plan of our project, Air Quality monitor will be done through three types of tests. They are;\n",
      "Unit Test\n",
      "Integration Test\n",
      "Load Test\n",
      "Unit Test\n",
      "This testing type will be used in-order to verify the behavior of the Air Quality monitor independently from other parts. From that it can ensure that every single unit in the system works correctly.\n",
      "Under Unit test, each sensor will be tested separately. How it is that output of each sensor will be compared with corresponding standard values or the values around our working environment. For an example, output from the temperature and humidity sensor will be compared with the values around our working area. Other values can be taken from Chemical department in our faculty. Inputs of sensors are in voltage, but after calibrating each sensor separately it will display output as temperature in Celsius, humidity as percentage and other gas sensors in ppm.\n",
      "Workability of MQTT server will be tested using publisher and subscriber which are implemented within a same computer, even though they should be at two separated computers. When subscriber sends a string as a topic to publisher and publisher responds it by sending relevant data, then it can say that the MQTT is running properly. Considering our project, if subscriber sends a message as ‘SO2’ and then publisher responds to it showing SO2 quantity in ppm, then it can say that the MQTT is working well.\n",
      "Integration Test\n",
      "Integration Test will be used in-order to demonstrate that different parts of a system work together in the real-life environment with the use of external resources. For our project, database and web servers will be used as external resources. By doing this testing. We hope to achieve a high level of confidence that the whole system works as expected.\n",
      "If our project is considered, it can be tested whether the data taken from sensors is sent to Main server using MQTT, while publisher and subscriber are in two devices. If we can get results as same as in unit test for MQTT, then it can realize that data transferring from sensors to Main Server happens properly.\n",
      "Furthermore, under this test, it can be checked whether data of every sensor is sent to database simultaneously by integrating each component of a node into a bread board. It can check whether the values shown at each unit test for every sensor can be seen in the LCD display. If it is, then it can finalize that all sensors are working correctly together.\n",
      "Load Test\n",
      "Under load test, it will be determined the speed, scalability of the system. From this test, the system behavior under both normal and peak load conditions (number of nodes) will be verified.\n",
      "Final system will come up with the ability to response many nodes other than a single node. So, doing this test, we will get an idea about whether the embedded system will work for multiple nodes or not as well as how many factories the Air Quality Monitor can handle successfully and how it avoids the potential problems in future such as increased number of factories for the use of server.\n",
      "This will be done by sending topics to publisher by subscriber. For each node that would be act as unique ones, when it handles different main topics for each node and the publisher gets separate response relevant to each node, then it can say the system can handle many of nodes. In here, past data will be deleted after those data are re-presented in graphs. Then it can save more space in database for the future use.\n",
      "Modified Test Plan\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Fire Detection and Alert System https://cepdnaclk.github.io/e15-3yp-Fire-Detection-and-Alert-System\n",
      "\n",
      "\n",
      "Fire Detection and Alert System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Fire Detection and Alert System\n",
      "Team\n",
      "E/15/154, JAYASOORIYA J.K.C.N., e15154@eng.pdn.ac.lk\n",
      "E/15/187, KULANJITH G.D., devingallage@gmail.com\n",
      "E/15/142, JAYALATH A.H.G.D., ganindudananja@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "According to National Fire Protection Association (NFPA), there were 1,319,500 fire cases were reported only in USA in 2017. Nearly 40% of them are structure fires. Moreover, following statements are highlights from NFPA report.\n",
      "In 2017, 22 fires in the United States resulted in losses of at least $10 million each, for a cumulative total of $12.5 billion in direct property losses. These fires resulted in the deaths of 52 civilians and one firefighter, and injuries to 213 civilians and 20 firefighters.\n",
      "The other 20 large-loss fires in 2017 involved structures and resulted in a total property loss of $747.7 million.\n",
      "Smoking materials were the leading cause of home fire deaths in 2012-2016.\n",
      "Intro\n",
      "Solution Architecture\n",
      "There are two ways a fire can be happened.\n",
      "Sudden fire\n",
      "Slowly growing fire\n",
      "We are going to implement a set of devices with the capability of detecting smoke and CO particles so that, the device will detect both the above mentioned fire types and the users will get warnings only if neccessary through an alarm on the device itself and an alert will be sent to the users of the mobile app and the web application. If the fire is massive or danger enough the intensity of the alarm will get increased and if the option for emergency is enabled, the emergency authorities will get notifications about the fire disaster.\n",
      "How the device works?\n",
      "There are two types of devices come with Ignio and they are “Ignio node” and the “Ignio relay”. The Ignio node is integrated with the sensors and an alarm so that it takes data from sensors and pass down to the Ignio relay through wi-fi which is connected to the ISP directly via a home network or an enterprise network. The sudden fires will get detected by the Ignio node itself through the sensors by detecting the passing of particular bandwidths for particle density and CO emission rate. And, the other type of fires will be predicted by analysing the periodic data on the microservice architectured API.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Health Watch https://cepdnaclk.github.io/e15-3yp-Health-Watch\n",
      "\n",
      "\n",
      "Page not found · GitHub Pages\n",
      "404\n",
      "File not found\n",
      "The site configured at this address does not\n",
      "contain the requested file.\n",
      "If this is your site, make sure that the filename case matches the URL.\n",
      "For root URLs (like http://example.com/) you must provide an\n",
      "index.html file.\n",
      "Read the full documentation\n",
      "for more information about using GitHub Pages.\n",
      "GitHub Status —\n",
      "@githubstatus\n",
      "\n",
      "\n",
      "Extracting Hydroponics Automation System https://cepdnaclk.github.io/e15-3yp-Hydroponics-Automation-System\n",
      "\n",
      "\n",
      "Hydroponics Automation System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Hydroponics Automation System\n",
      "Team\n",
      "E/15/299, L.M. Ranushka\t, e15299@eng.pdn.ac.lk\n",
      "E/15/139, D.S. Ishanthi, dsajini.i@gmail.com\n",
      "E/15/249, W.A.D. Pamoda, dasunip2@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "Hydroponics is the method of growing plants in a nutrient-rich water-based environment which uses artificial lighting. This method is widely used in modern agriculture because of less space and conservation of water. But the main disadvantage of this system is the need of constant monitoring to get the maximum benefits from it.\n",
      "With this Hydroponics Automation System, the plants are supplied automatically with enough water, proper amount of light intensity and proper nutrients depending on the sensors’ feedback. And also the data obtained from the sensors is accessible through a web application.\n",
      "Solution Architecture\n",
      "Hardware and Software Designs\n",
      "The modified final data flow\n",
      "of the system\n",
      "Testing\n",
      "The data gathered from the sensors are sent to the NodeMCU and sent to a web server and stored in a database. User can access this data through a web application. The automatic control of the actuators is done by the webserver and the Node MCU. Also if the user wants to take the control decisions, he can control the system through the web application.\n",
      "Conclusion\n",
      "For the demonstration purpose for now we have implemented the structure of the hydroponics system with water circulation. We are going to further improve and develop it.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Intelligent Road Traffic Control System https://cepdnaclk.github.io/e15-3yp-Intelligent-Road-Traffic-Control-System\n",
      "\n",
      "\n",
      "Intelligent Road Traffic Control System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Intelligent Road Traffic Control System\n",
      "Team\n",
      "E/15/280, PREMATHILAKA M.P.U., pubuduudara7@gmail.com\n",
      "E/15/316, Samarasinghe U.G.S.B., imsuneth@gmail.com\n",
      "E/15/123, HERATH H.M.M.E.W.L., wisheslakshan@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Vehicle travel across the world is increasing, especially in larger urban areas. It is a serious problem in traffic congestions in many major cities around the world and in these cities, it has become a nightmare for travelers. Since Traditional systems have implemented to follow a preset time schedule, they do not control variable flows coming near junctions.\n",
      "There is a goal of customizing traffic flow vehicles in a junction. As the number of roads increases steadily, and the resources provided by the current infrastructure are limited, intelligent control of traffic in the future will become a very important issue. Therefore, to better accommodation of this increasing demand, traffic control algorithms need to be simulated and optimized.\n",
      "“One study done in Boston has proved the timings of 60 intersections in one district of the city could save $1.2 million per year”\n",
      "Intro Video\n",
      "Solution Architecture\n",
      "Our Approach:\n",
      "Hardware and Software Designs\n",
      "Communication Protocol\n",
      "Components\n",
      "ESP32\n",
      "Arduino Nano\n",
      "nrf24l01 Modules\n",
      "In our system, the relay node is the ESP32 board. Arduino Uno board works as the microcontroller for the sensor node. We needed to build up a communication system between the sensor node and relay nodes in order to send real-time vehicle count taken by sensor nodes. There are 4 sensor nodes per junction in the prototype.\n",
      "Overview\n",
      "In order to establish the communication, we used nrf24l01 radio modules both in the sensor node and relay nodes. We tried to implement a protocol for our system using RF as the media and it is succeded. In this protocol relay node uses different pipes to communicate with each of the sensor nodes. Through this implementation, we could overcome the broadcasting issue and we could establish one to one communication.\n",
      "References\n",
      "Vehicle Simulator\n",
      "As the demonstration has planned to do with a prototype of a junction which intersects two roads, other junctions will be demonstrated using the simulator software. Using a camera fixed from the top of the prototype, the video stream is taken to the simulator for the convenience of observing the behavior of the algorithm.\n",
      "Simulator\n",
      "We started developing this software from scratch and we were able to implement the following feature in it.\n",
      "Add vehicle defining a custom path using GUI\n",
      "Stepwise simulation\n",
      "Continuous simulation\n",
      "Add vehicles while the simulation is running\n",
      "Simulating multiple vehicles at the same time\n",
      "Pause and continue the simulation\n",
      "Camera View added and it can work while the simulation is running (Not showing in this video)\n",
      "Communication Between Sensor nodes and the Relay node\n",
      "Problem :\n",
      "The sensor node should keep listening to the magnetic reed sensors all the time, while it should be listening for the requests from the Relay node at the same time. Since we have an Arduino Nano microcontroller as the driver of sensor nodes, they can not handle two tasks at the same time.\n",
      "Solution:\n",
      "So, we came up with a solution for the above matter. We found that the availability of an interrupt pin on the NRF24l01 modules which we use for the radio communication. The interrupt pin on the module is called “IRQ” (Interrupt ReQuest) pin.\n",
      "The IRQ pin is normally HIGH and by default, it will send out a low pulse at three different events when\n",
      "It received data\n",
      "It transmitted data\n",
      "Transmission failed or no ack received\n",
      "The maskIRQ (tx_ok, tx_fail, tx_ready) function from the TRMh20 RF24 library can be used to enable the above three functionalities.\n",
      "We used this signal to trigger an external interrupt (we used digital pin 3) on the Arduino Nano module. Then, when the Relay Node makes a request to the Sensor node asking for the required information, the sensor node can sense the incoming request and it will only reply on that point of the time and it goes back to keep listening to the magnetic reed sensors.\n",
      "Results:\n",
      "We implemented the above-mentioned functionality and tested it. We measured the response time of the Sensor node, the time it takes to receive the request from the relay node and respond to it with the vehicle count. The average time was about 24ms.\n",
      "Also, we sent requests from the Relay node with very fewer time delays between two requests, to check whether the sensor node has time to respond to the request and go back to counting vehicles. We set the delay between requests to 10ms and verified that the sensor node can even handle requests at the amount of requesting frequency.\n",
      "Complete Network Diagram & Protocols\n",
      "Communication between the Relay node and the Server\n",
      "In the system, the database, server and the server program running on a standalone Raspberry Pi 3 devices. ESP32 board uploads real-time vehicle count in each lane of the junction to the server.\n",
      "To accomplish this we have used MQTT protocol since it is the most suitable protocol for real-time communication. In this network, the Raspberry pi device is functioning as the mosquito broker and esp32 working as an MQTT client. We will describe how the overall protocol works in the coming posts.\n",
      "Web Application\n",
      "Any host on the same network can access to the system website using the raspberry pi’s IP address. The server program, database and the front end application is running on the Raspberry Pi device. The HTTP protocol is used for this communication.\n",
      "Prototype Developments\n",
      "Sensor node module\n",
      "Relay Node module\n",
      "This module is the one that keeps polling the Sensor node modules in a separate thread in it. It will send a request to a Sensor node. That request message will be received by the Sensor node and it produces an interrupt from the Sensor node’s NRF module using its IRQ pin. The Relay Node waits for the replay and stores the replay in it.\n",
      "The other role of the Relay node is to keep communication with the Server.\n",
      "Color lights arrangement\n",
      "Website of the project\n",
      "Introduction\n",
      "Optimizing the current traffic controlling system is a project that can be undertaken as a mandatory requirement for society as the current human lifestyle as mentioned before. Build up the website that fulfills the user needs will be a great help for the users to maintain their day to day lifestyle in the scope of traffic congestions.\n",
      "The front-end\n",
      "Usability, or User Experience, is the art of making your website simple, user-friendly and easy to use. Understanding the customer’s online behavior gives you insight into what works and what doesn’t.\n",
      "Homepage\n",
      "Login window\n",
      "On this website, the responsiveness is considered\n",
      "Database\n",
      "As of now, we have implemented a database that includes 7 tabulations. All the details are provided below.\n",
      "Junction1\n",
      "There are 3 more junctions which have the same table structure. From above table, the vehicle count at the update time can be obtained. laneId is the primary key. This table is filled by the relay node of the junction.\n",
      "Feedback table\n",
      "Above table can be used to obtain the user’s feedback and their suggestions about the service and also the websites. ID is the primary key of the table.\n",
      "User_Accounts\n",
      "Above table is reserved for the administrators. The purpose of building up this table is to reserve space for the people who update the algorithm that runs at the back-end of the project.\n",
      "MQTT clients and broker full system\n",
      "MQTT is a lightweight publish/subscribe messaging protocol designed for M2M (machine to machine) telemetry in low bandwidth environments. MQTT stands for Message Queuing Telemetry Transport.\n",
      "The first concept is the publish and subscribe system. In a publish and subscribe system, a device can publish a message on a topic, or it can be subscribed to a particular topic to receive messages\n",
      "MQTT Topic\n",
      "Topics are the way you register interest for incoming messages or how you specify where you want to publish the message.\n",
      "MQTT Broker\n",
      "The broker is primarily responsible for receiving all messages, filtering the messages, decide who is interested in them and then publishing the message to all subscribed clients. There are several brokers we can use.\n",
      "In the project we have used\n",
      "Mosquitto broker which is installed on the raspberry pi device and it works as the server to the junction. Relay node works as the MQTT client to the Mosquitto server. Broker is programmed using python and broker program uploads data to the SQL database which is located on the raspberry pi device.\n",
      "Links\n",
      "Documents\n",
      "Project Report\n",
      "Project Proposal\n",
      "Other Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Monitoring and Tracking System for Transportation of Pharmaceuticals https://cepdnaclk.github.io/e15-3yp-Monitoring-and-Tracking-System-for-Transportation-of-Pharmaceuticals\n",
      "\n",
      "\n",
      "Monitoring and Tracking System for Transportation of Pharmaceuticals\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Monitoring and Tracking System for Transportation of Pharmaceuticals\n",
      "E/15/021, M.M.M. Aslam, aslam.m9618@gmail.com\n",
      "E/15/131, M.H. Hisni Mohamed, hisnimohammed@eng.pdn.ac.lk\n",
      "E/15/348, S. Suhail, suhailsajahan@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "5 Links\n",
      "Introduction\n",
      "When Medicines or Drugs are transported or stored there are conditions that have to be satisfied, such as Temperature, Pressure, Moisture inside the box. It’s important for Medicine Distributors or Hospital management to ensure that medicines or medical samples are kept in a certain controlled environment. And also important to track these items when transported.\n",
      "This Project is a system that could monitor the variations in these parameters and track the locations of items being transported and let the relevant person know through a mobile app. This project will be helpful to Medicine Distributors and Hospital Management to transport Medicine, Medical Samples or Organs Safely.\n",
      "Solution Architecture\n",
      "An Embedded System which helps to:\n",
      "Measure Temperature, Pressure, Humidity, 3D Orientation of the product being transported and observe the variations through a mobile app and web interface.\n",
      "Get a warning alert when a parameter changes drastically or a condition is broken.\n",
      "Track the location of the product being transported.\n",
      "Maintain a database and analyze the variations in parameters being monitored\n",
      "Owner of the product, the person in charge of the distribution, the wholesale buyer can monitor the database.\n",
      "It can be used for all the products which are needed to be transported in controlled conditions.\n",
      "Hardware and Software Designs\n",
      "Overall Design\n",
      "Testing\n",
      "Test Plan for the Project\n",
      "We planed to do 4 tests for our project.\n",
      "1.Test for Backend Server\n",
      "2.Load Test for Relay Node (NodeMCU ESP8266 Access Point)\n",
      "3.Unit Test for Sensors (DHT22, BMP280)\n",
      "4.Unit Test for GPS module (uBlox Neo-6)\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Personal Physical Trainer PPT https://cepdnaclk.github.io/e15-3yp-Personal-Physical-Trainer-PPT\n",
      "\n",
      "\n",
      "Personal Physical Trainer (PPT)\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Personal Physical Trainer (PPT)\n",
      "Team\n",
      "E/15/059, DASSANAYAKE P.S.B., prageethda@gmail.com\n",
      "E/15/023, ATHAPATTU A.D., avishka0303@gmail.com\n",
      "E/15/238, NANAYAKKARA G.S.C., sewwandiecn@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "1.What is physiotherapy?\n",
      "Physiotherapy is a treatment method for injuries or deformities using physical exercises.\n",
      "2.What is Personal Physical Trainer?\n",
      "Personal Physical Trainer is an innovation for physiotherapy. It creates an environment where the patients would be more willing to engage in physiotherapy\n",
      "as well as it makes sure that patient would do the correct movements. This also allows the therapist to monitor the progress of his/hers patient and whether the patient carries out the necessary exercises.\n",
      "3.Why should people use PPT?\n",
      "There are millions and millions of people who do physiotherapy but\n",
      "about 20% of them get cured in the relevant time period if we trace the causes for it we can see that most of the time people give up physiotherapy and they do not do the exercises they supposed to. One of the major draw back in traditional methods of physiotherapy is that therapist would examine the patient at the start of therapy and then again examine the patient after period of time. Within that time period the patient’s progress isn’t not monitored. So they tend not engage on exercises or some do not have a clue whether they are doing the correct movements.\n",
      "4.How does PPT work?\n",
      "We build a wearable to read the movements of the patient. A game is develop that would be controlled by the movements of the patients. In order to reach the goe als with in the game the patient has to engage in the correct movements themselves.\n",
      "We record data that is needed for the therapist such as speed, time period patient engaged in the activity as well as number movement. With all the data therapist can monitor the patient’s development.\n",
      "Intro Video\n",
      "Solution Architecture\n",
      "Physiotherapy is one of the leading medical tactics that uses physical therapy to cure injuries or deformities. However the effectiveness of this method is not up to a satisfactory level yet. The reason cited for the said is that\n",
      "only 20% out of the millions of people who undergo physiotherapy, gets cured within the expected time period. A close example could be found out from our team itself. One of our team members underwent physiotherapy in order to cure torn tissue; however as soon as he felt better to a certain extent he stopped the treatments and he continues to suffer from on and off knuckle pains to this date. In the prevailing system, therapist only examines the patient at the beginning and after a certain time period.\n",
      "Within this duration the patient is not monitored at all.\n",
      "Unless the patient is very obedient towards his treatment, the chances of him following this procedure regularly and accurately are very low. Reasons for this could be identified as follows:\n",
      "Doing the same exercise can be boring\n",
      "With the busy schedules they tend to forget about therapy sessions\n",
      "Sometimes patients think that they are better and give up on the therapy.\n",
      "Some don’t know the right way to do it\n",
      "This is where PPT comes in it allows its users to follow the correct treatment.\n",
      "Hardware and Software Designs\n",
      "High Level Design\n",
      "Statistics show that effectiveness of physiotherapy has decreased into the level of 20% cause of the unwilling of patience continue on therapy, lack of knowledge about what exercises patient has to do, lack of constant monitoring of a patient and the lack of patient and therapist interaction our intent is to develop a system where we can reduce these barriers and lift up the effectiveness of physiotherapy. Physiotherapy is one of the leading medical fields in the world and which shows promising results by following the treatments correctly. Following diagram shows how Personal Physio Therepy (PPT) lifts up these issues.\n",
      "Background Maths\n",
      "Euler’s angle\n",
      "Euler’s angle is used to get the most accurate angle from the accelerometer.\n",
      "Complementary Filter\n",
      "Complimentary filter is used to get the most accurate angle with the data from the accelerometer and the gyroscope. Data from Gyroscope precise but tend to drift. Data from accelerometer is bit unstable but not drift. So we filter them out to get the best angle.\n",
      "The Complementary Filter is actually a union of two different filters: a High-pass Filter for the gyroscope and a Low-pass Filter for the Accelerometer. The first lets only pass the values above a certain limit, unlike the Low-pass filter, which only allows those below\n",
      "Total Anglex = 0.98 × (Total Anglex + Gyrodatay.elapsedTime) + 0.02 × accelerometer angle\n",
      "98% - Gyro data\n",
      "2% - Accelometer data\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Safer Travel Utility SaVy https://cepdnaclk.github.io/e15-3yp-Safer-Travel-Utility-SaVy\n",
      "\n",
      "\n",
      "Safer Travel Utility (SaVy)\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Safer Travel Utility (SaVy)\n",
      "Team\n",
      "E/15/363, THILAKARATHNE E.R.R.I., ireshe@outlook.com\n",
      "E/15/048, CHANDRASIRI S.A.G.L., laksaragayal1996@gmail.com\n",
      "E/15/043, BHAGYA T.P.Y., yasirubhagya@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "According to the Wikipedia once CTB was the largest omnibus company in the world. Currently CTB has more than 6000+ buses operating in the road which is the same number of private buses operating in Sri Lanka. Sri Lanka has the second highest road density in Asia in 2011 (173.8 km/km2). Although there are so many roads and buses in the road still people don’t like to use public transportation very much. we feel, it’s because public transportation is very unpredictable and sometimes, we have to wait hours and hours in bus stations waiting for a bus. It’s so hard to find the right bus for the right location if you don’t know the right route number. So, we feel this all happens due to the inefficiency and mismanagement of resources. So, our plan is to make a tracker management system for bus owners. So CTB and private bus owners can install our trackers in their buses to track their buses current locations, distance bus traveled for a specific time period, take rough idea of fuel required for the buses and check whether there’s any difference between consumed fuel and predicted fuel usages. So, by providing this information to owners our goal is to install our system in most of the buses that we can. Afterwards we are going to use those real time generated date from our trackers to provide commute assistance to general public. So general public can easily navigate using our app. They don’t have to wait in bus stands for the buses. Because now they know where their bus is, thanks to our app. So, using the real time data set we can provide push notifications to users about the right bus and where it is, ETA (Estimate time of Arrival) for their journeys. So, they don’t have to waste their valuable time looking for buses. And we believe this will be useful for the CTB and private bus owners to manage their fleets as well. They can find the hotspots in transportation and provide more buses to those places. And by implementing this method we believe we can minimize usage of private vehicle as people will prefer public transportation. So, it will minimize the traffic jams in Sri Lanka too.\n",
      "Intro Video\n",
      "Solution Architecture\n",
      "In introduction we explained issues that we are facing in Sri Lanka, now will see how we are going to make SaVy Happen.\n",
      "But in order to do this thing, we are planning to build our architecture like image below\n",
      "Service layer (orange) is the fundamental unit of our design (will talk more about this in next blog post). Application layer (Red) is fully customizable solution. So, all our web, mobile APP runs in this layer. It seems complicated and you might wonder why we choose such an architecture.\n",
      "Although it was little bit hard to build a system like this, in long term this would be very beneficial to us. When upgrading our system, we can seamlessly upgrade each component of the system without affecting the all system.\n",
      "And we can reuse same service layer to provide different kinds of services if needed (like assetless logistic service)\n",
      "Hardware and Software Designs\n",
      "Application Layer\n",
      "This is the abstract view of the application layer\n",
      "Service Layer\n",
      "Service layer mainly consist of a TMS (Tracker Management System) and Trackers. TMS is like the queen of a beehive which control and manage all the trackers. Then TMS will send data to the upper level.\n",
      "Tracker\n",
      "Tracker consist of\n",
      "GPS module to track GPS\n",
      "A battery to provide backup power when needed\n",
      "IMU (inertia measurement unit), magnetometer, Barometric Pressure Sensor\n",
      "So, in our service layer, simply what happens is trackers send real time GPS coordinates, IMU and other data to TMS. So TMS will process it and provide it to application layer. Then application layer display relevant information in the web and mobile app. Simple that is what SaVy does in a nutshell.\n",
      "Links\n",
      "Project Report\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Educational Management System https://cepdnaclk.github.io/e15-3yp-Smart-Educational-Management-System\n",
      "\n",
      "\n",
      "Smart Educational Management System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Educational Management System\n",
      "Team\n",
      "E/15/246, R.L. Opanayaka, rajithaopanayaka.ro@gmail.com\n",
      "E/15/385, S.P.A.P.E. Weerasinghe, amilaweerasinghe677@gmail.com\n",
      "E/15/233, P.N.N. Muthucumarana, nipunimuthucumarana@gmail\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Links\n",
      "Introduction\n",
      "Smart Educational Management System (SEMS) is specially designed for schools, colleges and institutes to automate the institutional processes. Use of SEMS makes your institution eco-friendly as all data and your reports are stored on the server, the use of paper and files are necessary only when needed. Attendance of students can be marked by taking the fingerprint using a device with an embedded system. SEMS is very affordable and comes with no limits on the number of students, teachers and parent logins. This system is highly secured and the automation helps in reducing costs and brings a lot of savings for you.\n",
      "Solution Architecture\n",
      "Smart Attendance Marking System (SAMS)\n",
      "Hardware and Software Designs\n",
      "Milestone 1-Project Evaluation one\n",
      "What we have completed up to now\n",
      "Finger print end node\n",
      "-Taking inputs from finger print sensor\n",
      "-Enter ID from each user\n",
      "-Enroll, Search, back function implementation\n",
      "We are capable of\n",
      "Enroll a new user\n",
      "Search for a enrolled user\n",
      "Web app\n",
      "-Implemented user login registration\n",
      "-Implemented retrieving and storing from Mysql DB using php backend\n",
      "Changes made\n",
      "-As with more relational connections occured in EER diagram we tend to use MySQL(realtional) instead of firebase(non-realtional)\n",
      "Testing\n",
      "Test plan PDF\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Mirror https://cepdnaclk.github.io/e15-3yp-Smart-Mirror\n",
      "\n",
      "\n",
      "Smart Mirror\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Mirror\n",
      "Team\n",
      "E/15/261, PERERA M.S.V., vidurangaperera1@gmail.com\n",
      "E/15/136, ILLANKOON H.M.A.U., ajuillankoon@gmail.com\n",
      "E/15/292, RANASOORIYA S.M., smadu1996@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "People today are so busy with their day to day activities, so most of us forget many stuff that we are supposed to do. And we are not used of using a note book or a diary to write our activities but we really need a method so that we can remember our activities. But what ever we miss due to our busyness we will never forget something specially in the mornings. That’s nothing but the mirror. Mirrors have been serving people from centuries. So can this tradition mirror remind us the things we have forgotten. Yes it can! That’s nothing but by a smart mirror. No matter what your age is, no matter what your profession is, no matter how busy you are, you will stand in front of a mirror with or without intentionally. If a mirror can remind our daily activities, how nice it would be. With this no need of looking into diaries for daily plans, just have to look at the mirror as usual. Mirror will simply display your to-do list for the day. This is the main function of the Smart Mirror.\n",
      "A smart mirror has these following features.\n",
      "It will remind us with our to-do list\n",
      "It will display the date and time\n",
      "News headlines - Today’s people have no idea of what is going on. So this can deliver the current situation while sorting the news feeds according to the interest of the user.\n",
      "Weather status - Knowing the weather forecast will help the user to manage his daily activities. So that will eliminate the embarrassing moments which the user faces due to\n",
      "the sudden changes in the weather.\n",
      "BMI Analysis - Nowadays people don’t pay much attention for their health. At least they don’t know whether they are healthy or not. This mirror will let us know if the BMI value changes.\n",
      "Intro Video\n",
      "Solution Architecture\n",
      "Project Layout\n",
      "Hardware and Software Designs\n",
      "Smart Mirror\n",
      "Project Proposal\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Monitoring and Automated Controlling System for an Aquarium https://cepdnaclk.github.io/e15-3yp-Smart-Monitoring-and-Automated-Controlling-System-for-an-Aquarium\n",
      "\n",
      "\n",
      "Smart Monitoring and Automated Controlling System for an Aquarium\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Monitoring and Automated Controlling System for an Aquarium\n",
      "Team\n",
      "E/15/362, K.A.H.P. Thilakarathna, hasinithilakarathna4@gmail.com\n",
      "E/15/081, S.L.I. Dinuwanthi, imalshadinu@gmail.com\n",
      "E/15/345, D.V. Sripadi, vidwasripadi@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "In almost all the aquariums, the filtering of water is done manually by the operating officers. But by using this system, filtering of the aquarium’s water can be done automatically which would increase the efficiency of an aquarium’s working routine. Filtering of water can be done by measuring and analyzing the oxygen level of water so that there will be a sufficient amount of oxygen for the survival of aquatic animals and plants. Even though the system will be operated automatically, the user or the owner of the aquarium could check the aquarium’s filtering process anytime he/she want as there is a web page connected to this system which is updating automatically when all the filtering activities are happening.\n",
      "Solution Architecture\n",
      "Hardware and Software Designs\n",
      "DESIGN OVERVIEW\n",
      "Conclusion\n",
      "MODIFIED DESIGN OVERVIEW\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Air Quality Monitoring system https://cepdnaclk.github.io/e14-3yp-Air-Quality-Monitoring-system\n",
      "\n",
      "\n",
      "Air Quality Monitoring system\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Air Quality Monitoring system\n",
      "Team\n",
      "E/14/049, KASUN VIMUKTHI, e140494@ce.pdn.ac.lk\n",
      "E/14/037, BANDARA M.K.G.E.S.P., e14037@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Monitoring and maintaining air quality and sound quality are most important aspects of city management. A significant proportion of the population lives in cities, where air quality index has exceeded limits for several air pollutants like - particulate matter (PM), ozone, nitrogen dioxide.The Noise pollution can cause hypertension, high stress levels, tinnitus, hearing loss, sleep disturbances, and other harmful effects.These pollution pose serious health and environment risks. Therefore air and sound quality monitoring system is an important component of any smart city.\n",
      "So in this unified project we develop a system to monitor , forecast and reducing air pollution in a city through actionable data. the data will be received from gas sensors and the sound sensor. we are trying measure the data using this module in urban areas.\n",
      "All those data taken from those sensors, are sent to a central server and processed there.if the permit levels are exceed Regulatory agencies or pollution control boards will be informed.and also person can see whether the city is suitable for living and what will be the future. they can get the information about Pollution Awareness.\n",
      "Solution Architecture\n",
      "Sense the quantities using\n",
      "5pcs LM393 sound detection sensor DC 3.3 -%v sound sensor module sound detector for sound quality measurements.\n",
      "CO2 Carbon Dioxide Sensor Module MG811 for mesuring the co2 content.\n",
      "2PCS Winsen ZE05 H2S/CO/NO2/SO2 Electrochemical Detection Module UART Output.\n",
      "MQ-136 H2S Hydrogen Sulfide MQ-137 NH3 Ammonia Gas Sensor Module Detection.\n",
      "1pc ORIGINAL New ZE03-O2 winsen Electrochemical Oxygen Sensor Module DHL FEDEX.\n",
      "Key Features\n",
      "GPRS based solution, no need of laying communication cables.\n",
      "Monitors H2O, CO2, CO, SO2, NO2, NH3.\n",
      "Keeps automatic record of above parameters.\n",
      "Alarms over email or SMS\n",
      "Manage all your plants on a single platform form anywhere.\n",
      "API to Upload data to regulatory agencies server.\n",
      "Data available for public awareness with comparisons.\n",
      "Hardware and Software Designs\n",
      "milestone 2: infrastructure\n",
      "Quentities that we are going to measure are as follows\n",
      "different air and sound levels in environment:\n",
      "co percentages\n",
      "Hydrocarbonic air percentages\n",
      "nox and sox percentages\n",
      "sound level percentages\n",
      "but there are many more polluted airs in the environment. such as O3,CO2 etc.we are considering the airs which are giving\n",
      "higher impact for the climate changes and other victims.\n",
      "co percentages measures from MQ7 sensor. Hydrocarbonic air measures from MQ3 sensor.nox and sox measurements will be measuring using suitable sensors.(didn’t buy them yet)\n",
      "A GSM module in each node will be sent the date to the server.Data from each node will be sent as JSON obejct and catch them in\n",
      "the server.\n",
      "In the back end ;\n",
      "1).MySQL\n",
      "2).Node.js\n",
      "Angular.js will use the for the front end.\n",
      "sensitive data in this system are as follows;\n",
      "1) Data which are coming from the factories should be protected.for example: owner may want to earn profits without considering damage to the environment. this can achieve only by maintaining the desired standards and the levels.therefore ,they might tend to change these value in to standards values in illegal ways.\n",
      "2).Information that are stored in the servers.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Attendance system https://cepdnaclk.github.io/e14-3yp-Automated-Attendance-system\n",
      "\n",
      "\n",
      "Automated Attendance system\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Attendance system\n",
      "Team\n",
      "E/14/018, ANURADHA WIJEWICKRAMA, e14018@ce.pdn.ac.lk\n",
      "E/14/068, DE SILVA N.G.M.H.K., e14068@ce.pdn.ac.lk\n",
      "E/14/243, SHEHAN DHINUKA, e14243@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "This project aims to automate the attendance procedure of an educational System using biometric technology. This replaces the traditional attendance marking methods to a fool Proof method.This will reduce the time spent in a lecture for attendance marking and increases the accuracy of the process.This will be a hand held device which is passed in the class while the lecture is going on. The students can simply place the finger over the sensor to mark the presence in their class.\n",
      "Solution Architecture\n",
      "CO321- Embedded Systems\n",
      "The fingerprint is recognized using a sensor. A LED display will be used to present the information about the student.\n",
      "CO324- Network and Web Applications\n",
      "Data (finger print) is transmitted to a centralized server and confirmation of the finger print with the relevant details will be transmitted back in real time. Controlling of the network traffic occurs when there is large number of classes and large number of students will be considered as a design task and it will be designed to reduce the drawbacks.\n",
      "CO325- Security\n",
      "The data that is transmitted should be encrypted so that no other party can access or modify the data.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Bike Sharing System https://cepdnaclk.github.io/e14-3yp-Automated-Bike-Sharing-System\n",
      "\n",
      "\n",
      "Automated Bike Sharing System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Bike Sharing System\n",
      "Team\n",
      "E/14/154, JAYASUNDARA J.M.S.M., e14154@ce.pdn.ac.lk\n",
      "E/14/141, IHALAGEDARA I.P.S.B., e14141@ce.pdn.ac.lk\n",
      "E/14/194, LOKUGE S.D., e14194@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "As the most of the universities have wide area of land, transportation within the university causes time waste, accidents, congestion because of using the private vehicles, parking problems and the energy consumption related to the mobility of workers and students of the universities. The bicycle sharing programs have received increasing attention in recent years with initiatives to increase bike usage,better meet the demand of a more mobile public and lessen the environmental impacts of our transportation activities. So the project aims to introduce automated bike sharing system to minimize above impacts while evaluating the mobility patterns of academic campuses and assessing the energy consumption and pollutant emissions produced by the universities. This system provides the users to unlock the\n",
      "chosen bicycle in the substations via a mobile app and start riding, check the availability of bicycles and authorized people to track the path of rides of all users.\n",
      "Due to the time limitation we are focusing only on smart locking system of bicycles and the mobile application.\n",
      "As this project is a Unified Project, the three aspects related to each subjects are as follows.\n",
      "CO321 : In the substations, the bicycles are locked using a smart lock and the rider have to unlock the chosen bicycle through a mobile app. Here we are using a QR code to open the each lock through the mobile app.\n",
      "CO324 : Each docks are considered as a node and they are connected to a another node placed in sub stations.Those nodes in the substation are connected to a centralized node. Each locks in the docks are controlled by the central server. The details of the each users are monitored at the central node. The locations of the bicycles are getting using the mobile app.\n",
      "CO325 : The details and data about each rider and the bicycle are sent through the system as encrypted data.\n",
      "Intro Video\n",
      "Solution Architecture\n",
      "Embedded System Designing\n",
      "Measuring and Controlling\n",
      "RFID reader and tags/stickers - To identify each bicycle is in the exact position and to identify the bicycle when returning to the dock station.\n",
      "Electric lock - To lock the bicycle\n",
      "Embedded Platform\n",
      "Arduino: Arduino\n",
      "is an open source computer hardware and software platform which is very easy to use. There are enough libraries and compatible modules which can connect to the arduino board. For serial communication we can have hardware serial ports or software serial ports. To control the locking mechanism there are digital I/O pins and ICSP pins.\n",
      "Connecting the system to the network\n",
      "Whole locking system will connect to internet using a GSM module\n",
      "Users will connect to the system using a Mobile App\n",
      "Peripheral devices\n",
      "RFID reader - used to read the RFID stickers in the bicycle. These stickers have a unique id which we use as the identification of bicycle. It is a 5V device, so you don’t need a external power source. ICSP pins are going to use for the communication between the reader and the arduino board.\n",
      "GSM module - used to connect with central server. TTL pins in GSM module will use to connect the module to Arduino board.\n",
      "A linear actuator - used in locking mechanism of the bikes. Digital I/O pins will be used to send control signals to the actuator.\n",
      "Limitations of peripheral devices\n",
      "There are various security problems with locking mechanism. Additional sensors have to use in order to make more secure.\n",
      "Web and Network Application Designing\n",
      "Protocols and Middleware\n",
      "HTTP - used to maintain the communication between dock stations and central server.\n",
      "I2C protocol - used to communicate between locks and the relay node.\n",
      "A central server - used to control the locks. A user scan the QR code in the lock and send the information with his login details to the server. Then the server will unlock the relevant lock and start to track the bicycle using the GPS system of the mobile using the given mobile app. It maintains a database of users and bicycles.\n",
      "Back End and Front End\n",
      "Back end\n",
      "Will use Node.js as the server side language\n",
      "Mongodb as database management system\n",
      "Heroku cloud application platform\n",
      "Front end\n",
      "Web interface for administrational usage\n",
      "HTML, CSS, Javascript\n",
      "Mobile Application\n",
      "Android studio\n",
      "Connecting components through APIs\n",
      "REST API\n",
      "Use to exchange information among components ( lock and mobile app)\n",
      "Google Maps API\n",
      "Will use to show to location of the bicycle\n",
      "Barcode API\n",
      "Will use to parse the QR code with different format\n",
      "Network Security\n",
      "Sensitive data\n",
      "Detail of users are stored in central server. Mobile app is used to login to the system. These login requests need to be secure.\n",
      "Passwords of users need to be stored in hash representation.\n",
      "Controlling responses from server should be secured\n",
      "Security features\n",
      "Encrypting the requests and responses.\n",
      "Encouraging users to use a strong password.\n",
      "Hardware and Software Designs\n",
      "Technologies used:\n",
      "React\n",
      "Redux\n",
      "Electron\n",
      "Material UI\n",
      "Overall system design\n",
      "Documents\n",
      "Project Report\n",
      "User Manual & Technical Note\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Electricity Billing System https://cepdnaclk.github.io/e14-3yp-Automated-Electricity-Billing-System\n",
      "\n",
      "\n",
      "Automated Electricity Billing System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Electricity Billing System\n",
      "Team\n",
      "E/14/018, ANURADHA WIJEWICKRAMA, e14018@ce.pdn.ac.lk\n",
      "E/14/068, DE SILVA N.G.M.H.K, e14018@ce.pdn.ac.lk\n",
      "E/14/243, Name, e14018@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "In present world embedded systems have become essential as every electronic and\n",
      "electrical day to day devices use the particular system for it's functionality.\n",
      "Here our target is to achieve an automated and centralized electricity billing system with more security and efficiency.\n",
      "Functionalities of the new system\n",
      "* Accurate meter reading\n",
      "* Can get update about the connection frequently\n",
      "* Digital display for customers\n",
      "* Customer can identify the trend of usage of the electricity\n",
      "Solution Architecture\n",
      "CO321\n",
      "-\n",
      "It's planned to implement a new device to measure the current,\n",
      "to transmit the data to the regional office and to display the certain facts to the customer using embedded systems.\n",
      "CO324\n",
      "-\n",
      "Data is to be transmitted to the regional office and from regional units then to a centralized server.\n",
      "CO325\n",
      "-\n",
      "Data has to be secured as a third party or the customer may try to alter. Device also has to be secured.\n",
      "Hardware and Software Designs\n",
      "Implementation of current measuring system\n",
      "When setting up the unique id display shows some relevent detalis\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Fishing Bot https://cepdnaclk.github.io/e14-3yp-Automated-Fishing-Bot\n",
      "\n",
      "\n",
      "Automated Fishing Bot\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Fishing Bot\n",
      "Team\n",
      "E/14/222, MEDAWATTE R.C., e14222@ce.pdn.ac.lk\n",
      "E/14/317, SENANAYAKE S.M.A.J., e14317@ce.pdn.ac.lk\n",
      "E/14/390, WIJEKOON D.W.M.M.P., e14390@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Fishery Industry has not always been friendly to fishermen. Identifying high density fishing areas, reaching there and spending hours to find and capture fish is just too much for a human being. Therefore, we are going to introduce a fishing bot. This bot will be able to handle above said difficulties and will help fishermen to expand fishing areas and monitor fishing information gathered which will eventually help the industry.\n",
      "Solution Architecture\n",
      "Hardware and Software Designs\n",
      "Hardware : includes Bots, Relay nodes and the Central Server\n",
      "Software : includes the website, Database, and a local interface for the relay node\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Greenhouse Fertilizing System https://cepdnaclk.github.io/e14-3yp-Automated-Greenhouse-Fertilizing-System\n",
      "\n",
      "\n",
      "Automated Greenhouse Fertilizing System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Greenhouse Fertilizing System\n",
      "Team\n",
      "E/14/287, R.M.K.D Rathnayake, e14287@ce.pdn.ac.lk\n",
      "E/14/335, K.R.W.R Subasinghe, e14335@ce.pdn.ac.lk\n",
      "E/14/402, G.A.A.M.B Wimalasena, e14402@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "This project aims to calculate the component(N , K , P) levels which are responsible for the growth of the plant in a real time basis and maintain the component level which is required for the relevant plant. Using this system we can increase the lifetime of a plant and can get the maximum harvest out of the plant.\n",
      "In the traditional system we won’t get the perfect component levels as we are not checking the current component level. (We are adding the same amount of water or fertilizers to the every plant irrespective of the component level in that plant).\n",
      "First using sensors we will get the current component level of each and every plant. Then the data will be transmitted to a centralized server. Then the server will check whether the component level of each plant are up to the required level. For different varities of plants the component levels are also differ. If a component level of a certain plant is not up to the required level the server will send a command\n",
      "to the automated pipeline system asking it to send the relevant amount of required components through the pipeline to the relevant plant.\n",
      "Solution Architecture\n",
      "Project Plan\n",
      "Embedded Systems Design\n",
      "PH sensors and Humidity sensors are used to measure the PH level and the humidity level of the soil in a particular plant.\n",
      "Temperature sensors are used to measure the temperature within the greenhouse.\n",
      "Node mcu is used to transfer data from the sensors to the server.\n",
      "Arduino uno will be used to control the fertilizer dispersion system.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automated Monitoring of Hospital Patients https://cepdnaclk.github.io/e14-3yp-Automated-Monitoring-of-Hospital-Patients\n",
      "\n",
      "\n",
      "Automated Monitoring of Hospital Patients\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automated Monitoring of Hospital Patients\n",
      "CHATHURANGI E.\tE/14/054\n",
      "WITHANAGE K.\tE/14/413\n",
      "DISSANAYAKE D.M.S.N.B\tE/14/084\n",
      "Team\n",
      "E/14/054, CHATHURANGI E., e14054@ce.pdn.ac.lk\n",
      "E/14/413, WITHANAGE K.\t, e14413@ce.pdn.ac.lk\n",
      "E/14/084, DISSANAYAKE D.M.S.N.B, e14084@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "This study develops a remote monitoring diagnostic framework to detect condition of patients in real-time which helps avoiding potential diseases.This system will be basically used in hospitals and medical centers. The proposed system has an embedded micro controller connected to a set of medical sensors (the sensors would differ according to the condition of the patient) and a wireless communication module (Bluetooth) . Each bed in the ward\n",
      "is considered as a node in a wireless sensor network and connected to a central node installed at the main monitoring location in the ward through an internet connection. The embedded micro controller checks if the patient health status is going well or not by analyzing the scanned medical signals. If even one of the sensing values goes out of the range, the monitoring system will indicate with an alarm that the particular patient is under a serious condition. If the condition is critical, then the system will automatically alarm the on-call doctor through a message. The medical report of each patient will be recorded separately and the overall details of each ward will be monitored by the hospital board. This system will be also helpful in reducing all the paper work done at hospitals as the records of each patient by the time he gets checked in till time he gets discharged will be recorded. The following aspects will be addressed by the system mainly.\n",
      "*Remote monitoring\n",
      "*Identifying emergency situations\n",
      "*Low cost\n",
      "*Data acquisition efficiency\n",
      "*Emergency data report\n",
      "*Scalability\n",
      "Solution Architecture\n",
      "Hardware and Software Designs\n",
      "Watch\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Automatic Speed Trap https://cepdnaclk.github.io/e14-3yp-Automatic-Speed-Trap\n",
      "\n",
      "\n",
      "Automatic Speed Trap\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Automatic Speed Trap\n",
      "Team\n",
      "E/14/349, THILAKARATHNA B.R.M., e14349@ce.pdn.ac.lk\n",
      "E/14/238, PATHIRAJA P.M.R.I., e14238@ce.pdn.ac.lk\n",
      "E/14/352, THILAKAWANSHA B.M.C.P., e14352@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Nowadays the transpotation is achieving developments in every alongside. Building highways and developing vehicles with new technologies are two side of developments. As a result of that, the vehicles could be achieved more speed than back days and this highspeed might causes unexpected accidents and might damage human life.\n",
      "So in this project we are expected to track the vehicle speed and if there any vehicle that travelling with more than maximum speed allowed, take a clear photo of the specific vehicle and send that to authorities to take further action.\n",
      "Solution Architecture\n",
      "CO321 - Using the embedded system we are expected to measure current speeed of the vehicles. And according to the pre-specified speed limit, check whether the vehicle travels with high speed and if then, using a specific carmera take a clear picture of the vehicle.\n",
      "CO324 - The photo that took on a specific vehicle, transmitted to a centralized server with the vehicle speed when it was captured. In addition to that few more details will be sent, such as date, time etc.\n",
      "CO325 - All the transmition are happeninig via encrypted method. Then any other parties cannot access and change the value.\n",
      "Hardware and Software Designs\n",
      "The overall design can be drawn as below.\n",
      "Here we have used an amplification system Doppler Sensor Module. That is because the output of the sensor is not enough to measure. The designed circuit and implementation\n",
      "are shown below.\n",
      "Documents\n",
      "Project Design\n",
      "User’s Manual\n",
      "Project Report\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Bus tracking system https://cepdnaclk.github.io/e14-3yp-Bus-tracking-system\n",
      "\n",
      "\n",
      "Bus tracking system\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Bus tracking system\n",
      "Team\n",
      "E/14/181, KAVINDA T.B.D.H., e14181@ce.pdn.ac.lk\n",
      "E/14/178, KARUNASINGHE Y.K., e14178@ce.pdn.ac.lk\n",
      "E/14/298, RUWANTHA J.M.D.J., e14298@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "A lot of people do not like to travel in crowded buses. We would love to travel sitting, sleeping. It will be very useful if there is a system to know whether the next bus on our route is full or not, to know the location of that bus, to know whether there are any alternative buses on route and etc.\n",
      "So we came up with a solution which is an embedded system and huge network of various devices. Real-time bus data, which comes from the bus tracking system, shows the expected time in minutes until the arrival of the relevant bus. Customers can view this anticipated arrival time at a location via an app, website or, where available on the public information display system at the bus stop.\n",
      "The main purpose in this idea is to check whether the buses are heavily loaded and late. So that if a person is willing to use another way of transportation, he can use that considering the information given by the system.\n",
      "After all, the collected data will be very valuable also. They can be used to analyse and check which route has heavy load of people, whether the time differences among buses should be adjusted and should there be more buses in a route in a particular time and any more.\n",
      "Solution Architecture\n",
      "CO321 – The relevant parameters will be measured using sensors such as IR, pressure sensors and GPS trackers and processed raw data using AVR controller.\n",
      "CO322 – The data will be transferred to a centralized server via Wi-Fi or using a GSM module. Those processed data can be viewed by an app or through a web interface.\n",
      "CO325 – The data will be sent encrypted not to have them seen by a third party before reaching the server.\n",
      "Hardware and Software Designs\n",
      "Project Proposal\n",
      "Project Design\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Control System for Heliostat Solar Power Plants https://cepdnaclk.github.io/e14-3yp-Control-System-for-Heliostat-Solar-Power-Plants\n",
      "\n",
      "\n",
      "Control System for Heliostat Solar Power Plants\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Control System for Heliostat Solar Power Plants\n",
      "Team\n",
      "E/14/233, NIROSHANA T.M.T., e14233@ce.pdn.ac.lk\n",
      "E/14/314, SENANAYAKA S.M.M.K.S , e14314@ce.pdn.ac.lk\n",
      "E/14/322, SENEVIRATHNE S.D., e14322@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "This is a system which focus sunlight into a one point in a solar tower and heat up the salts in it upto higher temperatures and then use them to store heat energy and produce steam and generate electricity. These systems make it possible to supply power even when the sun is down because of the stored heat energy. In these power plants, array of flat movable mirrors called heliostats are used to focus sunlight into a collector tower to heat salts and generate electricity through steam turbines. This is seen as\n",
      "a viable solution for renewable energy.\n",
      "Angle of heliostat is very critical in these solar power plants since the temperature of the tower will be significantly rely on the concentration of sunlight focused on it.\n",
      "Solution Architecture\n",
      "CO321 - The position of the sun is calculated by the local server in the solar tower and will be broadcast to the network via WiFi interface. Then the other nodes (heliostats) receives data and adjust them according to their relative position and give the control signals to the motors to rotate the heliostats. Initial inclination of the heliostats will be sensed through a gyroscope. So after a successful turn a feedback signal will be sent to the local server which could be used to sense malfunctions.\n",
      "CO324 - Usually these farms has nearly 2000 heliostats pointing one point. So sending a feedback to local server could induce a network conjunction. Data from the local server will be sent to the centralized server in real time or in short intervals from many farms owned by the same company throughout the country. So the network traffic which could occur in the systems will be considered in the design and it will be designed to minimize the drawbacks and control the overall MO of the system. Also the monitoring system can be used for maintenance scheduling by getting status feedbacks from the equipments, which adds an important feature to the implementation from adding network aspect.\n",
      "CO325 - The feedback data sent from local servers of the farms to the centralized server are sent as encrypted data as this implementation mainly focuses on R&D and the collected data is a valuable asset and they have a market value. Therefore, it needs to be encrypted and security becomes a key aspect in the implementation. Also the signals sent to each node is encrypted as outside parties can manipulate nodes to reduce the efficiency of the system by changing direction of the heliostats by giving wrong feedbacks.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Networked and Automated Weather Monitoring and Alerting System https://cepdnaclk.github.io/e14-3yp-Networked-and-Automated-Weather-Monitoring-and-Alerting-System\n",
      "\n",
      "\n",
      "Networked and Automated Weather Monitoring and Alerting System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Networked and Automated Weather Monitoring and Alerting System\n",
      "Team\n",
      "E/14/009, ADIKARI A.M.H.I., e14009@ce.pdn.ac.lk\n",
      "E/14/404, WITHANA S.S.P., e14404@ce.pdn.ac.lk\n",
      "E/14/410, DILSHAN I.D.H.I., e14410@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Weather conditions and climate changes must be logged and analyzed by relevant authorities like meteorological department each day. They take relevant actions observing those records obtained allover the island. But in the current manual system they collect information only from main cities and\n",
      "taking responses manually takes much time and effort.\n",
      "So in this unified project we develop a system that can be used to collect information from much many places allover Sri Lanka using an embedded system kept in those locations. The locations may be places in each district close to sea, rivers, reservoirs, tanks and other areas. The data are wind speed, rain status, rainfall, humidity, temperature etc.\n",
      "All those data taken from those sensors, are sent to a central server and processed there. If there are extreme weather cases, public must be warned. So the web application gives instant alerts to it’s users including relevant central authorities as well as regional authorities. The process is very quicker than manual method. So the damages due to extreme weather is reduced as well as meteorological department will have newest data from allover the country.\n",
      "Introduction Video\n",
      "Solution Architecture\n",
      "Embedded Systems Design\n",
      "What will you be measuring and/or controlling?\n",
      "In this unified project we develop a system that can be used to collect information from much many places allover Sri Lanka using an embedded system kept in those locations. The locations may be places in each district close to sea, rivers, reservoirs, tanks and other areas. The data are wind speed, wind direction, rainfall, humidity, temperature.\n",
      "Actually we are not going to control any physical quantity since weather cannot be controlled. We are only sensing the weather conditions and reporting.But we have few cases where it is needed to do an physical action based on the sensed data.That is the valve we use to remove water from rainfall-meter must be open only if water is filled and closed when water is removed totally.So the ultra-sonic sensor data is used to control the valve.\n",
      "What embedded systems platform(s) will you be using, and why?\n",
      "The combined embedded system will have following main sub parts.\n",
      "Wind Speed Sensing System - This is a wind Vane that rotates with wind. We are making a mechanism using IR sensor to get the time taken to complete a full cycle by vane. The wind speed is calculated using that data.\n",
      "Wind direction measuring System\n",
      "Rainfall measuring System - This has a cylindrical vessel with fixed cross section that collects rain water and measure the water level using an ultrasound sensor kept few cm below top of the vessel. Sensor not having at top most is to avoid water drops to go away hitting the sensor.\n",
      "Temperature and Humidity measuring System - This is a single sensor that sense temperature and humidity.\n",
      "Microcontroller - We use Atmega328p microcontroller for each node connecting all the above mentioned sub parts.\n",
      "How does the system connect to the network?\n",
      "System connects to network using GSM module. we use SIM808 module for that.\n",
      "What peripheral components will you be using, and how do they work? How do they interface\n",
      "IR sensor used in wind speed sensing, magnetometer used in wind direction sensing, ultra-sonic sensor used in rainfall sensing and also the temperature/humidity sensor will connect to the Arduino UNO board.\n",
      "The automatic valve used to remove water when needed will also connect to the Arduino Uno.\n",
      "The SIM808 will connect to serial ports of arduino UNO (using two PMW enabled digital pins and Software Serial library).\n",
      "What are the limitations of those components?\n",
      "The magnetometer we bought doesn’t give reliable readings as we expected. That is a limitation.\n",
      "The ultra-sonic sensor give reliable readings only when the water surface doesn’t shake.\n",
      "what workarounds can you come up with in order to deal with those limitations?\n",
      "We have to remove magnetometer from sensing. We need to use another technology to gain the wind direction.\n",
      "Web and Network Application Design\n",
      "What network protocols and middleware will you use, why, and how do they work?\n",
      "We use SIM808 GSM module as middleware and use HTTP protocol to send data.\n",
      "TCP/IP is used to get the connection.\n",
      "What back-end and front-end technologies will you use, and how do they work?\n",
      "Back-end technology is PHP and Front-end technology is HTML5. PHP used to get URL encoded data and to send data to database sing MYSQL queries.\n",
      "What APIs will you use when connecting different parts of the system?\n",
      "GoogleMap APIs are to be used in getting map services to the user interface.\n",
      "Computer and Network Security\n",
      "Are there any sensitive data in your system that need to be secured?\n",
      "All the data are weather related data. They must be protected from unauthorized changes.\n",
      "How might an unauthorized third party obtain data from your system?\n",
      "Unauthorized third party could access the data and has no problem. As the data are visible to anyone easily on the front end, no one will need to access data\n",
      "unethically.\n",
      "How might an unauthorized third party manipulate your system?\n",
      "Unauthorized third party should not be allowed to manipulate the system. Reliability and accuracy of data must be maintained.\n",
      "What security features are you able to implement, and how?\n",
      "As the very important data are sent to the central server from systems in rural places, the security of data is a fact to consider much. As stated by the examiners of Project Milestone 1 in comments, data encryption is not required in this case because we\n",
      "not need to hide data from anyone. Only thing we need is to protect data from being changed externally. So we are going to use MAC -Message authentication code for the requirement.\n",
      "Hardware and Software Designs\n",
      "Embedded system\n",
      "The combined embedded system will have 6 main sub parts.\n",
      "Wind Speed Sensing System\n",
      "This is a wind Vane that rotates with wind. We are making a mechanism using IR sensor to get the time taken to complete a full cycle by vane. The wind speed is calculated using that data.\n",
      "The model wind vane concept is given below.\n",
      "Infrared barrier module is the IR sensor we are planning to use. It emits infra red waves and monitor the reflected rays. It can identify black and white screens.\n",
      "Wind direction measuring System\n",
      "Wind direction is measured using a Vane that has a Triple-axis Magnetometer (Compass) Board - HMC5883L0\n",
      "Below is the model.\n",
      "Triple-axis Magnetometer (Compass) Board - HMC5883L is the sensor used to get the angle of rotation.\n",
      "Rainfall measuring System\n",
      "This has a cylindrical vessel with fixed cross section that collects rain water and measure the water level using an ultrasound sensor kept few cm below top of the vessel. Sensor not having at top most is to avoid water drops to go away hitting the sensor.\n",
      "Also this has a automatic valve to remove water daily after reporting to server, based on the sonar sensor reading.\n",
      "Also this has a rain sensor to identify whether it is raining or not.\n",
      "This is the ultrasonic sensor we are planning to use (HC-SR04)\n",
      "This is the automatic valve we are using. It is a plastic solenoid valve\n",
      "Temperature and Humidity measuring System\n",
      "This is a single sensor that sense temperature and humidity.\n",
      "For that we use Humidity and Temperature DHT11 Module\n",
      "Microcontroller\n",
      "We use Atmega328p microcontroller for each node connecting all the above mentioned sub parts.\n",
      "We will use ARDUINO UNO board which has Atmega328p microcontroller.\n",
      "Network Module\n",
      "As we need the embedded unit at places normally we can’t expect WIFI access, we decided to use a GSM module to send data collected to the central server.\n",
      "So the GSM module we are using is\n",
      "sim808 module.\n",
      "WEB APPLICATION\n",
      "We are sending the data collected in each time to the central database. we have implemented the database in 000webhost.com. So we are implementing a web application for users to view the data log using a user interface.\n",
      "We are sending data using protocol HTTP. HTTP GET request is used to send data. The microcontroler will send requests to the SIM808 as AT commands using serial port. Software Serial is used for that as digital pins are used for serial data sending.\n",
      "Front end will run HTML5 and back end will run PHP maintaining the connection with the database. MYSQL is used for database managing.\n",
      "User interface will allow users to view parameters rainfall, wind direction, wind speed, temperature, humidity based on map(current situation/latest) also based on time(history).\n",
      "This photo is an example image.\n",
      "The design of the Back End programme of the web application is given below.\n",
      "NETWORK SECURITY\n",
      "As the very important data are sent to the central server from systems in rural places, the security of data is a fact to consider much. As stated by the examiners of Project Milestone 1 in comments, data encryption is not required in this case because we\n",
      "not need to hide data from anyone. Only thing we need is to protect data from being changed externally. So we are going to use MAC-Message authentication code for the requirement.\n",
      "Rainfall measuring System\n",
      "Wind Speed Sensing System\n",
      "Demonstrations\n",
      "This is the video depicting the operation of GSM/GPRS module to send weather data to the server at 000webhost.com and how basic front end display it.\n",
      "This is a video demonstration of the functioning of the Embedded system including the sensors, GSM module and web application. All the sensors are working fine now. Only few are demonstrated in the video.\n",
      "Documents\n",
      "Project Report\n",
      "Design Document\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Real Time Water Qualtiy Measurement System https://cepdnaclk.github.io/e14-3yp-Real-Time-Water-Qualtiy-Measurement-System\n",
      "\n",
      "\n",
      "Real Time Water Qualtiy Measurement System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Real Time Water Qualtiy Measurement System\n",
      "Team\n",
      "E/14/142, INDIKA J.A.A., e14142@ce.pdn.ac.lk\n",
      "E/14/364, WARUSAMANA D.N., e14364@ce.pdn.ac.lk\n",
      "E/14/380, WELIKALA E.Y., e14380@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "The traditional method adopted by environmental authorities in measuring the quality of water is to collect water samples from various locations and send them to the laboratories for for analysis, but this is inefficient and ineffective as it is time consuming, wasting human labour, and not economical. To get a analysis by observing previous records will also be difficult in this technique. If real time monitoring is required, this method is unable to provide expected outcomes as it may not be possible to take samples and send them immediately to the laboratories for analysis.\n",
      "The system consists of several sensors located in remote locations to measure the water quality real time (most probably near water resources around industrial environments). The information received by sensors are sent to a centralized system which is monitoring the water quality measurement through GSM modules. These information can be sent at a predefined interval of time and they can be analyzed from the central monitoring system. Moreover, this system is only accessed by the authorized personnel only who works at environmental authorities. Hence, the system is secured with access restrictions.\n",
      "Main objectives are as follows\n",
      "Cost effective\n",
      "Time saving\n",
      "Remote monitoring and centralized controlling\n",
      "Higher scalability\n",
      "Higher security\n",
      "Easy Report generation for analysis\n",
      "Power efficient/ Power saving\n",
      "Overview\n",
      "These are the main subject areas to be covered in each course as this is a joint project.\n",
      "CO321 - Power efficiency is planned to control mainly through the embedded system. Since, this system is operating real time power consumption has to be controlled efficiently. Micro-controller based system is utilized for this purpose. Design has to be focused on power efficiency.\n",
      "CO324 - Information sensed through sensors are sent to the centralized system containing a central server which handles all the data received from various sensors located at different locations. Since information are sent through various nodes simultaneously, there will be a heavy network traffic and it has to be handled efficiently by techniques to handle them.\n",
      "CO325 - The system is only accessible by the officers working in the environmental authorities and data transactions are secured so that they cannot be retrieved or intercepted by third parties. Information authentication and verification, secure data transactions are the main issues regarding security.\n",
      "Solution Architecture\n",
      "Overview of Infrastructure:\n",
      "The qualities that can be measured vs qualities we wish to measure are as follows:\n",
      "According to the Central Environmental Authority (CEA) of Sri Lanka and Environmental Protection Agency(EPA) of United States of America these are the typical water quality parameters measured.\n",
      "pH\n",
      "Conductivity\n",
      "Temperature\n",
      "Turbidity\n",
      "Dissolved Oxygen (DO)\n",
      "BOD - Biological Oxygen Demand\n",
      "COD - Chemical Oxygen Demand\n",
      "Dissolved Heavy Metals and their concentrations\n",
      "Fully or partially dissolved organic and inorganic compounds and their concentrations\n",
      "From these only qualities from 1) to 4) can be measured in this project since rest of the qualities involve deep chemical analysis of samples.\n",
      "Embedded Systems Design\n",
      "pH value of water is measured using a pH probe and it is connected to an end node connected to the system.\n",
      "Temperature is measured using an LM35 temperature sensor\n",
      "Turbidity sensor has to be made manually. For that the amount of light traveled through the water is measured. Either an LED or a laser is used as a light source and it is measured\n",
      "using a photo diode/LDR and the levels are calibrated accordingly into levels.\n",
      "Conductivity is measured using two electrodes connected at an end node of the system.\n",
      "Atmega MCU is used at each node and it is used to manipulate the power consumption by each sensor. Further, it used to control all the peripherals connected to the end node.\n",
      "All the above components are connected to make a single end node of the system.\n",
      "Web and Network Application Design\n",
      "A GSM module connected at each end is used to communicate between the node and the central server.\n",
      "GPRS is used to transfer data packets from the end node to the central server via the Internet.\n",
      "TCP/UDP are used as Transport Layer protocols and IP is used as Network Layer Protocol.\n",
      "Back end\n",
      "The following technologies are used to develop the back end web application\n",
      "MySQL\n",
      "PHP or Node.js\n",
      "Front end\n",
      "HTML\n",
      "CSS\n",
      "JavaScript\n",
      "Bootstrap\n",
      "Computer and Network Security\n",
      "Sensitive data of this system include the following.\n",
      "1) Monitored data from each node - They have to be protected.For instance, an industry owner which may be releasing harmful substance to water resources may intercept the data transfer from a node situated in a water source near the industry and send fake data to cover up their actions\n",
      "2) User information stored in the central server\n",
      "3) Login requests to the central server\n",
      "Most of the above sensitive data can be encrypted to ensure security.\n",
      "Project overview video\n",
      "Documents\n",
      "A detailed description of infra structure\n",
      "User Manual\n",
      "Project Design\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting River water level and speed monitoring and alert system https://cepdnaclk.github.io/e14-3yp-River-water-level-and-speed-monitoring-and-alert-system\n",
      "\n",
      "\n",
      "River water level and speed monitoring and alert system\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "River water level and speed monitoring and alert system\n",
      "Team\n",
      "E/14/080, DILSHANI T.H.K., e14080@ce.pdn.ac.lk\n",
      "E/14/228, MUNASINGHE S.L., e14228@ce.pdn.ac.lk\n",
      "E/14/240, PAVITHYA M.B.D., e14240@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "This is a system that will monitor the water levels of a river/lake/stream and predicts the occurrence of a flood and generate an alert accordingly. This system would not only measure the water level but also the water velocity in order to give a better prediction of the risky situations.\n",
      "Background work\n",
      "Currently, this site gives an update of the river status of Sri Lanka. However this system is based on manually collected data and is updated only once per day. By constantly keeping track of this site we found that there are certain times that the system doesn’t output any data at all. Due to these reasons we proposed a sensor based flood alert system through water level and velocity monitoring.\n",
      "This project will be covering aspects from embedded systems (CO321), Network and web application design (CO324), Computer and network security (CO325)\n",
      "Intro Video\n",
      "Solution Architecture\n",
      "As this is a unified project, this project is consisted of aspects of embedded systems, networking and security.\n",
      "CO 321 - Sensors are used to measure the water level and to detect the speed of water flow. An equipment with the above mentioned capabilities would be built to analyse those parameters real time and to capture the data.\n",
      "CO 324 - The captured data would be sent to a centralized server in which a warning would be generated if a risk of a flood situation is seen.\n",
      "CO 325 - The network system should be encrypted and the alert system should be accessed only by the authorized personnel.\n",
      "Hardware and Software Designs\n",
      "Embedded Systems Design\n",
      "We would be measuring the water level of streams/rivers/lakes and the velocity of the water flow of such bodies. To measure the water level we are using ultra sonic sensors which should be implemented above the water body and the sensor would output the distance from that given body to the surface of the water. Through this we could check whether there’s a significant change in the water level by comparing this data with the pre-collected data. There were other sensing methods to get the water level but we chose ultra-sonic sensors as the best due to its accuracy when compared with other methods and its easy-maintainability since the components do not get in touch with the water (no rusting, less depreciation)\n",
      "The flow rate sensor has to be emerged somewhere below the surface (according to the principles of hydro physics as at this point a more accurate measurement regarding flow rate of a river could be obtained) The flow meter works on the principle of the Hall effect. According to the Hall effect, a voltage difference is induced in a conductor transverse to the electric current and the magnetic field perpendicular to it. Here, the Hall effect is utilized in the flow meter using a small fan/propeller-shaped rotor, which is placed in the path of the liquid flowing. The liquid pushes against the fins of the rotor, causing it to rotate. The shaft of the rotor is connected to a Hall effect sensor. It is an arrangement of a current flowing coil and a magnet connected to the shaft of the rotor, thus a voltage/pulse is induced as this rotor rotates. In this flow meter, for every liter of liquid passing through it per minute, it outputs about 4.5 pulses. This is due to the changing magnetic field caused by the magnet attached to the rotor shaft as seen in the picture below. We measure the number of pulses using a micro-controller.\n",
      "We chose Arduino UNO as the micro-controller because of its moderate price over other micro-controllers and because it serves our purpose. We just need to get the output signals of our sensors and some simple computations, so arduino UNO would suffice.\n",
      "We’d be also using an A7 GSM module to capture the signals from the micro-controller and to transfer these signals to the centralized server.\n",
      "Interface of the system\n",
      "Limitations\n",
      "Ultra-sonic sensor : The height from the surface to the fixed point can be obtained only with an accuracy of +-1cm. But since we do not need the minute changes of the water level and measure only the drastic changes, this error could be tolerated. With time, there might be a possibility to have a moisture layer on the face of the sensors and that’d change the density between the surface and might lead to erroneous results.\n",
      "Flow-rate sensor : Since the flow rate is embedded within a tube, the friction and the cohesive forces exerted by the walls of the tube would hinder obtaining the exact flow rate at the point. But since the velocity of a flowing water body is not uniform, there’s no point in trying to get the exact velocity. We can position the flow rate sensor in a place the maximum velocity could be measured (somewhere just beneath the surface) and that would be effective than getting the exact value since this measurement is going to be an average estimation of the velocity.\n",
      "Web and Network Application Design\n",
      "Protocols and middle ware\n",
      "Http/Https : To access the web application\n",
      "TCP/IP\n",
      "UDP : for DNS\n",
      "GPRS protocol\n",
      "Centralized web server: This centralized web server will maintain the main database and will be connecting to the web interface and the mobile application. The server should also manage the accounts of the administration.\n",
      "Back end technologies\n",
      "000Webhost(might switch to a cloud platform like heroku)\n",
      "Laravel\n",
      "Front end technologies\n",
      "Web Interface:\n",
      "HTML\n",
      "CSS\n",
      "Bootstrap\n",
      "JavaScript\n",
      "Mobile Application:\n",
      "Android Studio\n",
      "We’d be using Google maps API in the web interface in order to show the location based river status of the country.\n",
      "Computer and Network Security\n",
      "There are no sensitive data on our system,as anyone outside viewing the data won’t do any harm (since it is anyway accessible by the public through the web interface and the data contains only the measurement of water level and velocity) . But there should not be a\n",
      "possibility that any unauthorized 3rd party manipulating the data. The server protection should be taken into serious consideration and\n",
      "therefore authentication of the server could be done.\n",
      "Power Supply\n",
      "Threshold values\n",
      "The finalized threshold values used in the safety prediction application :\n",
      "In order to generate the danger alerts with respect to a river body, knowing the velocity alone won’t be sufficient. In order to give the maximum accuracy we are improving the system by taking many other factors into consideration. The safety of a river body would vary with aspects like depth and the level of height that is submerged by a man.\n",
      "In waist deep water it takes roughly 2-2.5 feet per second to push a man over a water body and in chest deep water it’s roughly about 1-1.5 feet per second.\n",
      "The threshold values may vary due to the depth of the water body also.\n",
      "Documents\n",
      "See for the attached pdf for the final Plan and design blue prints. This includes all the fine details regarding hardware design,network design,database design,the technologies used and the security aspects. This also covers the budget and the timeline plan.\n",
      "Project Plan\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Breathalyzer Test https://cepdnaclk.github.io/e14-3yp-Smart-Breathalyzer-Test\n",
      "\n",
      "\n",
      "Smart Breathalyzer Test\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Breathalyzer Test\n",
      "Team\n",
      "E/14/010, ADIKARI A.M.N.P., e14010@ce.pdn.ac.lk\n",
      "E/14/028, BANDARA D.M.N.T., e14028@ce.pdn.ac.lk\n",
      "E/14/065, DASSANAYAKA D.S.M.M.B., e14065@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "This project is mainly targeted for the Police Department in Sri Lanka. Until now they use conventional balloon test to identify drunk drivers. Providing an easy , efficient\n",
      "and more secure iot based solutions replacing old conventional method our aim is to reduce the chance of escaping such situations by bribing.\n",
      "Our project is to innovate a digital alcohol meter equipment communicating with a secured database-system with a user friendly GUI. We are aiming to produce two of such devices. These devices interact with the remote central server along with other local servers which will be located at regional police departments.These devices has their own ids. This method is fully automated such that the police officer has no any authority over the device. Once the police officer checks with the equipment the device automatically does everything to file a legal action against the drunk driver. And also we are developing our database such that only the higher level authority can interact with the informations. Once the data is sent to the remote server it sends a reply to the device requesting driver and vehicle informations which can be entered using the keypad included into the device itself. It is the only thing the police officer has to do.\n",
      "For this project basically we intend to use\n",
      "alcohol sensor for each device\n",
      "microcontroller (arduino)\n",
      "a keypad\n",
      "A GSM module\n",
      "Solution Architecture\n",
      "Embedded Systems Design\n",
      "Alcohol percentage in breath is measured using the MQ3 gas sensor which is calibrated to response to alcohol gas.\n",
      "Temperature and humidity sensors are used in the aim of getting accurate results in any changing environment.\n",
      "Design of the Smart breathalyzer device is completely innovated by us.\n",
      "Device is embedded with an Arduino uno, MQ3 sensor along with temperature and humidity sensors and a GSM/GPRS module to communicate with the server.\n",
      "A keypad, lcd display is attached to the module itself.\n",
      "Design templates and final outcome of the Embedded systems will be followed by this post.\n",
      "Web and Network Application Design\n",
      "A GSM module connected at each end is used to communicate between the device and the central server.\n",
      "GPRS is used to transfer data packets from the end node to the central server via the Internet.\n",
      "TCP is used as Transport Layer protocols and IP is used as Network Layer Protocol.\n",
      "Back end\n",
      "The following technologies are used to develop the back end web application\n",
      "Node.js with Express\n",
      "Free web hosting service like AWS\n",
      "Front end\n",
      "Javascript supported Frontend Framework such as Vue.js, AngularJS or REACT\n",
      "Computer and Network Security\n",
      "Driver License Number and Vehicle Number are the data that has to be sent to the central server from the device. Therefore there is not much security aspects involved in the device aspect.\n",
      "But when considering server\n",
      "No one should be able to edit, delete, or change data\n",
      "Accessing website should be secured (Only authorized persons should enter)\n",
      "Should establish a secure connection\n",
      "between device and server such that no any external device can enter data to server.\n",
      "Hardware and Software Designs\n",
      "Smart Breathalyzer Design\n",
      "3D Print Output\n",
      "Final Product Demo Video\n",
      "Documents\n",
      "Project Document\n",
      "Design Document\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Shopping Cart https://cepdnaclk.github.io/e14-3yp-Smart-Shopping-Cart\n",
      "\n",
      "\n",
      "Smart Shopping Cart\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Shopping Cart\n",
      "Team\n",
      "E/14/017, ANOJAN S., e14017@ce.pdn.ac.lk\n",
      "E/14/216, MAJURAGEERTHAN A., e14216@ce.pdn.ac.lk\n",
      "E/14/311, SANKEERTHAN K., e14311@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Trolleys are used in supermarket by customers in the modern world. but they remain in the same state without many improvements.\n",
      "Our target is to develop a smart trolley which satisfies all needful of customers.\n",
      "Intro Video\n",
      "OVERVIEW\n",
      "As this project is a Unified Project, aspects related to each subjects are as follows.\n",
      "CO321 - Sense bar code from product which are put in cart\n",
      "Show total bill , discounts , etc in LCD display which is attached in trolley.\n",
      "CO324 - When consumer put a product in cart, product’s\n",
      "bar code is sent to server in real time and server replay a description of that product for displaying in LCD.\n",
      "Offers and other details are also come from server to cart in real time.\n",
      "CO325 - There will be many carts in a super market. every cart has it’s own unique private key and communication between server and cart is fully encrypted.\n",
      "Solution Architecture\n",
      "Outline of the plan\n",
      "Scan the bar code of product.(customers will do it themself)\n",
      "Show price , offer details , total bills , reminders, paths , etc in the LCD display which is attached in the cart.\n",
      "All data are saved in branch server.\n",
      "If user accept to buy , then it will be added to user’s total bill.\n",
      "User can pay bill when leaving (Bill is already calculated in the cart).\n",
      "Hardware and Software Designs\n",
      "RFID\n",
      "Reader instead of Barcode Scanner\n",
      "Intial Project Plan we decided to use bracode to identify product,Now we have planned to replace barcode , continue project using RFID reader and tag attached Products.RFID has lot of issuses such as working in presence of electric field but some cases\n",
      "it is good to handle some situations, like counting and detecting no things in Shopping cart. It can read product id and product exp date and name.\n",
      "Documents\n",
      "Project Proposal\n",
      "Project Report\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Warehouse Monitoring for Paddy Storage https://cepdnaclk.github.io/e14-3yp-Smart-Warehouse-Monitoring-for-Paddy-Storage\n",
      "\n",
      "\n",
      "Smart Warehouse Monitoring for Paddy Storage\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Warehouse Monitoring for Paddy Storage\n",
      "Team\n",
      "E/14/336, SUCHINTHANA A.P.N., e14336@ce.pdn.ac.lk\n",
      "E/14/011, AGALAKUMBURA S.T., e14011@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Links\n",
      "Introduction\n",
      "Networked embedded systems have become\n",
      "quite important nowadays, especially for monitoring and control of distance and dislocated objects. This concept is applied in many fields in today as it increases the accuracy rather than controlling manually.\n",
      "Therefore we thought to implement a embedded system to monitor and control physical quantities of a rice paddy storage. Controlling such conditions precisely will ensure the best quality. This will helpful to the businessmen who having number of such stores in many locations as it is hard to control them manually. So by using this system they can operate it easily and being in any location.\n",
      "This system can be used in storage by changing the desired physical quantities.\n",
      "Features\n",
      "Monitoring and controlling physical quantities\n",
      "Automatically controlling physical quantities up to given preset value\n",
      "Maintaining a inventory system\n",
      "Project Complexity\n",
      "v\n",
      "Embedded system to\n",
      "Ø\n",
      "Sense the physical quantities\n",
      "Ø\n",
      "Control the physical quantities\n",
      "Ø\n",
      "Transfer data\n",
      "v\n",
      "Web interface to monitor and control manually.\n",
      "Each store have their own node and they are remotely operated.\n",
      "Solution Architecture\n",
      "·\n",
      "♦ CO321 – The desired quantities are measured using sensors and the values are transmitted through a micro-controller to the server and the monitoring system(on pre-defined time interval/ user request). Those conditions are automatically controlled up to preset value. Other than that quantities can be controlled manually.\n",
      "·\n",
      "♦ CO324 – Data from sensors and controllers are sent to a centralized server using GSM module as a SMS. Since there are many nodes, network traffic get high. It is concerned during design process to avoid drawbacks.\n",
      "·\n",
      "♦CO325 – The feedback data and control data is sent as encrypted to ensure the security. Otherwise any unauthorized parties can change the message(data) unethically. This can occur a huge loss. Therefore ensuring the security is must to have a good market value\n",
      "to our system.\n",
      "Hardware and Software Designs\n",
      "Detailed designs with many sub-sections\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Smart Waste Disposal Monitoring System https://cepdnaclk.github.io/e14-3yp-Smart-Waste-Disposal-Monitoring-System\n",
      "\n",
      "\n",
      "Smart Waste-Disposal Monitoring System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Smart Waste-Disposal Monitoring System\n",
      "Team\n",
      "E/14/122, Ahmedh J.R., e14122@ce.pdn.ac.lk\n",
      "E/14/213, Ariyarathna K.G.D. N., e14213@ce.pdn.ac.lk\n",
      "E/14/144, Jaseel M.I. A., e14144@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Waste management is one of the primary problem that the world faces irrespective of the case of developed or developing country. The key issue in the waste management is that the garbage bin at public places gets overflowed well in advance before the commencement of the next cleaning process. Sometime the garbage collector truck not sufficient for collecting all the garbage. These in turn leads to various hazards such as bad odor & ugliness to that place which may be the root cause for spread of various diseases. Another issue is in the waste management is having more trucks and human resources than needed. To avoid all such hazardous scenario and maintain public cleanliness and health this work is mounted on a smart garbage system.\n",
      "We are living in an age where tasks and systems are fusing together with the power of IOT to have a more efficient system of working and to execute jobs quickly! With all the power at our finger tips this is what we have come up with.\n",
      "The traditional way of manually monitoring the wastes in waste bins is a cumbersome process and utilizes more human effort, time and cost which can easily be avoided with our present technologies. The main theme of the work is to develop a smart intelligent garbage alert system for a proper garbage management. What our system does is it gives a real time indicator of the garbage level in a trashcan at any given time using weight and volume (solar) sensors. Using that data and as the bins are containing GSM module we can give an alert signal to the municipal web server then optimize waste collection efficient routes, sufficient number of trucks and labors. It allows trash collectors to plan their daily/weekly pick up schedule.\n",
      "Solution Architecture\n",
      "CO321 Embedded Systems:\n",
      "Garbage monitoring system detect the level of waste in the garbage bin and identify whether garbage bin is full or not by sensors. Location of the garbage bin will identify using GPS. After municipal send the truck to collect wastes from particular bin, a light indicator in bins switch on to inform the people that garbage collector trucks are on their way. Another light indicator in bins is used to inform the worker that the status of garbage bins.\n",
      "CO324 Network and Web Application Design:\n",
      "Send the data/message from garbage bins to municipal council to take relevant action. A summary report will send from municipal council to centralized server in main department within a period (per week/ per month).\n",
      "CO325 Computer and Network Security\n",
      "The data are sent by the controller in the garbage bin to the server. Database and network system is protected as it sent as encrypted data. Therefore third party couldn’t access and change the data.\n",
      "Hardware and Software Designs\n",
      "The basic Model works like so…\n",
      "We will first have to enter the height of the dustbin. This will help us to generate the percentage of trash in the trashcan. We then have two criterias which needs to be satisfied to show that the particular bin needs to be emptied :\n",
      "1.The amount of trash - let’s say if a bin is half full we don’t really need to empty it. Our thresh, or maximum amount that we permit of trash, is 75% of the bin.\n",
      "2.If supposing a particular trashcan fills up 20% and then for a week doesn’t change, it comes into our second criteria, time. With time even the little amount will start rotting leading to a smelly surrounding. To avoid that our tolerance level is 3 days, so if a trashcan is less than 75% but it is two days old it then will also need to be emptied.\n",
      "COMPONENTS IN OUR SYSTEM\n",
      "An ultrasonic sensor will be placed on the interior side of the lid, the one facing the solid waste. As trash increases, the distance between the ultrasonic and the trash decreases.\n",
      "An weight sensor will be placed on the bottom of the bin. Weight sensor detect the weight of the trash.\n",
      "This live data will be sent (distance & weight) to our microcontroller.\n",
      "Our micro- controller then processes the data and through the help of GSM/GPRS module sends it to an app (to MC).\n",
      "What the app does it visually represents the amount of trash in the bin with a small animation.\n",
      "This process will indicate all the bins which require attention, leading the user to take the most effective route.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Telepresence Robot https://cepdnaclk.github.io/e14-3yp-Telepresence-Robot\n",
      "\n",
      "\n",
      "Telepresence Robot\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Telepresence Robot\n",
      "Team\n",
      "E/14/262, Sanoj Punchihewa, e14262@ce.pdn.ac.lk\n",
      "E/14/305, Chandima B Samarasinghe, e14305@ce.pdn.ac.lk\n",
      "E/14/337, Yuvini Sumanasekera, e14337@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "A telepresence robot is a mobile, remote-controlled device that enables a person to be virtually present and to interact in a remote place. This project will be based upon developing such a robot for the department. With the use of interactive elements such as high definition audio and video, the robot will allow users (students/staff) to collaborate in person and remotely.\n",
      "Solution Architecture\n",
      "EMBEDDED SYSTEMS DESIGN\n",
      "What will you be measuring and/or controlling?\n",
      "Measuring/Inputs\n",
      "Ultrasonic Sensor: to measure the distance to the nearest obstacle in front of the robot.\n",
      "GPS Sensor: to track the robots position (assuming general purpose usage of the robot other than using inside the department)\n",
      "Microphone: to input voice signals.\n",
      "Web camera: to input video signals.\n",
      "Controlling\n",
      "Motor Controllers: to control the robots movement\n",
      "Servo Motor: to change the angle of the (camera+LCD screen)\n",
      "What embedded systems platform(s) will you be using, and why?\n",
      "Raspberry Pi 3 Model B\n",
      "To implement the controlling logic and all the softwares we are going to use high level programming languages such as Java and Python. It is required to choose a microcontroller capable of installing a OS like Linux.\n",
      "Has an inbuilt Wifi module.\n",
      "To control motor controllers, servos, ultrasonic sensors and other peripherals the raspberry pi has about 40 GPIO pins.\n",
      "To do real time full-duplex video+audio streaming, microcontroller with a high performance CPU is required.\n",
      "The robot includes a LCD screen. The cheap microcontrollers such as Arduino are not capable enough to produce required minimum frame rate, while the raspberry pi has dedicated GPU. Having a raspberry pi cut off the extra GPIO pin requirements of connecting the LCD as well.\n",
      "How does the system connect to the network?\n",
      "Primary:\n",
      "Using the inbuilt Wifi module, the robot will connect to the available department’s Wifi router to get access to the internet.\n",
      "Secondary:\n",
      "If for some reason Wifi is not available, the robot will connected to the internet using the GSM (module).\n",
      "Users:\n",
      "Users connect to the network using their END devices.\n",
      "What peripheral components will you be using, and how do they work?\n",
      "LCD Screen\n",
      "LCD screen will use to display the video of the user and to display the relevant information. This display will connect through the HDMI port of the raspberry pi. Power will be given through a suitable voltage regulator.\n",
      "Motor Controller (BTS7960 43A, Type: IBT_2) x 2\n",
      "Motors will draw huge current when in operation. In order to avoid drawing that current from the microcontroller pins these motor controllers are used. Motor controllers get power from the external power source and drive the motors according to the given signals by the GPIO pins connected to the microcontroller.\n",
      "Servo\n",
      "A servo is connected to the head section of the robot to change the angle of the head section (LCD+Camera+Mic…). Control signals to this servo is given through the GPIO pins and the power source is connected through a 6V voltage regulator.\n",
      "Ultrasonic Sensor (HC-SR04)\n",
      "Used to get the distance measurement to the nearest obstacle in front of the robot. Connected via the GPIO pins. Normally working current of these module is 15mA. Since the maximum current of a GPIO pin signal is 16mA (recommend 8mA), to be safe this module will also powered by the external power source through a 5V voltage regulator and only the control signals will give through GPIO pins.\n",
      "GSM module\n",
      "Will be using as the secondary method of connecting to the network. Control signals will give through GPIO pins. Power will give through a voltage regulator.\n",
      "GPS module\n",
      "Used to get the location data. Will connect through the GPIO pins. Power will be given through a suitable voltage regulator.\n",
      "Inbuilt WiFi module\n",
      "Primary method of connecting to the network.\n",
      "Web Camera\n",
      "Used to get the video input. Connected through the USB port of the raspberry pi.\n",
      "Speaker\n",
      "Will connect through the audio connection of the raspberry pi\n",
      "Mic\n",
      "Since there is no separate connector in raspberry pi to connect a mic, USB extension module will be used to connect a microphone to the raspberry pi.\n",
      "Hardware and Software Designs\n",
      "Conclusion\n",
      "#Issue\n",
      "Eventhough we successfully tested the peer-to-peer video streaming using default browser applications when it comes to integrating that into our java program we got to know that all the regular web components that we can use with java are not given permission to access resources like camera by the base implementation. Therefore, we have checked for the alternative web components and got to know that the only opensource web controller we can use with java is the CEF browser (chromium, JCEF) component. But, we had to build that from the source files before integrating that in our program. Eventhough, we were able to build that and run on amd64 architecture , we haven’t found clear explanations or successfull builds (or build methods) for arm architecture. Therefore, it seems to be integrating a browser component which can access to cameras in the java application itself seems to be rather difficult (or impossible) task.\n",
      "[we have used raspbian os in raspberry pi 3 b]\n",
      "#Possible Solutions\n",
      "01) Opening the video streaming mode using a regular browser (only for the video streaming mode)\n",
      "02) Using a different platform : (Android Things)\n",
      "The browser component we normally used in android application development can access to the resources like cameras. Therefore, we though of using android things os as our base os in our raspberry pi. Since, we are already familier with android application development we can develop the an andorid application for the bot.\n",
      "#The Solution we are currently working on : 2nd solution.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Train Movement Tracking and Level Crossing Safety Control https://cepdnaclk.github.io/e14-3yp-Train-Movement-Tracking-and-Level-Crossing-Safety-Control\n",
      "\n",
      "\n",
      "Train Movement Tracking and Level-Crossing Safety Control\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Train Movement Tracking and Level-Crossing Safety Control\n",
      "Team\n",
      "E/14/213, MAHALIYANA R.K., e14213@ce.pdn.ac.lk\n",
      "E/14/136, HETTIARACHCHI H.A.D.C., e14136@ce.pdn.ac.lk\n",
      "E/14/125, HASSANA A.L.F., e14125@ce.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Links\n",
      "Introduction\n",
      "Our project is to built a monitoring system for railways. In SriLanka, there is a traditional system to monitor trains in most of the stations. Usually from one station, they issue a device to the train and once that train reached to another station, train driver has to give that old device and get a new device from the newly reached station. Because of that, that train can be only monitored by the stations which are located along its path. So we intend to develop a system which can monitor all the trains from any where. As a feature of our system, we’ll add a railway gates controlling part.\n",
      "Solution Architecture\n",
      "Our system has a centralized sever. It monitors the trains and controls the gates. There are separate devices for those tasks. Basically we use GPS to get the locations of trains and continuous internet connection to feed the data to the server. If something happens to the GPS signals, there is a failsafe sensor for that. That sensor will trigger the gate controlling device when the train is in right position. That is how our system works.\n",
      "Hardware and Software Designs\n",
      "The GPS module that we are using for the project is Adafruit Wearable Ultimate GPS Module. The images will show you how its configured and the output.\n",
      "We have created a website for upload data and monitor the train. We hosted that website in 000webhost.com .\n",
      "This is the link for that site.\n",
      "Video - How our site works\n",
      "Video - Process\n",
      "Project Report\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting sleep apnea detection https://cepdnaclk.github.io/e14-3yp-sleep-apnea-detection\n",
      "\n",
      "\n",
      "Sleep Apnea Detection | e14-3yp-sleep-apnea-detection\n",
      "e14-3yp-sleep-apnea-detection\n",
      "Sleep Apnea Detection\n",
      "Objective\n",
      "Developing a 100% non intrusive method for detecting sleep apnea in infants.\n",
      "Approach\n",
      "A video feed is processed to detect the breathing pattern and then it is assessed for anomalies.\n",
      "Algorithms\n",
      "Canny edge detection, Center of graviry tracking, subspace filtering, adaptive filtering, maxima detection.\n",
      "Hardware\n",
      "Raspberry pi model 3 b\n",
      "Raspberry pi camera\n",
      "Software\n",
      "Python3, OpenCV\n",
      "People\n",
      "Gihan Jayatilaka , Harshana Weligampola , Suren Sritharan and Pankayaraj Pathmanathan developed this system as a course project for CO321 CO323 CO325.\n",
      "The project was supervised by Dr. Roshan Ragel and Dr.Isuru Nawinne .\n",
      "The embedded system was developed by Nuwan Jaliyagoda and Anupamali Willamuna.\n",
      "Acknowledgements\n",
      "Sanjaya Herath provided the hardware components. Dinidu Bhathiya provided a dataset.\n",
      "Future work (ideas)\n",
      "Identifying deafness in infants through behavioural analytics\n",
      "Identify risky behaviour of the baby (trying to climb out of the cot)\n",
      "Publications\n",
      "One algorithm developed in this project was published as G. Jayatilaka, H. Weligampola, S. Sritharan, P. Pathmanathan, R. Ragel and I. Nawinne, “Non-contact Infant Sleep Apnea Detection,” 2019 14th Conference on Industrial and Information Systems (ICIIS), Kandy, Sri Lanka, 2019, pp. 260-265, doi: 10.1109/ICIIS47346.2019.9063269.\n",
      "arXiv preprint arXiv:1910.04725.\n",
      "You may cite this work as,\n",
      "<pre>\n",
      "@INPROCEEDINGS{non-intrusive-sleep-apnea-detection,\n",
      "author={G. {Jayatilaka} and H. {Weligampola} and S. {Sritharan} and P. {Pathmanathan} and R. {Ragel} and I. {Nawinne}},\n",
      "booktitle={2019 14th Conference on Industrial and Information Systems (ICIIS)},\n",
      "title={Non-contact Infant Sleep Apnea Detection},\n",
      "year={2019},\n",
      "volume={},\n",
      "number={},\n",
      "pages={260-265},}\n",
      "</pre>\n",
      "\n",
      "\n",
      "Extracting Covid Tracer https://cepdnaclk.github.io/e17-3yp-Covid-Tracer\n",
      "\n",
      "\n",
      "Covid Tracer\n",
      "Covid Tracer\n",
      "Home\n",
      "About\n",
      "Features\n",
      "Solution Architecture\n",
      "High Level\n",
      "Hardware\n",
      "Security\n",
      "Budget\n",
      "Timeline\n",
      "Development\n",
      "Software\n",
      "Hardware\n",
      "Testing\n",
      "Team\n",
      "Autonomous Covid-19 Tracking System\n",
      "For a Well Aware and Safe Sri Lanka\n",
      "Project Repo\n",
      "Covid-19\n",
      "New Normal Situation due to the Pandemic\n",
      "Get Started\n",
      "Introduction\n",
      "Overview\n",
      "The Covid-19 Pandemic is the defining Global Health Crisis of the contemporary society. Since its emergence in late\n",
      "2019, the virus has spread across the entire world and led to a dramatic loss of human life. The economic and social\n",
      "disruption caused by the pandemic is devastating. Almost every sector is affected by this pandemic. In addition,\n",
      "this prevailing situation has raised unprecedented challenges to the daily routines of the people. While taking\n",
      "immense measures on infect diagnosis, Corona Virus treatments and controlling the spread of the disease a reasonable\n",
      "focus should be given to how we adjust to this new normal situation.\n",
      "When will the world be free of Covid? is an unanswered question. Our focus is to make the new normal situation due\n",
      "to Covid easily adjustable for the people while making their lives safe.\n",
      "Real World Problem\n",
      "Due to the prevailing pandemic situation people have a responsibility of providing accurate details of themselves at\n",
      "entrances of various commercial places like shopping malls, banks etc. and get their temperatures checked and accepted\n",
      "before entering. This situation is currently handled manually by people writing details on a book at entrances of various places.\n",
      "Some major issues with this system includes:\n",
      "Inefficient thus time consuming\n",
      "Risk of getting infected by everyone touching same stationary is high\n",
      "Details get blot by touching with wet hands after washing or sanitizing\n",
      "Personal details of people are publicly made available\n",
      "High probability for the guard at the entrance checking temperatures to get in contact with infects\n",
      "People providing inaccurate data, neglecting providing details and getting the temperature checked\n",
      "Inability to detect people under quarantine\n",
      "Inability to keep track of infected percentages of the locations visited\n",
      "Adhering to workplace safety and health practices and ensuring access to decent work and the protection of labour rights\n",
      "in all industries will be crucial in addressing the human dimension of the crisis.\n",
      "Features of our system\n",
      "Computerized system\n",
      "Covid-19 management software with computerized database system for the Government. This is also mainly used for demonstrating how over system gets latest\n",
      "covid information from the Government Authorities through a REST API\n",
      "Autonomous detail entering and temperature checking\n",
      "Details about the person will be entered to the system by scanning the barcode of NIC/ QR scanning, system will detect if the\n",
      "person is under quarantine. The temperature will be measured using sensors. These temperature measurements along\n",
      "with the visited location will be sent to the server and stored for a 2 weeks period. Your privacy will be highly protected\n",
      "Automated door opening\n",
      "This comes as an optional feature of our system. If certain satisfactory conditions are met like quarantine status, max\n",
      "temperature level then the doors will be opened automatically\n",
      "Covid tracking\n",
      "Check about reported infects of a particular location as a percentage before visiting.\n",
      "Our system will also keep records about the visited locations of a person for a period of 2 weeks. Infect percentages\n",
      "of these locations reported later will be tracked\n",
      "Website\n",
      "Local community can visit our website to view covid related information like daily/cumulative cases and deaths, infect percentages\n",
      "of areas. A seperate user login will be provided to view personal details like temperate fluctuations using data obtained\n",
      "at entrances, infect percentages of the locations visited for a period of 2 weeks\n",
      "Mobile app\n",
      "Similar interface as the website. This is designed for the easy use at the comfort of a mobile phone.\n",
      "High Level System\n",
      "Description\n",
      "Our system can be described in four segments.\n",
      "A software for data entering, data representing along with a computerized database system will be provided to the\n",
      "Government Authorities. They maintain detailed Covid related information like infects, pcr test reports,people under quarantine etc. in their\n",
      "server system. Our database system will be updated on certain intervals with the Government Server through a REST API.\n",
      "Our server system will be deployed in the cloud. We will keep information about people's NIC numbers,\n",
      "addresses, contact numbers, visited locations, temperature readings obtained at various entrances etc. Various calculations on data\n",
      "for example infect percentages will be done on a cloud virtual environment\n",
      "Commercial Merchants including shopping malls, banks etc. will be provided with an embedded system\n",
      "device based on a micro-controller. People can scan their IDs before entering and the system will check with the servers if the\n",
      "person's under quarantine. The temperature will be measured by contact-less sensors and checked if satisfactory. Whether the person\n",
      "is allowed to enter or not will be notified using LED displays and buzzers. ID number along with the temperature and location will be stored\n",
      "in our servers for a 2 week period. Therefore merchants don't have the burden of handling customer details. At the same time\n",
      "people don't have to provide their details publicly. Commercial merchants have the choice of implementing our door system which will\n",
      "be opened automatically based on the customer's conditions\n",
      "The local community will be provided with a website as well as a mobile app. They can visit our website/app to\n",
      "view general Covid related information in the country eg: daily/cumulative cases and deaths, infect persentages of different areas. A seperate\n",
      "user login is provided to view personal data eg: infect percentage reported later of visited locations, temperature fluctuations,\n",
      "general health alerts released by Government eg: vaccinating dates in different areas as well as user specific health alerts\n",
      "Embedded Hardware Device\n",
      "Microcontroller\n",
      "Microcontroller is the base of our device and it should accomplish several task at the same time.\n",
      "Hence, having a dual core processor in the microcontroller will be efficient to handle those tasks\n",
      "seperately. Low power consuption is a major concern as it is active 24x7 mostly.\n",
      "Modules\n",
      "GSM module\n",
      "GSM module(SIM 800L) supports a sim card to connect with server using 2G mobile data as a backup option when\n",
      "wifi is not available.\n",
      "External Flash Memory\n",
      "W25Q32(4MB) model is used as the external flash memory to increase the scalability of the device. As the system has to check with\n",
      "the cloud server whether the person is quarantined or not for each person, and since the server gets such requests from\n",
      "all over the country, the efficiency and scalability will be less. Therefore a local caching system will keep a list of quarantined people in there are,\n",
      "Thus only the information that is not available to the device can be requested from the server.\n",
      "Battery\n",
      "The device contains an internal rechargeable battery to keep the device active in case of\n",
      "power failures.\n",
      "Sensors\n",
      "IR Sensor\n",
      "Contactless IR sensor is used to detect the body temperature.\n",
      "Ultrasonic Sensor\n",
      "This sensor is used to detect the distance from IR sensor to hand and to the execution of sanitizing unit.\n",
      "Barcode Scanner\n",
      "Gm66 model 2D barcode reader is used to read the barcode in the ID card.\n",
      "Actuators\n",
      "Piezo Buzzer\n",
      "A piezo buzzer is used to indicate that certain process is successfully done or not.\n",
      "LCD Display\n",
      "The result of each process is dispalyed on the LCD.\n",
      "Security Aspects\n",
      "Why is it important?\n",
      "For any system it's crucial to pay attention to the security aspects. No system can be automatically immune.\n",
      "If we don’t consider this seriously, the impact and recoveries can be very expensive. Looking from the perspective of the CIA triad,\n",
      "Availability is necessary because the system mostly works 24/7 and the whole entrace system of the country depends on it.\n",
      "If the system is not available the effects can be very significant.\n",
      "Confidentiality also plays a major role as we handle sensitive data. Only the authorized people should be able to see the data.\n",
      "Integrity is necessary because if the data is modified without the knowledge of authorized people, it can break trust of people\n",
      "towards the system. Imagine providing inaccurate health details to people!\n",
      "what are the sensitive data that needs to be secured?\n",
      "Any system that handles PII(Personally Identifiable Information) or SPII(Sensitive Personally Identifiable Information) or any Health Care data, are legally obligated to protect these data.\n",
      "If these information are compromised it can lead to devastating consequences like identity theft incidents, high risk of damage to a individual, loss of\n",
      "trust on the system and many more.\n",
      "There are many international guidlines such a system needs to adhere to. For example GDPR(General Data Protection Regulation), HIPAA(Health Insurance Portability and Accountability Act)\n",
      "Our system keeps personal details about people like full name, NIC, address, contact details, locations they have visited, health details like temperatures and oxygen levels. These data have high criticality. When such system is deployed,\n",
      "many attackers try to play with the data since the data can be of interest to many. For example if a person can access to someone else's mobile app, he can checkin to places pretending to be someone else.\n",
      "If our database is compromised it can lead to a data breach which will expose all the PII details of the community.\n",
      "This can even result in Ransomware attacks.\n",
      "Budget\n",
      "Item\n",
      "ESP32 30-pin DOIT Board\n",
      "External Flash(W25Q32)\n",
      "Ultrasonic sensor(HC-SR04)\n",
      "Barcode reader(GM66)\n",
      "IR temperature sensor(MLX90614)\n",
      "Piezo buzzer\n",
      "16x2 LCD\n",
      "Power Supply Module\n",
      "9V AC/DC Adapter\n",
      "Transistor\n",
      "Water Pump\n",
      "Nozzle\n",
      "ESP32 Antena\n",
      "Rechargable battery\n",
      "***\n",
      "Quantity\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "***\n",
      "Unit Cost\n",
      "2400.00\n",
      "300.00\n",
      "200.00\n",
      "5000.00\n",
      "3000.00\n",
      "30.00\n",
      "320.00\n",
      "1100.00\n",
      "750.00\n",
      "130.00\n",
      "300.00\n",
      "180.00\n",
      "220.00\n",
      "1200.00\n",
      "Total\n",
      "Total\n",
      "2400.00\n",
      "300.00\n",
      "400.00\n",
      "5000.00\n",
      "3000.00\n",
      "30.00\n",
      "320.00\n",
      "1100.00\n",
      "750.00\n",
      "130.00\n",
      "300.00\n",
      "360.00\n",
      "220.00\n",
      "1200.00\n",
      "15510\n",
      "Timeline\n",
      "Our Team\n",
      "Kenath Perera\n",
      "E/17/252\n",
      "Deanna Coralage\n",
      "E/17/044\n",
      "Ruchika Perera\n",
      "E/17/242\n",
      "Our Supervisors\n",
      "Dr. Isuru Nawinne\n",
      "Senior Lecturer\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Senior Lecturer\n",
      "Covid Tracer\n",
      "We are a group of undergraduates from Department of Computer Engineering, University of Peradeniya.\n",
      "This system was implemented as our third year project\n",
      "----------------------------------- Links\n",
      "Project Repo\n",
      "Department Projects\n",
      "Department of Computer Engineering\n",
      "-----------------------------------\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "© Copyright eBusiness. All Rights Reserved\n",
      "Designed by BootstrapMade\n",
      "\n",
      "\n",
      "Extracting E Parking System https://cepdnaclk.github.io/e17-3yp-E-Parking-System\n",
      "\n",
      "\n",
      "E-parking system\n",
      "QuickPark\n",
      "Menu\n",
      "Home\n",
      "About\n",
      "Design\n",
      "Progress\n",
      "Development\n",
      "3D Models\n",
      "The Fastest & Easiest Way To Manage Your Parking Lot\n",
      "Assign parking spots and manage payments with ease\n",
      "Project Repository\n",
      "About us\n",
      "The motivation behind our product\n",
      "Urbanization has led to quick and efficient parking being vital.\n",
      "Human-operated parking lots have a lot of inherent flaws.\n",
      "An autonomous parking system could address these issues effectively.\n",
      "Why choose our product\n",
      "Manual systems are highly inefficient and leads to long queues and waiting times.\n",
      "It is difficult to manage the allocation of parking spaces.\n",
      "Owners cannot easily get an idea of the overall status.\n",
      "Our objective\n",
      "We aim at eliminating the overheads and inefficiencies associated with manual parking systems to provide a comprehensive solution that addresses the concerns of both the consumers as well as the owners of the parking lot.\n",
      "Features\n",
      "Key Features Of Our Product\n",
      "Reservation of parking spots\n",
      "Make reservations in advance and save time\n",
      "Providing directions to assigned spots\n",
      "Get directions with our mobile app\n",
      "Payments made easy\n",
      "Register through our mobile app for payments\n",
      "Bird’s-eye view of parking lot\n",
      "Parking lot owners can manage with ease and collect usage statistics\n",
      "Progress\n",
      "Product Timeline\n",
      "Week 7-8:Backend Design\n",
      "Week 9-10:Hardware design\n",
      "Week 11:UI and algorithm designs\n",
      "Week 12-14:App development\n",
      "Week 15:Cloud deployment\n",
      "Week 16:Integration\n",
      "Week 17-18:Testing\n",
      "Introduction\n",
      "Product Demo\n",
      "QuickPark\n",
      "An autonomous system for assigning and managing parking spots and processing payments in a car park.\n",
      "Team Members\n",
      "E/17/296 Ravisha Rupasinghe\n",
      "E/17/251 Sandun Sanjaya Perera\n",
      "E/17/018 Imesh Balasuriya\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Related Links\n",
      "Project Page\n",
      "Department Website\n",
      "Faculty Website\n",
      "Copyright ©2022 All rights reserved.\n",
      "\n",
      "\n",
      "Extracting Landmine Detector https://cepdnaclk.github.io/e17-3yp-Landmine-Detector\n",
      "\n",
      "\n",
      "React AppYou need to enable JavaScript to run this app.IntroductionSolution ArchitectureHardware DesignSoftware DesignTestingBudgetTimelineTeamLandmine Detection RobotLandmine DetectorIntroductionAboutLandmines are prominent weapons designed to destroy or disable enemy targets which detonate by the movement of its target, pressure, sound, magnetism and vibration. More than a hundred million land mines are scattered around the world which remain hazardous for years even after conflict termination posing a significant threat to civilians and the economy. More Effective and sophisticated tools to detect, locate and deactivate landmines are urgently needed to make lands safer for humans to use.ProblemCurrently available demining methods which include humanitarian and mechanical demining utilize manual prodders or metal detectors operated by humans and mine clearing machines respectively to detect the location of mines. This conventional methods are labor intensive, expensive, time consuming and possess high risk for the humans and machines involved in the process.SolutionWe introduce 'The Landmine Detection Robot' that accurately detects mines through sensors and send the GPS coordinates of the specific locations where mines are located to the server where a map of the mine field is updated. The deployment of multiple Mine Detection Robots to the mine field facilitates finding a safe pathway through the mine fields safely and efficiently without any human involvement making the challenging process of demining easier than ever.Solution ArchitectureWeb ApplicationThe Web Applciation is hosted using Amplify Serverless methods. Acts as the access point for all the users in the User Groups. After logging in users can access either modular front page for controling a spcific robot or User Admin Page related to a group who has all data access.Considering control page for a specific robot a detail entry point and control options will be available along with graphical representation of search area maps.Automated RobotIs the main hardware component of the project. Includes a core functionality of landmine detection, autonoumus navigation and data exchange. Accoring to tha main data flow the key aspects of the robot will be, accepting cordinates from server, storing a data structures to maintain search area details, passive landmine detection while navigatting through the path while updating the data and sending back data to the servers.Web ServerThe backend servers acts as an immediate between the hardware component and user all while doing essential tasks of data storing , calculating parameters and orgainzing inputs and outputs. When the inital inputs received from user server cloud functions would calculate intial boundaries for search area and relevent parameters for setting up the search.Once the search starts the robot updates data stored here to give a real time like data accessability for the users.DATA FLOWData Flow Generation at the user interfaceInserts GPS cordinates\n",
      "along with a search area. The data will be sent to the servers as raw inputWhen recieved cloud functions would run within the backend to calculate relevent boundaries of given search area in the real environmentThese values will be stored at the servers and at the same time send calculated values to the robot through the established networkWhen received a data structure would be created within the Robot to keep track of the path it travelled, Landmine locations, boundaries.While travelling the details of the search would first be stored at the local data structure. Then with timed HTTP requests would send the updates of the data to the backendThe received values would get stored at the servers, and also providing read access to the webserver for the updated dataWhen data received a virtual map drawn to represent the location data gets drwan at the user interface. Providing visual\n",
      "and informative data to the userSTATE DIAGRAMER DIAGRAMRELATIONAL SCHEMAHardware DesignMetal DetectorOur design of the metal detector will be built using the collpits oscillator circuit.The circuit provides a constant oscillation by a feedback loop and is in the range of 100kHz.The oscillation will be fed into an atmel (atmega328p) chip.When detected would case an interrupt.Calibrating the strength of the metal detector can be done by changing the current through the inductior (achieved by changing the supply voltage) or changing the number of wraps aroud the coil.Obstacle DetectionObstacles detected using Ultra-Sonic sensorsDirectly using the sensors gives somewhat accurate results but can deviate from actual value due to temperature and humidity.The landmine detector is an outdoor robot which means the values can change.To resolve this issue we add temperature and humidity compensation to distance calculated.DHT11 humisity and temperature sensor is used to get required values.Navigation and LocationingMainly done by using the Neo8M GPS module and the GY80 IMU.Through the sensors we get the position, direction, and orientation of the robot.In the event of obstacle or landmine detected locations of these would be stored and sent back to the server.Calculation of an alternative path will happen avoiding obstructions. Motor DriverThe motors will be driven by L298N motor driver.GY80 's sensors and encoders would provide requierd feedback for motor controlling.Selecting motors where done for our requirements of,Weight\n",
      ": 5kgNo of Motors\n",
      ": 4Radius\n",
      ": 0.045m(4.5cm)Velocity\n",
      ": 0.5m/sMax incline\n",
      ": 30[deg]Supply Voltage : 12VDesired Acc\n",
      ": 0.1m/s2Weight : 5kgOperating Time : 1.5hrsTheroetical values of a motor providing for above requirements,RPM\n",
      ": 150RPMTorque\n",
      ": 0.4NmTotal Power\n",
      ": 4.8WMax Current\n",
      ": 0.4ABattery Req\n",
      ": 1.6AhMetal DetectorOur design of the metal detector will be built using the collpits oscillator circuit.The circuit provides a constant oscillation by a feedback loop and is in the range of 100kHz.The oscillation will be fed into an atmel (atmega328p) chip.When detected would case an interrupt.Calibrating the strength of the metal detector can be done by changing the current through the inductior (achieved by changing the supply voltage) or changing the number of wraps aroud the coil.Obstacle DetectionObstacles detected using Ultra-Sonic sensorsDirectly using the sensors gives somewhat accurate results but can deviate from actual value due to temperature and humidity.The landmine detector is an outdoor robot which means the values can change.To resolve this issue we add temperature and humidity compensation to distance calculated.DHT11 humisity and temperature sensor is used to get required values.ConnectionsThe robot has a main I2C bus connecting two masters and sensors as slaves. Also an atmel chip is used as a slave for controlling motors and interrupt generator for the metal detector. One aster being the ESP32 handles the calculations while the second master the atmel chip is responsible for communiation and data buffering. The data would be stored in an SD card using the SPI conncetion protocol. Communication happens through the SIM900A GSM module using the UART protocol.PowerThere are three main power lines within the robot. A 5V power line for some sensors that require it and a 3.3V power line for specific components which needs it for optimum performance. Such as the ESP32 , GY80 and the NEO8M. The dedicated 12V would be for the motors and the metal detector. The power for the whole system will be provided using a LiPo 12V 10000mAh battery and voltage regulators will be used to get required voltages.Software Designcloud architectureUser is interacted with our front end which is hosted in AWS amplify. Authentication and authorization happen using cognito pools and identity groups. In the event of creating a user a lambda function is called to sign up a user to a relevant group. With authorized credentials the user calls the API to initiate a new search. The input values are stored in the database and at the same time lambda function is called to publish the data to a topic in the IoT core. Then the robots which are subscribed to the same topic receive data via the MQTT protocol. Returned data from the robot will be published using MQTT and using IoT rule by which the data can be processed. Once the data is received, an aws lambda function will trigger and check for identity and access of the robot and call the API to store the data into the database. And at the same time data is sent to the user.UI designsLogin UItwo-step verificationUser InterfaceHistoryProfileTestingAPI Postman Used to test GraphQL API calls to check for authorization, data manupilation, data type integration. Requests are sent using API keys to validate the requests. Used to tesst Appsync Graph QL requests. Helpful for accessing data elements with varying authorization levels.Lambda function Important when using a serverless architecture. Used to execute functions of servers. Currenctly all defined lambda functions in the system are running on node js. Tests are done to verify authorization roles and accessebility of data on trigger ro function call.Hardware Integration Mqtt Explorer used here to emulate node hardware behaviour. Check for viablity on mqtt messages passed to and from node hardware. Also to check for neccessary trigger aexecution. BudgetComponent Unit Price(Rs.)QuantityPriceESP32150011500Atmega328p75021500NEO8M-GPS219012190GSM Module195011950GY80 - IMU280012800Motors 150RPM150046000Tires Chassis and other robot components500015000DT1110001 1000Ultrasonic sensors(HCSR04)2503750Copper wire2501 (10m)250Resistors capacitors and other components500150012V battery LiPo500015000Total28440Timeline22 July 2021Milestone 1Project Proposal03 September 2021Milestone 2Designs of Hardware and SoftwareFull data and control flowGetting familiar with technologies.Milestone 3Implementation of Backend.Implementation of Frontend.Software Testing.Milestone 4PCB designs of circuits.Prototype & Testing3D Models for Robot.Milestone 5Complete Working SystemTeamAkila Karunanayake  Thisara Manohara  Vishva Navanjana  SupervisorsDr. Isuru Nawinne    Dr. Mahanama Wickramasinghe    Contact UsAkila KarunanayakePhone:\n",
      "+94 81 239 33 00 Thisara ManoharaPhone:\n",
      "+94 81 239 33 00 Vishva NavanjanaPhone:\n",
      "+94 81 239 33 00 University of PeradeniyaPhone:\n",
      "+94 81 239 33 00 Web-site:http://www.pdn.ac.lk/Faculty of EngineeringPhone:\n",
      "+94 81 239 33 02 Web-site:http://eng.pdn.ac.lk/Computer Engineering DepartmentPhone:\n",
      "+94 81 239 39 14 Web-site:http://www.ce.pdn.ac.lk/© 2022 LANDMINE DETECTOR | All right reserved | Terms of Service | Privacy\n",
      "\n",
      "\n",
      "Extracting Milk Testing and Collecting System https://cepdnaclk.github.io/e17-3yp-Milk-Testing-and-Collecting-System\n",
      "\n",
      "\n",
      "Milk-Testing-&-Collecting-System\n",
      "MilkTab\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Designs\n",
      "Designs\n",
      "Mobile User Interfaces\n",
      "Admin Panel Interfaces\n",
      "Hardware Designs\n",
      "Security\n",
      "Others\n",
      "Others\n",
      "Testing\n",
      "Timeline\n",
      "Budget\n",
      "Team\n",
      "Git Repository\n",
      "Milk-Testing & Collecting-System\n",
      "Introducing technology oriented milk collecting platform with a better way of testing milk.\n",
      "Easy usage\n",
      "Portabale\n",
      "Low Power consumption\n",
      "Detects milk adulterants\n",
      "Get Started\n",
      "Introduction\n",
      "View Introduction video\n",
      "The Problem\n",
      "In dairy industry, dairy collectors measure only few parameters when buying milk from dairy farmers. But, they usually don't measure quality parameters like fat content, acidity etc of milk at that spot. Also the financial deals are happening\n",
      "in a traditional way. The quality is very important in dairy related products. Currently small scale manufacturers do not use technology based methods to measure the quality of milk. They just use organoleptic tests such as smell and\n",
      "visual observation for that. The quality of raw milk is the primary factor determining the quality of milk products. Good-quality milk products can be produced only from good-quality raw milk. Milk testing and quality control should\n",
      "be carried out at all stages of the dairy chain\n",
      "Milk Adulterants\n",
      "There are many milk adulterants that are added to raw milk by supplier in order to get some financial benefits.\n",
      "Some of the major milk adulterants which cause serious adverse health effects are urea, formalin, detergents, ammonium sulphate, boric acid, caustic soda, benzoic acid, salicylic acid, hydrogen peroxide, sugars and melamine.\n",
      "Preservatives are special adulterants which increase the shelf life of milk.\n",
      "Eg: Formalin, Salicylic acid, Boric acid, Hydrogen Peroxide\n",
      "Water:\n",
      "Water is added to raw milk to increase milk volume. This is a common adulterant which is not harmful but decreases the milk quality.\n",
      "Urea:\n",
      "Urea, being a natural constituent of milk, constitutes the major portion of non-protein Nitrogen in milk. Maximum allowable limit for urea in milk is 70 mg/100 mL.\n",
      "Milk Adulterants\n",
      "Check here for more details\n",
      "Food Industry\n",
      "Quality is an important thing in food industry. Due to bio-chemical activities, there are changes in food time to time. Therefore, preservation is so impotant in food industry. Further, wastage of food happens due to expiration and many other reasons.\n",
      "In the case of diary industry, above problem becomes considerable because the wastage can be increased because of adding milk adultarents. It can be seen that almost all the dairy products we can see in the market are\n",
      "produced under the brand names of large scale companies. In Sri Lanka, it can observed that there are only few dairy products which are produced as rural domestic products like buffalo curd. Also a higher proportion\n",
      "of the dairy requirements are imported from other countries such as Australia and New Zealand because the domestic milk production is not sufficient. This is a good opportunity for small scale manufacturers to supply\n",
      "dairy products to catch up with the demand.\n",
      "Primary supply chain in Dairy industry\n",
      "Some restrictions for starting dairy related production;\n",
      "Not having an easy method to test the quality\n",
      "Not having knowledge of quality parameters and testing\n",
      "inability to buy laboratory equipments for testing.\n",
      "Find more details on 'Opportunities for dairy sector growth in Sri Lanka' here.\n",
      "Our Solution\n",
      "Our system can be used to measure and record important quality parameters of milk when the deal happens between the dairy collector and farmer to ensure milk is healthy and also it can be used to calculate financial value of milk according\n",
      "to those parameters and manage the financial records in a cloud based system.\n",
      "Whom do we target?\n",
      "MILK COLLECTORS\n",
      "LIQUID MILK SALES OUTLETS\n",
      "HOTELS & RESTAURANTS\n",
      "SMALL SCALE PROCESSORS\n",
      "Detection of Milk Adulterants\n",
      "Required Quality\n",
      "pH : 6.5 - 6.7\n",
      "Density : 1.026-1.032 g/ml\n",
      "Fat Content :\n",
      "Cow's milk (3.5-4.5)%\n",
      "Buffalo's milk (6-7)%\n",
      "Water\n",
      "Milk collectors use lactometer to measure the density of raw milk as a traditional method to detect if additional water is added to the raw milk. But, this method does not give an accurate result if the temperature\n",
      "is not considered, since the density varies according to the temperature.\n",
      "Water+Ammonium Sulphate\n",
      "Ammonium sulphate is added to increase the lactometer reading by maintaining the density of diluted milk.\n",
      "Urea\n",
      "Adding urea causes the increase of fat content. Since urea is basic, the PH value of raw milk can be used to detect this adulterant. Because urea is harmful, milk is unhealthy to consume when urea is added to\n",
      "it.\n",
      "Expected Outcomes\n",
      "Collectors\n",
      "Reducing wastage\n",
      "Get rid of traditional methods\n",
      "Reducing the need of high level laboratory testing\n",
      "Easy to expand production level\n",
      "Farmers\n",
      "Ability to get higher value & demand for good milk\n",
      "A smart way to access financial records\n",
      "Solution Architecture\n",
      "Measurements\n",
      "Using our hardware unit, following measurements of milk can be taken.\n",
      "1.PH value\n",
      "2.Fat rate\n",
      "3.Volume\n",
      "4.Weight\n",
      "5.Temperature\n",
      "Using these measurements as primary measurements, quality parameters which are focused on software sector are calculated.\n",
      "1.PH value\n",
      "2.Fat rate\n",
      "3.Corrected density\n",
      "Density can be calculated using weight and volume at the measured temperature. Then, that value is converted to the parameter 'corrected density' considering the temperature deviation from room temperature. Simply, the density is mapped for room temperature.\n",
      "PH value\n",
      "pH value is a important parameter in our system, which gives a better understanding about milk adulterants. The output voltage (analog) of the sensor is proportional to the pH value of the milk. The sensor is first calibrated using\n",
      "a standard sample (distilled water).\n",
      "Fat rate\n",
      "A high intensity LED is used as a light source and a LDR is placed to detect the amount of light passing through the milk. The more the fat content in the milk, more amount of light will be scattered by that milk.\n",
      "Corrected density\n",
      "Data communication\n",
      "Bluetooth is a popular communication method which is half duplex.\n",
      "We choosed bluetooth for communication because of the portable behaviour of the system.\n",
      "Milk Grading System\n",
      "What we do;\n",
      "Before the launching, we test fresh milk samples without any adultarents and get necessary data to observe the required range for each parameter. Then parameter values are tested after adding water content and graph it with\n",
      "additional water percentage as the independent variable and parameter values as dependent variables.\n",
      "How it works;\n",
      "According to the parameter values of a sample, a graphical visualization of each parameters can be obtained to get a better understanding about tested milk. Further, a grade will be displayed according to the quality as A/B/C/D.\n",
      "Main objective\n",
      "The grading system gives not only a grade for milk but also it is very useful to manage milk storage. It is recommended to store only milk with same grade in the same container, in order to reduce the possible wastages.\n",
      "Possible improvements\n",
      "This system can be improved so as to get an approximate value for fat percentage of milk which is called SNF value. Since the buyers are not interested in that type of parameters, the proposed grading system is sufficient for\n",
      "the targeted problem.\n",
      "Background Mechanism of Grading\n",
      "SNF - Solid Non Fat , CLR - Corrected Lactometer Reading\n",
      "The Solids-Not-Fat (SNF) means a collection of proteins, lactose, minerals, acids, enzymes and vitamins contents of the milk. It is the total solid content minus the fat content. The total milk solids are the sum of Fat and\n",
      "SNF. SNF can be calculated using following formula:\n",
      "SNF = (CLR/4) + (Fat x 0.21) + 0.36\n",
      "Our system is not highly focusing on SNF percentage or fat percentage. But what this formula shows is Fat and SNF percentages are factors which affects the milk quality. Hence, deviations from fresh milk is considered in our\n",
      "system to generate the Grade.\n",
      "Future Improvements with Machine Learning\n",
      "After the basic circuit is built up, a fresh milk sample is tested for all parameters with respect to additional adulterant percentages. This data set is used as the training data set to build a data model. Then, this model\n",
      "can be used to predict approximate adulterant percentage and notify to the user using a mobile notification. Since AWS supports jupyter notebook, after integrating this feature, user can get a better understanding about\n",
      "milk that he is going to purchase.\n",
      "Billing System\n",
      "According to the grade of tested milk, here is a mechanism to change the price for unit volume (1 litre) by the buyer(collector). For each grade he can assign a value in descending order as grade varies from A to D.\n",
      "History record of how the values varied is also displayed.\n",
      "Technologies\n",
      "Flutter\n",
      "Flutter is an open-source framework developed by Google and it is one of the most popular mobile development frameworks used by developers worldwide. It comprises all the essential elements, including cross-platform\n",
      "and native development models required to build high-performing and feature-rich applications in minimal time.\n",
      "Laravel\n",
      "Laravel is the best PHP framework to use and build efficient applications in any scale. Laravel application maintenance process is easier and also it provides high-security features such as token authentication.\n",
      "Laravel speeds the application development process by utilizing databases efficiently\n",
      "AWS\n",
      "AWS is designed to allow application providers, ISVs, and vendors to quickly and securely host the applications – whether an existing application or a new SaaS-based application. AWS is made up of so many different\n",
      "cloud computing products and services. AWS utilizes an end-to-end approach to secure and harden our infrastructure, including physical, operational, and software measures.\n",
      "Mobile Application User interfaces\n",
      "Previous\n",
      "Next\n",
      "Admin Panel User interfaces\n",
      "Admin dashboard home page\n",
      "Admin dashboard devices page\n",
      "Admin dashboard collectors page\n",
      "Price graph\n",
      "Volume graph\n",
      "Login page\n",
      "Admin change password page\n",
      "Admin change password page\n",
      "Admin change password page\n",
      "Previous\n",
      "Next\n",
      "3D Designs of model\n",
      "Milk container\n",
      "Main unit\n",
      "Sensor holder\n",
      "Container with main unit\n",
      "Register\n",
      "Login\n",
      "Configure\n",
      "Connect\n",
      "Analyze\n",
      "Buy\n",
      "Select as collector\n",
      "Enter a valid Email address\n",
      "Enter a strong password and re-type\n",
      "Click next to proceed\n",
      "Enter a valid mobile number\n",
      "Type your address\n",
      "Select your role\n",
      "Milk collector\n",
      "Small scale proceesor\n",
      "liquid outlet\n",
      "Hotel/Restaurent\n",
      "Sumbit your details\n",
      "Enter your email & password\n",
      "If you don't remember password, there is an option to reset it.\n",
      "If you still do not have an account, you can use guest mode\n",
      "Sign in to get the experience\n",
      "You can use this page to manage your profile\n",
      "Your basic details are displayed here\n",
      "Use edit options to change them if you want\n",
      "Use change price rate option to handle your deals\n",
      "In the home screen connect button will turn on bluetooth connection\n",
      "You can see the names of all connections\n",
      "Use lower text input to provide the name of the connection from the device\n",
      "Then each time, the conection will be automatically set.\n",
      "This page can be used to update your price values\n",
      "Only restriction is to enter values in descending order\n",
      "This values are public for other users\n",
      "This screen shows requests from farmers to buy milk from them\n",
      "After accepting both parties can contact each other.\n",
      "You can see contact details and locations of them\n",
      "Everytime before testing, you can select your seller\n",
      "A list of people you already connected, will be displayed\n",
      "If he/she does not use the app enter his/her nickname and select milk type you buy from him/her\n",
      "Sumbit your details\n",
      "After receiving data from the device parameter values will be displayed\n",
      "Upper box displays the grade and curret price value for a unit volume you have set.\n",
      "Then you have to enter the total volume of the milk, your sample belongs to\n",
      "After analyzing the report you can add or reject.(It is not recommanded to buy milk of Grade D)\n",
      "Anytime past details can be seen in a timeline\n",
      "There is the record for a specific farmer for a date\n",
      "You can see all the details aout the deal\n",
      "Features\n",
      "Low power consumption\n",
      "In this project, since the hardware unit is consumed less, the power usage is really effective. (Hardware use rechargeable batteries to get power)\n",
      "Portabale milk tester\n",
      "Our system is designed with the ability of using it as a portable device. In a milk collecting center also, it is applicable.\n",
      "Easy connection\n",
      "System can be used easily with bluetooth connection using your mobile phone as a smart way to test milk.\n",
      "Cloud based\n",
      "Users can experience an effective cloud based business environment and get rid of traditional testing and biling systems\n",
      "Calender based schedule\n",
      "All the records can be viewed in a timeline with an easy environment to see past records\n",
      "Customize your options\n",
      "Changing user details, price rate values can be done whenever you want.\n",
      "Synchronizable\n",
      "With the price changes in industry, it is easy to update the price rates.\n",
      "Testing\n",
      "Software Testing Tools\n",
      "Postman\n",
      "Postman is a scalable API testing tool which is a popular API workflow in testing and development. It has nice features like ability of creation of tests, ability of automated testing & etc.\n",
      "Testing unit\n",
      "What is tested\n",
      "Results\n",
      "Conclusion\n",
      "sign-up\n",
      "If any mandotary field is null\n",
      "Errors without allowing to submit\n",
      "email verification\n",
      "Successfull email notifications\n",
      "password verification\n",
      "check strength before submitting\n",
      "contact number verification\n",
      "sign-in\n",
      "If email is wrong\n",
      "login failed!\n",
      "If password is wrong\n",
      "login failed!\n",
      "If any field is null\n",
      "Errors without allowing to submit\n",
      "Appium\n",
      "Appium is an open source automation tool for running scripts and testing native applications, mobile-web applications and hybrid applications on Android or iOS using a webdriver.\n",
      "JMeter\n",
      "JMeter is a test tool from Apache used to analyze and measure the performance of applications, different software services and products.\n",
      "Security\n",
      "Admin panel security\n",
      "Registration as an admin is allowed only for specified people. This is done by inviting him/her by super admin with a time limit. Creating the super admin is done by seeding required credentials to the database when deploying.\n",
      "Details about invitations can be seen and it is possible to remove any email address that is already invited if admin wanted to invite him/her again.\n",
      "A session will expire after a specific time although an admin did not logged out. When registering and changing the current password, a strong password has to be entered and when changing the current password, admin has to verify his/her identity by giving\n",
      "the valid email and current password.\n",
      "Mobile Application Security\n",
      "JWT is the method of authentication for the users of the mobile application. A JSON web token (JWT) is an open standard (RFC 7519) and it is a compact and self-contained way for securely transmitting information between systems as a JSON object. This\n",
      "information can be verified and trusted because, it is digitally signed.\n",
      "Once the user is logged in and authenticated by the server, then the JWT token is generated and passed in response, and in each subsequent request, the token is passed to the server. This JWT token contains the information for\n",
      "the user's access and permission, which is part of the authorization.\n",
      "After registering and after using 'forgot password' option user has to verify himself by entering the OTP he received into his email. This is one security action in our mobile application.\n",
      "Timeline\n",
      "Project Planning\n",
      "Done\n",
      "6 weeks\n",
      "In first 6 weeks, our team discussed about several project ideas. Among them, we decided to build a milk analysor which can be used by dairy collectors to enhance the deal with dairy farmers. After deciding Hardware components, technologies and timeline,\n",
      "project proposal was presented in this phase.\n",
      "Backend Design\n",
      "4 weeks\n",
      "In this phase, basic backend functionalities are implemented in a Laravel project. API designing is the main task in this 4 weeks after creating database models.\n",
      "Frontend Design\n",
      "4 weeks\n",
      "Developing mobile application as a flutter project takes place in this 4 weeks. User interfaces are created in a way that the users of the application can easily manage their activities.\n",
      "Hardware Design\n",
      "In progress\n",
      "4 weeks\n",
      "Hardware solution is designed in this phase. All sensors are connected to the main unit and tested by getting measurements.\n",
      "Cloud Deployment\n",
      "1 week\n",
      "This week is for Deployment tasks. Some testing activities also take place on hosting. All issues in previous phases are also resolved.\n",
      "Integration\n",
      "1 weeks\n",
      "This is the last phase of our project where we test all the systems after integrating them together. After this phase, a final model is presented.\n",
      "Estimated budget\n",
      "#\n",
      "item\n",
      "quantity\n",
      "price(LKR)\n",
      "1\n",
      "ATmega328p\n",
      "1\n",
      "750\n",
      "2\n",
      "Bluetooth module HC-05\n",
      "1\n",
      "950\n",
      "3\n",
      "PH sensor\n",
      "1\n",
      "3800\n",
      "4\n",
      "HC-SR04 Ultrasonic sensor\n",
      "1\n",
      "200\n",
      "5\n",
      "20x4 LCD display\n",
      "1\n",
      "950\n",
      "6\n",
      "3.7 V power supply\n",
      "2\n",
      "900\n",
      "7\n",
      "Temperature sensor\n",
      "1\n",
      "250\n",
      "8\n",
      "Resistors\n",
      "10\n",
      "100\n",
      "9\n",
      "Load cell 5 kg\n",
      "1\n",
      "500\n",
      "10\n",
      "LDR\n",
      "1\n",
      "55\n",
      "11\n",
      "LED\n",
      "5\n",
      "100\n",
      "12\n",
      "Piezo Buzzer\n",
      "1\n",
      "25\n",
      "13\n",
      "HX711 converter\n",
      "1\n",
      "200\n",
      "14\n",
      "Battery charger\n",
      "1\n",
      "450\n",
      "15\n",
      "Cost for model\n",
      "1\n",
      "2000\n",
      "16\n",
      "Wires and others\n",
      "300\n",
      "Total\n",
      "11530\n",
      "Conclusion\n",
      "Team\n",
      "E/17/012, Aminda Amarasinghe, e17012@eng.pdn.ac.lk\n",
      "E/17/038, Anuruddha Chandrasekara, e17038@eng.pdn.ac.lk\n",
      "E/17/101, Anjalee Gunathilaka, e17101@eng.pdn.ac.lk\n",
      "Project Supervisors\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Aminda Amarasinghe\n",
      "Anuruddha Chandrasekara\n",
      "Anjalee Gunathilaka\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Department Projects\n",
      "Copyright © 2021 All rights reserved | MilkTab\n",
      "\n",
      "\n",
      "Extracting Remote Gatekeeping System https://cepdnaclk.github.io/e17-3yp-Remote-Gatekeeping-System\n",
      "\n",
      "\n",
      "Remote Gatekeeping System\n",
      "3YP(Group-19)\n",
      "Home\n",
      "Intro\n",
      "Components\n",
      "Timeline\n",
      "BOM\n",
      "Testing\n",
      "Scalability\n",
      "Security\n",
      "Team\n",
      "3rd Year ProjectDepartment of CE - UoP\n",
      "Remote Gatekeeping System\n",
      "Control unit wit|\n",
      "Control unit with intercom, Smart Mailbox, Remote gate\n",
      "unlocking system, Mobile controlling interface, Administrative\n",
      "web services\n",
      "Project Repo\n",
      "Web Application\n",
      "The motivation to our solution\n",
      "REAL WORLD PROBLEM\n",
      "In the busy and complicated lifestyle today, keeping\n",
      "interactions with outsiders is, inefficient, impractical and\n",
      "vulnerable. The ongoing pandemic has worsen the situation\n",
      "becase people are afraid to having physical intractions with\n",
      "outsiders.\n",
      "We have understood that people are having troubles with taking\n",
      "online deliveries to their door steps securely. Since people\n",
      "in Sri Lanka are so busy today, there is a good chance of not\n",
      "being in the house when an outsider or delivery person comes\n",
      "to the door.If the homeowners are not at home , delivery\n",
      "people are adapt to keep the delivery outside the\n",
      "house.Therefore delivery package is subjected to get stolen or\n",
      "get damaged.\n",
      "Otherthan that , when an outsider comes to the door, if the\n",
      "parents are not home, it is not a good idea to expose the\n",
      "children and elder people to that outsider. It would be better\n",
      "if there is a way to communicate with the outsider when she/he\n",
      "is at the gate.(before entering to the house premise)\n",
      "We thought we can come up with a system of interconnected\n",
      "devices (inspired from IoT) to provide an efficient solution\n",
      "for those problems.\n",
      "Next level delivery receiving and gatekeeping\n",
      "Our Solution\n",
      "Our solution is to introduce a system, to communicate remotely with\n",
      "an outsider who is at our gate or to undertaking deliveries, without\n",
      "making physical interactions.\n",
      "Watch the video\n",
      "How it works\n",
      "Components of the Sytem\n",
      "Control Unit\n",
      "This is the main component of the system and all the\n",
      "cotrolling related to the system is done using this\n",
      "unit.Outsider interacts with this component.\n",
      "Smart Mailbox\n",
      "This is used to receive the delivery packages safely and this\n",
      "can be remotely controlled by the homeowner from anywhere in\n",
      "the world.\n",
      "Smart Gate Locking\n",
      "Remotely controlled by the homeowner to serve the request of\n",
      "the outsider and locking and unlocking of the gate is done\n",
      "using this.\n",
      "Mobile Application\n",
      "Used by the homeowner and various features like capturing the\n",
      "photo of the outsider, intercom with the outsider and\n",
      "mailbox/gate controlling is handled using this.\n",
      "Web Interface\n",
      "Used to sign up, establish the connection between the system\n",
      "with the user account , download the mobile application and\n",
      "various other purposes.\n",
      "What happens under the hood\n",
      "Solution Architecture\n",
      "This is a high level representation of our system and it shows\n",
      "how our system works.\n",
      "All of the modules of our system is connected to the\n",
      "microprocessor Raspberry Pi 3 and it will be connected to the\n",
      "internet using built-in wifi module through the home wifi\n",
      "access point.\n",
      "Then it would be connected to the backend of our system which\n",
      "is firebase.Backend transfer data to the mobile application\n",
      "and the web interface. Connecting and data sharing between the\n",
      "hardware front-end and two software front-end is the main goal\n",
      "of the backend.\n",
      "Data/Control signal distribution\n",
      "Data and Control Flow\n",
      "This is a high level representation of our system and it shows\n",
      "how our the controlling and data transmission happens in the\n",
      "system.\n",
      "Purple Lines : Control Signals\n",
      "Black Lines :\n",
      "Data Transmission\n",
      "Control signals are supplied to all the modules that are\n",
      "connected to the Raspberry Pi3. Data is input to the Raspberry\n",
      "Pi by camera module, push button, usb microphone. The SD card\n",
      "is used to load the raspbian OS to the system and if there are\n",
      "any data to be stored, they are stored using SD card.\n",
      "IoT device is connected to the backend of our system therefore\n",
      "obvously data sharing happens there. Using the backend , the\n",
      "data transmission between mobile application, web site and the\n",
      "IoT device is achieved.\n",
      "Blocks and Components\n",
      "Block Diagram\n",
      "This figure shows how various components of our system\n",
      "interconnected.\n",
      "All the controling mechanisms are handled by the control unit\n",
      "of our system. When the homeowner wants to open up the smart\n",
      "mailbox , a control signal will be send to the control unit\n",
      "and control unit will send a control signal to the smart\n",
      "mailbox and it will be opened. This exact behaviour is applied\n",
      "for the smart gatelock as well.\n",
      "The control unit is going to connected to the power supply\n",
      "adapter and will get power from the wall plug. Then the power\n",
      "required for smart mailbox and smart gatelock will be provided\n",
      "by the control unit itself.\n",
      "Then it would be connected to the backend of our system which\n",
      "is firebase.Backend transfer data to the mobile application\n",
      "and the web interface. Connecting and data sharing between the\n",
      "hardware front-end and two software front-end is the main goal\n",
      "of the backend.\n",
      "UX-UI Design\n",
      "Mobile Application\n",
      "Login Screen\n",
      "Welcome Screen\n",
      "Active Event\n",
      "Close Active Event\n",
      "Previous Events\n",
      "Previous Event Info\n",
      "Download Mobile Application\n",
      "UX-UI Design\n",
      "Web Application\n",
      "Home Page\n",
      "Login From\n",
      "Signup From\n",
      "Dashboard\n",
      "UX-UI Design\n",
      "Hardware Interface\n",
      "Initialize system\n",
      "Choosing option\n",
      "Realtime Updates\n",
      "Realtime Updates\n",
      "Realtime Updates\n",
      "Failure Handling\n",
      "Algorithms of the System\n",
      "Algorithm runs on the hardware module\n",
      "Algorithm runs on the Mobile Application\n",
      "how we store the data\n",
      "Database Schemata\n",
      "We use Firebase Realtime Database as database of our system\n",
      "which is a cloud-hosted database. Data is stored as JSON and\n",
      "synchronized in realtime to every connected client. That means\n",
      "all the clients connected to our system share one Realtime\n",
      "Database instance and automatically receive updates with the\n",
      "newest data.\n",
      "Firebase Realtime Database is a non sql, dynamic and non\n",
      "relational database.\n",
      "Physical designs of our system\n",
      "3D Models\n",
      "Control Unit - Front End\n",
      "Control Unit - Isometric View\n",
      "-->\n",
      "How the modules are connected\n",
      "Circuit Diagram\n",
      "What we have implemented so far...\n",
      "Progress\n",
      "Initializtion Node\n",
      "Failure Handling\n",
      "Web App Demostration\n",
      "Interaction with the outsider Demostration\n",
      "-->\n",
      "hardware modules\n",
      "Sensors and Actuators\n",
      "Raspberry Pi Camera Module v2 (Sony IMX219)\n",
      "8 Megapixels\n",
      "Several image formats (JPEG, BMP, PNG) - smaller file size for\n",
      "faster and effective transmission\n",
      "300mA current, 1.2V\n",
      "RPi library: PiCamera\n",
      "16 x 2 LCD (CM 162-4)\n",
      "Affordable\n",
      "Suits our requirements\n",
      "Consumes less power compared to other options (3.3 ~ 5V)\n",
      "RPi library: Adafruit_CharLCD\n",
      "Servo Motor (SG90)\n",
      "Mechanical locks of the Mailbox and the Front gate\n",
      "Has enough torque to do small operations (2.5kgcm)\n",
      "Consumes less energy (5V) compared to other motors\n",
      "Mini USB Microphone (Adafruit 3367)\n",
      "Very reliable for voice recording, which allows optimum\n",
      "communication in Intercom\n",
      "Works great with a Raspberry Pi computer\n",
      "5V of electricity with a maximum current of 0.5A\n",
      "Factory Calibrated\n",
      "From Week 1 to Week 15\n",
      "Project Timeline\n",
      "Week 1 - Week 4\n",
      "Project Planing\n",
      "- Coming up with an idea\n",
      "- Getting familier with the tecknologies\n",
      "Week 5\n",
      "Project Proposal\n",
      "- Presentation explaining the Product and the Tecknologies\n",
      "Week 6 - Week 8\n",
      "Preperation and Learning Phase\n",
      "- Getting along with the tecknologies\n",
      "- Building the Algorithms\n",
      "Week 6 - Week 10\n",
      "Web App and Server Backend Dev\n",
      "- Development of the User registration system with ReactJS\n",
      "- Configuration of Firebase server backend and the database\n",
      "Week 7 - Week 12\n",
      "Mobile App Dev\n",
      "- Design of the application structure and laout\n",
      "- Implementation of the application\n",
      "Week 9 - Week 13\n",
      "Microcontroller Environment Dev\n",
      "- Implementation of Intercom capabilites\n",
      "- Setting up sensors and actuators\n",
      "Week 10 - Week 18\n",
      "Error Handling and Final Test\n",
      "- Handling the errors arise while combining the technologies\n",
      "- Testing of the final product\n",
      "- Fine tuning the system\n",
      "Proposed on Week 5\n",
      "Bill of Material\n",
      "Description\n",
      "Price - LKR\n",
      "Rasberry Pi 3 (Model B)\n",
      "8000\n",
      "Raspberry Pi Camera Module\n",
      "3800\n",
      "Raspberry Pi LCD\n",
      "2500\n",
      "Speaker Module\n",
      "2000\n",
      "USB Microphone Module\n",
      "1000\n",
      "Servo Motor × 2\n",
      "1000\n",
      "Micro SD card\n",
      "850\n",
      "Power Adapter\n",
      "800\n",
      "Other Expenses (Push Buttons, Cables, etc.)\n",
      "1000\n",
      "Total\n",
      "20950\n",
      "Testing\n",
      "Full test results can be found in the\n",
      "GitHub Repository\n",
      "Functionalaties ofthe Administrative Web Service\n",
      "Type : Automated\n",
      "Framework : Selenium\n",
      "Porgramming Languge : Python\n",
      "Test\n",
      "Description\n",
      "Purpose\n",
      "Expected Results\n",
      "Result\n",
      "User Login (i)\n",
      "Use logoing with correct email and password\n",
      "Check the user loging with with correct credentials\n",
      "Successful login to the system, Initial message of the History\n",
      "Table , Correct User name and the email appear on the Dashboard\n",
      "Pass\n",
      "User Login (ii)\n",
      "User loging with wrong email or password\n",
      "Try to use loging with wrong credential\n",
      "Blocking the invalid users\n",
      "Pass\n",
      "Device Initializtion (i)\n",
      "Device initialize with correct serial number & Valid use\n",
      "information\n",
      "Check whether the initialzaton work correct or not\n",
      "Successful signup to valid-user\n",
      "Pass\n",
      "Device Initializtion (ii)\n",
      "Device initialize with incorrect serial number\n",
      "Check whether the initialztion work with incorrect serial or not\n",
      "Unable to sign up an invalid user\n",
      "Pass\n",
      "Secutiry Fetures ofBackend & Frontend\n",
      "Type : Manual and\n",
      "Automated         Framework,\n",
      "Simulators & Libraris : Rules Playground - Firebase\n",
      "Test\n",
      "Description\n",
      "Purpose\n",
      "Expected Results\n",
      "Result\n",
      "Malicious user login\n",
      "Brute Forcing passwords\n",
      "Checking the security againsts the malicious access\n",
      "Security against the malicious access Blocking the selected\n",
      "email after a few unsuccessful attempts for a time period\n",
      "Pass\n",
      "Datebase Access (i)\n",
      "CRUD operations on the Users , Messages , InitNodes , Evernts ,\n",
      "Nodes collections\n",
      "To fine-grain tuning the outside access to the database\n",
      "Users - read and write access, authenticated users only for\n",
      "their collection.\n",
      "Nodes - Read access to any outside users, write access only to\n",
      "authenticate users for their collection\n",
      "Pass\n",
      "bakcend services\n",
      "Scalability\n",
      "For now, we are using the free tier of the Firestore. Cloud\n",
      "Firestore offers free quota that allows you to get started at\n",
      "no cost. The free quota amounts are listed here.\n",
      "Firebase offers upto 50,000 document writes per day. We have\n",
      "observed about 25 database reads will take for a single event.\n",
      "If we assume a normal user may encounter 10 events per day, we\n",
      "can handle about 200 nodes per day in the free tier.\n",
      "Firebase Realtime Database provides 100 simultaneous\n",
      "connections for the free tier. Since we are not expecting that\n",
      "much of events at the same time, it won't be a bottleneck. If\n",
      "it was, we can easily boost it to 200k by upgrading the system\n",
      "to paid tier.\n",
      "Firebase Realtime Database offers upto 5GB of data storage per\n",
      "day for the free tier. We have analysed for several test cases\n",
      "and found out average event may contains files upto 3MB. Since\n",
      "we are hoping to provide 1 month of backup data, it will be\n",
      "enough for 5 nodes. We can reduce the backup size to\n",
      "accommodate more users, or we can switch to paid tier.\n",
      "Additional 40GBs costs $1 and for that we can provide backup\n",
      "for 40 users.\n",
      "As a future Implementation, we are going to scale the system\n",
      "to have the ability of connecting several users for a single\n",
      "hardware node.\n",
      "simultaneousconnections\n",
      "upto 100\n",
      "initializeddevices\n",
      "upto 200+\n",
      "additionalbackup storage\n",
      "$1/ 40 users\n",
      "Security Aspects\n",
      "authentication\n",
      "To authenticate users with their email addresses and passwords, we\n",
      "are using Firebase Auth, which provides methods to\n",
      "create and manage users.\n",
      "At an event of Brute-force Attacks, we are temporarilty disabling\n",
      "the account\n",
      "which is being compromized to protect the system from the\n",
      "attackers. Firebase's\n",
      "Managed email-password authentication service\n",
      "tightens the default quota of the endpoints to prevent these\n",
      "attacks.\n",
      "To connect the backend to the hardware node and to communicate with,\n",
      "we are using a token-based authentication system, which uses\n",
      "JSON Web Tokens - JWT.\n",
      "authorization\n",
      "Firebase Security Rules secures the database and the storage,\n",
      "by fine-graining the user access. We have implemented our own rules\n",
      "which restricts the users from accessing unauthorized collections of\n",
      "the database.\n",
      "hosting\n",
      "We have deployed our web application using the Firebase service,\n",
      "Firebase Hosting. Since\n",
      "Zero-configuration SSL is built into Firebase Hosting, the\n",
      "content is always delivered securely, so we don't have to take\n",
      "care of it.\n",
      "web & mobile app\n",
      "We have implemented user input validation for both interfaces, at\n",
      "the client-end as well as at the server-end.\n",
      "Firebase Security Rules provide the validation at the\n",
      "server-end where as at the user interfaces we have implemented\n",
      "validation manully.\n",
      "Group 19\n",
      "Team Members\n",
      "Achintha Harshamal\n",
      "Computer Engineering UG\n",
      "Ishara Nawarathna\n",
      "Computer Engineering UG\n",
      "Pubudu Bandara\n",
      "Computer Engineering UG\n",
      "Advisors\n",
      "Dr. Isuru Nawinna\n",
      "Senior Lecturer\n",
      "Department of CE\n",
      "Dr. Mahanama Wickramasinge\n",
      "Senior Lecturer Department of CE\n",
      "Contact Info\n",
      "gatekeeper.remote@gmail.com\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting Secure Food Delivery https://cepdnaclk.github.io/e17-3yp-Secure-Food-Delivery\n",
      "\n",
      "\n",
      "Secure Food Delivery\n",
      "Home\n",
      "About\n",
      "Architecture\n",
      "Design\n",
      "Security\n",
      "More\n",
      "Testing\n",
      "Budget\n",
      "Timeline\n",
      "Conclusion\n",
      "Team\n",
      "Want to deliver your order to the doorstepmore secure manner?\n",
      "Secure Food Delivery\n",
      "Let's explore the new way to get your order !\n",
      "Project Repository\n",
      "Current Scenario\n",
      "As we are really busy with our day-to-day life, almost everyone is like to have their meal wherever and whenever they want.\n",
      "So, online food delivery services are really famous and very popular among people. There are so many food delivery services in Sri Lanka and there are huge beneficiaries also.\n",
      "Motivation\n",
      "There are some services, that are providing online food delivery services already. But, there are some serious issues regarding those services. The main thing is about security (Reliability/Trust).\n",
      "In this particular area, those questions 'How far do we can trust those services? as a customer and 'How far do we can trust those services? as a restaurant owner can occur.\n",
      "There are two major roles here. The first one is the restaurant owners who provide food through delivery services and the second one is the customer who orders food through delivery service (Website or Mobile App).\n",
      "We saw some complaints and some news about stating 'not delivering the ordered food accordingly' from the customers. Also, we could see those restaurant owners could not do anything about it since the delivery service provides the service of delivery. But they have an issue with their customer's trust. This becomes a problem in good service and we want to give a solution that would help to develop the online food delivery services more reliable.\n",
      "Our Solution\n",
      "As it becomes a real-world problem, we thought about having a solution for that.\n",
      "We provide a smart locking system for the food delivery carrier, which can only be accessible from two ends. The person from the restaurant side providing food can unlock the container using an RFID card and put the order into it. After locking the container, it can only be unlocked by the customer using an OTP or an RFID card, or both.\n",
      "That must satisfy customers as it can't be opened within the delivery. So, they can trust whatever they buy. And also both client and customer have proof about the delivery.\n",
      "Design Architecture\n",
      "Solution Architecture\n",
      "The solution architecture consists of both software and hardware node. In the software node, there is an API that is responsible for handle data. Also, there is a mobile APP that will use to access the lock, and the client system is the one that assigns a particular order to the related delivery carrier.\n",
      "In the hardware node, using a microcontroller, the carrier will be locked with a digital lock. To unlock the delivery carrier, an RFID tag or OTP will use through the mobile app. If there is an unauthorized opening then it will be detected. By using an LCD display, the necessary information such as OrderID that is in the carrier at that moment; will be displayed.\n",
      "Control and Data flow\n",
      "In the control and data flow, there are three significant roles in the system. They are restaurant admin, regular customers, and delivery riders.\n",
      "Once a regular customer ordered foods through the existing online food delivery service system, he will get an Order-ID. Then on the restaurant side, the restaurant admin will confirm the order and put the order in one of the available motorbike carriers by using provided RFID tag for that restaurant. In this process, the restaurant admin will confirm the order with that particular Carrier-ID. Then, the mobile number of that regular customer who ordered the food; will be sent to the SFD API with the Order-ID and Carrier-ID.\n",
      "In the SFD API, the OTP (One-Time-Password) will send to the customer. Also, API will search for the mobile number in the database to check whether that customer has registered for the RFID tag, then if yes, the relevant RFID code will send to the microcontroller.\n",
      "Once the regular customer logs into SFD's app, and if he entered the correct OTP then an unlocking signal will be sent to the microcontroller through the API. Here is the delivery rider's job once he confirms that particular order has arrived at the customer's place, then only the locker is available for the customer to unlock. Until then, the customer is not allowed to open the delivery carrier and that will display to the customer through the mobile app.\n",
      "Here is the delivery rider's job once he confirms that particular order has arrived at the customer's place, then only the locker is available for the customer to unlock. Until then, the customer is not allowed to open the delivery carrier and that will display to the customer through the mobile app.\n",
      "In the locking system, there is an unauthorized opening detection unit for the delivery carrier. Whenever the delivery carrier opened, it will generate an interrupt signal, if the unlocking signal from the API is not present at the microcontroller, it will alert the API as an unauthorized opening. Otherwise, the interrupt will ignore.\n",
      "The current status of the delivery carrier will display through the LED indicators, and the current order's Order-ID will display on the LCD screen.\n",
      "Design of the System\n",
      "Database ER Diagram\n",
      "Hardware - Power, Data, and Control Flow\n",
      "Circuit Design\n",
      "Delivery Box 3D Model Design\n",
      "UI Design\n",
      "Welcome Page\n",
      "This is the landing page of both customer and rider\n",
      ".\n",
      "Register Page for Customer\n",
      "If any customer wants to register in SFD service\n",
      "they can register by providing above details\n",
      ".\n",
      "Login Page For Customer\n",
      "To unlock the device, customer has to login in to the SFD app\n",
      "by providing contact details and the order id\n",
      ".\n",
      "Unlock Page using OTP\n",
      "After successfully logged in\n",
      "customers can unlock the device using OTP\n",
      ".\n",
      "Register Page for Rider\n",
      "If a rider wants to register in SFD service\n",
      "they have to provide above details with pre registered Device ID\n",
      ".\n",
      "Login Page for Rider\n",
      "Riders can log in to the app using contact details and the password\n",
      ".\n",
      "Order List Page for Rider\n",
      "After rider login, they can see their assigned orders\n",
      "also they can confirm orders by clicking the arrow button\n",
      ".\n",
      "Previous\n",
      "Next\n",
      "Hardware Components\n",
      "Microcontroller\n",
      "Communication Device\n",
      "Locking Device\n",
      "LCD Display\n",
      "RFID Sensor\n",
      "Unauthorized Access Detector\n",
      "BMS\n",
      "ESP32 Devkit V1\n",
      "Microcontroller unit of the system\n",
      "240 GHz Dual Core Processor\n",
      "4MB flash memory\n",
      "32-bit architecture\n",
      "512 KB RAM\n",
      "GPIO pins\n",
      "Peripherals (ADC/DAC/SPI/UART/I2C/PWM)\n",
      "Total of 30 Pins\n",
      "SIM800L GSM-GPRS EVB V2\n",
      "Communicational device of the system\n",
      "Communicate via GPRS\n",
      "Quad-band 850/900/1800/1900MHz\n",
      "AT Commands interface with “Auto Baud” detection\n",
      "Connect via UART protocol\n",
      "Clock Rate : 256kHz\n",
      "Data rate : 1.2 kbps - 115 kbps\n",
      "Consumes 2A in active mode, 0.7A in sleep mode\n",
      "12V Solenoid Lock\n",
      "Draws 650mA at 12V\n",
      "1-10 seconds long activation\n",
      "20x4 LCD Display\n",
      "20 Characters x 4 lines\n",
      "Connect via I2C interface\n",
      "LCD consumes 2mA\n",
      "Backlight consumes 40mA\n",
      "MFRC522 RFID Module\n",
      "Data Rate : 420 kbps\n",
      "Clock speed : 13.56 MHz\n",
      "Communication with Microcontroller over 4 pin SPI\n",
      "13 - 26 mA current consumption\n",
      "A3144E Hall Effect Sensor\n",
      "Operating Voltages : 4.5-24 V\n",
      "Maximum current : 25mA\n",
      "4S Battery Management System\n",
      "4 cells in series\n",
      "Maximum rated charge/discharge current : 30A\n",
      "Charging voltage : 16.8 V\n",
      "Balance current : 60mA\n",
      "Software Technologies\n",
      "Flutter\n",
      "For the implementation of the mobile aplication, Flutter has chosen as it supports both android and IOS applications with single code base.\n",
      "NodeJs\n",
      "To built the API, Node.js javascript runtime enviroment is used.Single treaded non-blocking operations, make the speed of the application much higher.\n",
      "MySQL\n",
      "As the database, the API uses a relational database.MySQL is used to build the relational database for the API.\n",
      "AWS Services\n",
      "AWS EC2 Service is used to host the API.For the MQTT connections, the AWS IoT Core is being plan to use.\n",
      "Security\n",
      "Security is the most important thing in the IT world right now.\n",
      "In our solution, we have deeply considered the security point of view of our system.\n",
      "We have developed our system with the help of the following techniques to enhance the application security in our solution.\n",
      "JSON Web Tokens (JWT)\n",
      "For authentication purposes, our API uses the JSON Web Token to ensure integrity.\n",
      "In the successful event of login, the user must receive a JWT, which is signed by the server.\n",
      "Whenever the client wants to communicate with API (after the login stage), it has to pass that returned token with the\n",
      "request.\n",
      "If somehow the token is modified, API would deny access to the data.\n",
      "Input Validations\n",
      "User Inputs are the most common way to commit a malicious attack.\n",
      "To prevent such scenarios, we validate the user input from both the front-end application and the back-end API.\n",
      "If inputs are not in the correct order, in the front-end, it denies the inputs. And from the back-end, it denies the request.\n",
      "Encrypt Sensitive Data\n",
      "Although we are using a relational database to work with data, we do not directly store sensitive data on the database.\n",
      "For that, we encrypt the sensitive data on the API with the help of well-known powerful libraries and then store those in the database.\n",
      "SSL/TLS Communication\n",
      "To ensure secure communication between the mobile application, and the API, we used the HTTPS protocol to securely transmit the data.\n",
      "With that, we can guarantee the message's integrity as well as the confidentiality of the data.\n",
      "In our API itself is secured with AWS EC2 security features. Hence the security of the system is more in an advanced manner.\n",
      "MQTT Broker Authentication\n",
      "Hardware to hardware communication (API and the Microcontroller), we have used the MQTT as the messaging protocol.\n",
      "For that, we have currently used AWS IoT Core as an MQTT message broker, which is a secured private message broker that requires certificate-based authentication for the MQTT clients.\n",
      "Testing Plan\n",
      "Budget\n",
      "Project Timeline\n",
      "Our Team Members\n",
      "Mahela Ekanayake\n",
      "E/17/083\n",
      "Lahiru Pathum\n",
      "E/17/405\n",
      "Nadeesha Diwakara\n",
      "E/17/240\n",
      "Our Advisors\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wickramasinghe\n",
      "About Us\n",
      "We are a group of undergraduates from Department of Computer Engineering, University of Peradeniya. This system was implemented as our third year project.\n",
      "Mail to us\n",
      "Quick Links\n",
      "Project Repository\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting Smart Cradle https://cepdnaclk.github.io/e17-3yp-Smart-Cradle\n",
      "\n",
      "\n",
      "Smart Cradle\n",
      "Home\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Software Design\n",
      "Hardware Design\n",
      "Security AND SAFETY\n",
      "Testing\n",
      "Budget\n",
      "TimeLine\n",
      "Team\n",
      "Contact Us\n",
      "Smart Cradle\n",
      "\"Because you and baby deserve care!\"\n",
      "PROBLEM\n",
      "As we are very well familiar with the hurdles faced by Parents to nurture their infant and especially in case if both the Parents are working.\n",
      "To give 24 hours of time in such cases is next to impossible.\n",
      "However they still need to look after their babies,thereby increasing workload and stress.\n",
      "They either send their babies to their parents or hire a baby caregiver while they are working.\n",
      "Some parents worry about the safety of their babies in the care of others.Thus they go home to check on their babies during their free time,\n",
      "such as lunch or tea break.\n",
      "A baby Monitoring System that can monitor the babies' condition real time is proposed to solve these problems.\n",
      "A baby monitoring System consisting of a vedio camera and microphone without limitations of coverage.It can send data and immediately notify the\n",
      "parents about urgent situations,thereby shortening the time needed to handle such scenarios.\n",
      "OUR SOLUTION\n",
      "The proposed solution involves live monitoring of the child through a mobile application remotely.Noice Sensor for the detection of the child's\n",
      "crying activity.When detect crying, cradle send a message to parent,plays a song.The Thermal sensor notifies the parent about the envioremental\n",
      "temperature near the baby and switch on the fan automatically with temperature.\n",
      "The proposed system uses the cloud service for remotely monitoring the child.\n",
      "Learn more\n",
      "SOLUTION ARCHITECTURE\n",
      "There is a cry detection mechanism which detects cry of the baby and send instant mobile app notifications to the user, at the same time some music will be played to soothe the baby.User can use play music option using their mobile application according to their wish at any occation even if a cry is not detected in order to soothe the baby.\n",
      "Using the temperature sensors, room temperature is delected and if it exceed 30 celcius ,mini fan will be turned on automatically.Turn on and off functions of the mini fan can be fully controled using the mobile application also according to the need of the user.Swing of the cradle is fully controlled by the Mobile application.\n",
      "Central server(AWS ) is used to maintain a database to keep a track of registrations and logins.Whenever the user log in to the system, mobile application will conect to the server and verify authentications.\n",
      "Hardware Control Flow\n",
      "Software Control Flow\n",
      "ER Diagram\n",
      "EER Diagram\n",
      "SOFTWARE DESIGN\n",
      "Mobile application is designed in a more user friendly manner.Graphics and picture are used to repesent the functionalites/options of the smart cradle.This will clearly deliver the content to the user and they can easily navigate to their requirements without much frustration.\n",
      "Basic functionaites of the mobile application:\n",
      "Monitor the baby\n",
      "Swing the Cradle\n",
      "Check the room temperature\n",
      "Play Music\n",
      "Switch on the Fan\n",
      "Get Notifications\n",
      "User have to first register giving their basic information,thereafter whenever they use the application,\n",
      "they can login giving their user name and the passward.This will assure our users that their information is protected and secure.\n",
      "Since real time visual monitoring of the baby option is available in the mobile application, assuring the privacy of the users as well as thier babies is more important.\n",
      "Because of high protection over the all the user information and the passwords,users can be make user that no unauthorized person can see their baby and no third party people can access the control of the smart cradle\n",
      "UI Design\n",
      "Front End Validation\n",
      "All the user inputs are checked before sending them to the server\n",
      "SignUp and Login\n",
      "When adding, removing and selecting a device\n",
      "Backend Validation\n",
      "Alert Boxes are displayed according to the resposnses recieved from the server\n",
      "SignUp\n",
      "Login\n",
      "Select a device\n",
      "Music\n",
      "Swing\n",
      "Settings\n",
      "Add a Device\n",
      "Remove Device\n",
      "Mobile App Demostration\n",
      "Technologies used\n",
      "HARDWARE DESIGN\n",
      "Hardware Components\n",
      "NodeMCU\n",
      "GPIO pins + WIFI module inbuilt\n",
      "Operating Voltage: 3.3V\n",
      "Input Voltage: 7-12V\n",
      "Flash Memory: 4 MB\n",
      "SRAM: 64 KB\n",
      "Clock Speed: 80 MHz\n",
      "Sound sensor\n",
      "Operating Voltage: 3.3V to 5V DC\n",
      "LM393 comparator with threshold prest\n",
      "Induction distance: 0.5 Meter\n",
      "Operating current:\n",
      "4~5 mA\n",
      "Microphone Sensitivity (1kHz): 52 to 48 dB\n",
      "Small, cheap and easily available\n",
      "Motor Driver\n",
      "Power Supply: DC 5 V - 35 V\n",
      "Operating current range: 0 ~ 36mA\n",
      "On-board +5V regulated Output supply\n",
      "Thermal sensor\n",
      "Working voltage: DC 3.3-5V\n",
      "can measure : -55°C to 150°C\n",
      "±0.5°C\n",
      "Accuracy\n",
      "Drain current is less than 60uA\n",
      "Low cost temperature sensor\n",
      "Small and hence suitable for remote applications\n",
      "Servo Motor\n",
      "Torque: 5.5kg/cm (at 4.8V)\n",
      "Working Voltage: 4.8V-6V\n",
      "Current Usage: <1000mA\n",
      "Camera Shield\n",
      "Voltage: 2.5V to 3.0V\n",
      "Lens Size: 1/6\" , Vision Angle: 25 degree\n",
      "High sensitivity for low-light operation\n",
      "Color saturation level auto adjust\n",
      "Mini fan\n",
      "DC Mode: 450 ~ 2150 RPM\n",
      "Operating Voltage: DC 5V～13.2V\n",
      "speaker\n",
      "Schematic Circuit Diagram\n",
      "PCB Design\n",
      "3D Model\n",
      "SECURITY AND SAFTY\n",
      "When we consider about a product like cradle ,security and safety is the most important thing.Security features of this product\n",
      "are achieved by using the above technologies.\n",
      "AWS :\n",
      "This is the cloud based serever that we use.We have choosen it ,because it provides secure services.\n",
      "It uses certificates to authenticate machine to machine communication and provides policies to control the\n",
      "actions of the devices.\n",
      "Amazon RDS :\n",
      "We create our own database server in cloud, and amzon RDS is the storage service that we use.We have choosen it because\n",
      "it supports MySQL and it is secure.It uses data encryption to secure data.The data stored in the disk is encrypted.\n",
      "The data which is transmited via the network is also encrypted.\n",
      "JSON Web Token (JWT) : This is used for the authetication.Once the user login to the system the server sends this token to the user.\n",
      "Passward Hashing : The orginal password is not stored in the database.Hashing performs a one-way\n",
      "transformation on a passward, turning the passward into another string.\n",
      "Sending JSON Web Token at the login.\n",
      "Store hashed passwords in the MySQL database.\n",
      "TESTING\n",
      "POSTMAN is a scalable API testing tool.\n",
      "HTTP requests that are sent to the server in each api call, are tested using this tools.\n",
      "Mobile application testing is done using APPIUM\n",
      "This enables testers to write test scripts against multiple platforms such as iOS and Android using the same API.\n",
      "Flutter test package is used for unit testing\n",
      "Front end validation is done using this\n",
      "API testing with POSTMAN\n",
      "Frontend And Backend Testing\n",
      "Testing Summary\n",
      "WHY we tested,\n",
      "signup and login : It is important to make sure that the system is only accessible by authorized users with accurate user details.\n",
      "add device and remove device : It is important to make sure that the ‘device’ and the ‘ownership’ tables in the database are correctly updated.\n",
      "select device : It is important to make sure that the devices are\n",
      "only accessible by their\n",
      "owners.\n",
      "swing , paly music ,fan , temperature monitor and settings : It is important to make sure that the basic functionalities of the mobile application are working properly\n",
      "backend : It is important to make sure that the all API endpoints are working correctly.\n",
      "BUDGET\n",
      "TIMELINE\n",
      "TEAM\n",
      "Our Team Members\n",
      "Madush Dilshan\n",
      "E/17/040\n",
      "Shashini Upekha\n",
      "E/17/356\n",
      "Hasara Wijesooriya\n",
      "E/17/407\n",
      "Our Advisors\n",
      "Dr.Isuru Nawinne\n",
      "Dr.Mahanama\n",
      "Contact Us\n",
      "University of Peradeniya.\n",
      "Phone: +94 81 239 33 00\n",
      "Email: vc@pdn.ac.lk\n",
      "Web-site: http://www.pdn.ac.lk/\n",
      "Faculty of Engineering.\n",
      "Phone: +94 81 239 33 02\n",
      "Web-site: http://eng.pdn.ac.lk/\n",
      "Computer Engineering Department.\n",
      "Phone: +94 81 239 39 14\n",
      "Web-site: http://www.ce.pdn.ac.lk/\n",
      "© Untitled. All rights reserved.Design: e17-3yp-Smart-Cradle_UOP\n",
      "\n",
      "\n",
      "Extracting Smart Locker https://cepdnaclk.github.io/e17-3yp-Smart-Locker\n",
      "\n",
      "\n",
      "Smart Locker\n",
      "Overview\n",
      "Solution\n",
      "Mobile App\n",
      "Architecture\n",
      "Technologies\n",
      "Security & Failure Handling\n",
      "Testing\n",
      "Budget\n",
      "Demonstration plan\n",
      "Timeline\n",
      "Supervisers & Mentors\n",
      "Overview\n",
      "The Smart Locker is a improvement for the traditional locker where we are trying to provide the lockers for public usage.\n",
      "Normal traditional lockers were used privately but as a team we think if lockers can be provided in a public way where citizens will\n",
      "book lockers for their access in public places it would be a market opportunity.\n",
      "We are as a team will develop a locker with digital improvements where users can unlock the locker by purchasing it online for a certain time period.\n",
      "The Lock itself will be developed by a arduino based electronic system where set of lockers will be monitered by a centeralized system.\n",
      "Motivation\n",
      "People from remote areas travel a long distance to the town in their day-to-day life. Employees come for their jobs.\n",
      "Students come for educational purposes such as schools and tuition classes. All these times they carry a lot of things here and there\n",
      "because they have to carry everything that they need in one go. So as a team we understand it is very difficult for those people.\n",
      "Then we came up with the idea of public lockers for making their day-to-day life easy.\n",
      "As a result we also understand that there are many people who can benefit from our solution rather than people who live in remote areas. This led to finalizing our idea as well.\n",
      "Our Solution\n",
      "⚫ Operable by a phone’s mobile application\n",
      "⚫ With map assistant to find where the lockers are\n",
      "⚫ Users can book lockers using application for certain duration of time.\n",
      "⚫ When booking users will receive a token.\n",
      "⚫ User can either use their phone or enter the token number to unlock the locker\n",
      "⚫ Token can share with another trusted person for accessing the locker by himself.\n",
      "Mobile Application\n",
      "Infrastructure and Architecture\n",
      "Components Used Inside the Locker\n",
      "This system consists of three main segments. The first one is the Locker. Others are\n",
      "backend and frontend which is also known as the mobile application. Smart locker includes four main parts.\n",
      "There are two input devices and they are Keypad and Ultrasonic sensor. There are two output devices and\n",
      "they are LCD display and solenoid lock. The keypad is used to enter tokens and other data. The\n",
      "Ultrasonic Sensor, helps the user to detect locker is empty or not. Through LCD display user can observe\n",
      "messages from the locker and the token which is entred.\n",
      "Initially, general information of lockers is stored in the cloud server database and it provides data to\n",
      "the mobile application and lockers. Also, it collects user data through the mobile application and the Locker. Users\n",
      "can ask about lockers and it gives details such as availability etc. If the user books a locker, then the\n",
      "backend generates a new token and sends it to the locker and user. The main functionalities of the locker\n",
      "are handled by the microcontroller and it makes a connection to the server through a Wi-Fi network. In\n",
      "advance, as a security feature buzzer is used. Finally, to enhance user experiance two LEDs are used for\n",
      "correctly identify whether the lock is in locked mode or not.\n",
      "Circuit Diagram\n",
      "Database Schema\n",
      "Technologies Used\n",
      "Security and Privacy\n",
      "In Software\n",
      "⚫ Prevent unauthorized access from the mobile application\n",
      "⚫ Block user IPs using a rate limiter\n",
      "⚫ Validate user inputs\n",
      "⚫ JSON Web Tokens for authorization\n",
      "⚫ JWT signature validation\n",
      "⚫ Encrypt the user password in the database\n",
      "⚫ Update locker password after every single usage\n",
      "⚫ Record login details\n",
      "⚫ Block unwanted traffic using built-in AWS firewalls\n",
      "In Hardware\n",
      "⚫ Durable Solenoid locks and lockers\n",
      "⚫ Sound buzzer if something wrong went wrong or malicious thing happen\n",
      "⚫ Private wi-fi connection for each cluster of lockers\n",
      "Failure Handling\n",
      "⚫ Solenoid lock is in Locked state at a power failure\n",
      "⚫ Solenoid lock is in Locked state at a server failure\n",
      "⚫ Show warnings to users\n",
      "⚫ Data fetched from sensors are stored within the device for a certaion period\n",
      "⚫ Send that data again to the server to mitigate if lost updates happen\n",
      "Testing Plan\n",
      "Budget\n",
      "Demonstration plan\n",
      "We are implementing two lockers as a bunch with the functionalities described above.\n",
      "Then an item is put in one locker. So it is unavailable. One of our team members books the\n",
      "available locker using the mobile application with map assistance. Then he opens it through the mobile\n",
      "app and puts something in it. Afterwards, he shares the token that he received with another team member. This other\n",
      "guy opens the same locker using the mobile application as well as the keypad by entering the token. Moreover, after\n",
      "expiring the time duration, the owner cannot open the locker furthermore.\n",
      "TimeLine\n",
      "Supervisers\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Mentors\n",
      "Mr. Dinidu Thilakarathna\n",
      "Group Members\n",
      "PGAP Gallage - E/17/091\n",
      "KPCDB Jayaweera - E/17/144\n",
      "KHSP Kodagoda - E/17/168\n",
      "Project Page\n",
      "Github Project Repo\n",
      "\n",
      "\n",
      "Extracting Smart Pet Feeder https://cepdnaclk.github.io/e17-3yp-Smart-Pet-Feeder\n",
      "\n",
      "\n",
      "Smart Pet FeederYou need to enable JavaScript to run this app.↑HomeAboutArchitecturesDesignsHardwareSecurityProgressTestingTeamWELCOME TOSmart Pet Feedersaving one pet won't change the world, but for that one pet the world will change foreverMobile AppPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenThe ProblemSmart Pet Feeder is a product that helps you to take care of your pets. It will help you to build the relationship with your pet better and better even you are not in the home. Have you ever been worried about your pet's meals when you are away from your pet? We provide the platform to come up with this problemThe SolutionWhen people are getting busy, they forget to take care of their pets even though they love their pets. Taking care of a pet's diet can be hard if they want to take good care of their pet's health. A smart pet feeder is one of the best solutions for that. It is capable of feeding a pet, in absence of its master. So, though the master is not at home, his pet will not miss his food. Smart pet feeders can be controlled by using a mobile app or a website. A small camera, which is mounted on the pet feeder, allows the master to see the machine's surroundings and observe the pet's behavior. Master can move the machine remotely while watching through the camera, to find the pet and deliver his food on time. If the master is too busy, even to operate it remotely through the mobile app or the website, he can switch on the automatic mode and schedule when to give food. A container that is placed on the machine can be used to store the foods and when the pet is being fed, the right amount can be passed to the plateReal-time visualizationGet the real-time activities of your pet, through the camera .SchedulingSchedule a feeding plan when you do not have time to control it manuallyHD live streamingRGet high quality video frames and using the UI to see real-time activities around.UPTO 4 TIMESFeed your pet 4 times per a dayEASY INSTALLATIONSetup the pet feeder and connect to the UI easilySTATUS VISUALIZATIONSee the remaining rounds, battery percentage and scheduling plan through the UI or the in-build displaySolution ArchitectureThe main device of our system is the pet feeder. It is connected to the Home Wifi and home Wifi is connected to the AWS server through the internet. In order to communicate with the AWS server there'll be a mobile application as well as a web application. Initially the user needs to log into the mobile application or web application by entering their email and the password. After logging into the system, they can control the pet feeder in order to feed their pets. Users can get real time visualization of their pets through the camera which is mounted on the pet feeder. To get a clear view of the pets, users can rotate the camera through the UI. If the users are unable to manually feed the pets, they can use the scheduling option. So they can create a scheduling plan in order to feed their pets at a given time. Users can see the status(Remaining feeding times, Battery capacity) of the pet feeder through the UI or inbuilt display.Data FlowThe users of the pet feeder can schedule a plan or control it manually using the website or a mobile app. Then From the UI, data will get into the Web server and the microprocessor in the Raspberry pi 3 will receive the data from the server. And also the users of the pet feeder can see their pet using the camera, which is in the feeding machine. That camera can be rotated remotely, and the live stream data will be sent to the UI through the AWS cloud. Mainly there are two different control units in the feeding machine.Food serving unitVisualizing unitFood serving unit is responsible for food serving. This unit contains a stepper motor and a motor controller. In the machine there is a food container which has a cylindrical shape and it has divided in to four partitions. To serve the foods, the food container in the pet feeder should be rotated to a certain angle. That is done by using the stepper motor. The raspberry pi will send the relevant control signals to the motor controller and the motor controller will control the rotation of the motor according to that signals.Visualizing unit is responsible for live streaming. There is a 5MP Omnivision 5647 Camera Module in this unit. When user wants to get a real time visualization of his/her pet, he/she will be able to get the live stream data to the UI through this camera. Also a 0.91 Inch LCD Display has included to this unit, and it will be used to display the data such as battery level or feeding times etc.AWS ArchitectureInitially the pet feeder will be configured as a thing in the AWS IoT. Pet feeder and AWS IoT will communicate using the MQTT protocol. When IoT receives a message from pet feeder, AWS IoT will execute a lambda function according to the rules that are defined. AWS IAM is used for Authentication purposes. AWS DynamoDB is used as the storage. It interacts with AWS lambda functions. AWS lambda The CRUD operations of AWS DynamoDB is performed by AWS Lambda functions.Live streaming data from the pet feeder is directed to the AWS Kinesis. That data will be processed using video processing application and converts to formats like MPEG4. Converted Streams will be sent to the UI for streaming.The UI can communicate with the UI via the AWS API gateway. When request is received to the gateway, API gateway will execute relevant lambda functions. Before executing relevant lambda functions, the request will be validated using another AWS lambda function. For that token based authentication is used.3D Design Of The Pet FeederThe Pet FeederThis is the 3D Design of the pet feeder. Mainly it includes a food container and a camera.The Food Container.This is a cylindrical shaped food container, which has diveded in to four partitions and it is rotatable through its axis. Every partition has a opening at the bottom, and there is a path to the food plate from the bottom of the cylinder. To serve foods the relevent partition should be coincided its opening with the path.UI DesignUsers can log into the system using the mobile application or web application by entering their email and password. After logging into the system, they can see the current status of the pet feeder. Status information includes remaining feeding times, scheduling plan and the battery capacity. They will be able to feed their pets by selecting the feeding option in the UI. And also they can get a real time visualization of their pets through the UI. To get a clear view, the UI provides another feature to rotate the inbuilt camera. There is a special feature called scheduling which allows users to schedule a feeding plan through the UI to feed their pets at a given time.allhomeuseradminHomeSign UpLoginUser StatusUser HistoryUser FeedbackUser NotificationsAdmin UsersAdmin FeedbackHardware componentsController PlatformCPU: 4 x ARM Cortex-A53 , 1.2GHzOS comes pre-loaded with python programming languageEnd nodes are connected to hardware interfaces.4GB SD card is used as memory5V main power supplyAs the main Controller Platform Raspberry Pi 3 Model B is used. It comes with pre loaded python programming language. It has 4 x ARM Cortex-A53 CPU which have 1.2GHz processing speed. Has a seperate Camera Serial Interface. Also 40 GPIO pins. Raspberry Pi 3 Model B comes with onboard Wi-Fi network interface which has about 38Mbps bandwith.As the other hardware components, Is has included a Camera Module v1.3 (MD0263), 0.91 Inch LCD Display, L298N Dual Bridge DC Motor Controllers and 12v Stepper motor. There are some main reasons to use the MD0263 camera module such as its high resolution, frame rate and ability to connect directly to microprocessor through camera serial interface. As the other hardware components,It has included an 5MP Omnivision Camera Module, 0.91 Inch LCD Display, L298N Dual Bridge DC Motor Controllers, 12v Stepper motor, Infrared IR Sensor and 5V Realy Module.SENSORSThe IR Sensor will be used to set the food container to its initial position and that Sensor shoul be given a input voltage between 3-5V.ACTUATORSWhen considering the actuators the 12v bipolar junction stepper motor has 200 step per revelution and it is capable of giving a high-torque up to 40 N.cm. Then the raspberry pi camera mocdule will give a Full HD video quality of 1080p with 30fps and if it reduced the quality to 720p the frame rate can be increased to 60fps. And the LCD display will be used for display the data such as signal strength, battery level and next feeding time.Also a motor controller has used to control the speed, direction and rotating angle of the stepper motor. A 5V relay module has used to supply the 5V input to the Raspberry PI from the 12V battery.As the power supply component, It has used a 12V Lithium battery of 3000mAh. Its Good capacity, lightweight, and rechargeability are very helpful to reduce the total weight and keep the machine active for a long time using battery current.Circuit DiagramSecurity Aspects2 factor authentication for login is used as a security mechanism. When user trying to login to the system he will receive OTP to his mobile phone. So If an attacker steals the email and password of a user he cannot login to the system unless he has owner’s mobile phone.Another security mechanism is AWS Web application firewalls. The firewall helps to protect our API from common web attacks and bots.Json web token are used to communicate between API and the UI. After user login to the system API will given a token to the frontend. So UI send request to the API along with the token. So the attackers cannot access our API without the token.BudgetProgressSIGNUP AND LOGINPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenUSER FUNCTIONALITIESPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenADMIN FUNCTIONALITIESPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenMOBILE APPLICATIONPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenIOT CONNECTIVITYPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenTestingSOFTWARE TESTINGPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenSECURITY TESTINGAPI TESTINGPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenE2E TESTINGPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenTesting ResultsPlay VideoPlayCurrent Time 0:00/Duration Time -:-Progress: NaN%Non-FullscreenTimelineProject Proposal(Milestone 1)Presenting our project proposal was the first milestone.19th July, 2021Design 3D ModelsDesign 3D models of the pet feeder.25th July, 2021Circuit & Software DesignDesign block diagrams, circuit diagrams, database schema, UI. Draw flow charts and design the algorithms.10th August, 2021Progress Review (Milestone 2)Tentative evaluation criteriaBlock diagramsCircuit diagramsDatabase schemataAlgorithms / Flow ChartsUI DesignsPerformance, Power, Security requirements.Failiure handlingSensors and actuatos.Controller platforms (programming, memory, available interfaces, connectivity, speeds, data-rates, built-in units, power, security, cost, etc.).Network technologies and protocols (interfacing, medium, bandwidth, security, availability, reliability).Back-end technologies (programming, storage, accessing, backups, security, cost, 3rd party services)Front-end technologies (programming, data visualization, security).30th August, 2021Front-End Of The Web ApplicationDesign and implement front end of the web application using React JS15th September, 2021Front-End Of The Mobile ApplicationDesign and implement front end of the mobile application using React Native25th September, 2021Develop Back-EndImplement the database and the back-end of the smart pet feeder using Node.js And MongoDB05th October, 2021Deployment And Software TestingDeploy the application in AWS servers and test the software20th October, 2021Progress Review(Milestone 3)Tentative evaluation criteriaCompleteness of back-end softwareCompleteness of front-end softwareCloud deploymentClear overview of the systemEnhance the user experience of software/hardware components and of the overall productClearly explain features and functionalities (including reliability, scalability and security aspects)Clearly explain implementation details27th October, 2021Implement Hardware PartDesign and implement the pet feeder unitNot Started YetConnect Software and HardwareEstablished the connection between pet feeder, cloud and the UINot Started YetProgress Review(Milestone 4)Tentative evaluation criteriaWorking PrototypeProgress video clipProgress presentationViva voceNot Started YetTestingTest the smart pet feeder and do relevant updates Not Started YetComplete product(Milestone 5)Tentative evaluation criteriaPresentationDemonstration of working productDesign Manual, User Manual, GitHub Repository, GitHub PageNot Started YetOur TeamR M S M GunathilakaE/17/100K S D PereraE/17/246R L D A S RathnayakeE/17/284Our AdvisorsDr. Isuru NawinneAdvisorDr. Mahanama WickramasingheAdvisorSmart Pet Feeder is a product that helps you to take care of your pets. It will help you to build the relationship with your pet better and better even you are not in the home. Have you ever been worried about your pet's meals when you are away from your pet? Smart pet feeder provide the platform to come up with this problemUseful LinksAbout UsContact UsContact UsSmart-pet-feeder, UOP, Kandy+94 76 869 9448+94 76 682 1877smartpetfeederuop@gmail.comwww.smartpetfeederuop.com© 2021 Smart Pet Feeder. All rights reserved\n",
      "\n",
      "\n",
      "Extracting Smart Pour https://cepdnaclk.github.io/e17-3yp-Smart-Pour\n",
      "\n",
      "\n",
      "Smart pour\n",
      "Home\n",
      "About\n",
      "Features\n",
      "Architecture\n",
      "Design\n",
      "Processing Unit\n",
      "Circuit Diagram\n",
      "E-R Diagram\n",
      "UI/UX\n",
      "Demos\n",
      "Mobile App Demo\n",
      "Backend Demo\n",
      "3D Model\n",
      "Data Flow\n",
      "Testing and Security\n",
      "Others\n",
      "Budget\n",
      "Timeline\n",
      "Team\n",
      "Now you can feel the Energy\n",
      "Coffee Making\n",
      "at your fingertips\n",
      "Project\n",
      "Repository\n",
      "Smart Pour\n",
      "An automated coffee machine that is controlled by an app\n",
      "The Smart Pour is an improvement for traditional coffee makers.\n",
      "Traditional coffee making is inconvenient with today's hectic\n",
      "lifestyle. We, as a team, came up with a more convenient coffee\n",
      "making system that can be controlled by an app.\n",
      "Features\n",
      "Make your life easier with Smart Pour\n",
      "Scheduling\n",
      "You can schedule your coffee at anytime and enjoy a hot coffee\n",
      "whenever you want\n",
      "Ingredient tracking\n",
      "You can know the ingredient amounts from the mobile application\n",
      "and shortages by notifications.\n",
      "Customizing user’s preference\n",
      "Smart Pour can store the recipes of the users.So you can\n",
      "experience your favourite coffee without any effort\n",
      "User friendly interface\n",
      "Smart Pour mobile application is very easy to handle and it's\n",
      "with simple structure which anybody can understand\n",
      "High Security\n",
      "Smart Pour is high security product only users with password can\n",
      "operate through the mobile application\n",
      "Durability\n",
      "Smart Pour device can be used for a long time and it will\n",
      "provide you a satisfied service\n",
      "Solution Architecture\n",
      "Mobile Application\n",
      "An Android mobile application is available for SmartPour coffee\n",
      "machine to allow users to remotely make coffee in a scheduled\n",
      "manner as well. The mobile application sends a notification when\n",
      "the coffee is made and reminders for scheduled coffee.Users can\n",
      "log in to the mobile app anytime to check the availability of\n",
      "the ingredients to make coff.The app is designed using Flutter.\n",
      "Web Server\n",
      "AWS server is used as the web server for the SmartPour System.\n",
      "Signals from sensors are passed to the mobile application as\n",
      "well as control information from mobile applications are passed\n",
      "to the machine and response mechanisms through this server.\n",
      "Database which is used to store favourite recipes,\n",
      "availabilityof the ingredients and logs of the system is hosted\n",
      "at the server.\n",
      "SmartPour Machine\n",
      "The coffe making is done in the machine. The pouring of coffee,\n",
      "ingredient seperation, ingredient tracking is identified through\n",
      "sensors. It will consist of wireless sensors suchas ultra-sonic\n",
      "sensors, reflective optical sensors, valves and servo motors.\n",
      "NodeMCU is used as the microcontroller of the SmartPour and\n",
      "ESP8266 WiFi modules are used for wireless sensors.\n",
      "Processing Unit\n",
      "The Processing Unit handles all the data processing and remote\n",
      "communications. The storage containers have the ultra-sonic\n",
      "sensor to track the ingredients availability. The valve is used\n",
      "to seperate liquid and servo motors are used to seperate dry\n",
      "ingredients from the storage containers. A reflective optical\n",
      "Sensor is there to detect the availability of a cup before\n",
      "pouring the coffee. The machine consists of storage containers\n",
      "to store ingredients. A heater and motor are used to boil water\n",
      "and stir the ingredients respectively. The power supply is given\n",
      "via current electricity.\n",
      "The processing unit also consists of inbuilt Wi-Fi via an\n",
      "ESP8266 Development board. Through this the consumer can\n",
      "directly connect our device to the internet through their home\n",
      "router and send data to our server\n",
      "Circuit Diagram\n",
      "E-R Diagram\n",
      "UI / UX\n",
      "Previous\n",
      "Next\n",
      "App Demo\n",
      "The mobile aplication is implemented using Flutter technology and Dart language.\n",
      "All the features and functionalities have been completed. Some unit testings and validation\n",
      "tests have been done for the application using Flutter test cases. To enhance the\n",
      "user experience, a simple design with a user friendly interface has been used.\n",
      "Back End\n",
      "For the backend, springboot and mysql technologies are used.\n",
      "The whole backend is deployed on Amazon Web Services(AWS) cloud as EC2 instances.\n",
      "Backup services, S3 services and security services given by AWS are\n",
      "used for this process. This demo shows the relational database implemented for\n",
      "the project accessed through EC2.\n",
      "3D Model\n",
      "This is the expected prototype view. Dimensions can be slightly varied\n",
      "due to the components of the real hardware.\n",
      "Dataflow\n",
      "Previous\n",
      "Next\n",
      "Testing and Security\n",
      "Previous\n",
      "Next\n",
      "Budget\n",
      "Item Name\n",
      "Quality\n",
      "Unit Price(LKR)\n",
      "Total Cost(LKR)\n",
      "Nodemcu ESP8266 12E\n",
      "1\n",
      "985\n",
      "985\n",
      "Heater\n",
      "1\n",
      "400\n",
      "400\n",
      "DC Motor\n",
      "1\n",
      "95\n",
      "95\n",
      "Relay\n",
      "3\n",
      "60\n",
      "180\n",
      "Valves\n",
      "2\n",
      "690\n",
      "1380\n",
      "Servo Motor\n",
      "2\n",
      "350\n",
      "700\n",
      "TCRT5000L Reflective Optical Sensor\n",
      "1\n",
      "175\n",
      "175\n",
      "Ultra-sonic Sensor\n",
      "3\n",
      "165\n",
      "495\n",
      "Containers\n",
      "4\n",
      "250\n",
      "1000\n",
      "12V 1A Full Wave Transformer\n",
      "1\n",
      "550\n",
      "550\n",
      "Others\n",
      "1000\n",
      "Total\n",
      "6960\n",
      "Timeline\n",
      "Week 1\n",
      "Idea Selection\n",
      "Week 3\n",
      "Software and Component Selection\n",
      "Week 4\n",
      "UI & Circuit Design\n",
      "Week 5\n",
      "Front End Development\n",
      "Week 7\n",
      "Back End Development\n",
      "Week 8\n",
      "Cloud Development\n",
      "Week 9\n",
      "Hardware Development\n",
      "Week 10\n",
      "Integrate Software and Hardware​\n",
      "Week 11\n",
      "System Testing & Debugging​\n",
      "Week 12\n",
      "Performance Evaluation\n",
      "Team\n",
      "Shazna Isthikar\n",
      "E/17/122\n",
      "Odasara Karunachandra\n",
      "E/17/153\n",
      "Mishel Rossmaree\n",
      "E/17/294\n",
      "About Us\n",
      "An automated coffee machine that is controlled by an application\n",
      "Copyright ©\n",
      "2022\n",
      "All rights reserved | Smart Pour\n",
      "Newsletter\n",
      "Stay update with our latest\n",
      "Follow Us\n",
      "Let us be social\n",
      "Home\n",
      "About\n",
      "Features\n",
      "Architecture\n",
      "Design\n",
      "Processing Unit\n",
      "Circuit Diagram\n",
      "E-R Diagram\n",
      "UI/UX\n",
      "Demos\n",
      "Mobile App Demo\n",
      "Backend Demo\n",
      "3D Model\n",
      "Data Flow\n",
      "Testing and Security\n",
      "Others\n",
      "Budget\n",
      "Timeline\n",
      "Team\n",
      "\n",
      "\n",
      "Extracting Wild Life Tracker https://cepdnaclk.github.io/e17-3yp-Wild-Life-Tracker\n",
      "\n",
      "\n",
      "Wild Life Tracker\n",
      "Wild Life Tracker\n",
      "Home\n",
      "About\n",
      "Design\n",
      "Budget\n",
      "Timeline\n",
      "Contact\n",
      "Menu\n",
      "Video by NickyPe from Pixabay\n",
      "3rd year project\n",
      "Wild Life Tracker\n",
      "Project Repositry\n",
      "Introduction\n",
      "Problem Overview\n",
      "The traditional method of wildlife researching in Sri Lanka, and many other developing as well as developed countries in the world is to stay in wild areas for a long time, observe animals randomly, and identify areas that animals are most active. This method is ineffective because some animals hide when they sense humans. They don't behave naturally around humans. Thus, it consumes a lot of time to observe their natural behavior. Researchers have to stay in the wild throughout this long period. So, this is a formidable process. Sometimes their life is in danger because there is a possibility to face an attack by wild animals while they are in the jungle. An immense amount of time, money, and human resources are spent in vain for traditional tracking of wild animals for researchers.\n",
      "Solution\n",
      "Our solution to this problem is a,\n",
      "Remotely controlable\n",
      "Real time\n",
      "Efficent and effective\n",
      "tracking system.\n",
      "This system consists of three major components, A hardware unit, a cloud server, and a web App. The hardware unit consists of camera traps, PIR sensors, and a location tracker. One unit of these three components makes a station. Researchers need to set up this station in the researching area. One researcher can have more than one station established in different places according to their choice. The sensors in a station can detect animals when they are in the sensing range and it will trigger the camera. A real-time photo is captured at that moment and they are stored in the station itself and also sent to the cloud server. Then the researcher can analyze these observed data through the web app.\n",
      "Remotely controlable\n",
      "Researcher can monitor the station through the web app after it is successfully established in researching area.\n",
      "High Performance Camera Module\n",
      "A powerful camera unit to capture perfect photos in any lighting condition.\n",
      "Also provides video recording facilities, recorded videos are stored in the own memory of station.\n",
      "Tracking System\n",
      "Pinpoint the exact location of the station.\n",
      "The most active station can be observed by the Web App.\n",
      "Solar Power\n",
      "The stations are powerd by battaries.\n",
      "A solar cell system is used to recharge them.\n",
      "Durable\n",
      "Can be set up in any environment. Made with highly durable and waterproof materials so that animals\n",
      "and unforgiving weather can't damage it.\n",
      "Self Storage In Stations\n",
      "Data obtained by the system is stored in itself when there is no connection with the database.\n",
      "NEXT GENERATION OF WILDLIFE RESEARCHING!\n",
      "**********************\n",
      "Project Design\n",
      "Web Application\n",
      "Organization of the Web App\n",
      "Home\n",
      "Registration\n",
      "Login\n",
      "Password recovery\n",
      "User Dashboard\n",
      "Admin Dashboard\n",
      "Previous\n",
      "Next\n",
      "Here are the two registration pages in our web application.\n",
      "01. The user registration Page\n",
      "02. The admin registration Page\n",
      "Form validations and feedbacks are used to give a better user experience.\n",
      "Clients have to fill all the fields correctly in the forms to enable the submit button.\n",
      "The button provided in left top corner directs user to the home page.\n",
      "Previous\n",
      "Next\n",
      "Here are the two login pages in our web application.\n",
      "01. The user login Page\n",
      "02. The admin admin Page\n",
      "02. The error message if the credentials are not valid.\n",
      "Form validations and feedbacks are used to give a better user experience.\n",
      "The user have to provide the correct credential to login to the system.\n",
      "If the credentials are not matching it will display the error message. With error message, links back to the login page or\n",
      "password recovery are provided.\n",
      "Also in the login pages we have provided a link to password recovery. Users can reset their password using this link.\n",
      "Previous\n",
      "Next\n",
      "These are the pages in user dashboard.\n",
      "There is a home tab, photos tab, location tab and a contact tab.\n",
      "In photos tab user can see the photos taken by devices connected to his profile. Also there is a option to connect new devices\n",
      "with the profile.\n",
      "The map provided in location tab pinpoints all the location of devices connected to users profile.\n",
      "Previous\n",
      "Next\n",
      "Here are the pages in admins dashboard. The user tab will show all the user requests to the system.\n",
      "Admin can see details and the letter uploaded by each user by clicking on a request in the list.\n",
      "Then they can submit or reject the request. If they are rejecting the request, they have to provide the reason for the rejection\n",
      "in given text box.\n",
      "This is the home page of our web application. Clients can login to there accounts by click on the log in button.\n",
      "The get started button directs clients to user registration form.\n",
      "The button provided in the right bottom corner provides a link to contact us via emails.\n",
      "Previous\n",
      "Next\n",
      "There are two pages for password recovery process. The first one is for reqest a password recovery.\n",
      "Here, user have to enter the email of his account and submit.\n",
      "If the entered email is valid, it will show up the success message. Else, it will showup the error message.\n",
      "Database Schema\n",
      "We use MongoDB as our database managment system. Because of its scalability,\n",
      "its powerful querying capabilities and the fexibility it provides for modele and\n",
      "manipulate data structures.\n",
      "Cloud Deployment\n",
      "We have used AWS EC2 instance to deploy our web application. NGINX is used as the load balancer And\n",
      "revers proxy of our frontend because of its capability of handling high volume of connections. This helps our\n",
      "web application to handle number of clients at once. Since we have used NodeJS to implement the backend of our\n",
      "web aplication we have used PM2 process manager to keep our nodeJS application alive at all the times.\n",
      "Because of the limitations of AWS Educate accounts we were not able to use R3 services to get a domain name.\n",
      "Therefore we had to use seld signed certificate to serve HTTPS.\n",
      "We have used MongoDb Atlas as our database managment system. Therefore we have connected the database to server\n",
      "running in EC2 instance.\n",
      "Devices are sending data to AWS IoT core using MQTT. These data are stored in a S# bucket. Then the server running in\n",
      "EC2 instance is accessing these data. We were not able to implement this part yet because the AWS educate account dont have permissions\n",
      "to use IAM services. Therefore, at this point we have created the file structure in the server itself.\n",
      "Hardware\n",
      "Organization of the Hardware System\n",
      "Algorithm that runs in the camera unit\n",
      "Hardware Implementation\n",
      "Camera And Sensor unit\n",
      "Connection And GPS unit\n",
      "Power unit\n",
      "Data processing unit\n",
      "This unit handles the sensing and taking snapshots of wild animals\n",
      "accordingly.\n",
      "It is consist of ESP32 Cam Board, PIR motion sensor(HC-SR501), Flash\n",
      "LED and a LDR.\n",
      "PIR sesor is capable of sensing motions within 7 meters and 120° range.\n",
      "This sensor will trigger the camera\n",
      "to take photo and then a 30 second video is captured.\n",
      "ESP32 cam board is consist of a powerfull image processing\n",
      "unit that allows to take very clear photos\n",
      "and a SD card slot. The PIR sensor is directly connected to the ESP32\n",
      "cam board. The captured photos are\n",
      "stored in the SD card before send to the cloud database. Videos are not\n",
      "sent to cloud database they will be stored\n",
      "in the SD card.\n",
      "The LDR is used to monitor light conditions and according to\n",
      "those readings the LED flash will automatically turn on.\n",
      "This allow us to capture clear photos in bad light conditions.\n",
      "The connection and GPS unit is consist of SIM800L module and\n",
      "GPS module.\n",
      "The GPS module is used to get the best possible position information.\n",
      "User can check the exact\n",
      "position of the device through the web app. The data observed by this\n",
      "GPS module is used to\n",
      "pinpoint the location.\n",
      "SIM800L module is used to communicate with the AWS server.\n",
      "This module allows for GPRS\n",
      "transmissions without Wi-Fi. This module is very suitable for long range\n",
      "connections.\n",
      "The main components in this unit are 3.7V 1800mAh batteris,\n",
      "Solar panel, voltage regulator and battery charger.\n",
      "Solar cell recharges the batteries when there is optimal sunlight.\n",
      "This generated power can be used to power the system very efficiently in\n",
      "harsh environments.\n",
      "ESP32-SIM800L module is the main component in this unit. It\n",
      "interconnects all the units\n",
      "and gathering data from other units to send to the AWS IoT core. This\n",
      "module consist of inbuilt\n",
      "SIM800L module which capable of sending and receiving GPRS data without\n",
      "WiFi.\n",
      "All MQTT certificate and GPS data are stored in inbuilt 4MB\n",
      "flash of ESP32-SIM800L module.\n",
      "Stored GPS data are used to check whether there is a defferance between\n",
      "new readings.\n",
      "If there is a difference GPS data is sent to the cloud.\n",
      "Security Features\n",
      "Our system handles really sensitive information about wildlife. Therefore, the CIA triad (Confidentiality, Availability, Integrity) of the application is maintained in the best way possible.\n",
      "JsonWebTokens (JWT) are used for the authorization of users. These tokens are stateless, portable, high performing and decentralized which improves the security and scalability of the web application as well.\n",
      "HTTPS protocol is used for secure communication.\n",
      "A special system of user registration is introduced to ensure the users of our web app are researchers.\n",
      "Testing Plan\n",
      "Unit Testing\n",
      "Test functionality of each page of the web app\n",
      "Test login, registration and form validations\n",
      "Test sensors and hardware components\n",
      "Integration Testing\n",
      "Test front end and back end intergration.\n",
      "Test database and back end intergration.\n",
      "Test web app and hardware device intergration.\n",
      "End to End Testing\n",
      "Test overall functionality of the web app and hardware device.\n",
      "Check user registraton, registration aproval.\n",
      "Check data flow from devices to user profiles.\n",
      "Check data flow from devices to cloud.\n",
      "Testing Tools\n",
      "Front End Testing\n",
      "We use selenium automated testing framework to test the front end of our web app.\n",
      "Main reasons to pick selenium is it supports different browsers and platforms. Also,\n",
      "it supports testing scripts written in multiple languages.\n",
      "We are planing to use selenium to test, form submissions, form validations\n",
      ",response handling functionalities in our web app.\n",
      "Back End Testing\n",
      "We use insomnia API testing tool to test the back end of the web application.\n",
      "insomnia allows us to send HTTP requests using a graphical user interface.\n",
      "insomnia acts as the client and it is possible to analyze server responses\n",
      "to HTTP requests.\n",
      "We are using insomnia to test, routings implemented in backend, authentication and authorization,\n",
      "error handlings and sending responses in the API.\n",
      "Testing Procedure and Results\n",
      "Unit Testing\n",
      "Front end testing\n",
      "As an unit test we tested the functionality of the front end of our web application.\n",
      "This is very important because the front end is used by our clients. So, it must provide all the expected outcomes correctly to give a\n",
      "better user experiance. Therefore, we needed to make sure that the front end of our web application works fine.\n",
      "We have used the automate testing tool selenium to test front end. The first test we have done is the navigation test. We wrote a\n",
      "script to click the all possible links inour web application and the we have checked whether it navigate to expected page. Form validations are\n",
      "another important aspect in UI. So, we wanted to test whether our app provides correcet feed backs when the client fill a form. For this also we\n",
      "wrote a selenium script. In this script, we tested all of our forms with invalid data to make sure they are giving correct feed back. Also, we tested\n",
      "the froms with valid data to make sure that the forms are not giving any invalid feedback wheth client inputs valid data.\n",
      "The scripts are attached here.\n",
      "The testing results are listed below.\n",
      "Back end testing\n",
      "Prior to the intergration of frontend and backend, we wanted to make sure that our rest API returns correct responses to\n",
      "clients requestes. We use 'Insomnia' to test the API. We have implemented lot of routes in our API to do various tasks and to handle various\n",
      "requests from the frontend of our web application. It is very important to make sure that the API is providing correct responses. Because the\n",
      "security of the web application is depends on these responses. Using insomnia we have tested each route in our API for valid and invalid data.\n",
      "We have tested whether the API responds with correct status codes, data and error messages for different data sets. Also as an security test,\n",
      "we have passed wrong credentials to the API using insomnia and checked whether it rejects those requests. We have used JWT tokens to authorize clients.\n",
      "It is very important to make sure tha API is rejecting invalid tokens. Therefore we have tested whether the API is rejecting invalid tokens by sending\n",
      "invalid token using insomnia. All of these tests are conducted manually. The below figure contains all the cases we have tested using insomnia.\n",
      "Integration Testing\n",
      "To test the integration of the backend, frontend and the database, we used selenium. We have tested the response from the server to\n",
      "logins, user registrations, password recoveries and invalid inputs to make sure that the data flow from front end to back end and from back end to\n",
      "data base is fine. We have wrote scripts to enter valid and invalid credentials in login pages and check the response of the server.\n",
      "If these compnent intergrations are fine, the logins for valid credentials must be successfull. We have tested whether the\n",
      "request with correct credentials directs the client to the dashboards in the scripts. We had to check the database manually to make sure all the\n",
      "data entered by the script is recorded in database correctly.\n",
      "Also, we have tested the same script for three popular browsers. Google Chrome, Microsoft edge and Operamini to make sure our web\n",
      "application is ccompatible with different platfoorms.\n",
      "The testing scripts are attached here.\n",
      "Testing Results\n",
      "Results of tests by Selenium\n",
      "Test run No 1: Chrome Browser\n",
      "Passed: 6\n",
      "Faild: 1\n",
      "Test run No 2: Chrome Browser\n",
      "Passed: 7\n",
      "Faild: 0\n",
      "Test run No 1: Microsoft Edge Browser\n",
      "Passed: 7\n",
      "Faild: 0\n",
      "Test run No 2: Microsoft Edge Browser\n",
      "Passed: 6\n",
      "Faild: 1\n",
      "Test run No 1: Operamini Browser\n",
      "Passed: 6\n",
      "Faild: 1\n",
      "Test run No 2: Operamini Browser\n",
      "Passed: 7\n",
      "Faild: 0\n",
      "Test Case\n",
      "Chrome\n",
      "Edge\n",
      "Opera\n",
      "Navigations to all the pages\n",
      "passed\n",
      "passed\n",
      "passed:1 Faild:1\n",
      "Form validations for incorrect inputs\n",
      "passed:1 Faild:1\n",
      "passed:1 Faild:1\n",
      "passed\n",
      "Form validations for correct inputs\n",
      "passed\n",
      "passed\n",
      "passed\n",
      "User login and dashboard function\n",
      "passed\n",
      "passed\n",
      "passed\n",
      "User registration test for valid and invalid data\n",
      "passed\n",
      "passed\n",
      "passed\n",
      "Admin login and dashboard function test\n",
      "passed\n",
      "passed\n",
      "passed\n",
      "Password recovery test for valid and invalid emails.\n",
      "passed\n",
      "passed\n",
      "passed\n",
      "Results of tests by Insomnia\n",
      "Test Case\n",
      "Returned Status Code\n",
      "Expected Status Code\n",
      "Observation\n",
      "Faild / Passed\n",
      "User and Admin login for correct credentials\n",
      "200\n",
      "200\n",
      "Backend responds with status code 200 and send a token to client\n",
      "passed\n",
      "User and Admin login for incorrect credentials\n",
      "401\n",
      "401\n",
      "Responds with status code 401 and rejects the request. Just recived credentials invalid message.\n",
      "passed\n",
      "User and Admin Registration for emails that are already registered in system\n",
      "409\n",
      "409\n",
      "Rejects registration for same emails.\n",
      "passed\n",
      "Password recovery for emails that are not registered in system\n",
      "401\n",
      "401\n",
      "Rejects password recovery for invalid emails.\n",
      "passed\n",
      "Password recovery for emails that are registered in system\n",
      "201\n",
      "201\n",
      "Recived message indicating that the password recovery email is sent to entered email.\n",
      "passed\n",
      "Try to reset password for second time using a link used before.\n",
      "401\n",
      "401\n",
      "Recived message indicating that the password recovery link is invalid or expiered.\n",
      "passed\n",
      "Try to reset password of a accont using a token sent to another email\n",
      "401\n",
      "401\n",
      "Recived message indicating that the password recovery link is invalid or expiered.\n",
      "passed\n",
      "Try to register as an admin using a link that already used to register.\n",
      "401\n",
      "401\n",
      "Recived message indicating that the link is invalid or expiered.\n",
      "passed\n",
      "Try to log in to the admin dashboard using a token recived for user login\n",
      "401\n",
      "401\n",
      "Recived message indicating that the client is not an admin. Redirection rejected.\n",
      "passed\n",
      "Confirm or Reject request with admin token.\n",
      "200\n",
      "200\n",
      "With admin token. Possible to confirm or reject client request.\n",
      "passed\n",
      "Confirm or Reject client request with user token.\n",
      "401\n",
      "401\n",
      "With user tokens. Cannot confirm or reject requests. Recieved message unauthorized.\n",
      "passed\n",
      "Project Budget\n",
      "(Budget is made for 1 Hardware unit only)\n",
      "Hardware Component\n",
      "Amount\n",
      "Price(Rs)\n",
      "Place\n",
      "Infrared PIR motion Sensor\n",
      "1\n",
      "235.00\n",
      "tronics.lk\n",
      "ESP32 Cam Board\n",
      "1\n",
      "1890.00\n",
      "tronics.lk\n",
      "FTDI connector\n",
      "1\n",
      "470.00\n",
      "tronics.lk\n",
      "ESP32-SIM800L module\n",
      "1\n",
      "3250.00\n",
      "tronics.lk\n",
      "Ublox NEO_6M GPS module\n",
      "1\n",
      "985.00\n",
      "tronics.lk\n",
      "1W LED\n",
      "1\n",
      "25.00\n",
      "tronics.lk\n",
      "LDR\n",
      "1\n",
      "10.00\n",
      "tronics.lk\n",
      "Solar Panel (>6V) 165mA\n",
      "1\n",
      "560.00\n",
      "duino.lk\n",
      "Battery Charger\n",
      "1\n",
      "90.00\n",
      "tronics.lk\n",
      "3.7V 4800mAh batteris\n",
      "2\n",
      "700.00\n",
      "nilambaraelectronics.com\n",
      "Other Expenditures\n",
      "-\n",
      "1500.00\n",
      "TOTAL\n",
      "9715.00\n",
      "Project Timeline\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wikramasinghe\n",
      "Group Members\n",
      "Group 9\n",
      "E/17/176\n",
      "Kumara W.M.E.S.K\n",
      "E/17/006\n",
      "Alahakoon A.M.H.H\n",
      "E/17/338\n",
      "SRIMAL R.M.L.C\n",
      "Project Repositry\n",
      "Project Page\n",
      "Department Of Computer Engineering\n",
      "University of Peradeniya\n",
      "A Project by, group of 3rd year computer engineering undergraduates, University of Peradeniya, Sri Lanka\n",
      "\n",
      "\n",
      "Extracting maker mate https://cepdnaclk.github.io/e17-3yp-maker-mate\n",
      "\n",
      "\n",
      "Maker Mate\n",
      "MakerMate\n",
      "Home\n",
      "About\n",
      "Services\n",
      "Team\n",
      "Makes your makersfeel comfortable\n",
      "See how it works\n",
      "Project Repository\n",
      "What\n",
      "Maker Mate brings to you?\n",
      "Maker Mate enables the lab users to apply for the project/ experiment requirements online and collect tools and equipment accordingly from a pickup locker while the lab admin can manage the entire inventory online with ease. Maker Mate can take similar role but for different use case on demand.\n",
      "Learn more\n",
      "Services\n",
      "Client Web App\n",
      "The web app provides services according to privileges of users. Admin can have full access to the inventory system and users signed in can apply for components to borrow from Maker Space. Guest users can access the lab equipment and component documentation.\n",
      "Information Console\n",
      "A touch screen that provides simple and easy to use user interface to authenticate and unlock the locker. Makers can easily search for tools and components and get to know how to use them and other required details.\n",
      "Monitored Pick-up Locker\n",
      "A locker which is monitored by a camera when it is opened by a user with authorization. The lock is controlled by a Raspberry Pi, which provides commands to unlock according to authentication.\n",
      "Information Console Interface\n",
      "Tech Stack\n",
      "We use necessary software and hardware tools to develop and test the product\n",
      "Wanna know more about Maker Mate?\n",
      "Find more descriptive details about Maker Mate\n",
      "Learn More\n",
      "Our Team\n",
      "Thilini\n",
      "Member\n",
      "Thanujan\n",
      "Member\n",
      "Madhushan\n",
      "Member\n",
      "Hashan\n",
      "Mentor\n",
      "Jaliyagoda\n",
      "Mentor\n",
      "Dr. Isuru\n",
      "Supervisor\n",
      "Dr. Mahanama\n",
      "Supervisor\n",
      "© Copyright Reveal. All Rights Reserved\n",
      "Designed by BootstrapMade\n",
      "\n",
      "\n",
      "Extracting remote billiard https://cepdnaclk.github.io/e17-3yp-remote-billiard\n",
      "\n",
      "\n",
      "Project Page - Remote Billiard Game | Home\n",
      "Home\n",
      "About\n",
      "Solution\n",
      "Design\n",
      "Solution\n",
      "Infrastructure\n",
      "Software\n",
      "Budget\n",
      "Team\n",
      "Github Repository\n",
      "Remote Billiard\n",
      "We have combined\n",
      "the live game play of billiard with a online platform. You can experience the Excitement\n",
      "of the live billiard game with a opponenent who is not in the same room!\n",
      "INTRODUCTION\n",
      "\"Remote Billiard\" is a project which provides usual Billiard game experience via online platform.Not all the players could be in the same place to play a billiard game now a days. Project \"Remote Billiard\" solves this problem. Players can play their game physically at their own places individually.\n",
      "PROBLEM\n",
      "Usually if a pool game is supposed to\n",
      "be played, the players should physically be present. But the issue is not everyone has the luxury\n",
      "of time to attend a game due to various reasons. In this case, the least thing that they could do is\n",
      "play the game online via a mobile or a PC with their friends. But if you ask such players\n",
      "whether the experience was satisfying, they would definitely say no! So to avoid this issue we\n",
      "have planned to give the player the so called Physical experience at their own comfort zones.\n",
      "According to our plan we will be solving a lot of problems such as the issue with time,\n",
      "travelling issue, could reduce expenses and will be able to provide the player the real physical\n",
      "experience which would be a great chance to enhance their skills at the same time would be\n",
      "more fun than online games. Therefore in overall , Remote-Billiard project solves these\n",
      "problems.\n",
      "OUR SOLUTION\n",
      "Simple Solution\n",
      "Solution Techniques\n",
      "Solution Architecture\n",
      "Simple Solution demonstrated between two players.\n",
      "Lets cosider two players who are at two different locations as PLAYER A and PLAYER B\n",
      "Lets assume PLAYER A makes the first shot.\n",
      "When the first shot is made, the ball arrangement of the table of player A is captured by the device.\n",
      "This captured image is then processed and sent to the device of player B.\n",
      "This processed image is then projected onto the table of PLAYER B.\n",
      "Player B then has to arrange the balls based on the projected image and will have to play his shot.\n",
      "Techniques used for our solution.\n",
      "BALL DETECTION\n",
      "First the image of the Player A is captured.\n",
      "Next Using QR tags which are already pasted on the 04 corners of the pool table, the captured image is aligned.\n",
      "IMAGE PROCESSING\n",
      "Then this aligned image is processed.\n",
      "This processed image is sent to the device of player B.\n",
      "BALL PROJECTION\n",
      "If projection happens for the first time, the projecting area of table of plyaer B is calculated. For this,\n",
      "first a set of QR tags are projected on to the table, the cordinates of these QR tags are matched with the existing QR tags which were already pasted on the table.\n",
      "Once the projecting area is calculated the processed image is processed on to the table of player B.\n",
      "Solution Architecture of how two or more players connect.\n",
      "The camera module and the projector of one player is connected to the microcontroller.\n",
      "The microcontroller of one player is connected to another players microcontroller via the internet which goes accross a web server.\n",
      "Mobile applications of each players are connected with each other via the the internet which goes accross the web server.\n",
      "DESIGN\n",
      "3D MODEL OF OUR PRODUCT\n",
      "Solution Overview\n",
      "CLOUD DEPLOYMENT\n",
      "APPLICATION DESIGN\n",
      "MOBILE APP DEMONSTRATION\n",
      "SIGNUP and SIGN IN functionalities for multiple clients.\n",
      "REGISTERED PLAYERS\n",
      "MULTIPLAYER FUNCTIONALITY\n",
      "( Shows only the players who are online at the moment , and if the player is available for a game then a game invitation can be sent.)\n",
      "TOSS FUNCTIONALITY\n",
      "(As soon as the players connect , they have the ability to toss in and decide who is going to play first. The toss is generated randomly.)\n",
      "CALL FOR FOUL FUNCTIONALITY\n",
      "(while the game is on going , if a player notices a foul made by his opponnent through the live stream then he can call for a foul. And if it was a foul then the oponnent can either accept it or decline the call.)\n",
      "CHOOSE POCKET FUNCTIONALITY\n",
      "(Players can choose a pocket before they make their shot. The chosen pocket number will be displayed to the opponent.)\n",
      "REAL TIME CHAT FUNCTIONALITY\n",
      "(While the game is ongoing the players can chat real time).)\n",
      "Flow Chart\n",
      "Circuit Diagram\n",
      "Data Control Flow\n",
      "Flow Chart\n",
      "ER Diagram\n",
      "Circuit Diagram\n",
      "Circuit Diagrom\n",
      "SOLUTION INFRASTRUCTURE\n",
      "Control Unit\n",
      "Projector\n",
      "Supporter\n",
      "QR Tag\n",
      "Control Unit\n",
      "Following Components are included\n",
      "Raspberry pi 3 model B Microcontroller\n",
      "Camera module\n",
      "SD card(16 GB)\n",
      "Distance sensor\n",
      "Cooling fan\n",
      "Indicators\n",
      "Projector used to project the ball positions onto the table\n",
      "Supporter\n",
      "The projector and the control unit can be mount with the help of the supporter.supporter is an adjustable one. So that we can adjust the height between the table and the device\n",
      "which is really important to focus the device perfectly on to the pool table.\n",
      "QR tags are used to detect the perfect alignment of the picture.\n",
      "T\n",
      "MOBILE APP TESTING\n",
      "UNIT TESTING\n",
      "Login Validation\n",
      "CLIENT AND SERVER CONNECTION TESTING\n",
      "INTEGRATION TESTING\n",
      "Multiple client connection\n",
      "SignUp and Login testing\n",
      "Currently online players list\n",
      "Displays all registered users\n",
      "Sends game invitation to another player who is online\n",
      "Random Toss generation\n",
      "Foul call\n",
      "Pocket selection\n",
      "Real-time messaging between players\n",
      "EMBEDDED SYSTEM TESTING\n",
      "Connecting the Remote-Billiard device (pi module) to the mobile app via bluetooth\n",
      "Based on the ball movements the device sends SIGNALS to the opponents mobile application.\n",
      "IOT device to IOT device communication TESTING\n",
      "Raspberry pi module is taken as one IOT device and the PC is taken as the other IOT device\n",
      "Both the devices are subscribed to the same topic.\n",
      "Using OpenCV implementations ball movements is detected and once the balls stop movements, Image is captured and the raw image is processed inside pi.\n",
      "This processed image is then published to the relevant topic. (Test : Raspberry pi to PC)\n",
      "OpenCV Implementations\n",
      "1. Supporter adjusment\n",
      "With the use of hight adjusting supporter and the aruco markers on the board we can calculate real world height from supporter plate to\n",
      "The board.When the height reached required value, a in openCV code a signal will generate. With that flag signal a indicator will light on the microcontroller. This is helpful for the accuracy of capturing the playing area\n",
      "and to do the final projection.\n",
      "For this height detection function, camera calibration matrix and distortion values are needed as inputs.\n",
      ".\n",
      "2. Projection area adjusment\n",
      "Four aruco tags will be attached near corners of poolboard.\n",
      "And their coordinates are taken with their ID. Link to the implementation\n",
      "Then another set of aruco tags are projected on to the table, the cordinates of these aruco tags are matched with the existing aruco tags which were already pasted on the table.\n",
      "If the projection alignment is right a signal will sent to the microcontroller to light up a LED.\n",
      "3.Board area isolation and wrapping\n",
      "To get the board area from the captured image. Corners were identified and using corner coordinates image was wraped.\n",
      "Link to the implementation\n",
      "4.Ball colour detection isolation and generate processed image\n",
      "OpenCV trackbars are used to get the accurate colour levels of balls.\n",
      "Link to the implementation\n",
      "Using those hsv valuse ball location were identified and locations are drawn on a white backbround. Final processed image is ready to sent.\n",
      "Link to the implementation\n",
      "5.Ball Movement Identification\n",
      "To identify whether the balls still moving or stopped moving first the video was captured from OpenCV\n",
      "then grabed the video frame by frame. If the previous frame is exact with the current frame this means the video vision is still. Ball moving or not moving signal is genereated using this concept.\n",
      "Link to the implementation\n",
      "BILL OF MATERIAL\n",
      "OUR SUPERVISERS\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wickramasinghe\n",
      "OUR TEAM\n",
      "M.I.Rishard\n",
      "S.P.D.D.S.Weerasinghe\n",
      "A.M.F.Shalha\n",
      "\n",
      "\n",
      "Extracting remote keyboard tutoring system https://cepdnaclk.github.io/e17-3yp-remote-keyboard-tutoring-system\n",
      "\n",
      "\n",
      "Remote Keyboard Tutor\n",
      "forté\n",
      "Menu\n",
      "Home\n",
      "About\n",
      "Architecture\n",
      "Design\n",
      "Devices\n",
      "UI / UX\n",
      "Data Flow\n",
      "Generation of Data\n",
      "Flow of Data\n",
      "Software\n",
      "Frontend\n",
      "Backend\n",
      "Other\n",
      "Hardware Functionalities\n",
      "Security Aspects\n",
      "Features\n",
      "Research Findings\n",
      "Timeline\n",
      "Budget\n",
      "Contact\n",
      "Learn or Teach PianoIn\n",
      "The Remote Keyboard Tutoring System is a web\n",
      "based system that can be attached to any (electronic) keyboard synthesizer through a MIDI\n",
      "connector. Once our system is connected to the keyboard, the user can interactively learn,\n",
      "play or teach in combination with the web application that we provide.\n",
      "Project Repository\n",
      "×\n",
      "Key-press Indication\n",
      "Remote key-presses as well as local key-presses (when working offline) are displayed in\n",
      "real-time with low latency.\n",
      "Interactive Exercises\n",
      "Upload exercises for the students as sheet music and let the system handle the rest. The\n",
      "system keeps records of student's mistake while practicing.\n",
      "Schedule Classes Easily\n",
      "Teachers can schedule the classes easily with the web application. Students can also\n",
      "easily find teachers near by.\n",
      "Offline Helper\n",
      "Upload the sheet music that you want to practice and the helper will assist you while\n",
      "playing.\n",
      "Why do you need a keyboard tutoring system?\n",
      "The Problem\n",
      "Piano is the most\n",
      "admired musical instrument so far. Over 25% of the world population fancy playing it. Yet not\n",
      "everyone is fortunate to learn from the best. This has fabricated a vast difference in the skill\n",
      "level of people who are playing the piano. The reason would be that most of the experts in the field\n",
      "lives in either the western hemisphere or east Asia. Even local experts aren't scattered throughout\n",
      "the island. So most of them tend to make use of the online procedures to teach piano. The current\n",
      "online methods would be using a platform like zoom and an app that simulates what one plays from his\n",
      "instrument. This hasn't shown profound results since the teacher or the student has problems when\n",
      "showing what he's playing on the piano in real time. The accuracy of the app isn't acceptable and\n",
      "the relationship between the student and the teacher isn't sturdy like in a live class room.\n",
      "Our Solution\n",
      "The solution we present\n",
      "is a web based system that can be attached to\n",
      "any keyboard synthesizer through a MIDI connector (Legacy or USB). Thus, the only requirement for\n",
      "the keyboard is MIDI support. Once our system is connected to the keyboard, the user can\n",
      "interactively learn, play or teach in combination with the web application that we provide. The user\n",
      "has to be logged in as either a typical user or an expert (a tutor) depending on the user's needs.\n",
      "Users can\n",
      "get connected to each other in the network and they can share their music with each other. Users can\n",
      "play shared music in their own keyboard and join to experts to learn remotely in real-time. The\n",
      "tutor can handle multiple students at a time. When the tutor plays on the keyboard, those notes will\n",
      "be displayed and played in the students keyboards simultaneously. Tutor can upload exercises and\n",
      "when a student plays incorrectly, the wrong key presses will be displayed to both the student and\n",
      "the tutor. Their is also an offline helper which will assist the user while practicing when\n",
      "connected to the mobile phone via Bluetooth.\n",
      "Solution Architecture\n",
      "Our system consists of two devices: the Processing Unit and the Visualizer Bar which is a\n",
      "composition of visualizer blocks. The processing unit can be connected to our server via a home router and exchange MIDI data with the\n",
      "server or with another remote processing unit if they are connected in a session. In order\n",
      "to communicate with the server there'll be a mobile application as well as a web platform.\n",
      "Through the web platform, students or teachers can login to the system and use the facilities that we provide in our system. When a student is logged in, he/she can easily find teachers near their area or based on the teacher's ratings and reviews. The students can interactively learn what the teacher plays remotely due to the low latency real-time key press indication.\n",
      "Using the offline helper we provide in the mobile application (which can be used when the device is connected to the mobile via BT), students can practice music with the assistance of the offline helper. Students can also upload sheet music and play them in their own keyboard synthesizer. When they make a mistake, it'll be displayed in the mobile app by highlighting the particular note in the sheet music\n",
      "as well as in the visualizer bar. They can also record and store their playings to the cloud and show them to the tutor at any time.\n",
      "When a tutor is logged in to the system, he/she can create their own courses or classes within the system. They can also schedule their existing classes. During a class, tutors can independently monitor his students' playings and give feedback to them. The tutor can upload exercises and when the students practice them, their progress will be recorded until the student marks them as finished. Even if the student practices\n",
      "the exercises offline, the progress will be stored temporarily in the mobile phone and will be uploaded to the tutor when the student logs in again.\n",
      "Previous\n",
      "Processing Unit\n",
      "The Processing Unit handles all the data processing and remote communications. It\n",
      "has two MIDI interfaces (one for MIDI-in and the other for MIDI-out) as well as\n",
      "two USB-C ports. One USB port act as a MIDI redirect interface which also allows\n",
      "the processing unit to be recognized as a USB device when connected to a\n",
      "computer. The other USB port is to connect the visualizer bar in.\n",
      "The processing unit also consists of inbuilt Wi-Fi as well as Bluetooth via an\n",
      "ESP 32 Development board. Through this the consumer can directly connect our\n",
      "device to the internet through their home router and send MIDI data to our\n",
      "server or another processing unit in a remote location.\n",
      "Visualizer Bar\n",
      "The visualizer bar is where all the key press information will be displayed at.\n",
      "The bar has to be placed on the keyboard near\n",
      "the end where the key hinges are. We provide the visualizer bar as\n",
      "easy-to-connect blocks in order for our product to fit any\n",
      "kind of keyboard and to make our product portable. The three common keyboard\n",
      "sizes are 61-keys, 76-keys and 88-keys. Therefore,\n",
      "the blocks are such that it covers an octave. Since blocks might not cover the\n",
      "whole keyboard, we provide the visualizer bar as a\n",
      "whole for the most common keyboard sizes as well.\n",
      "The visualizer bar has a USB-C port at the right end to connect in to the\n",
      "processing unit. The visualizer blocks have magnetic\n",
      "ends to stay still when they're connected. Left end of a block has a female\n",
      "USB-C port and the right end has a male USB-C connection. The bar has RGB LEDs\n",
      "representing each key and they will lit according to the key presses.\n",
      "Next\n",
      "UI / UX Design\n",
      "Previous\n",
      "Web UI\n",
      "Once the user creates an account on this apllication, the processing unit can be connected to it. Then the user can,\n",
      "Select and enroll in courses.\n",
      "Upload score sheets to the account and play them on the keyboard.\n",
      "Create score sheets using MIDI files.\n",
      "Record what he/she plays on the keyboard.\n",
      "Convert recordings into score sheets.\n",
      "Remotely play the student's/teacher's keyboard synthesizer.\n",
      "More features will be included along with the implementation of the product.\n",
      "Mobile UI\n",
      "Once the user creates an account on this apllication, the processing unit can be connected to it. Then the user can,\n",
      "Select and enroll in courses.\n",
      "Upload score sheets to the account and play them on the keyboard.\n",
      "Create score sheets using MIDI files.\n",
      "Record what he/she plays on the keyboard.\n",
      "Convert recordings into score sheets.\n",
      "Remotely play the student's/teacher's keyboard synthesizer.\n",
      "More features will be included along with the implementation of the product.\n",
      "Next\n",
      "Generation of Data\n",
      "MIDI - Musical Instrument Digital Interface\n",
      "MIDI is standard protocol for communication between computers and musical instruments.\n",
      "Made up of an 8-bit command byte,\n",
      "generally followed by 1 or 2 data bytes.\n",
      "MIDI Commands\n",
      "Note on - This MIDI command will be sent when a note is played.\n",
      "Note off - This MIDI command will be sent when a note is released.\n",
      "After touch - This defines the preassure applied to the key.\n",
      "You can read more details about MIDI from here.\n",
      "Flow of Data\n",
      "When some key strokes are played in a keyboard, the keyboard itself will convert those notes to MIDI data. Then those MIDI data are send to our processing unit and from there the MIDI data can be send to our remote server in order to store or if that processing unit is in a session with a another processing unit those data can be directly send to that processing unit via the internet. Even though the processing unit is not connected to the internet it will generate necessary control signals in order to visualize those notes in the local visualizer bar.\n",
      "So if the processing unit is in a session with a remote processing unit the two processing units can exchange MIDI data via the internet. The processing units can send received MIDI data to the keyboard and the control signals to the visualizer bar. Thus, the recipient can here as well as see what the remote sender is playing.\n",
      "Frontend\n",
      "Frontend Technologies\n",
      "For our frontend web platform would be implemented using React.js. React will assure a fast and easy development of the frontend since React provides lots of readymade components to use and React uses javascript it will be easier to coordinate with the backend as well. Other than that React apps can be made SEO friendly by making them server-side rendered rather than client-side rendered.\n",
      "Our frontend mobile platform will be implemented using Flutter since it also provides a lot of components to use and Flutter performs well in a lot of mobile devices. Since Flutter uses Dart as the programming language we can use the same codebase for both ios and android applications.\n",
      "What we have done so far?\n",
      "Click here to see what we have done upto now in the web frontend and click here to see what we have done so far in the mobile frontend.\n",
      "Backend\n",
      "Backend Technologies\n",
      "Our backend computing platform would be Node.js along with express as the framework. It'll assist us in hadling multiple online requests and the working environment will be more effective and better-coordinated since javascript laguage is used in both frontend and backend development. MongoDB will be used as our database system. As the number of users for our product increase, it is very much practical to use MongoDB since it is very easy to scale up or down. MongoDB works on all types of cloud platforms. Since we'll be using aws to host our services MongoDB will be a great choice. NGINX is used as a reverse proxy so we can get access through http, https and Let's Encrypt is used to get free SSL certificates. All our backend services will be hosted using AWS services. An AWS EC2 instance is used run all the processes and AWS backup will be used to automate and manage backups.\n",
      "click here to see what we have done so far.\n",
      "Hardware Functionalities\n",
      "The brain of our processing unit is the ESP32 Development board. As shown in the high-level diagram, it's needed to have a MIDI interface in between the visualizer bar and the keyboard synthesizer for communicating with MIDI messages. The processing unit will be connected to Wifi as well as to the mobile phone via bluetooth. We use this BT connection for the offline helper as well as to authenticate to a Wifi router.\n",
      "When MIDI messages arrive at the processing unit either from the user's keyboard or from remotely through the server, the microcontroller will process them and send control signals to the visualizer bar appropriately. The communication between the visualizer bar and the processing unit will happen via an USB interface through a wired connection. The visualizer bar will also need to send signals to the processing unit because in order to light up the correct key on the keyboard, the processing unit needs to know the positional information of the particular visualizer block. So, before the user starts using the system he needs to do a very simple calibration procedure: play both the first note and the last note one after the other that the visualizer bar covers when the app prompts and thereafter the processing unit will memorize which block is where. In order to achieve this, the visualizer bar will also require a microcontroller. We will be using an arduino pro micro for this purpose.\n",
      "Security Aspects\n",
      "Security Aspects\n",
      "Cybersecurity of connected embedded system devices has always been important. Since our system also involves sharing confidential information through the internet such as passwords and online payments, we have taken extra care to ensure the security of the system. The diagram to the right shows how we have designed our system to ensure the CIA triad.\n",
      "To ensure the confidentiality of the system, all the data stored in the server will be encrypted with AES or hashed. When connecting the mobile application to the device for the first time or after a long time of inactivity, the device will ask for a password pin. The pin will be sent to the server and if it is correct the device will be allowed to connect to the mobile phone. The diagram itself explains the countermeasures we have taken to ensure the other two cybersecurity aspects.\n",
      "Our Secure Design Process\n",
      "The following diagram shows our secure embedded system design process. The gray color path is the ideal embedded system design process that anyone would follow.\n",
      "In addition to that, we have added a security approach that'll happen in parallel with the embedded system design process. Starting from our concept of operations, we will do a threat analysis while collecting the functional requirements to analyze the potential attacks that the system may be subjected to when deployed. The next step is to specify how our demand measures the security requirements of the system. Once we have the security requirements, we will start developing the security approach after some rounds of evaluations.\n",
      "Features\n",
      "Previous\n",
      "Real-time Keypress Indication\n",
      "The visualizer bar will display the keys pressed at one end, in the other end with minimum latency. The key presses will be indicated using a light beam directed to each key. What's being played is heard through the speakers of the keyboard synthesizer\n",
      "Schedule Classes and Assignments\n",
      "Tutors can schedule classes easily after setting up tutors’ profiles on our platform. Then after supplying the relevant information about the class such as the difficulty, number of lessons, course fee and etc., tutors can schedule classes.\n",
      "Then tutors can set up assignments for those classes, so the students can easily submit their recordings through our platform.\n",
      "Offline Helper\n",
      "The offline helper will give students the assistance need while doing their assignments and while practicing. First student has to choose a song (MIDI File) that wants to practice, then the visualizer bar will visualize the keystrokes so the student can practice. Prallaly to that the application will show the incorrect notes, as well as out-of-tempo notes that the students have played.\n",
      "In order to this offline helper to function the device (laptop or Mobile device) should be connected via Bluetooth or wifi so the devices can communicate with each other.\n",
      "Recorder\n",
      "Using the recorder students as well as tutors can record their piano pieces without bothering about the mic quality and the background sound since the recording is happening in the MIDI format directly through the MIDI output of the keyboard. Since MIDI data are light weight users don’t need to worry much about managing the cloud storage space.\n",
      "So the tutors can easily provide sample pieces to their to the students recorded and the students can easily record the pieces that needs to be submitted and submit them to their tutors.\n",
      "Next\n",
      "Research Findings\n",
      "Previous\n",
      "MIDI to Sheet Music\n",
      "Our product will often use MIDI messages to transmit data between the keyboard visualizer bar and the processing unit. But MIDI itself isn't interactive with most of the beginners. They'll be needing score sheets or sheet music to recognize what to play or, what is being played in his/her keyboard synthesizer. Therefor we'll be introducing a feature in a our web and mobile apps to convert these midi files to sheet music. We'll be using BYVoid/MidiToSheetMusic\n",
      "opensource project to acheive this.\n",
      "Usage of this project can be found here.\n",
      "Next\n",
      "Timeline\n",
      "19th July, 2021\n",
      "Project Proposal(Milestone 1)\n",
      "Presenting our project proposal was the first milestone.\n",
      "The first project proposal presentation can be seen from here.\n",
      "Finished: 19th July, 2021\n",
      "23rd July, 2021\n",
      "CAD Models\n",
      "Build the CAD models for both the processing unit and the visualizer bar.\n",
      "Finished: 01st August, 2021\n",
      "24th July, 2021\n",
      "Sheet Music Read / Write\n",
      "Trying to understand how to integrate music scores and tabs into the web application using the flat.io API.\n",
      "Intended features :\n",
      "1. Feed real-time MIDI data to the sheet music display.\n",
      "2. Output the sheet music as a MIDI data in real-time.\n",
      "3. Edit / Create sheet music in the web platform both online and offline.\n",
      "4. Upload / Download sheet music.\n",
      "This research is being paused for now.\n",
      "Finished: n/a\n",
      "06th August, 2021\n",
      "Mobile platform Front-End\n",
      "Design and implement a mobile platform front-end.\n",
      "Finished: n/a\n",
      "07th August, 2021\n",
      "Web platform Front-End\n",
      "Design and implement a web platform front-end.\n",
      "Finished: n/a\n",
      "12th August, 2021\n",
      "Testing the ESP32 Board\n",
      "Wifi and BLE testing.\n",
      "Finished: 28th August, 2021\n",
      "25th August, 2021\n",
      "Database Schema\n",
      "The database schema (ER diagrams) for the system has been designed.\n",
      "Finished: 29th August, 2021\n",
      "29th August, 2021\n",
      "Designing backend APIs\n",
      "Implementing backend APIs with authentication and authorization.\n",
      "Finished: 02nd September, 2021\n",
      "29th August, 2021\n",
      "Redesigning the high-level diagrams\n",
      "The high-level diagrams for the system are being redesigned with the protocols and technologies being used.\n",
      "Finished: 28th August, 2021\n",
      "30th August, 2021\n",
      "Building Schematics\n",
      "Designing schematics for the processing unit and the visualizer blocks.\n",
      "Finished: 31st August, 2021\n",
      "03rd September, 2021\n",
      "Progress Review 1(Milestone 2)\n",
      "Criteria to be met before the presentation:\n",
      "1. Block diagrams.\n",
      "2. Circuit diagrams.\n",
      "3. Database schemata.\n",
      "4. Algorithms / Flow Charts.\n",
      "5. UI Designs.\n",
      "6. Performance, Power, Security requirements.\n",
      "7. Failiure handling.\n",
      "8. Sensors and actuatos.\n",
      "9. Controller platforms (programming, memory, available\n",
      "interfaces, connectivity, speeds, data-rates, built-in units,\n",
      "power, security, cost, etc.).\n",
      "10. Network technologies and protocols (interfacing, medium,\n",
      "bandwidth, security, availability, reliability).\n",
      "11. Back-end technologies (programming, storage, accessing,\n",
      "backups, security, cost, 3rd party services)\n",
      "12. Front-end technologies (programming, data visualization,\n",
      "security).\n",
      "The presentation for Progress Review 1 can be seen from here.\n",
      "Finished: 03rd September, 2021\n",
      "04th September, 2021\n",
      "Mobile App / ESP32 BT Test\n",
      "Test Bluetooth communication and WiFi SSID, Password extraction inside the mobile application.\n",
      "Try to send encrypted WiFi SSID and Password to the ESP32 via Bluetooth.\n",
      "Finished:\n",
      "17th September, 2021\n",
      "15th October, 2021\n",
      "Testing\n",
      "Testing the API, front-end and security testing.\n",
      "Finished: n/a\n",
      "25th October, 2021\n",
      "Progress Review 2(Milestone 3)\n",
      "Criteria to be met before the presentation:\n",
      "1. Completete back-end and front-end software.\n",
      "2. Cloud deployment.\n",
      "3. Ability to provide a clear overview of the system.\n",
      "4. Ability to clearly explain features and functionalities (including reliability, scalability and security aspects)\n",
      "5. Ability to clearly explain implementation details\n",
      "6. Attention paid to enhance the user experience of software/hardware components and of the overall product\n",
      "7. Details of three or more tests carried out on the software components (what was tested?, why is it important?, how was the test done?, results and findings)\n",
      "8. Designs for embeded node hardware.\n",
      "Finished: n/a\n",
      "Not started yet.\n",
      "MIDI Read / Write Test\n",
      "Build and test a circuit to read and write MIDI messages using Arduino. An\n",
      "introduction to what MIDI is can be found here.\n",
      "Finished: n/a\n",
      "Not started yet.\n",
      "Implement gRPC services for ESP32\n",
      "Implementation of gRPC services in the backend for the embedded hardware.\n",
      "Finished: n/a\n",
      "Not started yet.\n",
      "Implement ESP32 gRPC client\n",
      "Implementation a gRPC client in the ESP32 and test with the gRPC supported backend.\n",
      "(gRPC direct usage w/HTTP2, and not the gRPC transcoding -> REST API)\n",
      "1. Connect ESP32 to HTTP/2 Server.\n",
      "1. Efficient IoT with Protobuff\n",
      "Finished: n/a\n",
      "Not started yet.\n",
      "Migrating from JSON to Protobuff\n",
      "Change the data serialization format from JSON to Protobuff in the backend.\n",
      "Compare the performance difference between the two versions.\n",
      "Finished: n/a\n",
      "Budget\n",
      "Our Budget\n",
      "Item Name\n",
      "#Units\n",
      "Per Unit Price (Rs.)\n",
      "Price (Rs.)\n",
      "ESP32 Development Board\n",
      "2\n",
      "1, 550\n",
      "3, 100\n",
      "Arduino Pro Micro Development Board\n",
      "3\n",
      "1, 130\n",
      "3, 390\n",
      "5mm LEDs(12 per block)\n",
      "36\n",
      "4\n",
      "144\n",
      "RGB LEDs\n",
      "2\n",
      "15\n",
      "30\n",
      "3.7V 4000mAh Li-Po Rechargeable Battery\n",
      "2\n",
      "800\n",
      "1, 600\n",
      "DIN 5 pin Connector (Female)\n",
      "4\n",
      "175\n",
      "700\n",
      "MIDI-to-MIDI Cable\n",
      "2\n",
      "400\n",
      "800\n",
      "TP4056 Charger Module\n",
      "2\n",
      "65\n",
      "130\n",
      "LTC3440 IC\n",
      "2\n",
      "130\n",
      "260\n",
      "6N139 Optocoupler\n",
      "2\n",
      "34\n",
      "68\n",
      "BC212 Transistor\n",
      "2\n",
      "5\n",
      "10\n",
      "Resistors (220Ω, 680Ω, 2.7k, 6.8k, 10k, 20k, 1M, 200k)\n",
      "8 packs of 40 pcs\n",
      "40\n",
      "320\n",
      "Capacitors (100μF, 470μF, 0.1μF, 22μF, 10μF)\n",
      "6\n",
      "2\n",
      "12\n",
      "10μH Inductor\n",
      "1\n",
      "5\n",
      "5\n",
      "Latching Push Button Switch\n",
      "2\n",
      "50\n",
      "100\n",
      "DPST Switch\n",
      "2\n",
      "30\n",
      "60\n",
      "Push Button\n",
      "2\n",
      "5\n",
      "10\n",
      "PCB Printing Cost\n",
      "_\n",
      "_\n",
      "2, 000\n",
      "3D Printing Cost\n",
      "_\n",
      "_\n",
      "2, 000\n",
      "TOTAL\n",
      "14, 739\n",
      "The above BoM is considering two processing units and three visualizer blocks, one processing unit and one visualizer block for tutor's end demonstration and the rest for the student's end demonstration.\n",
      "Our Team\n",
      "Dinura Dissanayake\n",
      "E/17/072 Developer\n",
      "Sathira Silva\n",
      "E/17/331 Developer\n",
      "Shamal Weerasooriya\n",
      "E/17/380 Developer\n",
      "Our Advisors\n",
      "Dr. Isuru\n",
      "Nawinne\n",
      "Dr. Mahanama\n",
      "Wickramasinghe\n",
      "Remote Keyboard Tutor\n",
      "The Remote Keyboard Tutoring System is a web based system that can be attached to any\n",
      "(electronic) keyboard synthesizer through a MIDI connector. Once our system is connected to\n",
      "the keyboard, the user can interactively learn, play or teach in combination with the web\n",
      "application that we provide.\n",
      "Have a Questions?\n",
      "+94 77 416 1509\n",
      "(Dinura)\n",
      "+94 77 600 7404\n",
      "(Sathira)\n",
      "+94 76 468 5395\n",
      "(Shamal)\n",
      "bitlasagna.mail@gmail.com\n",
      "Or you can put your general Comments / Questions\n",
      "here.\n",
      "University of\n",
      "Peradeniya\n",
      "Faculty of Engineering\n",
      "Department of Computer Engineering\n",
      "Copyright © Bitlasagna\n",
      "\n",
      "\n",
      "Extracting remote medical diagnostics https://cepdnaclk.github.io/e17-3yp-remote-medical-diagnostics\n",
      "\n",
      "\n",
      "Remote Medical Diagnostics System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Remote Medical Diagnostics System\n",
      "Team\n",
      "E/17/134, Kavindu Jayasooriya, e17134@eng.pdn.ac.lk\n",
      "E/17/318, Udith Senanayake, e17318@eng.pdn.ac.lk\n",
      "E/17/207, Pasindu Marasinghe, e17207@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Hardware Components\n",
      "Circuit Designs\n",
      "Software Tools\n",
      "UI Designs\n",
      "3D Prototypes\n",
      "Algorithms\n",
      "Testing\n",
      "Hardware\n",
      "Software\n",
      "Detailed budget (tentative)\n",
      "Project Timeline\n",
      "Conclusion (will be available after testing)\n",
      "Supervisors\n",
      "Links\n",
      "Introduction\n",
      "People have to face a lot of challenges when they want to see a doctor, from having to waste time on the road full of traffic, waiting in long queues for hours to being in hospitals full of patients with contagious diseases. We aim to minimize these problems by introducing a platform where doctors and patients can meet online and a convenient diagnostics device to go with it; eliminating the need to go to a hospital for most of the common medical conditions and get diagnosed in the comfort of your own home.\n",
      "While there are some solutions already available in the market trying to solve some of these problems like E-channeling, audio and video conferencing they don’t provide a good way for the doctor to monitor the patient’s condition easily. We aim to design a cheap yet convenient and effective tool to make everybody’s life easier by taking patient’s measurements in real-time.\n",
      "What’s available in the system:\n",
      "Making appointments online\n",
      "Video Consultation.\n",
      "Diagnostics device that reads commonly needed measurements\n",
      "Heartbeat sensing (clear audio with little to no background noise)\n",
      "Temperature sensing ( 0.5°C tolerance)\n",
      "Glucose levels in the blood\n",
      "Blood pressure\n",
      "Ability to handle the device via software and hardware\n",
      "Real-Time measurements.\n",
      "Getting valid prescriptions from the doctor\n",
      "Verified authenticity of the doctor\n",
      "Privacy and Confidentiality\n",
      "Patient history and other analytics\n",
      "User experiences and reviews for a doctor\n",
      "Who is it for?\n",
      "As an individual patient one simply have to sign up and log on to our system to meet verified doctors with audio conferencing; for a more accurate diagnosis, our medical device can be used. Hospitals can use our system to manage doctor-patient communication remotely by getting the platform set up along with their existing systems. Individual doctors can use our system by going through a verification process that assesses the validity of their license to practice medicine ( Doctors, patients who are associated with a hospital that uses our system can directly use this platform )\n",
      "Solution Architecture\n",
      "This diagram shows how components in our system connect with each other. The device that assists the diagnostics takes two main measurements; heart/lung sounds and temperature. Support for additional peripherals that are used to measure glucose levels in the blood, blood pressure is available. These are the information a doctor usually takes to diagnose a patient initially, most of the medical centers do not have complex and expensive machinery with them unless it is a fully-fledged hospital that treats inpatients. This is because they are not needed for most of the common sicknesses that patients take medicine every day. Our device takes these common measurements, therefore, saves the vast majority of hospital trips people need to take. There is some portion of diseases that require laboratory test results and inner body images which our device does not support. But for reviewing those lab results and blood works this system can be used easily.\n",
      "The online platform provides userfriendly interfaces that include the following functionality for each user type:\n",
      "For a doctor:\n",
      "Schedule Sessions\n",
      "Interact with the Patient\n",
      "See Patient’s Medical History\n",
      "Make Notes\n",
      "Write the Prescription\n",
      "Control the Device\n",
      "For a patient:\n",
      "Make Appointments\n",
      "Interact with the Doctor\n",
      "Make Payments\n",
      "Obtain the Prescription\n",
      "Get Notified About the Appointments\n",
      "Rate and Give Feedback to the Doctor\n",
      "Information about patients like their medical history, NCDs (non-communicable diseases: heart disease, stroke, cancer, diabetes, and chronic lung disease), allergies to medication (Penicillin and related antibiotics, Antibiotics containing sulfonamides (sulfa drugs), Anticonvulsants, Aspirin, ibuprofen and other nonsteroidal anti-inflammatory drugs (NSAIDs), Chemotherapy drugs) or food and lifestyle are going to be stored and made available to the doctor who treats that particular patient; this can be useful for the diagnostician and is not usually accommodated in the conventional way of seeing a doctor.\n",
      "About the doctors, information about their medical license, specialty, and available times are stored and shown to the users. Functionality for reviewing and feedback is also planned to be implemented.\n",
      "Apart from the information about the users, scheduling times, metadata, and statistics will be stored.\n",
      "Hardware and Software Designs\n",
      "3D Prototype\n",
      "The device is completely wireless, WiFi is used to do data communication (can connect with a smartphone/computer without manual configuration).\n",
      "Powered with Li-ion rechargeable batteries. There are two inbuilt sensors; a temperature sensor and a microphone (stethoscope).\n",
      "The microphone is controlled by the doctor over the internet. (microcontroller is signaled to initiate reading and transmitting data)\n",
      "The temperature sensor is activated when pressed against the skin. (continuous measurements are not needed)\n",
      "An on/off switch is available to power down the device\n",
      "Hardware Components\n",
      "esp32\n",
      "Relatively high sampling rate\n",
      "12 bit ADC bit depth\n",
      "Wifi capabilities\n",
      "LM35 Temperature Sensor\n",
      "0.5°C typical accuracy\n",
      "Low-Cost\n",
      "Linear scale\n",
      "Calibrated Directly in Celsius\n",
      "Less Than 60-μA Current Drain\n",
      "4V - 30V (operating voltage)\n",
      "Amplifier\n",
      "To increase signal-to-noise ratio and also as a unity gain buffer\n",
      "Features excellent power supply rejection ratio (112 dB)\n",
      "Excellent common-mode rejection ratio (126 dB)\n",
      "Cell Fuel Gauge\n",
      "To measure battery level\n",
      "Accurate battery level as a precentage\n",
      "Uses I2C protocol\n",
      "Circuit Designs\n",
      "The following diagrams show the proposed designs for the prototype device:\n",
      "Schematic Diagram\n",
      "LM53: temprature sensor\n",
      "CAO106: electret condenser microphone\n",
      "NJM5532: low noise operational amplifier\n",
      "PCB Layout\n",
      "3D Circuit Model\n",
      "Design Decisions\n",
      "I2C interface is utilized to allow connectivity for most of the common sphygmomanometers (blood pressure monitors)\n",
      "The built-in capacitive touch sensor capability is used to trigger the temperature sensor\n",
      "A bandpass filter is used to filter out the unwanted frequencies\n",
      "The low pass filter is set to lower frequencies than usual to better suit internal body sounds\n",
      "Software Tools and Technologies\n",
      "React\n",
      "Virtual DOM feature that allows rendering only the changed UI components (avoiding simple changes at the top level from causing huge ripples to the user interface)\n",
      "Provide high performance making complex apps run extremely fast\n",
      "Node.js\n",
      "Load balancing and the capability to handle a huge number of concurrent connections\n",
      "Possible to create a separate microservice for any functionality\n",
      "Data is divided into small chunks that are sent to the front end piece by piece (Good for video conferencing)\n",
      "AWS\n",
      "Highly scalable\n",
      "Flexible in choosing OS, programming languages, database, and other services\n",
      "The pay-as-you-go pricing (pay only for the exact amount of resources used)\n",
      "MongoDB\n",
      "A non-relational database that is favorable to the data in the system.\n",
      "It is a natural form to store data (human-readable)\n",
      "Structured and unstructured information can be stored in the same document\n",
      "Dynamic schema; adding fields or leaving a field out is possible\n",
      "UI Designs\n",
      "Click here to see all UIs.\n",
      "UI Prototypes\n",
      "Patient’s UIs\n",
      "Doctor’s UIs\n",
      "Algorithms\n",
      "When a patient adds an appointment\n",
      "When patients join a session\n",
      "Testing\n",
      "Hardware Testing\n",
      "Prototypes with different hardware implementations are planned to be used to test the system. Data generated by our device will be compared against freely available heart/lung sounds measured by the state of the art equipment.\n",
      "Software Testing\n",
      "Importance of test-driven development (TDD)\n",
      "With TDD we identify the bugs right in the development stage. It is impossible to test each component manually when the project grows. And if done by hand it would cost\n",
      "a lot of time.\n",
      "Unit Tests\n",
      "The idea behind Unit Testing is to test every single part of the program separately and show that the individual parts are correct. In unit testing, we test the business logic of a function or a component. The number of test cases for a unit will depend on all the different execution paths.\n",
      "For front-end unit testing, we render component trees in a simplified test environment and assert their output\n",
      "Integration tests\n",
      "The idea behind Integration testing is to combine small units in the application and test as a group to see that\n",
      "they are working fine together.\n",
      "Integration tests involve database queries and network requests most of the time.\n",
      "We use integration tests to prevent bugs from reaching the production stage.\n",
      "End to end tests\n",
      "The main purpose of End-to-end (E2E) testing is to test from the end user’s experience by simulating\n",
      "the real user scenario and validating the system under test and its components for integration and data integrity.\n",
      "We use the selenium framework to test the web application.\n",
      "Tests in this project\n",
      "We have automated unit tests and integration tests using Github workflows. This helps us to refactor with confidence\n",
      "and make sure that new pull requests pass all the test cases before they are merged into the main branch.\n",
      "Front-end related tests\n",
      "Back-end related tests\n",
      "End-to-end tests\n",
      "Detailed budget\n",
      "All items and costs according to the current plan: (might change in the future)\n",
      "Item\n",
      "Quantity\n",
      "Unit Cost (Rs.)\n",
      "Total (Rs.)\n",
      "ESP32\n",
      "1\n",
      "1500\n",
      "1500\n",
      "LM35 Temperature Sensor\n",
      "1\n",
      "110\n",
      "110\n",
      "3.7V Li-ion Rechargeable Battery\n",
      "2\n",
      "200\n",
      "400\n",
      "Max17048 Cell Fuel Gauge\n",
      "1\n",
      "500\n",
      "500\n",
      "AMS1117-3.3 Voltage Regulator\n",
      "1\n",
      "10\n",
      "10\n",
      "Logic Level Converter\n",
      "1\n",
      "135\n",
      "135\n",
      "Condenser mic CA0106\n",
      "1\n",
      "20\n",
      "20\n",
      "Stethoscope\n",
      "1\n",
      "840\n",
      "840\n",
      "Others\n",
      "2000\n",
      "TOTAL\n",
      "5515\n",
      "Project Timeline\n",
      "Supervisors\n",
      "Dr.Isuru Nawinne web page\n",
      "Dr.Mahanama Wickramasinghe web page\n",
      "Conclusion\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Survey Results\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting remote proctoring system https://cepdnaclk.github.io/e17-3yp-remote-proctoring-system\n",
      "\n",
      "\n",
      "Remote Proctoring Device\n",
      "Home\n",
      "About\n",
      "Solutions\n",
      "Progress\n",
      "Timeline\n",
      "Designing overall system\n",
      "Frontends Implementations\n",
      "Students' UI\n",
      "Proctors' UI\n",
      "Administrators' UI\n",
      "Backend Implementation\n",
      "Hardware Implementation\n",
      "Testing and Integration\n",
      "Features\n",
      "Budget\n",
      "Team\n",
      "Contact\n",
      "Connexa\n",
      "REMOTE PROCTORING DEVICE\n",
      "Project Repository\n",
      "SEE OUR PRODUCT VIDEO\n",
      "Web Application\n",
      "Explore the Connexa space\n",
      "What is the Remote Proctoring Device?\n",
      "A single device which integrates the hardware and software components needed to conduct an examination in the currently implemented system, which will provide a seamless process for the proctors and students involved in an examination.\n",
      "why\n",
      "Why do we need a seperate device?\n",
      "When conducting examinations where the skills of the students should be evaluated in a limited timeframe, it's crucial to manage the external factors affecting the performance of the students at a satisfactory level. However it could be\n",
      "challenging to manage these factors in an online environment.\n",
      "Currently, multiple hardware devices and software tools are used to conduct online examinations while ensuring the quality of the examinations. We have noticed that this method can cause a lot of distractions and unnecessary\n",
      "burdens to students as well as proctors.\n",
      "System Overview\n",
      "What Are The Technology We Use\n",
      "System\n",
      "The device on the student's side is capable of capturing the video and audio stream from students continuously even incase of a power failure. The proctor will be able to monitor the video and audio streams captured\n",
      "from all the students facing an examination through the browser application in the proctor's side.\n",
      "High-Level System Overview\n",
      "Method used to ensure secure video/audio streaming:HTTPS protects the user from “Man-in-the-Middle” attacks where hackers can use vulnerabilities in public networks to steal data transmitted to the viewer. Using HLS\n",
      "encryption to mask a user's connection with the website can prevent this sort of attack.\n",
      "Technology Stack\n",
      "The system consists of three main endpoints...\n",
      "Web browser in Proctor's end\n",
      "Desktop application in Student's end\n",
      "Database and server application hosted on the Cloud\n",
      "Timeline\n",
      "The completion of the product will undergo 5 phases\n",
      "Phase 1\n",
      "Phase 2\n",
      "Phase 3\n",
      "Phase 4\n",
      "Phase 5\n",
      "Phase 1\n",
      "2 Weeks : Determine the design architecture and connections of overall infrastructure.\n",
      "System overview\n",
      "High-Level System Overview\n",
      "Technology Stack\n",
      "Aproximate Budget\n",
      "See more >>\n",
      "Phase 2\n",
      "7 Weeks : Develop the frontend (Both web and desktop apps)\n",
      "Students' User Interface\n",
      "Proctors' User Interface\n",
      "Admins' User Interface\n",
      "See more >>\n",
      "Phase 3\n",
      "8 Weeks :\n",
      "Develop the backend and server side programs\n",
      "ER-diagram\n",
      "See more >>\n",
      "Phase 4\n",
      "5 Weeks : Hardware implementation\n",
      "Proctoring device circuit\n",
      "Power supply unit circuit\n",
      "See more >>\n",
      "Phase 5\n",
      "6 Weeks : Testing and Integration\n",
      "Software testing plan\n",
      "Hardware testing plan\n",
      "See more >>\n",
      "Progress\n",
      "Our Progress So Far\n",
      "Student App Unit Testing\n",
      "See more details >>\n",
      "Electron application unit testing\n",
      "Spectron and Mocha\n",
      "Proctors' Web App Unit Testing\n",
      "See more details >>\n",
      "React application unit testing\n",
      "React testing libraries and Jest\n",
      "API testing\n",
      "See more details >>\n",
      "API request testing\n",
      "Authentication testing\n",
      "Access control testing\n",
      "Jest and Postman\n",
      "Your browser does not support HTML video.\n",
      "Students' Desktop App\n",
      "See more details >>\n",
      "See course details\n",
      "See exam schedule\n",
      "Join examination\n",
      "Upload locally saved videos\n",
      "Your browser does not support HTML video.\n",
      "Admin Portal\n",
      "See more details >>\n",
      "Add proctors to the system\n",
      "Add students to the system\n",
      "Add courses to the system\n",
      "Add exam schedule using master sheets\n",
      "Remove exam schedules\n",
      "Your browser does not support HTML video.\n",
      "Proctors' Web App\n",
      "See more details >>\n",
      "See course details\n",
      "See exam schedule\n",
      "Invigilate an examination\n",
      "See disconnections of students\n",
      "Get the link of the students saved videos\n",
      "API call documentation\n",
      "See more details >>\n",
      "Authentication\n",
      "Access control\n",
      "Student App Unit Testing\n",
      "See more details >>\n",
      "Electron application unit testing\n",
      "Spectron and Mocha\n",
      "Proctors' Web App Unit Testing\n",
      "See more details >>\n",
      "React application unit testing\n",
      "React testing libraries and Jest\n",
      "API testing\n",
      "See more details >>\n",
      "API request testing\n",
      "Authentication testing\n",
      "Access control testing\n",
      "Jest and Postman\n",
      "Your browser does not support HTML video.\n",
      "Students' Desktop App\n",
      "See more details >>\n",
      "See course details\n",
      "See exam schedule\n",
      "Join examination\n",
      "Upload locally saved videos\n",
      "Your browser does not support HTML video.\n",
      "Admin Portal\n",
      "See more details >>\n",
      "Add proctors to the system\n",
      "Add students to the system\n",
      "Add courses to the system\n",
      "Add exam schedule using master sheets\n",
      "Remove exam schedules\n",
      "Your browser does not support HTML video.\n",
      "Proctors' Web App\n",
      "See more details >>\n",
      "See course details\n",
      "See exam schedule\n",
      "Invigilate an examination\n",
      "See disconnections of students\n",
      "Get the link of the students saved videos\n",
      "API call documentation\n",
      "See more details >>\n",
      "Authentication\n",
      "Access control\n",
      "Student App Unit Testing\n",
      "See more details >>\n",
      "Electron application unit testing\n",
      "Spectron and Mocha\n",
      "Proctors' Web App Unit Testing\n",
      "See more details >>\n",
      "React application unit testing\n",
      "React testing libraries and Jest\n",
      "API testing\n",
      "See more details >>\n",
      "API request testing\n",
      "Authentication testing\n",
      "Access control testing\n",
      "Jest and Postman\n",
      "Your browser does not support HTML video.\n",
      "Students' Desktop App\n",
      "See more details >>\n",
      "See course details\n",
      "See exam schedule\n",
      "Join examination\n",
      "Upload locally saved videos\n",
      "Your browser does not support HTML video.\n",
      "Admin Portal\n",
      "See more details >>\n",
      "Add proctors to the system\n",
      "Add students to the system\n",
      "Add courses to the system\n",
      "Add exam schedule using master sheets\n",
      "Remove exam schedules\n",
      "Your browser does not support HTML video.\n",
      "Proctors' Web App\n",
      "See more details >>\n",
      "See course details\n",
      "See exam schedule\n",
      "Invigilate an examination\n",
      "See disconnections of students\n",
      "Get the link of the students saved videos\n",
      "API call documentation\n",
      "See more details >>\n",
      "Authentication\n",
      "Access control\n",
      "Demonstration\n",
      "User Interface Implementation\n",
      "Your browser does not support HTML video.\n",
      "Security\n",
      "Security is a key concern in our product since we deal with highly sensitive data related to examinations and personal security.\n",
      "We ensure security using 3 main methods.\n",
      "Isolation\n",
      "Encyrption\n",
      "Authorization and authentication\n",
      "Security\n",
      "Data Encryption\n",
      "Encryption in Server and Database\n",
      "The secure MongoDB, Atlas cluster ensures secure data encryption both at transit and rest using TSL and AES-256 standards\n",
      "Encryption in Jitsi-Meet server\n",
      "Jitsi-Meet provides end-to-end and hop-to-hop encryption for multiparty conferences.\n",
      "The meeting rooms are password protected and ephemeral.\n",
      "Encrypting locally stored videos\n",
      "To ensure that students or any other third party cannot tamper locally stored recordings, they are encrypted using AES-256.\n",
      "Node.js's built-in cipher class File-encrypter is used to encrypt the recordings.\n",
      "AWS Key Management Service is used to control and manage the encryption keys.\n",
      "Features\n",
      "Check Our Amazing Features\n",
      "All\n",
      "For The Proctor\n",
      "For The Student\n",
      "video/audio feed\n",
      "Get video/audio feed from multiple students\n",
      "One-on-one interaction\n",
      "One-on-one interaction with students\n",
      "Detect disconnections\n",
      "Detect disconneted students immediately\n",
      "Detect unauthorized activities\n",
      "Detect unauthorized activities by warning messages\n",
      "Notify examinations\n",
      "Notify students about up coming examinations\n",
      "Capture the video & audio\n",
      "Capture the video & audio stream from student's environment\n",
      "Record and Upload\n",
      "Continuously record the video in case of a power failure and store it locally\n",
      "Backup Power\n",
      "Continuous power supply even incase of a power failure\n",
      "Easily mountable\n",
      "can easily mountable on a surface\n",
      "Display remaining time\n",
      "See the remaining time on the screen\n",
      "Budget\n",
      "Bill of Materials\n",
      "COMPONENT\n",
      "PRICE (Rs.)\n",
      "PLACE\n",
      "FOR THE MAIN CIRCUIT\n",
      "Rasberry pi board 3B+\n",
      "9500\n",
      "microchip.lk\n",
      "Rasberry pi power cable and adapter\n",
      "800\n",
      "microchip.lk\n",
      "Touch screen 5' with integrated speaker\n",
      "6350\n",
      "tronic.lk\n",
      "Speaker\n",
      "50\n",
      "microchip.lk\n",
      "PAM8406 Digital Amplifier\n",
      "350\n",
      "microchip.lk\n",
      "Cooling Fan\n",
      "260\n",
      "microchip.lk\n",
      "Camera module\n",
      "1800\n",
      "microchip.lk\n",
      "USB Microphone\n",
      "485\n",
      "tronic.lk\n",
      "Flash drive (SD card) 32gb\n",
      "1800\n",
      "microchip.lk\n",
      "Total for the RPI\n",
      "21395\n",
      "FOR THE UPS\n",
      "Lithium Battery 18650 1200mAH\n",
      "200\n",
      "microchip.lk\n",
      "LM2596 Buck Converter\n",
      "650\n",
      "microchip.lk\n",
      "BMS 18650 balanced charger with protection\n",
      "350\n",
      "microchip.lk\n",
      "Capacitor 220 microF\n",
      "10\n",
      "12V power inout barrel jack\n",
      "15\n",
      "Micro USB jack\n",
      "40\n",
      "Nilambara Electronis\n",
      "Miscellaneous\n",
      "500\n",
      "TOTAL\n",
      "23160\n",
      "Our Team\n",
      "Developers\n",
      "Isuri Devindi\n",
      "E/17/058\n",
      "Sashini Liyanage\n",
      "E/17/190\n",
      "Savindu Wannigama\n",
      "E/17/369\n",
      "Advisors\n",
      "Prof. Roshan Ragel\n",
      "Professor\n",
      "Dr. Isuru Nawinne\n",
      "Senior Lecturer\n",
      "Dr. Mahanama Wickaramasinghe\n",
      "Senior Lecturer\n",
      "Contact\n",
      "Contact Us\n",
      "Email:\n",
      "connexa.info@gmail.com\n",
      "Call:\n",
      "Isuri- +94713713686\n",
      "Sashini- +94713585988\n",
      "Savindu- +94776259252\n",
      "\n",
      "\n",
      "Extracting smart apartment security system https://cepdnaclk.github.io/e17-3yp-smart-apartment-security-system\n",
      "\n",
      "\n",
      "Smart Apartment Security System\n",
      "Home\n",
      "Introduction\n",
      "Architecture\n",
      "Design\n",
      "Budget\n",
      "Team\n",
      "SAFENET\n",
      "SMART APARTMENT SECURITY SYSTEM\n",
      "Introduction\n",
      "For years, the need to protect one’s property has become one of people’s\n",
      "main concerns. The sense of security and protection is one of those feelings that makes us\n",
      "comfortable and complements quality living. Although there are existing solutions for home\n",
      "security like video surveillance cameras, alarms etc., they are very expensive, and the\n",
      "installation process is also not easy. Most of the existing security system solutions\n",
      "address the needs of the people who are living in private houses. But people who live in\n",
      "apartments in urban areas have some added needs to be satisfied with a particular security\n",
      "system. Therefore, addressing all these issues along with some added unique features we have\n",
      "come up with the idea of a Smart Apartment Security System. Smart Apartment security system\n",
      "is a system that secure entry points, like doors and windows, as well as interior spaces in\n",
      "an apartment from a burglary or a fire by notifying the owners and security officer at the\n",
      "apartment gate whenever a threat has been identified through a mobile application.\n",
      "Solution Architecture\n",
      "Mobile Application\n",
      "An Android mobile application is available for\n",
      "SafeHome security system to allow users to remotely monitor and control the security system.\n",
      "Users are able to arm and disarm the system, get mobile alerts and contact the security\n",
      "officer whenever a threat has been identified by the security system. Users can log in to\n",
      "the mobile app anytime to view the status of sensors, activity logs for door locks and more\n",
      "as well. The app is designed using Flutter.\n",
      "Security System\n",
      "The security system is used to identify\n",
      "threats in the entry points and interior spaces of an apartment through sensors. It will\n",
      "consist of wireless sensors(door and window sensors, motion sensors, smoke detector), a\n",
      "siren and a smart door lock with fingerprint access for added security. ESP 32 development\n",
      "board is used as the microcontroller of the door lock and ESP-01S WiFi modules are used for\n",
      "wireless sensors.\n",
      "Web Server\n",
      "AWS server is used as the web server for the\n",
      "SafeHome Security System. Signals from sensors are passed to the mobile application as well\n",
      "as control information from mobile applications are passed to the smart door lock and\n",
      "response mechanisms through this server. Database which is used to store sensor statuses and\n",
      "logs of the system is hosted at the server.\n",
      "Highlevel\n",
      "Diagram\n",
      "Infrastructure\n",
      "Technologies\n",
      "Frontend Development\n",
      "As the front end development we use flutter as our front\n",
      "end development software in this development process the\n",
      "expectations are to provide user friendly and\n",
      "interesting interface with enhanced UI and UX experience\n",
      "to the client.Other than that cross platform support is\n",
      "required for us to maintain the target clients by giving\n",
      "them access to our services independant their mobile os\n",
      "type.\n",
      "Backend Development\n",
      "In the backend server requires to handle a larger amount\n",
      "of requests. Therefore the scalability and\n",
      "sustainability if uncaught error exceptions happend are\n",
      "critical points under choosing a optimum backend server.\n",
      "For those requirements, Node js would be the best\n",
      "solution for this project. Therefore the backend server\n",
      "side requests managements are done by the NodeJs.\n",
      "Cloud Deployment\n",
      "Due to financial issues met in the process of developing\n",
      "the physical server of maintaining cost. The team sole\n",
      "decision and the academic guidance as well based on\n",
      "cloud services. Therefore the cloud server deployment\n",
      "was decieded. In that case the EC2 instance of AWS\n",
      "server support is selected.\n",
      "Database Development\n",
      "For storing data puroposes' requirements were the\n",
      "structured schema with the same type of data that have\n",
      "the ability to contain all the details of the target\n",
      "market when the product able to cover the whole market\n",
      "itself. Also the data base should be able to scalable\n",
      "from a smaller database. For these requirements are\n",
      "fulfil when the chosen selection was Mysql. Because the\n",
      "mysql have the ability contain 1000 different tables and\n",
      "all our reqiurements are fulfilled under 1000 tables.\n",
      "Also a table can record 21 million records with the\n",
      "space under 1GB. The maximum row table will be our user\n",
      "table but it will not exceed 21 million because the\n",
      "targeted ordience is less.\n",
      "Circuit Diagrams\n",
      "Door Circuit Unit\n",
      "Flame and PIR Sensor Unit\n",
      "Window Sensor Unit\n",
      "Schematic Diagrams\n",
      "Hardware Design\n",
      "Diagrams\n",
      "ER Diagram\n",
      "Relational Schema\n",
      "Detailed Budget\n",
      "Interfaces of Mobile Application\n",
      "User Login Interface\n",
      "The user can login here. He has to enter his email address\n",
      "and password. Two factor authentication is used here.\n",
      "Therefore, an OTP is sent to the relevant email address. If\n",
      "the user doesn't have an account, he can sign up to the\n",
      "system.\n",
      "Security Officer Login Interface\n",
      "The security officer can login here. He has to enter his\n",
      "email address and password. Two factor authentication is\n",
      "also used here.\n",
      "Therefore, an OTP is sent to the relevant email address. The\n",
      "registration of security officer is done by the\n",
      "Administrator.\n",
      "User Home Interface\n",
      "The user can change the mode of house. If the user select\n",
      "'Home Mode', the notifications wouldn't get when the motion,\n",
      "door and winsow semsors are triggering.\n",
      "There are 6 buttons in the home screen and user can go into\n",
      "the relevent option.\n",
      "User Registration Interface\n",
      "The users can register here. The email address is verified\n",
      "by sending OTP. Only the owner of the house can register to\n",
      "the system.\n",
      "Other members of the house can login with his user\n",
      "credentials.\n",
      "User Details Interface\n",
      "The owner details can be seen here. The name and the phone\n",
      "number can be changed\n",
      "here.\n",
      "Sensors' Details Interface\n",
      "All the sensor details can be seen here.One button is to\n",
      "deactivate the sensors and\n",
      "other button is to give access to the\n",
      "security officer to enter the house when there is a security\n",
      "threat.\n",
      "Layout Interface\n",
      "The user can find the places of the sensors in the house\n",
      "using the unique ID of\n",
      "them.\n",
      "Notification Interface\n",
      "The notifications when the sensors are triggering, can be\n",
      "seeen here. The date and\n",
      "time are also there.\n",
      "Contact Details Interface\n",
      "The emergency contacts can be seen here. By pressing the\n",
      "button, the user can calling to the\n",
      "relevant person.\n",
      "Security Officer Home Interface\n",
      "There are 4 buttons. Using 'Front Door Sensors', SO can\n",
      "find the front door of houses which he can access.\n",
      "Sensor Details(SO) Interface\n",
      "The status of all the sensors' of the apartment are showing\n",
      "here.\n",
      "The activate sensors of the apartment can be seen in red\n",
      "color.\n",
      "User Awaymode Interface\n",
      "When the awaymode is activated, background color of the interface is changed blue to green and the sensors are not triggering\n",
      "Interfaces of Administrator Web Application\n",
      "Previous\n",
      "Next\n",
      "AWS Deployment\n",
      "Previous\n",
      "Next\n",
      "Security\n",
      "Security is the most important thing in the IT world right now.\n",
      "In our solution, we have deeply considered the security point of view of our system.\n",
      "We have developed our system with the help of the following techniques to enhance the\n",
      "application security in our solution.\n",
      "JSON Web Tokens (JWT)\n",
      "Our application use JSON Web Tokens (JWT) to allow the client to indicate its identity for\n",
      "further exchange after authentication. It is a self-contained way for securely transmitting\n",
      "information between parties.\n",
      "User Input validation\n",
      "This prevents improperly formed data from entering an information system. Because it is\n",
      "difficult to detect a malicious user who is trying to attack software, applications should\n",
      "check and validate all input entered into a system specially in Resgistration and Login.\n",
      "Input validation as a mitigation strategy for both SQL injection and XSS.\n",
      "Two Factor Authentication\n",
      "Used in Authentication is used in the Registration of the Mobile Application. When Email is\n",
      "provided, OTP is sent to email address and user has to Enter that OTP for the registration.\n",
      "Password Hashing\n",
      "Password hashing is used in our application to verify the integrity of passwords, sent\n",
      "during login, against the stored hash so that actual passwords never has to be stored. A\n",
      "salt is added to the hashing process to force their uniqueness, increase their complexity\n",
      "without increasing user requirements, and to mitigate password attacks like hash tables\n",
      "AWS EC2 Security Groups\n",
      "A custom security group is assigned to the instance where our application is deployed which\n",
      "allows only http/tcp connections on port 80. Security groups offer protection at the ports\n",
      "and protocol access level.\n",
      "Testing Plan\n",
      "Project Timeline\n",
      "Link to Demonstrations\n",
      "Our Team Members\n",
      "Dananjaya Morais\n",
      "E/17/212\n",
      "Ishini Udara\n",
      "E/17/312\n",
      "Kanishka Dilhan\n",
      "E/17/065\n",
      "Our Advisors\n",
      "Dr.Isuru Nawinne\n",
      "Dr.Mahanama Wickramasinghe\n",
      "University of Peradeniya.\n",
      "Phone: +94 81 239 33 00\n",
      "Email: vc@pdn.ac.lk\n",
      "Web-site: http://www.pdn.ac.lk/\n",
      "Faculty of Engineering.\n",
      "Phone: +94 81 239 33 02\n",
      "Web-site: http://eng.pdn.ac.lk/\n",
      "Computer Engineering Department.\n",
      "Phone: +94 81 239 39 14\n",
      "Web-site: http://www.ce.pdn.ac.lk/\n",
      "Github repo\n",
      "Find more informations and\n",
      "codes details.\n",
      "Copyright 2019 All Right Reserved By Department of Computer Engineering/FOE/UOP\n",
      "\n",
      "\n",
      "Extracting smart garbage collection https://cepdnaclk.github.io/e17-3yp-smart-garbage-collection\n",
      "\n",
      "\n",
      "Smart Garbage Collector\n",
      "TrashCube\n",
      "Home\n",
      "About\n",
      "Architecture\n",
      "Features\n",
      "Data Flow\n",
      "Data Generation\n",
      "Flow Chart/ Algorithms\n",
      "Diagrams\n",
      "Design\n",
      "Circuit\n",
      "3D Model\n",
      "UI /UX\n",
      "Progress\n",
      "Timeline\n",
      "Budget\n",
      "Team\n",
      "Contact\n",
      "Smart Garbage Collector\n",
      "For A Proper Garbage Management For Smart Cities\n",
      "Project Repository\n",
      "why\n",
      "Why do we need a Smart Garbage Collector?\n",
      "Proper garbage collection & disposal has been a continuous struggle. Main issue that we identified is that there is no way to get an overview of fill levels of the bins. Therefore, authorities in charge of collecting garbage do not\n",
      "know when and where to collect garbage. This leads to inefficiency in assigning garbage collectors. And also time and fuel consumption are hight when collecting garbage, due to lack of a proper system. People tend to burn plastic/polythene\n",
      "because of the lack of a proper household garbage collection system and it gives rise to severe environmental polution. Furthermore, overflowing garbage bins which can be seen very often in public areas affect on public health\n",
      "negatively and scenic beauty of the environment is also destroyed.\n",
      "Solution Overview\n",
      "What is Smart Garbage Collector?\n",
      "Smart garbage collection system provides a platform to manage garbage collecting in a large area with proper coordination between the responsible authorities and the workers assigned to collect garbage while utilizing the available\n",
      "resources effectively. And also the people who are in need of a proper system to dispose garbage will be benefited by the system. The system can be implemented in cities, grounds, parks and any large public areas and it will make\n",
      "a high positive impact on public health & environment as well.\n",
      "Architecture\n",
      "Solution Architecture\n",
      "The main device of our system is the Smart Garbage Bin.\n",
      "Inside the Garbage bin the main controller is ATmega328p microcontroller. From this controller,\n",
      "we implement three main features. They are User Alerting system, Fill Level Detection System\n",
      "and Compaction mechanism. Considring compaction mechanism, it has seperate security system to\n",
      "detect the compation mechanism. The main power supply of the system is solar panel unit. There\n",
      "is also a bin location identification system inside the smart garbage bin.\n",
      "The Smart Garbage Bin can be connected to the AWS server\n",
      "via the GSM module and GPS module. In order to communicate with the server, there will be a web\n",
      "application as well as a mobile application. When garbage is put in to the bin, the LED indicators in\n",
      "Fill Level Detection Unit will be turned on according to the fill level. And, if the Garbage Bin is\n",
      "already full, Bin sends the fill level information to the server. Then, the server is responsible for\n",
      "updating details in both mobile application and web application. According to the compaction process\n",
      "details in the web server, the garbage bin will be automatically compacted. Otherwise, web application\n",
      "will send the request to Garbage Bin Collector through the mobile application. He/ she can view all\n",
      "the locations of assigned bins using the Google map in the mobile application.\n",
      "Features\n",
      "Check Our Special System Features\n",
      "FEATURES OF GARBAGE BIN\n",
      "Fill Level Detection\n",
      "Can decide on the priority to collect garbage\n",
      "LED Indicators\n",
      "Users can know whether to dispose or not & night visibility\n",
      "Compaction\n",
      "Reduce number of times garbage should be collected, max space utilization\n",
      "FEATURES OF WEBSITE\n",
      "Get Overview\n",
      "Can decide on priority, can stop overflowing bins efficiency\n",
      "Set Parameters\n",
      "Parameters to detect fill levels change as prefered\n",
      "View on a Map\n",
      "Easy to keep track of the procedure\n",
      "Add/Remove Bins\n",
      "Expanding the system with more units\n",
      "FEATURES OF Mobile App\n",
      "Handle Requests\n",
      "Can cancel or accept requests based on availability\n",
      "Get Overview\n",
      "Can get an idea on how much garbage is there to be collected\n",
      "Locate on a Map\n",
      "Can easily find the best route to collect the garbage bins assigned, increased efficiency\n",
      "Website\n",
      "Used for administration purpose by the adminintrator\n",
      "Mobile App\n",
      "Used by the garbage collectors\n",
      "Garbage bin\n",
      "Used by the general public\n",
      "Data Flow\n",
      "Data Generation\n",
      "Smart Garbage Collector system's block diagram consists of following four units\n",
      "Input Unit\n",
      "Controlling Unit\n",
      "Processing Unit\n",
      "Output Unit\n",
      "The input unit acts as the power supply unit in the system. Here the solar panel\n",
      "collects power from the sun’s rays.\n",
      "It is a monocrystallic panel, containing solar photovoltaic cells which convert the sun\n",
      "rays into electricity. The Dc power from the solar panel is then stored in the 12 volts battery\n",
      "used to operate all the electronic components in the controlling unit and processing unit.\n",
      "Then the controlling unit consists of relay switch [5V dual channel], ardino UNO [ATmega328 8-bit], ultra- sonic sensor\n",
      "and LED indicators.\n",
      "These components are used to control the complete processing unit. The ultra- sonic sensor senses the garbage\n",
      "accumulated in the container bin at the constrained level (say about 5cm from the top of the container bin) and sends signal\n",
      "to the micro chip. The micro chip is programmed to actuate the GSM module which sends a message to the administrator\n",
      "when the constrained level of garbage is accumulated in the garbage bin. It also controls the relay switch to actuate the DC motor.\n",
      "And considering the fill level information, LEDs are turned on by the micro chip.\n",
      "Next, the processing Unit has the DC motor. The Dc motor is connected to relay switch which\n",
      "actuates the scissor mechanism to compact the garbage in\n",
      "the garbage bin at constrained level. The relay switch with a H-bridge arrangement is used to control the Dc motor. This\n",
      "relay switch as two switch s1 and s2. When s1 is ON’s, the motor terminals with a positive polarity, thus the direction of\n",
      "rotation of the lead screw connected to the motor is in clockwise direction to extend the mechanism, similarly when s1 is\n",
      "off and s2 is actuated the lead screw will rotate in counter-clockwise direction to retract the mechanism. Next, the output unit\n",
      "consists of a GSM module, when the ultra-sonic sensor senses the level of garbage in the container bin, therefore actuating the\n",
      "scissor mechanism for compaction of waste and when the garbage\n",
      "reaches about 3cm at top of the container bin, the ultra sonic sensor sends signal to the GSM module via mocro chip,\n",
      "thereby it sends the message stating that the bin is going to be filled and need to dispose the wastes. Tha data and control flow can be observed in the diagram.\n",
      "Block Diagram\n",
      "×\n",
      "Data and Control Flow\n",
      "×\n",
      "Flow Diagram\n",
      "Firstly, the GSM module and other ports are initialized.\n",
      "Then, we check whether garbage bin is used by someone. If it is used, the fill height is sensed\n",
      "and fill level is calculated. If the fill level is lower than 50%, Green colored LED is turned on,\n",
      "if the fill level is in between 50% - 80%, yellow LED is turned on. Otherwise, red LED is turned on.\n",
      "If red LED is turned on, it s checked wheth bin needs to be compacted or not by using the number\n",
      "of compaction processes. If number of compaction processes are lower than 3, then the compaction\n",
      "process is automatically turned on. When compaction is going, if someone tries to put garbage\n",
      "in to the garbage bin, it will be automatically stopped. If it is not, compaction process will be\n",
      "completed. After that the number of compaction processes will be updated.\n",
      "×\n",
      "Algorithm\n",
      "Automation Algorithm\n",
      "For What?\n",
      "How Implemented?\n",
      "Initial Condition\n",
      "To stop assigning\n",
      "same location to two Garbage Collectors.\n",
      "Check the database whether another bin in the unit related to\n",
      "bin in which the request is sent has been assigned to another garbage collector.\n",
      "Assign the request to that same Garbage Collector.\n",
      "First Criteria\n",
      "To distribute the workload evenly among Garbage Collectors.\n",
      "Define an amount of tasks for one round.\n",
      "Store the number of active tasks of every garbage collector in the database.\n",
      "Find round number for each collector using amount of active tasks and tasks per round.\n",
      "Select collector who has the lowest round number.\n",
      "Second Criteria\n",
      "To assign the nearest collector to the bin.\n",
      "Get smallest distances from collectors to bins\n",
      "using locations.\n",
      "Select collector who has the smallest distance to the bin.\n",
      "Third Criteria\n",
      "When the Garbage Collecting starts, everyone can start from the same round and same location.\n",
      "To assign the bins next to each other in the same zone to a collector by Preventing two bins\n",
      "that are too far apart from, being assigned to the same collector.\n",
      "Every red bin must be assigned to relevant collector in the zone.\n",
      "Access database and find any relevant collector in the zone corresponding to the bin\n",
      "where the request came from.\n",
      "Diagrams\n",
      "Check our Database System\n",
      "This is the Conceptual Schema of the relational databse of our system.\n",
      "Each entity can be explained as given below.\n",
      "ADMIN - The administrator of whole Garbage Colllection and Disposal System can register to\n",
      "our system and they will be provided an unique id.\n",
      "COLLECTOR - The Garbage Collector also can register to the system and he/she will be provided an\n",
      "unique id which is given for only garbage collector.\n",
      "ZONE - A zone has units and it has a n unique id. The Collectors are allocated to zone.\n",
      "SYSTEM - The Garbage Collection system settings can be changed by the administrator. The administrator\n",
      "can change bin height and fill level details (Green range, Yellow range and Red range)\n",
      "BIN - A Smart Garbage Bin is registered to the system by using an id and the category,\n",
      "battery capacity, compaction cycles and fill level details are the main attributes of the Bin.\n",
      "UNIT - One Unit consists of bins. Each unit has an id and the location details.\n",
      "Conceptual Schema\n",
      "×\n",
      "Logical Schema\n",
      "×\n",
      "Circuit Designs\n",
      "Check our Circuit Diagrmas\n",
      "POWER SUPPLY UNIT\n",
      "Solar panel absorbs sunlight with the help of photovoltaic cells which convert the sun rays into electricity.\n",
      "Battery Charge controller is used to control the rate at which electri current is added from electric batteries and it prevents overcharging.\n",
      "Then electric power stored in the battery which is used to operate all the electric components.\n",
      "View Circuit Diagram\n",
      "FILL LEVEL DETECTION UNIT\n",
      "The ultrasonic sensor senses the waste in the bin at the constrained level and send signals to the microcontroller.\n",
      "0-50% of fill level - on Green LED\n",
      "50-80% of fill level - on Yellow LED\n",
      "Greater than 80% of fill level - on Red LED\n",
      "View Circuit Diagram\n",
      "COMPACTION UNIT\n",
      "Microcontroller turn on the relay switch, once the bin is full and compaction times are less than 4 to actuate the DC motor.\n",
      "DC motor activates the scissor jack mechanism to compact the waste in the bin.\n",
      "When the compaction begins, buzzer will be turned on and User activity can be monitored using IR sensor.\n",
      "View Circuit Diagram\n",
      "3D Model Designs\n",
      "Check our Smart Garbage Bin Designs\n",
      "UI /UX Design\n",
      "Web Apllication UI Designs\n",
      "Once the administrator creates an account and login to\n",
      "this application, he/she can,\n",
      "Get a full Overview of the entire Bin Systemwith the fill levels and other Details.\n",
      "Search certain Units by Unit ID.\n",
      "Toggle between the views(Table View and Graph View).\n",
      "Add/ Remove Bins to the System.\n",
      "Change System parameters(Bin Height, Fill Level Ranges).\n",
      "View accepted/declined requests by Garbage Collectors.\n",
      "Mobile Apllication UI Designs\n",
      "Once the Garbage Collector creates an account and login to\n",
      "this mobile application, he/she can,\n",
      "Accept/Decline all garbage collecting requests.\n",
      "Accept one/more than one request.\n",
      "See all locations of accepted Garbage bins.\n",
      "Filter requests.\n",
      "Previous\n",
      "Next\n",
      "Previous\n",
      "Next\n",
      "Security\n",
      "System Security Concerns\n",
      "JSON Web Token(JWT) - JWT is used to securely transmit messages\n",
      "of communication between\n",
      "Garbage bin and Administrator and communication between Garbage Collector and Administrator. By using JWT, the messages\n",
      "can be verified and trusted as they are digitally signed.\n",
      "Password Hashing - When Administrator login to the website by entering username and\n",
      "password, we use passwoord hashing to verify the integrity of the password. From this the actual password would never\n",
      "be stored in the database.\n",
      "AWS RDS/EC2 Security Features - We use SSL/TLS to communicate with AWS resources. And we setup the API\n",
      "and logging details using AWS CloudTrail.\n",
      "Progress\n",
      "Web App Completed Video\n",
      "Mobile App Completed video\n",
      "Cloud Deployment\n",
      "AWS Cloud Deployment\n",
      "AWS Deployment of the system is done by according the given AWS architectute. All the steps are given below.\n",
      "And We connect the backend of our system to AWS and tested it through POSTMAN tool.\n",
      "Testing\n",
      "Check Our Testing\n",
      "View Our Testing Codes\n",
      "Timeline\n",
      "Our Project Timeline\n",
      "05th July, 2021 - 19th July, 2021\n",
      "Presenting the Project Proposal\n",
      "Thinking innovative ideas for the project and presenting one specific idea with\n",
      "a project proposal.\n",
      "20th July, 2021 - 27th July, 2021\n",
      "Frameworks and Technologies\n",
      "Getting familiarized with the frameworks and technologies.\n",
      "27th July, 2021 - 10th August, 2021\n",
      "Front End Development\n",
      "Website Basic Front End Development.\n",
      "Mobile App Basic Front End Development.\n",
      "10th August, 2021 - 24th August, 2021\n",
      "Designing 3D Model\n",
      "For Smart Garbage Collector, the 3D model is designed. See 3D model from here.\n",
      "24th August, 2021 - 03rd September, 2021\n",
      "Progress Review - Milestone 2\n",
      "Presenting detailed soultion architecture.\n",
      "Presenting Technology familiarity.\n",
      "Demonstrating progress of software applications.\n",
      "Presenting testing methods which are used in system development.\n",
      "03rd September, 2021 - 17th October, 2021\n",
      "Back End Development\n",
      "Website Back End Development.\n",
      "Mobile App Back End Development.\n",
      "17th October, 2021 - 20th October, 2021\n",
      "Software Testing\n",
      "Web and Mobile App UI Testing by using Appium.\n",
      "REST API Testing by using Postman.\n",
      "Server Loading Testing by using JMeter.\n",
      "20th October, 2021 - 25th October, 2021\n",
      "AWS Deployment\n",
      "Storage and backups - Amazon S3\n",
      "Database - Amazon RDS MySQL\n",
      "Hosting - Amazon EC2\n",
      "25th October, 2021\n",
      "Progress Review II\n",
      "Presenting System Functional completeness.\n",
      "Presenting the software testing plan.\n",
      "Presenting 3D Model.\n",
      "Our Budget\n",
      "Bill of Materials\n",
      "Component\n",
      "Quantity\n",
      "Unit Price (LKR)\n",
      "Price (LKR)\n",
      "ATMEGA328P Microcontroller\n",
      "1\n",
      "600\n",
      "600\n",
      "GSM Module\n",
      "1\n",
      "1950\n",
      "1950\n",
      "GPS Module\n",
      "1\n",
      "1250\n",
      "1250\n",
      "Solar Panel (20W, 12V) with Polycarbonate shield\n",
      "1\n",
      "6000\n",
      "4500\n",
      "PWM Charge Controller(12V, 20A)\n",
      "1\n",
      "4200\n",
      "4200\n",
      "Battery(12V)\n",
      "1\n",
      "2499\n",
      "2499\n",
      "Ultrasonic Sensor\n",
      "2\n",
      "190\n",
      "380\n",
      "IR Sensor\n",
      "1\n",
      "110\n",
      "110\n",
      "LED\n",
      "3\n",
      "11\n",
      "33\n",
      "Buzzer\n",
      "1\n",
      "35\n",
      "35\n",
      "DC Motor(12V)\n",
      "1\n",
      "1000\n",
      "1000\n",
      "Dual-Channel Relay Module\n",
      "1\n",
      "250\n",
      "250\n",
      "Outer Cover with Scissor Jack\n",
      "1\n",
      "2000\n",
      "2000\n",
      "Total\n",
      "18772\n",
      "Our Team\n",
      "Developers\n",
      "Isara Tillekeratne\n",
      "E/17/352\n",
      "Hashini Wijerathne\n",
      "E/17/398\n",
      "Vidurangi Kalpana\n",
      "E/17/148\n",
      "Advisors\n",
      "Dr. Isuru Nawinne\n",
      "Senior Lecturer\n",
      "Dr. Mahanama Wickaramasinghe\n",
      "Senior Lecturer\n",
      "Smart Garbage Collector\n",
      "Call Us\n",
      "Messsage Us\n",
      "Quick Links\n",
      "Smart garbage Collector is an IoT system which facilitates the management of Garbage Collection and disposal.\n",
      "+94 77 764 8682 (Isara)\n",
      "+94 77 269 3120 (Hashini)\n",
      "+94 70 327 2396 (Vidurangi)\n",
      "e17352@eng.pdn.ac.lk\n",
      "e17398@eng.pdn.ac.lk\n",
      "e17148@eng.pdn.ac.lk\n",
      "University of Peradeniya\n",
      "Faculty of Engineering\n",
      "Department of Computer Engineering\n",
      "\n",
      "\n",
      "Extracting smart home https://cepdnaclk.github.io/e17-3yp-smart-home\n",
      "\n",
      "\n",
      "Smart-Home\n",
      "Smart Home\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Hardware\n",
      "Hardware model\n",
      "Circuit Diagram\n",
      "Software model\n",
      "Others\n",
      "Budget\n",
      "Timeline\n",
      "Team\n",
      "Future Home for everyone\n",
      "Everything is on mobile, why not home?\n",
      "Github Repository\n",
      "Features of our smart devices\n",
      "Smart-bulbs\n",
      "Smart Switches\n",
      "System\n",
      "Introduction\n",
      "Smart-Home is meant for convinence and efficecy. Controlling and monitoring\n",
      "your home by your smart-phone make things easier. Smart-bulbs,smart-switches and\n",
      "smart-bliends\n",
      "make your home more smarter.\n",
      "Problem\n",
      "In the Non-smart-Homes or the traditional homes, so much energy waste\n",
      "is due to improper management.\n",
      "Monitoring the full home appliances is insane. When the peak of the electric bill,\n",
      "we don't know what eats the power so much. It is so inconvenient some time for example,\n",
      "when you forgot to turn off the light before sleeping or going far away and forgot to turn\n",
      "off\n",
      "your bulbs or switches..\n",
      "Solution\n",
      "Solution is simple. Using concepts like IOT, HCI and AI(future plan)\n",
      "we can implement smart devices for the homes. They can be control using our mobiles and they can\n",
      "semi-automated. And also you can monitor your home power consumption details by using and\n",
      "smart-switch\n",
      "embeded with\n",
      "voltage and current sensor. For this project we going build smart bulbs and the\n",
      "switches.\n",
      "Solution Architecture\n",
      "Our solution Architecture contains two types of devices, they are\n",
      "Smart-Bulbs & the Smart-Switchs. They both devices, sensors like motion\n",
      "sensor,\n",
      "AC current sensor, AC voltage sensor and the Rellay are directly connected with the Central\n",
      "Unit.\n",
      "Our mobile application and the central unit connectedto the cloud via internet. So they can\n",
      "communicate\n",
      "with them-self. The central unit will use the MQTT protocol to communicate with the\n",
      "server.\n",
      "The energy consumption monitoring, this is a feature embeded with all the switches to\n",
      "calculate the\n",
      "energy consumption and update it to the cloud. This is can be implemented using Two sensor\n",
      "AC Current\n",
      "sensor\n",
      "and AC voltage sensor.\n",
      "Motion Sensing, Motion sensing is another feature built-in with the bulbs, The motion\n",
      "sensors are\n",
      "connected\n",
      "to the central unit. When a motion detected or the central unit wil turn on the bulb and if\n",
      "no\n",
      "motion/human detected\n",
      "the CU will turn off the bulb.\n",
      "Mobile applications communicate with the central unit through the cloud or diretly using\n",
      "wifi router.\n",
      "The User settings, user data, and the reports will be stored in the cloud/server.\n",
      "UI DESIGN\n",
      "ER Diagram\n",
      "Hardware Model\n",
      "This our Hardware model of our project.\n",
      "These are the hardware componets we planned to use:\n",
      "NodeMCU32\n",
      "PIR sensor\n",
      "Relay switch\n",
      "AC Dimmer\n",
      "AC Current\n",
      "Sensor\n",
      "AC\n",
      "Voltage\n",
      "sensor\n",
      "NodeMCU32S\n",
      "NodeMCU32S is development board which is embeded with the esp32 micro\n",
      "controller which\n",
      "so small but powerfull. It's the perfect controller for our project because it's\n",
      "cheap, it already\n",
      "comes with the wifi module and it has many features.\n",
      "Feature of the ESP32:\n",
      "18 Analog to DC converter\n",
      "3 SPI interfaces\n",
      "3 UART interfaces\n",
      "2 I2C interfaces\n",
      "16 PWM output channels\n",
      "2 DAC\n",
      "2 I2S interfaces\n",
      "10 Capacitive sensing GPIOs\n",
      "Referense\n",
      "Link\n",
      "Hardware Model\n",
      "PIR Sensor\n",
      "Passive Infrared Sensor commanly known as Proximity motion\n",
      "sensor. PIR sensors are\n",
      "used to detect the movements. It functioning by absorbing the IR rays emits\n",
      "from the objects.\n",
      "Humans and animals emit the IR radiation other than that the hot objects\n",
      "also emits the IR rays so\n",
      "IR sensor detect the movements of the objects. Many variety of sensors in\n",
      "the market they vary\n",
      "with price, sensitivity and range. For this project we HC-SR501. Because it\n",
      "mid range wide, angle,\n",
      "good sensitivity and cheap\n",
      "Referense Link\n",
      "Hardware Model\n",
      "Current Sensor\n",
      "ACS 712 Current sensor used to measure the current using the\n",
      "Hall-Effect princile.\n",
      "Many current sensors are in the market but we selected this because of it's\n",
      "size and accuraccy.\n",
      "it's so small but it can measure up to 30A and the energy wastage is\n",
      "negligible.\n",
      "30 A module\n",
      "5V Operating Voltage\n",
      "Scale factor 100 mV per Amp\n",
      "Referense Link\n",
      "Hardware Model\n",
      "Voltage Sensor\n",
      "ZMPT101b is a voltage sensor which accurate and small in size\n",
      "and best suited for\n",
      "the\n",
      "IoT developments.\n",
      "Measure up to 250 V\n",
      "Operating Voltage: DC 5V-30V\n",
      "Output Signal: Analog 0-5V\n",
      "Referense Link\n",
      "Hardware Model\n",
      "3-3.3V Relay\n",
      "Relay is an electrically operated switch. It consists of a set of input\n",
      "terminals for a\n",
      "signal or multiple control signals, and a set of operating contact\n",
      "terminals. The\n",
      "switch may have any number of contacts or multiple contact forms, such as\n",
      "make\n",
      "contacts, break contacts, or combinations thereof.\n",
      "Relay are used where it is necessary to control a circuit by an independent\n",
      "low-power\n",
      "signal, or where several circuits must be controlled by one signal.\n",
      "Referense\n",
      "Link\n",
      "Hardware Model\n",
      "AC Dimmer\n",
      "The AC Dimmer is designed to control the alternating current voltage,\n",
      "which can transfer current up to 400V/8А. In most cases, Dimmer is used to\n",
      "turning the power ON/OFF for lamps or heating elements, it can also be used\n",
      "in\n",
      "fans, pumps, air cleaners, e.t.c. Lately, Dimmer has become an often-used\n",
      "decision\n",
      "for smart home systems. For example, when you need to smoothly change the\n",
      "light brightness.\n",
      "Power : up to 400V/600V (8A~24A)\n",
      "Operating Voltage 0 - 3.3 V\n",
      "Current signal > 10mA\n",
      "Referense Link\n",
      "Hardware Model\n",
      "❮\n",
      "❯\n",
      "CAD MODEL\n",
      "Circuit Diagram\n",
      "Circuit Diagram of the Smart Plug.\n",
      "Here the led denotes the Load.\n",
      "Circuit Diagram\n",
      "Circuit Diagram of the Smart Bulb.\n",
      "Here the led denotes the Bulb.\n",
      "Software Model\n",
      "Flutter\n",
      "Node.js\n",
      "MongodB\n",
      "MQTT\n",
      "AWS-Cloud\n",
      "TESTING DEMO\n",
      "Budget of our Project\n",
      "This is the budget of our project\n",
      "Timeline\n",
      "Team Members\n",
      "Arshad MRM   E/17/015\n",
      "Nishankar S   E/17/230\n",
      "Varnaraj N   E/17/358\n",
      "Supervisor\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Step in to the future\n",
      "App\n",
      "store Google play\n",
      "© Copyright digitalHuT. All Rights Reserved\n",
      "Designed by Students of UOP\n",
      "\n",
      "\n",
      "Extracting smart shopping cart https://cepdnaclk.github.io/e17-3yp-smart-shopping-cart\n",
      "\n",
      "\n",
      "Smart Shopping Cart\n",
      "Smart Shopping Cart\n",
      "Home\n",
      "About\n",
      "Solution Architecture\n",
      "Implementation\n",
      "Team\n",
      "Supervisors\n",
      "More..\n",
      "budget\n",
      "Timeline\n",
      "Mobile App\n",
      "Desktop App\n",
      "Testing\n",
      "Get Started\n",
      "Better Experiance with Smart Shopping Cart\n",
      "Make your shopping more easy\n",
      "Get Started\n",
      "Watch Video\n",
      "Introduction\n",
      "Smart Shopping Cart is an innovative consumer purcjasing product that is designed to help shoppers' fast-track their shopping experince. The concept of this smart cart will revolutionize the purchasing experience\n",
      "of every buyer.\n",
      "Problem\n",
      "Long waiting queues\n",
      "Waste time on searching products\n",
      "Forget to buy products\n",
      "Safety and health during a pandemic\n",
      "Difficult to display offers\n",
      "Lot of labour for scanning and billing process\n",
      "Our Solution\n",
      "Customer can purchase the product by just scanning the barcodes printed on the products before adding it to cart\n",
      "Mobile app keeps adding the items in list and the total amount is updated accordingly\n",
      "Customers can scan and remove any item\n",
      "LCD will show the improved bill at each instance\n",
      "Billing will be done automatically\n",
      "Customers can do the bill payment through their preferred payment method\n",
      "Customers will be able to view their digital receipts via app\n",
      "Solution Architecture\n",
      "Solution based on our project idea\n",
      "Data Path\n",
      "In our system have many data transfer process this is the data transfer flow in software, hardware and server\n",
      "Overview\n",
      "These are our implementations for our project\n",
      "Mobile App\n",
      "Mobile Application developed for the Customer who uses our smart shopping cart\n",
      "Web App\n",
      "Web Application developed for the Admin and staffs they can manage the activity and transactions.\n",
      "Hardware\n",
      "Our Hardware system will be placed on the shopping cart\n",
      "Testing\n",
      "Software and Hardware tesing\n",
      "BUDGET\n",
      "Timeline\n",
      "Our project plan timeline\n",
      "Timeline\n",
      "We planed to improve the project in this time flow\n",
      "Team\n",
      "We are the members who develop this projects\n",
      "Rilwan M.M.M\n",
      "E/17/292\n",
      "Studing at university of peradeniya\n",
      "Kavinaya Y\n",
      "E/17/159\n",
      "Studing at university of peradeniya\n",
      "Piriyaraj s\n",
      "E/17/256\n",
      "Studing at university of peradeniya\n",
      "SUPERVISORS\n",
      "The supervisors who give guidance for the project\n",
      "Dr. Isuru Nawinne\n",
      "Senior Lecturer\n",
      "Dr. Mahanama Wickramasinghe\n",
      "Senior Lecturer\n",
      "© Copyright SMART SHOPPING CART. All Rights Reserved\n",
      "Designed by\n",
      "KRP ROCKERS\n",
      "\n",
      "\n",
      "Extracting agribot https://cepdnaclk.github.io/e16-3yp-agribot\n",
      "\n",
      "\n",
      "AGRIBOT\n",
      "Menu\n",
      "About\n",
      "introduction\n",
      "Architecture\n",
      "Design\n",
      "Team\n",
      "budget\n",
      "Autonomous Agricultural Robot\n",
      "AGRIBOT\n",
      "Find More\n",
      "About\n",
      "Overview\n",
      "Agriculture sector has always performed as a major economic force in Sri Lanka, making a significant contribution to the national economy, food security and employment. At the same time agriculture is the livelihood of the majority in the rural sector and plays a key role in alleviating rural poverty. This has been well recognized from the time of independence and there has always been a cabinet portfolio set aside for the agriculture sector.\n",
      "Problem\n",
      "Lack of laborers, the difficulty of finding labourers or can't afford daily wages for them are some of the main problems that today's farmers are facing. Not only that less knowledge about environmental conditions and pests also a problem faced by farmers.\n",
      "Solution\n",
      "The solution to the problem will be an automated robot to automated the seeding process as well as to identify the environmental conditions.\n",
      "INTRODUCTION\n",
      "Why AgriBot?\n",
      "Smart Farming is a widely growing area. In smart farming user can monitor their field via smart\n",
      "device and control the watering, fertilizing autonomously. With this concept, people tried to develop into the next level. They want to use robots into the field to reduce the labour work. There are robots which can do seeding, cropping, identify diseases and literally everything. So now people are not just monitoring the field, they can maintain the whole field and labour cost is minimum.\n",
      "So you will ask if there are already machines which can seeding, why do we need an AgriBot? The answer is normally there are some machines which consume a lot of power because they have heavy machinery components. They have a lot of disadvantages like, they have huge drilling components which turn upside down the field area, not good for the soil creatures and soil structure, sound and air pollution, not good for small seeds. In that case, AgriBot works really well, it can map the whole field and seeding. Agribot is the only drill point where we need to put seed. Also cost-effective, lightweight and eco friendly. This is the best way to seeding small seeds in big areas. Another thing is very easy to operate through a user-friendly mobile app.\n",
      "AgriBot for Greenhouse farming\n",
      "AgriBot is the best solution for modern Greenhouses because those are full covered areas which have sensitive sensors all over the place. Because in greenhouses every condition which plant will depend, is measured and controlled accurately and another thing is there are tap\n",
      "lines all over the place. For areas like this, you can’t use heavy machinery or drones to seed plants and AgriBot is the perfect solution.\n",
      "Solution Architecture\n",
      "Mobile Application\n",
      "Android mobile application is available for the AgriBot. The app is designed using Android Studio. Mainly the app is used to configure the robot while temperature and humidity readings can get through the mobile app. Both these procedures happen through AWS servers.\n",
      "Automated Robot\n",
      "The robot is used to plant seeds over a farming area.We use ESP32 SIM8000I as the microcontroller of use robot.An MPU6050 and encoders are used to navigate the robot in the farming area. An ultrasonic distance sensor is used to identify the obstacles in the path of the robot.A drill bit is used to dig the ground and put seeds. Motors are used to drill the land and control the drill bit.\n",
      "Web Server\n",
      "AWS server is used as the webserver for the AgriBot. Initial parameters which we will take by mobile app are passed to the robot through this server. Firebase database is used for store the credentials details as well as the specific data of the Robot.\n",
      "Highlevel Diagram\n",
      "Design\n",
      "Click on the image to see details of each sub-sections.\n",
      "Mobile Application\n",
      "Overview\n",
      "Frontend UI\n",
      "Testing\n",
      "Server Backend\n",
      "Overview\n",
      "Deploy\n",
      "Database\n",
      "Agribot\n",
      "Overview\n",
      "3D Model\n",
      "Hardware Components\n",
      "Circuit Diagram\n",
      "Navigation\n",
      "Communication\n",
      "Our Team\n",
      "\"Alone we can do so little; together we can do so much.\" – Helen Keller\n",
      "Maneesha Randeniya\n",
      "E/16/313\n",
      "Nipun Dewanarayane\n",
      "E/16/360\n",
      "Denuke Disanayake\n",
      "E/16/089\n",
      "Our Advisors\n",
      "“Education is the passport to the future, for tomorrow belongs to those who prepare for it today.” – Malcolm X\n",
      "Dr.Isuru Nawinne\n",
      "Dr.Ziyan Maraikar\n",
      "Dr.Upul Jayasinghe\n",
      "Budget\n",
      "Full detailed estimated budget according to market price in Sri Lanka.\n",
      "Github repo\n",
      "Find more informations and codes details.\n",
      "Visit\n",
      "University of Peradeniya.\n",
      "Phone: +94 81 239 33 00\n",
      "Email: vc@pdn.ac.lk\n",
      "Web-site: http://www.pdn.ac.lk/\n",
      "Faculty of Engineering.\n",
      "Phone: +94 81 239 33 02\n",
      "Web-site: http://eng.pdn.ac.lk/\n",
      "Computer Engineering Department.\n",
      "Phone: +94 81 239 39 14\n",
      "Web-site: http://www.ce.pdn.ac.lk/\n",
      "Contact Us\n",
      "Get in touch with us.\n",
      "Send Message\n",
      "Copyright © Agribots 2021\n",
      "Overview\n",
      "Overall design\n",
      "Objective:Navigate through the farm area and do the seeding.\n",
      "Height :15-20 cm\n",
      "Length : 20-25 cm\n",
      "Width : 15-20 cm\n",
      "Weight : 1 - 1.5 kg\n",
      "Speed : 0.5 ft/s\n",
      "Average work time : 60 - 90 min\n",
      "Close\n",
      "3D MODEL\n",
      "3D model views of the Agribot\n",
      "3D model was implemented by using Tinckercad which is available for free online tool. Below pictures shows some views of the agribot 3D model which is taken from different angles.\n",
      "Get the obj file from here\n",
      "Close\n",
      "Hardware Components\n",
      "Hardware components which will use for implement agribot\n",
      "Microcontroller\n",
      "Temperature & Humidity sensor\n",
      "DHT11 Temperature & Humidity Sensor\n",
      "Take measurements every 30 mins. Measure the humidity and temperature of the current environment\n",
      "Use the DHT11 sensor module because the module will have a filtering capacitor and pull-up resistor inbuilt.\n",
      "The sensor is factory calibrated and hence easy to interface with other microcontrollers.\n",
      "Humidity measurement range: 20% ~95%\n",
      "Humidity measurement error: ±5%\n",
      "Temperature measurement range: 0℃~50℃\n",
      "Temperature measurement error: ±2 ℃\n",
      "Operating voltage:3.3 V~5 V,\n",
      "Operating current: 0.3mA\n",
      "Relay module\n",
      "SRD-3VDC-SL-C Relay Module\n",
      "The drilling operations of the drill bit is operated using an SRD-3VDC-SL-C Relay Module.\n",
      "Sealed typed\n",
      "Coil nominal voltage - 3 v\n",
      "Nominal current - 120 mA\n",
      "Power consumption of coil - abt. 0.36W\n",
      "Motor Driver\n",
      "Driver Model: TB6612FNG H-Bridge\n",
      "Motor supply voltage of 2.5 to 13.5 volts DC.\n",
      "Logic supply voltage of 2.7 to 5.5 volts DC.\n",
      "Output current of 1.2 amperes continuous, 3.2 amperes peak.\n",
      "Built-in thermal shutdown.\n",
      "Efficiency 91-95%\n",
      "Small module, no heat sink required\n",
      "Servo Motor\n",
      "Model: SG90\n",
      "Two servo motors to work as a valve of our seed container and another one to place the drill bit in the correct position\n",
      "Operating voltage - 3.0V~7.2V\n",
      "Working Frequency - 50Hz\n",
      "Motor Type - Brushed DC Motor\n",
      "Gear Type - Plastic Gears\n",
      "Close\n",
      "Circuit Diagrams\n",
      "This Diagrams shows how components wired.\n",
      "Close\n",
      "android application\n",
      "This is the overview of Android mobile application\n",
      "Android mobile application is available for the AgriBot. The app is designed using Android Studio. Mainly the app is used to configure the robot while temperature and humidity readings can get through the mobile app.\n",
      "Overview\n",
      "Start of the app user have to enter the Product Id to Login\n",
      "Using that ID, App will subscribe to corresponding topics\n",
      "App will display the sensor data and connection state of the Robot\n",
      "Also user can publish initial plantation instructions to Robot\n",
      "And essential control signals to autonomous process\n",
      "Scalability\n",
      "Firebase Database can easily increase storage and entries.\n",
      "New hardware devices can be added\n",
      "App can simply connect with any Device for a given ID.\n",
      "In the broker, support the Asynchronous process\n",
      "Can handle multiple topics at a time.\n",
      "Reliability\n",
      "Responsive UI\n",
      "Connect with any device simply entering the device ID\n",
      "Unique topics to isolation\n",
      "Check the connectivity of the device\n",
      "No need to have steady internet connection to work\n",
      "Close Project\n",
      "frontend ui\n",
      "This images shows the user interface of the Android mobile application.\n",
      "This is the 1st impression of user. When user run the app, appliication will start with this splash screen.\n",
      "This is the login screen UI. User need to enter credential which will be provided by seller for specific robot. Each robot has unique username and password.\n",
      "After user logged in, he/she can see the configuration fragment UI. This is the UI which user will use to configure the robot. As well as, it will display whether robot is connected with server.\n",
      "This UI will display the weather report. This report include data which was send by the robot. Currently robot implemented with temperature and humdity sensors only. Therefore, app will fetch only temperature & humidity.\n",
      "This UI includes the details of the purchesed robot. Data will be fetched from firebase database along with login. Each data are unique with the login credentials.\n",
      "When user clicks the logout in bottom navigation bar, this confirmation box will appear. User may choose yes or no to logout or keep stay login.\n",
      "Close\n",
      "Testing\n",
      "Tests that need to be done during the App building\n",
      "Testings were done during the development of the app to identify the problems with the mobile app. ( Connectivity, User Inputs etc… )\n",
      "Used test cases to check the expected values come as the output.\n",
      "Easier than manually testing each case over and over again.\n",
      "1. Subscribe the Broker\n",
      "Checked the subscription - connectivity between the Mobile app and the EC2 Broker.\n",
      "This is important because through the Broker only mobile app get the readings from the Robot.\n",
      "Though an IP is correct, invalid topic can be subscribed. But this won’t happen in the app because topics are assigned when user successfully login to the app ( Using correct ID and the Password).\n",
      "Subscription is tested using mosquitto broker(Representing Sensors of the Robot) also; using Temperature and Humidity values.\n",
      "2. Publish to Broker\n",
      "Checked the Publish - connectivity between the mobile app and the EC2 Broker\n",
      "It is important to check whether only the correct values are delivered to the Broker from the mobile app.\n",
      "Terminal is used as the Robot to check the received values are correct.\n",
      "3.\tUser Inputs\n",
      "Most critical place the Robot can go wrong is with User Inputs.\n",
      "Important to check whether correct values are input by the User to the app.\n",
      "4.\tUI test with espresso\n",
      "Additional test to check the functionality of the login page using espresso with test cases.\n",
      "Summary report\n",
      "Close Project\n",
      "overview\n",
      "Overview of the cloud deployment,MQTT and Technologies.\n",
      "Overview\n",
      "Create AWS EC2 instance and install Mosquitto MQTT Broker\n",
      "Using EC2 IP address and port, mobile app and Robot can connect to the MQTT broker\n",
      "MQTT broker will handle the publications and subscriptions\n",
      "We created firebase database and entries for each Robot\n",
      "Using the database app will connect with the correct device\n",
      "Cloud Deployment\n",
      "Create EC2 instance, Ubuntu virtual machine\n",
      "Install mosquitto MQTT brokerr\n",
      "Used IP of VM to connect the application\n",
      "Setup security rules of EC2\n",
      "Give access only to port numbers 1883 and 22 (MQTT, SSH)\n",
      "MQTT Setup\n",
      "Used Mosquitto broker to handle mqtt clients (App,Device)\n",
      "Set Password protection to the broker\n",
      "Not anyone can publish or subscribe to broker and increase the traffic\n",
      "when we want to publish or subscribe we have to use the password\n",
      "Used unique topics for each device\n",
      "to identify whether Robot is connected or not\n",
      "Set MQTT Last Will message\n",
      "Publish QOS 2 messages\n",
      "Data send only one time.\n",
      "Highlevel Diagram\n",
      "Close\n",
      "Deploy in AWS\n",
      "Steps to follow deploy in AWS server.\n",
      "The Internet is composed two types of machines: a server or a client. A server provide services to you while the client request for the service. To ensure that our MQTT broker(the service) can be accessed using other computer or electronic devices anytime, we need to install the broker to a server machine that is always turned on and connected to the internet. To do this, we rent a virtual machine on AWS that functions like a computer.\n",
      "Go to AWS Management Console\n",
      "& Select EC2.\n",
      "Select Launch Instances\n",
      "Select the ubuntu server.\n",
      "Select “ Free tier Eligible” Option & Click “Next: Configure Instance Details”\n",
      "In “Configure Security Group” Tab add above rules using “Add Rule” option. Then Click “ Review and Launch”\n",
      "Click “Launch”\n",
      "“Create a new key pair” option & Give a “Key pair name” ,Then Download the key pair\n",
      "Newly Created instance is Running there in instances.\n",
      "Details of the instance. “Public IPv4 address” is used to connect with in the instance.\n",
      "Start, Stop or Connect the Instance can be done by write clicking on the instance.\n",
      "When select “Connect” this dialog box is displayed.\n",
      "Close\n",
      "database\n",
      "Overview about Firebase database\n",
      "Overview\n",
      "Firebase realtime NoSQL database.\n",
      "There is a one entry for every agribot device\n",
      "Used for Login process\n",
      "Using that data, app will assign unique client id\n",
      "Because of that, only one app can connect to a device at the time\n",
      "Using that data, app and device share data via unique topic\n",
      "Useful to isolate other devices data\n",
      "No write access for users\n",
      "Easy to retrieve and scale the database\n",
      "Close\n",
      "Deploy in AWS\n",
      "Steps to follow deploy in AWS server.\n",
      "Use this area to describe your project. Lorem ipsum dolor sit amet, consectetur adipisicing elit. Est blanditiis dolorem culpa incidunt minus dignissimos deserunt repellat aperiam quasi sunt officia expedita beatae cupiditate, maiores repudiandae, nostrum, reiciendis facere nemo!\n",
      "1. Go to AWS Management Console\n",
      "& Select EC2.\n",
      "Close Project\n",
      "\n",
      "\n",
      "Extracting automated railway ticketing system https://cepdnaclk.github.io/e16-3yp-automated-railway-ticketing-system\n",
      "\n",
      "\n",
      "Automated Railway Ticketing System\n",
      "PROJECT BLOG\n",
      "About\n",
      "Design\n",
      "System Info\n",
      "Circuits\n",
      "Software\n",
      "Testing\n",
      "Demonstration\n",
      "Documents\n",
      "Benefits\n",
      "Budget\n",
      "Contact\n",
      "Automated Railway Ticketing System\n",
      "Travel Easy\n",
      "Get Started\n",
      "Problem\n",
      "In srilanka people waste there valuable time by spending in long queues in railway stations. Eventhough people do not get better experience when travelling. This problem effects badly on every aspects in day to day life of passengers.\n",
      "And another thing is using cardboard tickets for entrances increases environmental pollutions and keeping several officers for ticket issueing increase the government expenses.\n",
      "Solution\n",
      "Introducing fully automated system which consisting automatic gates and realtime web services with a one card for every travel.\n",
      "This reduces the time wastage as passengers have several entrances and no unefficient human involvements for ticketing. No environmental pollution any more as no tickets in the system. This will make the life easier.\n",
      "Solution Architecture\n",
      "Every passenger should enroll to the department and when he/she enroll will get a plastic card which has a key to his/her account. Passenger can recharge their account at the cashier or using their bank accounts. When he/she enters to the platform he/she only\n",
      "have to swipe the card and the starting point will be added to the database.\n",
      "Then they can seated anywhere he/she like Ticket checker will swipe their card again and class(1,2,3) will be added to the database. Finally passenger should swipe their card at the destination station. Then the cost will be deducted from their account.\n",
      "The gate at the destination will be closed until this procedure for each passenger.\n",
      "All money transactions and travelling history can be tracked and a database can be managed. All of the details related to passengers account can be managed by using app or website.\n",
      "Physical Design\n",
      "CAD Designs\n",
      "Design for handheld device\n",
      "Previous\n",
      "Next\n",
      "Design for Gate device\n",
      "Previous\n",
      "Next\n",
      "System Flow\n",
      "Initially a passenger should register to our system by purchasing a swipe card from the railway department. Then that person will be elligible to use our traveling system by using their card. Card owner can recherge their account on their own by using their bank accounts. Otherwise\n",
      "Payment methods are added to recharge from the counter at the railway station. When the person who travels, should swipe their card at the entrance gate. Then by checking theri account status gate will be activated.\n",
      "If there is no error and if there is no any illegal activity at his entrance, then he can enter to the train. When entering to the train his/her account will be holded\n",
      "until he/she leaves destination after swiping their card. In the train, ticket checker checks\n",
      "about the passenger class & will update the person's class(class 1, class 2). Any persons' default class will be \"class 3\".\n",
      "Then at the exit, passenger should swipe the card and system releases the holded accuont. At that time all the calculations will be happened and travel cost will be reduced from his/her account.\n",
      "and if the passenger don't swipe\n",
      "the card then their account will be transfered in to a freezed state. In the freeze state what happens is, he can't enter again from an entrance gate without paying his last travel cost.\n",
      "All these activities will be recorded in to a database. If a passenger wants to see their travel details, that person can register to our web application using his/her user id. That user id will be provided when that person\n",
      "initially register to our travelling system.\n",
      "Entity Relationship Diagram\n",
      "Circuit Diagrams\n",
      "Gate Circuit\n",
      "Handheld Device Circuit\n",
      "Previous\n",
      "Next\n",
      "Gate controlling Software\n",
      "This is the software used for the physical opertions of the system. This contain the software handlers at the gates(entrances and exits).\n",
      "This software system is also conneted with the central server and is running on the stations PCs mounted in each station. This is capable of all the\n",
      "functionalities needed.Entering, Exiting, Authenticating & Error checking are some such funtions.This is written in Java and some hardware functionalities\n",
      "are also displayed using the GUI.\n",
      "User Web application\n",
      "This web application can be used by both admins(officers incharged by railway department) and the users. Users can get smart facilities like\n",
      "account balance details checking, Rechgarge their account, travel details checking etc. Admins can do better performances using this web application. All the security actions\n",
      "are taken here to enhance the better performances. Front end consists of html, css, java script where use react.js and backend consists of java script\n",
      "where use node.js.\n",
      "Hands on experience\n",
      "To use as a user\n",
      "User ID: user001\n",
      "Password: user001\n",
      "To use as an admin\n",
      "User ID: admin001\n",
      "Password: admin001\n",
      "click here to tryout!\n",
      "Database Point of View\n",
      "Both Gate Controller Software & Web Application connected to a central server written in javascript where node.js, express is used. As the Database MongoDB Atlas cloud used\n",
      "due to security aspects and scalability. There are more things offering us by Mongo. Specially it takes less time to read/write to the database.\n",
      "Testing\n",
      "several main functionalities of the web application was tested.\n",
      "For the testing purpose we used unit testing on the middlewares and some integration testings.\n",
      "Testing gives the clear overview of outcomes of the functionalities.It is very helpful in debugging and diagnosing.\n",
      "so these are helpful to enhance the code. Doing these test with\n",
      "development saves the cost and enhance the security aspects.\n",
      "It automatically uplift the product quality and ensure the customer satisfaction.\n",
      "For testing the backend(Nodejs) of our server, we used Mocha, Jest and chai.They give the clear understanding about the details about\n",
      "the end points in out api. The main usage was using unit testing we were able to find the bugs in the authentication purpose of the admin and users.\n",
      "The full details about our testing results were given on the github repo of out project.\n",
      "#\n",
      "Test Type\n",
      "What Tested\n",
      "Importance\n",
      "Way of test done\n",
      "Results & Findings\n",
      "1\n",
      "Unit testing\n",
      "Middleware :\n",
      "Post method for user logging\n",
      "Correctness of the user name was tested\n",
      "Someone can enter any password and can enter to the system using several bruteforce checkings.\n",
      "Our system always gives security for the incorrect user names.\n",
      "Using mocha,chai,supertest\n",
      "Tools\n",
      "Incorrect user names were given as json objects and system gives correct outputs as we expected.\n",
      "What we expected was given and sometimes expectation and output was differ and using those tools able to identify the code statements needed to be modified.\n",
      "2\n",
      "Unit testing\n",
      "Middleware :\n",
      "Post method for user logging\n",
      "Correctness of the user password was tested\n",
      "Using bruteforcing someone can enter the correct password.\n",
      "System works corrently for the password issues.\n",
      "Using mocha,chai,supertest\n",
      "Tools\n",
      "Incorrect passwords were given as json objects and system gives correct outputs as we expected.\n",
      "Here password formats and other types were changed and tested and system worked correctly.\n",
      "What we expected was given and sometimes expectation and output was differ and using those tools able to identify the code statements needed to be modified.\n",
      "3\n",
      "Unit testing\n",
      "Middleware :\n",
      "Get method for admin authentication\n",
      "By changing admin usernames and passwords\n",
      "System gave authentication fails warning correctly\n",
      "Using mocha,chai,supertest\n",
      "Tools\n",
      "Incorrect passwords and admin names were given as json objects and system gives correct outputs as we expected.\n",
      "Here password formats and other types were changed and tested and system worked correctly.\n",
      "What we expected was given and sometimes expectation and output was differ and using those tools able to identify the code statements needed to be modified.\n",
      "4\n",
      "Unit testing\n",
      "Middleware :\n",
      "Get method for user details cheking after logged as an admin\n",
      "Giving different usernames try to get user details. Have to have authenticate the admin correctly otherwise this didn’t work. Have to have correct tokens.\n",
      "Try to acces user details without logging as admin system gives authentication fails warnings. Tried different tokens gave authentication fails.\n",
      "Expected was given and sometimes expectation and output was differ and using those tools able to identify the code statements needed to be modified.\n",
      "5\n",
      "Unit testing\n",
      "Middleware :\n",
      "Post method for user logging\n",
      "Check correctness of tokens\n",
      "System generate unique tokens and it is the one responsible for activities done on the server after logging. If someone can cheat then security fails.\n",
      "Change the tokens and try different aspects in the web and try do things inside the web\n",
      "Gives authentication fails warnings and some functionalities were accessed so were able to identify them.\n",
      "Some Test Results\n",
      "Full Demonstration of the System\n",
      "Download Documents from here👇\n",
      "Design Manual\n",
      "User Manual\n",
      "Benefits for the man kind\n",
      "Best passenger experiance\n",
      "User friendly Interactive App\n",
      "Save more Time to User\n",
      "More Security Provided\n",
      "Future Enhancements\n",
      "We hope to extend our payment methods far beyond.\n",
      "Introduce our cross platform mobile app\n",
      "Maximize performances with the help of Artificial Intelligence & Machine Learning\n",
      "For more details\n",
      "Visit our github project repository\n",
      "Visit Now\n",
      "Connect With Us\n",
      "Deshan L.A.C\n",
      "Madushan K.H.G.H\n",
      "Madushanka H.M.K\n",
      "deshanch9678@gmail.com\n",
      "hasindumadushan325@gmail.com\n",
      "kavindumadushanka972@gmail.com\n",
      "+94 71 1204836\n",
      "+94 76 4825922\n",
      "+94 77 2894172\n",
      "\n",
      "\n",
      "Extracting automatic fish tank control system https://cepdnaclk.github.io/e16-3yp-automatic-fish-tank-control-system\n",
      "\n",
      "\n",
      "Fish Tank Control System\n",
      "e16377@eng.pdn.ac.lk\n",
      "+94 77 88 75 74 7\n",
      "Fish Tank Controller System.\n",
      "Home\n",
      "Introduction\n",
      "Hardware\n",
      "Mobile App\n",
      "Software Testing\n",
      "Design\n",
      "Team\n",
      "Budget\n",
      "Contact\n",
      "Welcome to Fish Tank Controller System\n",
      "We are team of talanted Engineering Undergraduates making the world a better place\n",
      "Get Started\n",
      "Check our Mobile App\n",
      "Demonstration\n",
      "Connect\n",
      "Connect to your fish tanks remotely and control it\n",
      "Keep Track\n",
      "Keep a log about the fish varieties in the fish tanks\n",
      "Feed on time\n",
      "Feed them as you need.\n",
      "Clean It\n",
      "Renew the water when the tank get polluted\n",
      "Introduction\n",
      "What Are We Going To Do\n",
      "Many fish are dying in aquariums due to lack of food or polluted water. We found a solution for that.\n",
      "We have invented a Fish Tank Control System\n",
      "So you can control multiple fish tanks from anywhere in the world.\n",
      "Read the pH value and Temparature inside the fish tank.\n",
      "Through the sensors you can check the pH value and temparature inside the fish tank.\n",
      "Control your fish tanks from anywhere\n",
      "You can set the feeding times and how much mass you are gonna feed to the fish. And also you can\n",
      "log the fish types and count of each fish type using the mobile app.\n",
      "Depend on the water quality, the water renew system will work automatically.\n",
      "Planing 100%\n",
      "User Interface Designing95%\n",
      "Back End Developing 75%\n",
      "Hardware Implementation 20%\n",
      "Mobile App 30%\n",
      "Total Progress 55%\n",
      "5\n",
      "Milestones\n",
      "1\n",
      "Project\n",
      "2\n",
      "Semesters\n",
      "3\n",
      "Hard Workers\n",
      "Hardware\n",
      "Check our Hardware Technologies\n",
      "We are using several Hardware Technologies\n",
      "ESP32-WROOM\n",
      "GPIO pins + WIFI module inbuilt\n",
      "18 Analog-to-Digital Converter (ADC) channels\n",
      "16 PWM output channels\n",
      "Dual-core 32-bit LX6 microprocessor, up to 240 MHz\n",
      "448 KB ROM for booting and core functions\n",
      "520 KB SRAM for data and instructions\n",
      "4MB Flash\n",
      "Supply Voltage : 3.3V\n",
      "XH-M603 Charger module\n",
      "Input Voltage : DC 10-30V\n",
      "Can Control Input Voltage\n",
      "Inbuilt Display\n",
      "12V lead acid battery\n",
      "Very Durable\n",
      "Rugged Construction\n",
      "7.2AH Capacity\n",
      "Ph meter sen-0161\n",
      "pH signal conversion board + pH probe\n",
      "Supply Voltage : 3.3V~5.5V\n",
      "Accuracy : ±0.1 at 25℃\n",
      "Temperature Range : 5~60 ℃\n",
      "Response Time: < 1min\n",
      "Probe Life : 1 year\n",
      "DS18B20 Waterproof Sensor\n",
      "Communicate using 1 wire method\n",
      "Operating Voltage: 3V to 5V\n",
      "Temperature range : -55~125 ℃\n",
      "Programmable\n",
      "0.5 ℃ accuracy\n",
      "G1/2 plastic Solenoid valve\n",
      "Normally Closed\n",
      "Thread : G1/2”\n",
      "Rated Voltage : 12V\n",
      "Current 300mA\n",
      "Applicable fluid Temperature : 0~55 ℃\n",
      "Applicable Water pressure : 0.02-0.8MPa\n",
      "Assembly Design of Final Overview\n",
      "Front View\n",
      "This is the front view of our tank that we willing to gain at as final overview.\n",
      "Final Overview 1\n",
      "Feeding Controller\n",
      "This is the feeding controller design which will attach to the tank of user.\n",
      "Final Overview 2\n",
      "Sensor Panel\n",
      "This is the sensor panel that can easily paste to user tanks.\n",
      "Final Overview 3\n",
      "Controller PCB Designs\n",
      "Controller Circuit\n",
      "Controller circuit consists of four regelators that helps to manage the voltage levels required for the components .\n",
      "Controller Circuit layer 1\n",
      "Controller Circuit\n",
      "This contains the bottom layer of our controller circuit .\n",
      "Controller Circuit layer 2\n",
      "Power Circuit\n",
      "This power circuit contains a transformer and a rectifier,which helps to connect with our charger module and LED ACID battry\n",
      "Power\n",
      "Circuit layer 1\n",
      "Power Circuit\n",
      "This contains the bottom layer of our power circuit .\n",
      "Power\n",
      "Circuit layer 2\n",
      "Final Overview of\n",
      "Component Placement\n",
      "Overview of Component Placement\n",
      "This view shows the final hardware component placement in our device.The device consists of a plastic cover .\n",
      "Battry Display\n",
      "The Display indicates the volatge level of our led battry.\n",
      "Side overview of Device\n",
      "Package of Device\n",
      "Package that covered with nice wrapper.\n",
      "Hardware Designs\n",
      "Demonstration of Outputs using LED\n",
      "In here as we have limited hardware components we have demonstrated outputs using LED bulbs. There is a buzzer for alerts, water inlet, water outlet, feed motor\n",
      "Sensors\n",
      "Two sensors are immersed in water here for testing. Temperature is measured using DS18B20 waterproof temperature sensor. Also there is a PH sensor.\n",
      "Power supply\n",
      "Power is supplied after converted into 12V DC. Then through voltage regulaters.\n",
      "Testing on Hardware\n",
      "Many tests have been done for hardware.\n",
      "Hardware Tests\n",
      "Following tests have been done\n",
      "1.\n",
      "Authentication test (Integrated\n",
      "security test)\n",
      "This is important for the security of the app and user accounts. In Fish Tank Control System security is far more important as someone can kill all the fish in seconds\n",
      "2. Data Mapping testing\n",
      "Database testing helps in protecting the most important component of the app which is data. The correct Structure is very\n",
      "import for the whole process of renewing and feeding\n",
      "3. Stored Procedures(Black box testing)\n",
      "Perform an operation from the front end (UI) of the application and check for the execution of the stored procedure and its results.\n",
      "4.\n",
      "Device compatibility testing\n",
      "Users will use android and ios with different versions and screen size\n",
      "Mobile App was tested across various mobile devices to confirm its compatibility.\n",
      "5.\n",
      "Wi-Fi Connection test\n",
      "Microcontroller connects to the server using Wifi. Therefore we done few test to make sure the communication happened perfectly.\n",
      "Download the test report here!\n",
      "Special Features\n",
      "Whatsapp Integration\n",
      "We are sending you a message if anything is out of ordinary\n",
      "Using Whatsapp API we have developed the app to send you an error message\n",
      "Security is the most important thing!\n",
      "If the PH value goes wrong\n",
      "You will get an error message saying that PH is not in a good range with the tank number.\n",
      "If the Temparature value goes wrong\n",
      "You will get an error message saying that Temparature is not in a good range with the tank number.\n",
      "Mobile App\n",
      "We built an app compatable with both Android and ios\n",
      "We are using several software Technologies like flutter, python etc.\n",
      "Mobile App View\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "Spread the word!\n",
      "Close\n",
      "We have done some testing testing\n",
      "These tests have done only for the software parts\n",
      "TEST NAME\n",
      "PURPOSE OF THE TESTING\n",
      "METHOD\n",
      "RESULTS\n",
      "CONCLUSION\n",
      "Signup route testing\n",
      "1.A user can enter duplicate or malicious email\n",
      "2.User can send wrong data types\n",
      "3.User can send a request with missing fields\n",
      "We used five python scripts with sign up requests\n",
      "1. Request with a wrong email address\n",
      "2. Request with a already signup email\n",
      "3.Request with wrong data types\n",
      "Ex number for the name\n",
      "4.Request without the email field\n",
      "5.Correct Request\n",
      "Case 1\n",
      "Response with\n",
      "Status code 422\n",
      "Case 2\n",
      "Response with status code 406\n",
      "Case 3\n",
      "Response with\n",
      "Status code 422\n",
      "Case 4\n",
      "Response with status code 422\n",
      "Case 5\n",
      "Response with\n",
      "Status code 200\n",
      "All test cases pass\n",
      "Login route testing\n",
      "1.User can enter wrong credentials\n",
      "2.User can send a request missing field\n",
      "3.A black hat user can try to sql injection\n",
      "4.Correct request\n",
      "5.User can send wrong data types\n",
      "We used four python scripts with login requests\n",
      "1.Request with wrong email\n",
      "2.Request with a wrong password\n",
      "3.Request that use password as “pass OR 'x'='x’”\n",
      "4.Request with correct credentials\n",
      "5.Request with a number as email\n",
      "Case 1\n",
      "Response with status code 401\n",
      "Case2\n",
      "Response with status code 401\n",
      "Case 3\n",
      "Response with status code 401\n",
      "Case 4\n",
      "Response with status code 200\n",
      "And user details\n",
      "Case 5\n",
      "Response with status code 422\n",
      "All test cases pass\n",
      "Control route\n",
      "1.Control route for feed particular tank fishes\n",
      "2.Control route for renew the water of particular tank\n",
      "We use dummy mqtt client to subscribe the tank id and looking for the mqtt message\n",
      "1.Send a feed\n",
      "Signal with valid token\n",
      "2.Send a feed signal with invalid token\n",
      "3.Send a feed signal with expired token\n",
      "4.Send a renew\n",
      "Signal with valid token\n",
      "5.Send a renew signal with invalid token\n",
      "6.Send a renew signal with expired token\n",
      "Case 1\n",
      "Response with status code 200\n",
      "Case  2\n",
      "Response with status code 401\n",
      "Case 3\n",
      "Response with status code 401\n",
      "Case 4\n",
      "Response with status code 200\n",
      "Case 5\n",
      "Response with status code 401\n",
      "Case 6\n",
      "Response with status code 401\n",
      "All test cases pass\n",
      "Tank routes\n",
      "1.Send data , tank to server\n",
      "1.Data with wrong tankid\n",
      "2.Data with correct request\n",
      "Case 1\n",
      "Response with\n",
      "s=0\n",
      "Response with status code 200\n",
      "All test cases pass\n",
      "Tank routes\n",
      "2.Get stable temperature of tank\n",
      "1.Send a request with tank id\n",
      "Case 1\n",
      "Response with a temperature\n",
      "Test Case pass\n",
      "Server reliability\n",
      "We need to check whether server can function under bulk of requests\n",
      "1.We use 3 python scripts that contain “for” loop with 1000 login requests\n",
      "Then we run that there python scripts at the same time\n",
      "After few time request got response code as 500 as server error\n",
      "Test case failed\n",
      "Solution :\n",
      "Earlier we used only one thread after this we increase it to 20 threads then we test again and test was successful\n",
      "Rate limit test\n",
      "We need to check rate limiting of our server\n",
      ".We use 4 python scripts that contain “for” loop with 1000 login requests\n",
      "Then we run that four python scripts at the same time\n",
      "Response with status code 200 also last request took some time to response\n",
      "Rate limiting functions properly\n",
      "App data view routes\n",
      "We check adding a new tank functionality\n",
      "1.Add tank request with wrong token\n",
      "2.Add tank request with expired token\n",
      "3.Add tank request with a not valid data type\n",
      "4. Add tank request with correct data and valid token\n",
      "Case 1\n",
      "Response with status code 401\n",
      "Case 2\n",
      "Response with status code 401\n",
      "Case 3\n",
      "Response with status code 422\n",
      "Case 4\n",
      "Response with status code 200\n",
      "All test cases passed\n",
      "Python Code Samples of  our Test Cases\n",
      "Test Results\n",
      "Swagger Ui Testing\n",
      "Also we use an inbuilt swagger uI tester that supplies by Fast API,to test and confirm our functionalities of our every router. This UI supplies an api caller for every route ,we have coded with a fast api object.Also it provides us with good documentation that contains required data type and requested responses.\n",
      "Some screenshots are given here\n",
      "Swagger UI is a good api testing platform with visual documentation that makes backend testing easier (Documentation for the link is given here https://swagger.io/tools/swagger-ui/)\n",
      "Also this comes as a inbuilt flatform in FastApi package(Details of fastapi with swagger https://fastapi.tiangolo.com/advanced/extending-openapi/#check-it)\n",
      "Unit Testing\n",
      "We did unit testing in front end code .In here we checked the graph viewing function that written in dart.First we make a dummy object of data that contains temperature and pH.Then we inject it in to our function and looking for the view showing in our mobile device\n",
      "Test Result: Visualize the graph correctly\n",
      "Time taken for the visualization is higher\n",
      "Modification:Increase the visualize time using flutter graph package\n",
      "Back end testing conclusions\n",
      "every end point validate the data\n",
      "Wrong data types give an error code and message\n",
      "No duplicate emails can create an account\n",
      "Login validation checking\n",
      "Every route checking through the swagger UI\n",
      "with 20 threads server gives superior efficiency\n",
      "...\n",
      "Dr. Upul Jayasinghe\n",
      "Advisor\n",
      "Dr. Asitha Bandaranayake\n",
      "Advisor\n",
      "Dr. Suneth Namal Karunarathna\n",
      "Advisor\n",
      "Dr. Isuru Nawinne\n",
      "Advisor\n",
      "Dr. Ziyan Maraikar\n",
      "Advisor\n",
      "Dr. Upul Jayasinghe\n",
      "Advisor\n",
      "Dr. Asitha Bandaranayake\n",
      "Advisor\n",
      "Dr. Suneth Namal Karunarathna\n",
      "Advisor\n",
      "Dr. Isuru Nawinne\n",
      "Advisor\n",
      "Dr. Ziyan Maraikar\n",
      "Advisor\n",
      "Dr. Upul Jayasinghe\n",
      "Advisor\n",
      "‹›\n",
      "Design\n",
      "Check our Designs\n",
      "This is a brief explanation about our design\n",
      "All\n",
      "Hardware\n",
      "Overall\n",
      "User Interface\n",
      "3D Design\n",
      "Drawn using tinkercad\n",
      "Circuit Diagram\n",
      "Designed using easyEDA\n",
      "NODE MCU ESP32 WROOM\n",
      "Pin Diagram (30pin version dev kit)\n",
      "Flow\n",
      "How nodes connected to each other\n",
      "UI Design\n",
      "User Interface of Login page\n",
      "Circuit Diagram\n",
      "Power Supply Circuit\n",
      "ER Diagram\n",
      "ER diagram of mongoDB\n",
      "Fighter Fish\n",
      "User Interface Design\n",
      "Team\n",
      "Our Hardworking Team\n",
      "Vindula I B S\n",
      "E/16/377\n",
      "Harshana P Y S\n",
      "E/16/127\n",
      "Samaraweera A A R V\n",
      "E/16/332\n",
      "Budget\n",
      "Estimated Budget According to the market price\n",
      "F.A.Q\n",
      "Frequently Asked Questions\n",
      "These are some of the freequently asked questions\n",
      "How much will this cost?\n",
      "Around 18000LKR. Roughly 97.5 USD.\n",
      "Is it easy to control?\n",
      "You just need to download the app. This will be the easiest way you ever tried. Trust Us!\n",
      "What happen if the power goes down?\n",
      "This has inbuilt backup power which is enough for 2-3 Days. So it will be very much useful in household\n",
      "fish tanks as well as larger scale aquariums, companies etc.\n",
      "Contact\n",
      "Contact Us\n",
      "Fell free to contact regarding any matter\n",
      "Address\n",
      "University of Peradeniya, Peradeniya\n",
      "Email Us\n",
      "e16377@eng.pdn.ac.lk\n",
      "Call Us\n",
      "+94 77 88 75 74 7\n",
      "Loading\n",
      "Your message has been sent. Thank you!\n",
      "Send Message\n",
      "Github Repo\n",
      "Visit our project Repository\n",
      "github repo\n",
      "Pre-Order\n",
      "Enter the E-mail. One of our team member will contact you\n",
      "University of Peradeniya.\n",
      "University of Peradeniya\n",
      "Peradeniya\n",
      "Sri Lanka\n",
      "Phone: +94 81 239 33 00\n",
      "Email: vc@pdn.ac.lk\n",
      "Web-site: http://www.pdn.ac.lk/\n",
      "Faculty of Engineering.\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "Peradeniya\n",
      "Sri Lanka\n",
      "Phone: +94 81 239 33 02\n",
      "Web-site: http://eng.pdn.ac.lk/\n",
      "Computer Engineering Department.\n",
      "Computer Engineering Department\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "Peradeniya\n",
      "Sri Lanka\n",
      "Phone: +94 81 239 39 14\n",
      "Web-site: http://www.ce.pdn.ac.lk/\n",
      "Designed by Group 4\n",
      "Home\n",
      "Introduction\n",
      "Hardware\n",
      "Mobile App\n",
      "Software Testing\n",
      "Design\n",
      "Team\n",
      "Budget\n",
      "Contact\n",
      "\n",
      "\n",
      "Extracting chessMATE https://cepdnaclk.github.io/e16-3yp-chessMATE\n",
      "\n",
      "\n",
      "chessMATE | e16-3yp-chessMATE\n",
      "e16-3yp-chessMATE\n",
      "chessMATE\n",
      "Smart Chess Platform\n",
      "Back to our Repository\n",
      "Group Members:\n",
      "Isurika Adikari\n",
      ": E/16/012 : e16012@eng.pdn.ac.lk\n",
      "Damsy De Silva\n",
      ": E/16/069 : e16069@eng.pdn.ac.lk\n",
      "Chaminie De Silva : E/16/070 : e16070@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Problem\n",
      "Solution\n",
      "About Product\n",
      "Vision of the Product\n",
      "Product Overview\n",
      "High-Level Architecture\n",
      "3D Model of our Product\n",
      "User Interfaces for Mobile Application\n",
      "Cloud Architecture\n",
      "Mobile App Demonstrations\n",
      "PCB Designs\n",
      "Test Summary\n",
      "Test Results\n",
      "Mobile App Testing\n",
      "Server & Database Testing\n",
      "Embedded System Testing\n",
      "System Test\n",
      "Demonstration\n",
      "Budget of the Product\n",
      "Advising Lecturers\n",
      "Links\n",
      "Problem\n",
      "Chess is one of the most popular and oldest board games played by millions of people worldwide. But still there are some difficulties chess players face which limits them to enjoy this game to its fullest.\n",
      "When chess players have trouble finding competent opponents in their locality, they try online chess on a mobile or desktop application. We found out that most of the professional as well as casual chess players are more likely to play chess game on a physical chess board rather than on a mobile or desktop screen.\n",
      "Many chess players have stated that they have trouble in focusing and attacking aggressively during games played through mobile or desktop applications. And also, they have confessed that when playing using the physical chess board, they get to touch the pieces as they make a move, and this really draws them into the game.\n",
      "Solution\n",
      "Our solution is an IOT platform which will provide the grand usual chess board experience to whom that need online chess.\n",
      "About Product\n",
      "Vision of the Product:\n",
      "The vision of the chessMATE is to add a cool online chess game experience on everyday lives of people. Our endeavour is to give people more human experience with the new next generation technology.\n",
      "Product Overview:\n",
      "Our product consists of two main sections; an electrically powered chess board (Smart chess board) and a mobile app.\n",
      "In order to start a game, first you need to connect the board with the mobile app. Next you have to connect to an opponent who is registered on our platform via the mobile app. Then you can start the game.\n",
      "When you make a move on your chess board, that move is sent to the chess board and mobile app of the opponent and the path of the move is displayed along with the start and end squares on the chess board owned by the opponent using the LEDs on the board. Then the opponent is required to manually place the specific chess piece moved by you on the correct end square in order to continue the game.\n",
      "The main game mode we offer to our clients is the Board Vs Board game mode. Further the Board Vs App and App Vs App game modes can be experienced by the chessMATE clients.\n",
      "High-Level Architecture\n",
      "Given below diagram shows the high-level architecture of our solution.\n",
      "3D Model of our Product\n",
      "Given below is the 3D overview of our chess board.\n",
      "Following shows the 3D overview of the inner section of our chessboard. There are 64 compartments where each compartment being used by a square.\n",
      "User Interfaces for Mobile Application\n",
      "These are our currently implemented user interface designs.\n",
      "Cloud Architecture\n",
      "Mobile App Demonstrations\n",
      "Here we have demonstrated how the Sign-In and Login functionalities work for multiple clients.\n",
      "The following demonstration shows how a new game is started between two players and how the movements are being sent and received by the players successfully.\n",
      "PCB Designs\n",
      "PCB design for Main Unit\n",
      "PCB design for a compartment unit.\n",
      "Test Summary\n",
      "Test Results\n",
      "Mobile App Testing\n",
      "Server and Database Testing\n",
      "Client Connection Establishments\n",
      "Get all available online users\n",
      "Check multiple games between multiple pairs of players\n",
      "Client 1 initiates a new game with Client 2\n",
      "Client 3 initiates a new game with Client 4\n",
      "Moves are sent and received by the respective clients in the parallely conducted games without resulting any conflicts.\n",
      "Client 1 and Client 2\n",
      "Client 3 and Client 4\n",
      "Check database access and queries\n",
      "When a new player sign-in into the platform a new record will be created in the database\n",
      "When a player log into the platform his login information will be checked in the database\n",
      "Embedded System Testing\n",
      "LED Panel Test\n",
      "What is the test?\n",
      "Whether the opponent’s move is correctly shown on the led panel\n",
      "Why is it important?\n",
      "Ensures the correctness in indication of opponent’s move\n",
      "Establishment of connection (Bluetooth) between Mobile app and ESP32\n",
      "How was the test done?\n",
      "Algorithm Test\n",
      "Test 01\n",
      "Test 02\n",
      "System Testing\n",
      "Demonstration\n",
      "App vs App Game Demonstration\n",
      "Game Streaming Demostraion\n",
      "System Demonstration\n",
      "Part 01\n",
      "Part 02\n",
      "Budget of the Product\n",
      "Advising Lecturers\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Ziyan Maraikar\n",
      "Links\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting computerized timetabling and attendance marking system https://cepdnaclk.github.io/e16-3yp-computerized-timetabling-and-attendance-marking-system\n",
      "\n",
      "\n",
      "Attendance Marking System\n",
      "Home\n",
      "Solution\n",
      "Services\n",
      "Design\n",
      "website\n",
      "app\n",
      "hardware device\n",
      "Cloud Deployment\n",
      "Testing\n",
      "Software Testing\n",
      "Hardware Testing\n",
      "Demonstration\n",
      "Budget\n",
      "Future Developments\n",
      "Team\n",
      "Contact\n",
      "Computerized Timetabling And Attendance\n",
      "Marking System\n",
      "In this project,our goal is to develop a\n",
      "modern attendance marking system that is suitable for\n",
      "today's world.In parallel with the attendance marking system,a fully-fledged time table\n",
      "managing\n",
      "and lecture reminding system is developed.\n",
      "Read\n",
      "More\n",
      "How things work?\n",
      "On the registration day of the students,fingerprints and student details are taken and added to the\n",
      "database using the website.A RFID token is registered for a student and given to them.Student can do\n",
      "the registration via the website or mobile app.Before a particular class starts,corresponding\n",
      "student details and fingerprint details are loaded into the sd card and fingerprint device with the\n",
      "help of nodemcu & backend server for student identification purposes.when a particular student put\n",
      "their attendance using fingerprint device and RFID sensor student details are displayed in the LCD\n",
      "display.At the same time,new attendance data is sent to the backend.All timetable data is added to\n",
      "the database and lecture reminding is automatically done by the server.Student and teachers are able\n",
      "to analyze and visualize attendance data via the website or mobile app.\n",
      "Services\n",
      "Attendance marking System\n",
      "Identifying the students in a lecture will be done by a hardware device which is in the\n",
      "lecture rooms by fingerprints and rfid cards.Students can see they were identified correctly\n",
      "in hardware device itself by seeing his information in the lcd screen.During the lecture\n",
      "time attendance details will be sent to the server and attendance will be updated.\n",
      "Lecture Notifications\n",
      "Before a lecture of a particular course students who had registered to that course will get\n",
      "notifications regarding lecture,lecture time,lecture duration and lecture room\n",
      "Student Registration\n",
      "Student will registered to the system via the website.This process will done by an\n",
      "admin.Student details including fingerprint will be taken into the system.\n",
      "Course Registration\n",
      "Beginning of the each semester registered students can do the course registration via the\n",
      "website or the app\n",
      "Automated Timetable\n",
      "Admin will initially enter the time table details (date,time,course,lecture room,lecturer) to\n",
      "the system via website.After that before each lecture students will get notifications via\n",
      "the mobile app\n",
      "Attendance Review\n",
      "Students can see their attendance percentage,daily attendance details via the mobile\n",
      "app.Lecturers can see their students' attendance for lab sessions and lecture sessions via\n",
      "the website.\n",
      "UI Design - Website\n",
      "UI Design - App\n",
      "Final Hardware Device\n",
      "Power On\n",
      "Power Off\n",
      "Keypad\n",
      "Setting the course code\n",
      "Selection Menu\n",
      "Selecting modes such as course registration,attendance marking for the\n",
      "device\n",
      "RFID sensing area\n",
      "Fingerprint Scanner\n",
      "LCD display\n",
      "Displaying student details after making the attendance\n",
      "Hardware Components Used\n",
      "1. ATmega328P microcontroller\n",
      "Operating Voltage: 1.8V-5.5V\n",
      "Flash Program Memory: 32 kbytes\n",
      "EEPROM Data Memory: 1 kbytes\n",
      "I/O Pins: 23\n",
      "SPI and I²C Master and Slave Support\n",
      "USART Support\n",
      "External Oscillator: up to 20MHz\n",
      "2. ESP8266 microcontroller\n",
      "Operating Voltage: 3.3V\n",
      "Flash Memory: 4 MB\n",
      "EEPROM Data Memory: 1 kbytes\n",
      "Digital I/O Pins : 16\n",
      "SPI and I²C Support\n",
      "USART Support\n",
      "PCB Antenna\n",
      "Integrated TCP/IP Protocol Stack\n",
      "External Oscillator: up to 80 MHz\n",
      "3. R307 Fingerprint Module\n",
      "Interfacing\n",
      "UART -> for microcontrollers/ARM processors\n",
      "USB 2.0 ->for computers\n",
      "Software serial -> to use other digital pins\n",
      "Reliability\n",
      "Flash memory for saving fingerprint templates -> Avoids data loss in\n",
      "power failures\n",
      "Power Usage\n",
      "Operating on 3.3v or 5v\n",
      "Sensing circuitry consumes 5µA(very low)\n",
      "4. RC522 RFID Module\n",
      "Operating voltage: 2.5V to 3.3V\n",
      "Communication : SPI, I2C protocol, UART\n",
      "Maximum Data Rate: 10Mbps\n",
      "Maximum Read Range: 5cm\n",
      "Current Consumption: 13-26mA\n",
      "5. Keypad & Port Expander(PCF8574P)\n",
      "4x4 keypad -> 8 pins(wastage of pins)\n",
      "Port expander\n",
      "Pin usage reduces to 2 pins\n",
      "Uses I2C protocol\n",
      "6. 16x2 LCD Dispaly & Port Expander(PCF8574P)\n",
      "LCD module - > 11 pins(wastage of pins)\n",
      "Port expander\n",
      "Spi -> i2c Conversion\n",
      "Pin usage reduces to 2 pins/li>\n",
      "7. Rechargeable battery(Li-Po)\n",
      "Output voltage - > 12v\n",
      "Capacity - > 2500mAh\n",
      "Circuit Diagrams\n",
      "PCB design\n",
      "Protocols\n",
      "Software Testing\n",
      "Integration Testing\n",
      "Integration testing is a level of software testing\n",
      "where individual units / components are combined and\n",
      "tested as a group. The purpose of this level of testing is to expose faults in the interaction\n",
      "between\n",
      "integrated units. Test drivers and test stubs are used to assist in Integration Testing.\n",
      "Spring Boot Application Architecture\n",
      "Spring Boot Application has a 3 Tier Architecture with\n",
      "Controller, Service and Persistence Layer.\n",
      "When we talk about integration testing for a spring boot application, it is all about running an\n",
      "application in ApplicationContext and run tests. Spring Framework does have a dedicated test module\n",
      "for integration testing. It is known as spring-test. If we are using spring-boot, then we need to\n",
      "use spring-boot-starter-test which will internally use spring-test and other dependent libraries.\n",
      "Example :- Adding a Lecture room\n",
      "Results\n",
      "Unit Testing - API\n",
      "UNIT TESTING, also known as COMPONENT TESTING, is\n",
      "a level of\n",
      "software testing where individual units / components of a software are tested. The purpose is to\n",
      "validate that\n",
      "each unit of the software performs as designed.\n",
      "Example :- Lecture Attendance Percentage Update\n",
      "Results\n",
      "UI Testing - Mobile App\n",
      "In     UI TESTING, test runs on a device or an emulator.\n",
      "In the background, your app will be installed and then a testing app will\n",
      "also be installed which will control your app, lunching it and running UI\n",
      "tests as needed\n",
      "Example :- User Login\n",
      "First Student will enter the username .\n",
      "Then he/she will close the keyboard.Next, student will enter the password.\n",
      "After that, he/she will close the keyboard again.\n",
      "Finally, student will preform click button.\n",
      "Programme\n",
      "Result\n",
      "After Running the Test, Mobile app's Login UI will redirect to corresponding user's home page.\n",
      "Performance Testing - Website\n",
      "website performance, was measured using\n",
      "Web.dev\n",
      "site.Performance details are as follows.\n",
      "Results\n",
      "Summary Report-Software Testing\n",
      "Feature / Unit\n",
      "Functionality\n",
      "Tools\n",
      "Results\n",
      "1\n",
      "Backend Validations\n",
      "Registration number and Email were tested for proper pattern with different inputs\n",
      "JUnit\n",
      "Given Registration number and Email should have proper pattern for user registration\n",
      "2\n",
      "Frontend Validations\n",
      "Frontend forms were tested with different set of inputs.\n",
      "Jest and Enzyme\n",
      "Forms can not submit without proper inputs\n",
      "3\n",
      "Joins in the database\n",
      "After Course registration of a student, Course and Student and Attendance Collection\n",
      "details were tested.\n",
      "Course and Lecturer collections was tested\n",
      "Course and TimeTable collections were tested\n",
      "JUnit\n",
      "Attendance details were join correctly with Course and the Student\n",
      "Lecturer collection joins correctly with course collection.\n",
      "Course collection joins correctly with Timetable collection\n",
      "4\n",
      "Lecture Attendance\n",
      "Tested whether correct present days,absent days and attendance percentages of student is\n",
      "calculated after adding attendance of a lecture by hardware device\n",
      "JUnit\n",
      "Attendance details are correctly calculated and stored in the database.\n",
      "5\n",
      "UI Testing in Mobile App\n",
      "Mobile App UI s were tested with different user inputs.\n",
      "Button clicks were checked with different pressed times to see output\n",
      "Expresso\n",
      "Forms can not submit without proper inputs\n",
      "Only registered students can log in\n",
      "No matter which time duration button was pressed.It gives the correct function after button was released.\n",
      "6\n",
      "Performance Testing in website\n",
      "Test the performance of the website by metrics such as\n",
      "first paint and time to interactive to determine lag.\n",
      "Test the HTTPS usage to correct image aspect ratios.\n",
      "Check for best practices to ensure site is discoverable.\n",
      "Check for common issues that may prevent users from accessing website content.\n",
      "Web.dev\n",
      "performance is quite low the following reasons may be possible\n",
      "Usage of unencoded images\n",
      "Bad aspect ratios of images\n",
      "Bad API response time\n",
      "Accessibility and Best practices are at a good level\n",
      "SEO is very high because website is hosted in AWS and AWS is take care of SEO\n",
      "Hardware Testing\n",
      "Unit Testing\n",
      "Every Component (Fingerprint,RFID module,SD card module,\n",
      "...) should be tested for proper functionality.\n",
      "Sensor\n",
      "What will be Tested\n",
      "Importance\n",
      "1\n",
      "RFID sensor\n",
      "Test the results according to the environment in which the tag is being read.\n",
      "Test the distance range and the orientation of the tag.\n",
      "Accuracy of identifying the tags should be high\n",
      "2\n",
      "Fingerprint sensor\n",
      "Ability to scan a fingerprint.\n",
      "Test the tolerance level of the sensor.\n",
      "Accuracy of identifying the fingerprints should be high\n",
      "3\n",
      "Push Buttons\n",
      "Debouncing of push buttons.\n",
      "To improve UX with debouncing of push buttons\n",
      "4\n",
      "LCD Display\n",
      "Test the screen clearness of the LCD display under different light conditions\n",
      "LCD display screen must be clear to use the hardware device.\n",
      "Letters and numbers must be clearly visible\n",
      "5\n",
      "SD Card module\n",
      "Test the ability to create files in unique names\n",
      "Test the ability to write and delete files\n",
      "Test the ability to delete files\n",
      "To properly handle the connection failure or power failure conditions\n",
      "Testing Power Supplies\n",
      "After soldering testing power supplies one by one\n",
      "Main power input(Battery)\n",
      "check ripple voltages (using oscillator)\n",
      "Is noise acceptable\n",
      "Micro Controller circuit\n",
      "checking connectivity (using Oscilloscope or Logic probe)\n",
      "check the basic functioning\n",
      "Sensors\n",
      "checking connectivity\n",
      "check the basic functioning\n",
      "Cloud Deployment\n",
      "Demonstration\n",
      "Website\n",
      "Mobile App\n",
      "Hardware Device - Part 01\n",
      "Hardware Device - Part 02\n",
      "Budget\n",
      "Future Developments & Plans\n",
      "develop mobile app for ios platform\n",
      "Introduce the product into ,\n",
      "Universities\n",
      "Post graduate institutes\n",
      "Technical schools\n",
      "Team\n",
      "We are 3rd year Computer Engineering Students of University of Peradeniya\n",
      "Eranadana Wijerathna\n",
      "E/16/399\n",
      "Computer Engineering Undergraduate\n",
      "Saubhagya Munasinghe\n",
      "E/16/242\n",
      "Computer Engineering Undergraduate\n",
      "Nuwan Piyarathna\n",
      "E/16/286\n",
      "Computer Engineering Undergraduate\n",
      "Visit Our Github Repository\n",
      "Visit Now\n",
      "Contacts\n",
      "Nuwan Harsha\n",
      "nuwan.harshamatrix@gmail.com\n",
      "Saubhagya Munasinghe\n",
      "sm201211d@gmail.com\n",
      "Erandana Wijerathna\n",
      "erandanawijerathna@gmail.com\n",
      "Home\n",
      "Solution\n",
      "Services\n",
      "Design\n",
      "website\n",
      "app\n",
      "hardware device\n",
      "Cloud Deployment\n",
      "Testing\n",
      "Software Testing\n",
      "Hardware Testing\n",
      "Demonstration\n",
      "Budget\n",
      "Future Developments\n",
      "Team\n",
      "Contact\n",
      "\n",
      "\n",
      "Extracting digital signage based user targeted advertising https://cepdnaclk.github.io/e16-3yp-digital-signage-based-user-targeted-advertising\n",
      "\n",
      "\n",
      "Digital Signage Based User Targeted Advertising\n",
      "PROJECT BLOG\n",
      "About\n",
      "Design\n",
      "Progress\n",
      "3Dmodels\n",
      "Services\n",
      "Places\n",
      "Contact Us\n",
      "Digital signage based user targeted advertising\n",
      "A novel approach...\n",
      "Find Out More\n",
      "Problem and Solution\n",
      "Most of the advertisements displayed in the digital screens are not relevant for the targeted audience. So,ninety percent of the advertisements displayed using the currently existing digital signages are not very effective. Also the provided digital signage solutions are expensive to afford for most of the SMEs(Small and Medium Enterprises).\n",
      "To overcome these kind of issues our proposed solution consists of an upgraded version with additional hardware/software which can do User Targeted Advertising. Here our aim is while showing content that changes dynamically, when a particular crowd (male/female/children) is identified in front of the screens it will change the current content flow and show some relevant,interesting advertisement for the targeted audience that might catch their attention.\n",
      "The buyer(shop owner) of the digital signage unit can upload their advertisements using the provided user authenticated web application or the mobile application. Also add some specific advertisements categorized by gender and age group. When a user in front is detected specific content will be visible to the targeted audience.\n",
      "Watch Product Video\n",
      "Design Architecture\n",
      "Design Technologies\n",
      "The digital signage control unit consists of raspberry pi 3 which acts as the heart of the system.\n",
      "The digital display is connected to raspberry pi using HDMI and the user detecting and identifying unit is attached to the digital display. This user detecting and identifying unit mainly consists of a Raspberry Pi camera module\n",
      "Firebase is used as the back-end and cloud firestore NoSQL database to store,sync and query data.\n",
      "Flutter is used as the mobile app framework for the front-end development. Dart is used as the programming language where the same code base can be used to develop both android and ios applications.\n",
      "As an additional improvement, a smart power supply unit which can control the digital screen on/off through the mobile application will be implemented.\n",
      "ER Model - Database Structure\n",
      "Main Entities Of The Database are ADMINISTRATION, CUSTOMER(Shop owner who is willing to buy signage unit), ADVERTISEMENT and WORK_TIME. Main relationships are REGISTERS, UPLOADS and SCHEDULES.\n",
      "ADVERTISEMENT entity has a unique id as the primary key. Advertisements can be in three types.\n",
      "-Image,\n",
      "Ticker(Text),\n",
      "Video\n",
      "CUSTOMER table has a composite key, Customer_id along with Device_id. Having a composite key here is useful when same customer is buying more than one signage unit. Here,Device_id refers to the MAC address of the NIC of digital signage controlling unit.\n",
      "1:n relationship exists between ADMINISTRATION and CUMSTOMER, beacause a customer only has one ADMINISTRATION and ADMINISTRATION has many customers. And we can see total participation in both sides because everyone should be registered to use the system.\n",
      "As digital screen can be turned on and off only within the working hours because of our smart power supply unit, customer can schedule the time slots for each day. That data is stored in WORKING_TIME entity. It is a weak entity that does not have a primary key. Here, we have got a weak key 'Day' and same key can be repeated.\n",
      "Simplified Circuit Diagrams\n",
      "Components Needed\n",
      "Digital Signage Controlling Unit\n",
      "Raspberry Pi - $ 35\n",
      "RPi Power Supply - $ 9\n",
      "SD card - $ 10\n",
      "Cooling Fan - $ 4\n",
      "HeatSink - $ 1\n",
      "LED Push Button - $ 4\n",
      "Cover - $ 7\n",
      "User Identifying and Detecting Unit\n",
      "Raspberry Pi - $ 35\n",
      "RPi Power Supply - $ 9\n",
      "SD card - $ 10\n",
      "Cooling Fan - $ 4\n",
      "HeatSink - $ 1\n",
      "Camera Module - $ 10\n",
      "LED Push Button - $ 4\n",
      "Cables - $ 5\n",
      "LEDs, Resistors(220Ω) - $ 0.5\n",
      "Cover - $ 7\n",
      "Smart Power Supply Unit\n",
      "NodeMCU esp8266 - $ 5\n",
      "Relay Module - $ 3\n",
      "Rocker Switch - $ 5\n",
      "Plug socket & Top - $ 5\n",
      "Cables - $ 3\n",
      "LED, Diodes, Resistors(100kΩ) - $ 1\n",
      "Cover - $ 7\n",
      "Flow Chart\n",
      "Data Flow\n",
      "User is supposed to upload the advertisements using the mobile app.\n",
      "Those advertisements are uploaded into the selected google slides page according to age and gender. Default advertisement lists are uploaded to the RPi SD card.\n",
      "Image of the person who is infront of the screen is captured by the camera module and processed in the RPi to extract the face by running haar-cascade classifiers\n",
      "That image is processed with pre trained deep learning model to predict the gender and age group of the person.\n",
      "The age,gender details are updated in firestore database in realtime and signage control unit listens and query these new data.\n",
      "According to the received results, matching google slides presentation is selected and displayed on the digital screen.\n",
      "Software Architecture\n",
      "Data Flow\n",
      "User information and shop details are stored in Firebase(in Cloud Firestore database).\n",
      "Users can upload advertisements using the mobile app after login into their account.\n",
      "Advertisements are uploaded as google slides which are stored inside google cloud. Because of using google slides, we could minimize the cloud storage of our system. And users can easily create and edit advertisements using google slides.\n",
      "Detected persons age and gender prediction values are realtime updated in firebase firestore.\n",
      "Screenly API (in RPi) fetches the matching(to age and gender) google slides presentation link and display the advertisements in the screen.\n",
      "User Detecting & Analysing Unit\n",
      "Real Implementation and Design\n",
      "This unit mainly consists of a RaspberryPi board and a camera module.\n",
      "Image of people in front of the screen\n",
      "is processed inside the RPI for predicting the gender and the age.\n",
      "Haar Cascade classifier is used to detect faces from the captured images.\n",
      "To obtain results, OpenCV libraries are used with a trained cnn model.\n",
      "Predicted age and gender information is updated real-time in firebase.\n",
      "Trained Data Model\n",
      "Age and gender detection in our system is mainly done with Convolutional Neural Networks.\n",
      "We have used the CNN models trained by Gil Levi and Tal Hassner (two Israel researchers) using caffe framework and we have used the OpenCV’s dnn package which stands for “Deep Neural Networks”.\n",
      "To detect faces from images,webcam and to import neural network trained models, opencv libraries such as haarcascade,dnn packages are used in our implementation for predicting gender and age.\n",
      "CNN consists of 8 values for 8 age classes (“0–2”, “4–6”, “8–13”, “15–20”, “25–32”, “38–43”, “48–53” and “60-100”) and two values for two gender clases (\"Male\" and \"Female.\")\n",
      "As you can see in these pictures, this model accurately predict the gender and the age group.\n",
      "Link for Github Files\n",
      "Test To Check Accuracy When Multiple Faces Appears\n",
      "Test\n",
      "Check if image predicted correctly when there is more than one face appearing.\n",
      "Test Type\n",
      "Unit Testing(We did Black Box Testing)\n",
      "Tool\n",
      "Unit Test Library In Python\n",
      "Results\n",
      "Smart Power Supply Unit\n",
      "Overall Design\n",
      "Components and Procedure\n",
      "MQTT messaging protocol is used to design the smart power supply unit.\n",
      "Mobile app (MQTT client) publishes user given messages (ON or OFF) to a unique topic for that power supply unit.\n",
      "Mac address of the Node MCU is used as the topic to make the topic unique for that power supply unit.\n",
      "Node MCU(ESP8266) subscribes to the certain topic and recieves user given message through the broker.\n",
      "EMQX broker is used in our implementation.\n",
      "After recieving the user given message, a signal is given to 5V relay module by the NodeMCU. According to the message,the relay triggers and screen will turn on or turn off.\n",
      "Hardware Design\n",
      "Demonstration Video\n",
      "Safety Factors\n",
      "5A fuse is included in the plug to protect the relay module from high currents.\n",
      "Heat sink is added to protect the device if it becomes overheated.\n",
      "Earthing is used here to protect the user from an electric shock.\n",
      "Special Concerns\n",
      "If a wifi failure happens, you can disconnect the smart power supply unit by the switch and switch on or off manually.\n",
      "If there is a power failure, you don’t have to worry. It will execute the last message given by the user.\n",
      "Using WifiManager library, ESP8266 can be connected to Wifi router without hardcoding router SSID and password in the code.\n",
      "Digital Signage Controlling Unit\n",
      "Actual Implementation & Design\n",
      "Demonstration Video\n",
      "This unit mainly consists of a Raspberry Pi Board.\n",
      "SD card is inserted into the Raspberry Pi board.\n",
      "Screenly OSE is installed in RPI.\n",
      "Screenly API fetches the correct google slide according to the gender and age of the person.\n",
      "When\n",
      "more than one person is appeared, generic advertisements are displayed.\n",
      "App Frontend Design...\n",
      "1. Login/Authentication\n",
      "2. Dashboard/Drawer Bar\n",
      "3. Signage Control/Add assets\n",
      "4. Create/Edit Advertisements\n",
      "5. Power Supply Control\n",
      "6. Customize Profile\n",
      "App Features and Functionality\n",
      "1. Login/Authentication\n",
      "Two factor authentication for login\n",
      "First login through PhoneAuth then Google Sign-In\n",
      "Provide personal and shop details for initial profile setup\n",
      "Shared preferences are used to save credentials after inital login for easy access to app\n",
      "2. Dashboard/Drawer Bar\n",
      "Drawer bar consists of Dashboard, User Targeted Signage, Smart Power Supply and Profile pages\n",
      "Dashboard contains current playlist previews of the actual digital screen\n",
      "Customer analytics are included for strategies\n",
      "3. Signage Control/Add assets\n",
      "Choose Signage device to control from the drop down menu and rename features included\n",
      "Select age and gender category to select a specific advertisement(asset) list\n",
      "Add assets and Watch Previews\n",
      "User targeting turn on/off as per the users choice\n",
      "4. Create/Edit Advertisements\n",
      "Create,Edit assets through google slides by accessing from add assets button\n",
      "Latest advertisment updates are realtime synced and displayed\n",
      "Preview advertisment playlists anytime inside the app through google slides\n",
      "5. Power Supply Control\n",
      "Add multiple power supply units and rename feature to enhance user friendliness.\n",
      "Choose a power supply to control from drop down menu\n",
      "Digital screen on/off button for easy control of the power supply\n",
      "6. Customize Profile\n",
      "Maintain user profile and preview details\n",
      "Customize details as per the users choice\n",
      "Log in through different account by logging out of current account.\n",
      "Unit testing for app and backend\n",
      "Results and Findings\n",
      "cloud firestore mocks and flutter test dependencies are used for several testing in both app and the backend firebase\n",
      "User entry validations performed to provide a better user experience. Invalid user inputs captured and informed properly. Added mac addresses by users are realtime synced to the menus and testing done for device adding and deleting procedures in app.\n",
      "Firestore is used as the backend databse and collections are used to organize data structure of users and devices.\n",
      "Mac addresses are used for document topics in firestore to identify each device. Testing perfomed with this structure for correct retrieval and deletion of devices through app by the user.\n",
      "Results from tests optimized the structure of the firestore for categorizing users and also providing analytics by realtime counts of people captured for user targeting in each gender category.\n",
      "Test Summary\n",
      "Digital Signage Control Unit Designs...\n",
      "Outer view\n",
      "Inner components\n",
      "Inner design\n",
      "Outer back view\n",
      "Top view\n",
      "Vertical view\n",
      "User Detecting & Identifying Unit Designs...\n",
      "Outer view\n",
      "Inner components\n",
      "Inner Design\n",
      "Stand front view\n",
      "Stand back view\n",
      "Stand design\n",
      "Smart Power Supply Unit Designs...\n",
      "Outer view\n",
      "Inner components view\n",
      "Inner design\n",
      "Outer back view\n",
      "Cover and Box\n",
      "Outer/Inner view\n",
      "Design Decisions for Fabrications\n",
      "Digital Signage Control Unit\n",
      "Maximum space utilization within the box\n",
      "Holes to get air into the fan are designed such that small objects are not get into the box\n",
      "User Detecting and Identifying Unit\n",
      "The length between jaws can be easily adjusted according to the table\n",
      "Adjustable hand to change the angle of the camera\n",
      "Fits properly with the RPi cover\n",
      "Smart Power Supply Unit\n",
      "Compact structural design (box dimensions - 17.5cm x 8cm x 4cm)\n",
      "All components screwed for solidity and easy replacement.\n",
      "Air vents added to optimize airflow\n",
      "Clearance space for connecting wires and cables\n",
      "What we provide...\n",
      "Dynamic real-time content changes\n",
      "upload content to display anytime\n",
      "Easy set up and User friendly\n",
      "register with an account to discover features\n",
      "Upload advertisements through mobile app\n",
      "display promotions,sales,new arrivals\n",
      "Shows relevant content to audience\n",
      "detects person in front and show interesting,eye catching ads\n",
      "Where we can see digital signage...\n",
      "Shopping malls\n",
      "Outdoor\n",
      "Restaurants\n",
      "Supermarkets\n",
      "Clothing-retail\n",
      "Airports\n",
      "Find more details from our github project repository\n",
      "Visit now!\n",
      "Get In Touch!\n",
      "Feel free to visit our github accounts or email us for further details!\n",
      "Viraj Dhanushka\n",
      "Sumudu Lakmali\n",
      "Hans Thisanke\n",
      "smviraj@gmail.com\n",
      "sumuduliyanage888@gmail.com\n",
      "hansthisanke@gmail.com\n",
      "End of page\n",
      "\n",
      "\n",
      "Extracting full body motion tracking system https://cepdnaclk.github.io/e16-3yp-full-body-motion-tracking-system\n",
      "\n",
      "\n",
      "Full Body Motion Tracking System\n",
      "Home\n",
      "Design(current)\n",
      "Deployment\n",
      "Testing\n",
      "Budget\n",
      "Team\n",
      "Game Console\n",
      "The game console is a collection of sensors and wireless modules that can track the motion of arms, legs, and body.\n",
      "The collected data use as input for a multiplayer first-person shooter game.\n",
      "The smartphone is used to display the graphics and play the sound of the game.\n",
      "Motivation\n",
      "People spend more time on online gaming and they do not get enough exercises for their body.\n",
      "In urban places not enough space for exercising.\n",
      "VR gaming devices give solution for both problems.\n",
      "The game console market was valued at 34.27 billion USD in 2019**.\n",
      "The game consoles are influenced by new technologies like VR, AR, and voice recognition.\n",
      "Consumers are increasing continuosly.\n",
      "Related Links\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "Univerity of Peradeniya\n",
      "github\n",
      "© Copyright 2020 Full Body Motion Tracking System\n",
      "\n",
      "\n",
      "Extracting gas level indicator and leakage detector https://cepdnaclk.github.io/e16-3yp-gas-level-indicator-and-leakage-detector\n",
      "\n",
      "\n",
      "GAS MATE\n",
      "University of Peradeniya 3rd year Students Project\n",
      "Goto\n",
      "HOME\n",
      "Description\n",
      "Team\n",
      "SERVICES\n",
      "CONTACT\n",
      "Further\n",
      "Presentation\n",
      "Blog Post\n",
      "GitHub Repo\n",
      "More\n",
      "Gas Level Indicator and Leakage Detector\n",
      "Group 18\n",
      "PROCEED\n",
      "THE REAL LIFE PROBLEM & SOLUTION\n",
      "Gas tank users face difficulties because of not having a precise way to\n",
      "find the remaining gas amount. To over come those problems with some protection. We are introducing gas level indicator and leakage detector.Gas Level Indicator and Leakage Detector is a system aimed on LP gas tank users and distributors, consisting 3 main areas\n",
      "Gas level indicator\n",
      "The device display and the mobile/web application will be updated in real-time, displaying the current existing gas percentage in the tank.\n",
      "A delivery system for gas renewal\n",
      "When a gas tank is finished, the user will be notified and will be asked whether they need delivery of a gas tank or not. According to their selection, a new gas tank will be delivered to the user.\n",
      "Gas leakage detector\n",
      "If a gas leakage happens around the gas tank, a gas sensor will detect the leakage. As soon as the leakage is detected, a buzzer will alarm the user about it while sending a notification to the mobile/web application.\n",
      "Contents\n",
      "01. Solution Overview\n",
      "02. Technologies\n",
      "03. Hardwares Required\n",
      "04. Circuit Diagram\n",
      "05. UI Design\n",
      "06. Container Diagram\n",
      "07. Bill of Materials\n",
      "08. Unit and Integration Testing\n",
      "09. Embeded System Testing\n",
      "10. Unit and Integration Testing Summary Report\n",
      "11. Security Report\n",
      "12. Embeded System Testing\n",
      "13. 3D designs of the Product\n",
      "14. Demonstration\n",
      "15. Team Profiles\n",
      "16. Services\n",
      "17. Contact\n",
      "18. Advisers\n",
      "Solution Overview\n",
      "In order to answer the above mentioned problems. As a solution we are introducing a hardware module able to detect the level of gas amount and interpret to a user using a display. Also for security measures the device have the capability to notify any imminent danger if there is a gas leakage happend.These are the services clients could obtain from the hardware end.\n",
      "Also in order to available data about the tank usage, current amounts and the status of the tank if there is a leakage in device. The user had to reach the hardware always. As a solution for that difficulty using a mobile application will be the optimal solution for the client. Therefore We provide you user friendly mobile application for the ease of usage.\n",
      "In order to connect these mobile application and the hardware module, there is a requirement of a backend server. Therefore cloud based backend server is used because of the neccessity of the current situation. Otherwise using a physical server will be finantailly disadvantagious. The choice over physical server will be discussed further under technology section as well.\n",
      "Technologies\n",
      "As the front end development we use flutter as our front end development software in this development process the expectations are to provide user friendly and interesting interface with enhanced UI and UX experience to the client.Other than that cross platform support is required for us to maintain the target clients by giving them access to our services independant their mobile os type.\n",
      "In the backend server requires to handle a larger amount of requests. Therefore the scalability and sustainability if uncaught error exceptions happend are critical points under choosing a optimum backend server. For those requirements, Node js would be the best solution for this project. Therefore the backend server side requests managements are done by the NodeJs.\n",
      "For storing data puroposes' requirements were the structured schema with the same type of data that have the ability to contain all the details of the target market when the product able to cover the whole market itself. Also the data base should be able to scalable from a smaller database. For these requirements are fulfil when the chosen selection was Mysql. Because the mysql have the ability contain 1000 different tables and all our reqiurements are fulfilled under 1000 tables. Also a table can record 21 million records with the space under 1GB. The maximum row table will be our user table but it will not exceed 21 million because the targeted ordience is less. Overall the total storage space if the project was a success as purposed the overall database will not be exceed 2GB of storage from the web server space.\n",
      "In the deployment it is required to consider the following facts. Those facts are what will be the platform the deployment will be happend. There are two suggestions one is assembling a physical server and the other one is the deploy the project on cloud as well. Due to finantial issues met in the process of developing the physical server of maintaining cost. The team sole decision and the academic guidance as well based on cloud services. Therefore the cloud server deployment was decieded. In that case the EC2 instance of AWS server support is selected. Under that there was free tier eligible service which will be provided 8Gb amount of virtual PC for the establishment of the project.\n",
      "Hardware\n",
      "As see on the image left, ESP86266 module is gonna use as the main controller and the connection establisher of the device. Since building connection between the cloud and the device is a requirement convensional arduino and a wifi module is not a convinient solution. That was the main reason behind selection of the Node MCU module rather using the wifi module with a arduino device.\n",
      "Using a li-ion power supply is for the usage of the battery even there is a power shortage if there is a leackage with a power shortage as a contengency plan. But the device can be maily powered by using a power supply from the location it self the cable requirements are all handled by the device it self.\n",
      "Gas sensor is there for detect any gas releases from the tank to the premises from the tank. For those requirements Using an implimented gas sensor for detecting natural gas is convenient.\n",
      "For making weight measurements for the to the system using a weight sensor with strain gauge technology is making the weight measurements more reliable because this method is sensitive to smaller weights changes also.It is very useful for keeping track of the gas usage.\n",
      "Pieso Buzzer is for when there is an identified threat imminent. For notify the close people to take necessary actions. Before been late and loosing control of an emegency situation. The main emergency the device will notify you if there is a leackage there and a short term notification using the buffer if it is not connected to the main power source and further the device is low on battery.\n",
      "LCD screen is using to graphically interpret the current state of the device such the remaining amount of gas in the device. The user interface for adding a tank and removing tank\n",
      "Circuit Diagram\n",
      "This circuit diagram developed using fritzing. This implementaion is describe how the hardware components are connceted to each other as well. The support for simulating the device quite complex therefore please consider the overall operation of the device may contain bugs. Since all the units of the system when developing should be tested.\n",
      "User Interface\n",
      "The following video shows the current progress on the software mobile application implemented using flutter and basic functions of the application is at an final staged but the user experience and the user interfaces are need to be improved further.\n",
      "Your browser does not support the video tag.\n",
      "Container\n",
      "The data flow overview is displayed as follows.\n",
      "Bill of Materials\n",
      "The bill of materials can be displayed as follows\n",
      "Testing\n",
      "In Testing the following tests are done.\n",
      "Up to the third milestone The testings are done according to the following. Methods of testing. The first testings are done under unit testing. In unit testing, the backend and the front end separate in to smaller units. In this scenario the units were login,sign in, add new device, add new tank such single processes independantly.\n",
      "Following tests are done due to following reasons.\n",
      "Checking multiple users access the same device - Since the devices are only registered per customer. Therefore the access only grants per customer\n",
      "Session Expiration - After Signed in the user initialize a session. once the session time expired the user have to log in again.\n",
      "Session Maintaining - The session time defines here.\n",
      "Check the input device an existing device - In order to function the mobile application the device should be a valid device. Therefore the validation testing is done under this testing.\n",
      "Validation Testing on the front end.\n",
      "Embedded System Testing Plan\n",
      "The Embedded System Testing Plan can be displayed as follows. In this scenario our plan was to test the embedded system according to the given testing plan. In this testing procedure followings are tested.\n",
      "Firmware Testing\n",
      "There may be containg erronous values in the firm ware may harms the itself. Also avoiding overflows, detect and avoid typos is required before uploading the codes in to the flashes.\n",
      "Board bring up related testing.\n",
      "In board testing we were looking at the soldering issues. Power failures due to loss of connection issues in linking each components to each other. Checking section by section in the hardware designs. Each node may not containing any communication to other nodes. Check weather where the overheated surfaces may occure while soldering.\n",
      "Sensor indicating and hardware protocol testing.\n",
      "Ensure the identified any malfunctioned components. Ensure the protocol functionality.\n",
      "Pressure Testing\n",
      "Hardware Structure stability are tested in this. And Find the rigidness of the failures.\n",
      "Hardware Designs\n",
      "Complete User Interface Design\n",
      "Inside View of the User Interface design\n",
      "Final View of the product with the gas Tank\n",
      "Caster Wheel Design\n",
      "Interior design of the product including weight sensor and other components\n",
      "Demonstration Plan\n",
      "Mobile Application Demonstration video Link\n",
      "Your browser does not support the video tag.\n",
      "Final Mobile and Hardware Demonstration video Link\n",
      "Your browser does not support the video tag.\n",
      "Hardware Demonstration videos Link\n",
      "OUR TEAM PROFILE\n",
      "Sudam Kalpage\n",
      "Thilini Deshika\n",
      "Hashan Eranga\n",
      "Services\n",
      "Supportive Mobile Application\n",
      "A mobile application that shows the current gas level and\n",
      "detect any leakages.\n",
      "Built in Level Detector on the hardware\n",
      "The current gas level will appear in the hardware\n",
      "Notify any gas leakage quickly\n",
      "If there is any leakage buzzer in the device as well as a notification will notify the owner\n",
      "Easily Refilling Plans\n",
      "You will be connected to any Gas suppling company instantly.\n",
      "Contact\n",
      "Sudam Kalpage\n",
      "Thilini Deshika\n",
      "Hashan Eranga\n",
      "Advisers\n",
      "Dr.Isuru Nawinne\n",
      "Dr. Ziyanm Marikkar\n",
      "\n",
      "\n",
      "Extracting obstacle bots for swarm robots https://cepdnaclk.github.io/e16-3yp-obstacle-bots-for-swarm-robots\n",
      "\n",
      "\n",
      "Swarm Robotics Platform | e16-3yp-obstacle-bots-for-swarm-robots\n",
      "e16-3yp-obstacle-bots-for-swarm-robots\n",
      "Swarm Robotics Platform\n",
      "Team\n",
      "Members\n",
      "Thushara K A R\n",
      ":: E/16/369 :: e16369@eng.pdn.ac.lk\n",
      "Thilakarathna D M D U\n",
      ":: E/16/366 :: e16366@eng.pdn.ac.lk\n",
      "Dissanayake D M T H\n",
      ":: E/16/088 :: e16088@eng.pdn.ac.lk\n",
      "Supervisor\n",
      "Dr. Isuru Navinna\n",
      "Mr. Ziyan Marikkar\n",
      "Prof. Roshan Ragel\n",
      "Dr. Upul Jayasinghe\n",
      "Related links\n",
      "Faculty website\n",
      "Department website\n",
      "Web Application Home Page\n",
      "Swarm Dash Board\n",
      "Git Hub Repository\n",
      "Design Manual\n",
      "User Manual\n",
      "TABLE OF CONTENT\n",
      "OVERVIEW\n",
      "GOALS\n",
      "SPECIFICATIONS\n",
      "SOLUTION ARCHITECTURE\n",
      "HARDWARE\n",
      "WEB INTERFACE\n",
      "ALGORITHM\n",
      "TESTING\n",
      "BUDGET\n",
      "OVERVIEW\n",
      "In swarm robotics the major barrier is that the researchers have to do a lot of hardware implementation prior to their projects. In this particular project we are going to come up with obstacle bots for a swarm robotic arena which is a part of a swarm robots platform project which eventually solves the above mentioned problem.\n",
      "GOALS\n",
      "Automated obstacle bots monitored by an overhead camera setup.\n",
      "Bots can move to the desired positions with a user friendly interface.\n",
      "SPECIFICATIONS\n",
      "Obstacle robot swarm is capable of moving every individual obstacle robot to their own destination with the consideration of\n",
      "collision\n",
      "avoidance.\n",
      "With the help of collision avoidance algorithms, obstacle robots can be placed in certain positions which allows the researcher to make\n",
      "various obstacle shapes on the arena made out of obstacle robot combinations .\n",
      "Obstacles can be programmed to be static or dynamic. Dynamic obstacles can model scenarios that have a motion in the obstacle.\n",
      "Each robot has its own radio module\n",
      "which uses a 433Mhz radio band. These modules can be used to communicate with the base station.\n",
      "Each robot has two independent wheels that can perform forward, backward and turning operations. With the help of inbuilt gyroscope robots can perform accurate turning operations.\n",
      "SOLUTION ARCHITECTURE\n",
      "HARDWARE\n",
      "REAL HARDWARE\n",
      "3D MODEL\n",
      "3D MODEL DEMO VIDEO\n",
      "SAFTY MEASURES\n",
      "PCB DESIGN\n",
      "PCB DEMO VIDEO\n",
      "WEB INTERFACE\n",
      "#### Web Interface\n",
      "WEB INTERFACE DEMO VIDEO\n",
      "#### 3D Interface\n",
      "3D INTERFACE DEMO VIDEO\n",
      "#### Platform PC Operator GUI\n",
      "3D INTERFACE DEMO VIDEO\n",
      "ALGORITHM\n",
      "TESTING\n",
      "#### Algorithm Deployment\n",
      "Algorithm Deployment Video\n",
      "#### Web Interface Authentication And Authorization Testing\n",
      "Web Interface Testing Video\n",
      "#### Hardware Testing\n",
      "Hardware Testing Video\n",
      "BUDGET\n",
      "FUNDING\n",
      "This project was funded by the Prof. Suhada Jayasuriya Project Support Fund through .\n",
      "FINAL DEMO VIDEO\n",
      "Final Demo Video\n",
      "FUTURE IMPROVEMENT\n",
      "We plan to run all the algorithms first and then send the data to the robots.\n",
      "We have to further tune the parameters\n",
      "to get a smooth process.\n",
      "\n",
      "\n",
      "Extracting qurantine tracker https://cepdnaclk.github.io/e16-3yp-qurantine-tracker\n",
      "\n",
      "\n",
      "Qurantine Tracker\n",
      "Quarantine Tracker\n",
      "A third year students project University of Peradeniya\n",
      "Home\n",
      "Team\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Designs\n",
      "Testing\n",
      "Budget\n",
      "Conclusion\n",
      "Team Details\n",
      "Team Members :\n",
      "Nimashi Uthpala\n",
      "E/16/039 e16039@eng.pd.ac.lk\n",
      "Sachini Dissanayaka\n",
      "E/16/087 e16087@eng.pd.ac.lk\n",
      "Tharushi Suwaris\n",
      "E/16/364 e16364@eng.pd.ac.lk\n",
      "Advisors :\n",
      "Dr. Isuru Nawinna\n",
      "Dr. Zian Maraikkar\n",
      "Department of Computer Enginnering\n",
      "Faculty of Enginnering\n",
      "University of Peradeniya\n",
      "Introduction\n",
      "Backgound\n",
      "The COVID19 pandemic, also known as the coronavirus pandemic, is an ongoing global pandemic of coronavirus disease 2019 (COVID19), caused by severe acute respiratory syndrome coronavirus 2 (SARSCoV2). The outbreak was first identified in December 2019 in Wuhan, China. The World Health Organization declared the outbreak a Public Health Emergency of International Concern on 30th January 2020 and a pandemic on 11th March. The first case of the virus was confirmed in Sri Lanka on 27th January 2020, after a 44-year-old Chinese woman from Hubei Province in China was admitted to the National Institute of Infection Diseases.\n",
      "As of 16 August 2020, 2,890 confirmed cases have been reported in the country with 11 deaths. On 3rd March 2020, the first reported case involving a Sri Lankan origin outside Sri Lanka was reported in Italy. As of 23 March, forty-five quarantine centers have been built in the country by the Sri Lanka Army as a preventive measure to tackle the coronavirus pandemic. Nearly 3,500 people have been under quarantine in 45 quarantine centers which also include 31 foreigners from 14 countries.\n",
      "As of 25 March 2020, Sri Lankan authorities have tracked down over 14,000 people who had contacted the identified patients and had ordered self-quarantine for such people.\n",
      "Motivation\n",
      "When putting a person under self-quarantine, medical officers and the police will come to the house where that person lives and advise that person not to go out. Even though the person under self-quarantine is advised not to go out the medical officers cannot be guaranteed that the person will not go out because they do not have a proper method to monitor the people under self-quarantine. If people under self-quarantine do not obey the rules and go out of the home and interact with other people, there will be a risk of exposing other people to the virus if those self-quarantined people are infected\n",
      "Real world Apllication of the Quarantine Tracking Device\n",
      "The device is designed to be used by the medical authorities to track if the person who is under quarantine (wearing the device) is breaking the law and also to track his/her health; to check if he/she would implementing the symptops of the illness\n",
      "using thier smart phone and reduce the spreading of the virus as much as possible.\n",
      "Solution Architecture\n",
      "As a solution we present a band which is wearable by the person who are unde quarantine such that the corresponding data such as body temperaure, the movements of the person and the location\n",
      "will be gathered and send to the mobile app which is used by the medical authority. so they can track and moniter the person keeping their distance and as well as improve the quality of their job.\n",
      "Features of the device\n",
      "Location tracking\n",
      "Can set a virtual fence\n",
      "Detect and monitor the body temperature\n",
      "Unauthorized removal notifications\n",
      "Low battery notification\n",
      "Hardware And Software Designs\n",
      "Hardware Design\n",
      "Components\n",
      "Node MCU 12e module\n",
      "ublox NEO-6M GPS md0153 Module\n",
      "LM 35 temperature module\n",
      "MAX30100 Pulse Oximeter and Heart-Rate Sensor\n",
      "NiMH rechargeable batteries\n",
      "3V mini buzzer\n",
      "LEDs\n",
      "Power Requirement\n",
      "The node mcu works with 3.3 v so we supply power of 7.4v(power supply) from the betteries to the Vin pin of the node mcu.\n",
      "since the node mcu has an in built voltage regulator we can supply a voltage range of 7-12Vs to Vin\n",
      "Circuit Diagram\n",
      "PCB Design\n",
      "Product view\n",
      "Product Dimension : 59x65x20 mm (WxLxH)\n",
      "Software Design\n",
      "Mobile Application And Website\n",
      "User Interfaces of Website\n",
      "Technology front end : HTML,CSS,Javascript\n",
      "Technology back end : Nodejs\n",
      "User Interfaces of Mobile app\n",
      "Technology : React Native\n",
      "Additional Libraries : React NAtive Vector icons, Animated API, Custom Fonts from Google fonts\n",
      "For navigation: React navigation library\n",
      "Stack navigation: For login and signup screens\n",
      "Drawer navigation : All the other screens\n",
      "For better user experience two kinds of navigations have been used to navigate though the different tabs of the mobile app.\n",
      "Data Handling\n",
      "Database\n",
      "Technology : MongoDB\n",
      "Testing\n",
      "Data validation testing and UI testing is done in frontend of the website in manual basd procedure.\n",
      "User is only allowed to enter data within the given restrictions. They are all indicated to the user when they use\n",
      "the website.\n",
      "In validation of data, the limitations are as follows:\n",
      "All kinds of Names, ID numbers only should be 25 of character length in maximum.\n",
      "One line an address can be 30 in character length maximally.\n",
      "Contact number should be exactly 10 characters long\n",
      "Password should be more than 8 characters\n",
      "These values were selected based on the database configuration in Backend, making sure the intergrity of data.\n",
      "In frontend it is tested that the user enters the data as expected and do not allowed to proceed through otherwise.\n",
      "During the tests, nearly 5 test cases were used t ckeck in individual case.\n",
      "The summery of the tests conducted as follows :\n",
      "UI testing were conducted testing performance of the website, mainly checked whether the buttons of the pages are working properly and also the links are directed as they are supposed to be.\n",
      "Budget\n",
      "Component\n",
      "Price (LKR)\n",
      "Supplier\n",
      "NodeMCU\n",
      "665\n",
      "SKYTRONIKS(PVT)LTD\n",
      "Neo 6m GSP Module\n",
      "1350\n",
      "SKYTRONIKS(PVT)LTD\n",
      "LM 35 temperatuer sensor\n",
      "110\n",
      "SKYTRONIKS(PVT)LTD\n",
      "MAX 30100 pulse rate sensor\n",
      "450\n",
      "SKYTRONIKS(PVT)LTD\n",
      "3V mini buzzer\n",
      "20\n",
      "SKYTRONIKS(PVT)LTD\n",
      "TOTAL\n",
      "3535\n",
      "Conclusion\n",
      "Github repo link\n",
      "\n",
      "\n",
      "Extracting smart door lock https://cepdnaclk.github.io/e16-3yp-smart-door-lock\n",
      "\n",
      "\n",
      "SmartDoorLock - Responsive HTML5 Template\n",
      "Toggle navigation\n",
      "Home\n",
      "About\n",
      "Solution Architecture\n",
      "Hardware\n",
      "Software\n",
      "Testing\n",
      "User Experience\n",
      "Budget\n",
      "Contact\n",
      "SmartDoor Lock\n",
      "A project of third year students developing a Smart door lock for the entrance\n",
      "All Features\n",
      "View Plans\n",
      "Problems at the entrance\n",
      "People who use doors for the entrances face different types of problems when entering. The security level, accuracy and efficiency of the current lock system at the entrance are some major causes for the user problems.\n",
      "Therefore by this project we are developing a smart door lock including the following main features.\n",
      "Face Recognition\n",
      "Finger Print detection\n",
      "RFID card reader\n",
      "-In addition to them following features will be included in the smart door lock.\n",
      "- Unlock record of the current user at the door\n",
      "- Information display of the current user\n",
      "- Allowing only one person to enter at a time\n",
      "- Web Application to control access\n",
      "- Access at night only for specified persons\n",
      "Solution Architecture\n",
      "user data can be taken from the Finger print sensor, RFID card module and camera module.Those data can be compared with the data stored in the firebase realtime database.\n",
      "Hardware components communicate with the firebase database using get and post requests of HTTP protocol. Realtime database is connected with the web application and read\n",
      "and write data from it. Firebase Hosting services are used for cloud deployment of the web site.\n",
      "Product Overview\n",
      "Acoording to the diagram camera is placed in the height of an average\n",
      "person for the handiness of the door lock. IR sensors are kept at a corner of the door to captue the object(person) efectively.\n",
      "Other two modules, Fingerprint sensor and RFID reader are placed near the lcd display . So that while enterring the credintails\n",
      "use can read the lcd display information easily.\n",
      "Hardware design\n",
      "1 / 3\n",
      "Circuit Daiagram\n",
      "2 / 3\n",
      "Full Pcb Design\n",
      "3 / 3\n",
      "❮\n",
      "❯\n",
      "Main Hardware components\n",
      "Raspberry Pi 3 Model B\n",
      "As we are doing Face recognition we have choosen Raspberry Pi module becuase it\n",
      "has 1GB RAM to process and Micro SD port for loading operating system and storing data.\n",
      "Also python libraries like OpenCV can use with it.\n",
      "There is a CSI camera port in the module for connecting a Raspberry Pi camera.\n",
      "Raspberry Pi Camera Module\n",
      "Finger Print Sensor\n",
      "RFID module\n",
      "LCD display\n",
      "3D Model of the product\n",
      "1 / 6 --Try different views by clicking below\n",
      "2 / 6 --Try different views by clicking below\n",
      "3 / 6 --Try different views by clicking below\n",
      "4 / 6 --Try different views by clicking below\n",
      "5 / 6 --Try different views by clicking below\n",
      "6 / 6 --Try different views by clicking below\n",
      "❮\n",
      "❯\n",
      "Software Implementation\n",
      "Web Application\n",
      "Web appliaction is designed to control access to the system. In our web application there are three types of administrator roles.They are,\n",
      "- To monitor database\n",
      "- To add/update/delete personal data through web application\n",
      "- To view all door users' access history, admin sign in history to the web site and notifications about unauthorized access\n",
      "Speciality of this roles is that, each of these administrators able to handle only the given role. It makes the web application more secure. Moreover, Only these persons can login to the web applcation.\n",
      "For the authentication purpose we have added 2 factor authentication.\n",
      "- By using email and password\n",
      "- Send OTP to predeteremined mobile phone number.\n",
      "FrontEnd technology\n",
      "ReactJs has been used for the implementation of the web application.\n",
      "Why ReactJs ?\n",
      "Create components\n",
      "virtual DOM and server side rendering\n",
      "BackEnd technology and cloud deployment\n",
      "Firebase realtime database, which is a NOSQL database has been used as the database.\n",
      "Why Firebase ?\n",
      "Reliability\n",
      "Reliable data tranfer in firebase allow to frequent state syncing and low latency in data transfer\n",
      "Realtime data transfer is important as hardware components needs data from firebase\n",
      "to allow the access. Also in an entering, it helps to monitor the door access records through web application in\n",
      "real time\n",
      "Scalability\n",
      "Due to the high\n",
      "performance and scalability of firebase, when there is any data change, Firebase helps in the calculation of the\n",
      "minimum set of updates needed to keep all the clients synchronized.\n",
      "Data can be synchronized in real time eventhough there are multiple doors.\n",
      "Multiple users can use the web Application (concurrent connections )\n",
      "Authentication\n",
      "With the use of Firebase auth services,two\n",
      "factor authentication has been used for the web application.\n",
      "firebase Email and password authentication\n",
      "firebase phone authentication\n",
      "UI designs\n",
      "Visit our web application\n",
      "UI designs\n",
      "Software Testing\n",
      "Firebase Security Rules\n",
      "The Firebase Local Emulator Suite consists of individual service emulators built to accurately mimic the behavior of Firebase services.It enables app to directly connect to these emulators to perform integration testing.Through this we checked whom can access to the data as we set security rules to deny permission for unauthorized access.\n",
      "Check UsedID validity\n",
      "Always the\n",
      "IDs stored in the database are compared with the ID which is taken by the hardware. So it is important confirm that that process is correctly processing if not the unlocking records will be inacurrate.\n",
      "Data encryption and Decryption function testing\n",
      "In the database, userID of each employee and the security status of a Admin is considered as most sensitive data stored in the database as userID is directly connected with hardware components which gives the access to the doors and admin privilages are depend on the security status of a admin. So these data is stored in the database after encryption. We have implemented AES encryption decryption functions.\n",
      "All the hardware configurations are planned to do in python language and Reactjs is used for implementation of web Application.So tests are done to verify that both python and JavaScript functions give the same result in encryption and decryption process.\n",
      "Test 5 - Time taken for encryption and decryption\n",
      "Data encryption and decryption may cause the delays in the reliable data transfer to the frontend and hardware components. So we have checked the time taken for that. Actualy\n",
      "it takes few microseconds. So the effect of delay can be negligible. Following values may slightly change according to the data we use\n",
      "- for encyption = 0:00:00.000782\n",
      "- for decryption = 0:00:00.000019\n",
      "Click here to know more details about software testing >>>>\n",
      "Hardware Testing Plan\n",
      "01.\n",
      "Check each unit separately\n",
      "Fingerprint sensor\n",
      "- Ability to scan a fingerprint\n",
      "- Validate the fingerprint accuracy - Test after updating new fingerprints\n",
      "- Test with valid user when,\n",
      "Finger is dipped with water\n",
      "Finger is dipped with any color\n",
      "Sketch mark is on finger\n",
      "Finger is covered with transparent gloves\n",
      "Different angle of the finger is used\n",
      "Rfid card reader\n",
      "- Test the environment in which the tag is being\n",
      "read (need to check whether this is being too vulnerable to environment factors)\n",
      "- Test different orientations of the tag\n",
      "Face recognition\n",
      "- Test the three important stages of face recognition process\n",
      "I.\tFace detection\n",
      "Using different lighting conditions\n",
      "Using different times of day\n",
      "II.\tFace capture\n",
      "III.\tFace match\n",
      "Using different lighting conditions\n",
      "Using different times of day\n",
      "Using different moods and emotional states\n",
      "IR sensors\n",
      "- How the sensors can be detected (Can use a small circuit of led blinking)\n",
      "- Test if two people get detected and check that message goes to buzzer\n",
      "02.\n",
      "Check whole combined unit\n",
      "- After updating new user details check how the entire system works\n",
      "- Power Supply\n",
      "- Check the connectivity of whole system ( Using blinking an led or oscilloscope and logic probes)\n",
      "Performance Testing\n",
      "A. \tTest the performance of each unit and whole system for allowing a valid user\n",
      "the time taken by the each unit and whole system to allow the\n",
      "B. \tTest the performance of each unit and whole system for not allowing an invalid user\n",
      "the time taken by the each unit and whole system to identify an invalid user\n",
      "C. \tTest the time of the entry of the user is recorded to the system after been authorized\n",
      "How to use our product\n",
      "As we mentioned in the introduction there are several reasons\n",
      "to prove that tradition door\n",
      "lock systems at the entrance are inefficient. But in this product we have overcome all those problems and give a\n",
      "quick access to the door user while providnig important addtional services such as take access\n",
      "records and giving realtime update about the access using a lcd display\n",
      "Register Users\n",
      "In order to register an user,\n",
      "administrator should fill the form provided in the website\n",
      "with uniquely provided userid. Here, the corresponding userid is registered for one specific person.\n",
      "Access Given\n",
      "First contact the RFID card/tag to the RFID reader. Then place the finger on the fingerprint sensor and look at\n",
      "the camera to capture a photo of the user.\n",
      "Then the access will be granted if all there steps are correctly passed by that person. LCD display will\n",
      "display the information whether access has been given or not. All the accesses will be recorded on the website.\n",
      "Identify Unauthorized Aceess\n",
      "If any unauthorized access is detected i.e. using an unregistered card/tag or trying to access more than one person\n",
      "into the room using one card/tag, access will not be granted and the buzzer will make a loud sound. LCD display\n",
      "will display the information whether access has been given or not. These accesses will be recorded on the website.\n",
      "Demostration of user experience of admin\n",
      "who can view history of the access to the door and the web site\n",
      "Click here to get the user manual >>>>\n",
      "Advising Lecturers\n",
      "Dr.Isuru Nawinne\n",
      "Dr.Ziyan Maraikar\n",
      "Links\n",
      "Visit our github repository\n",
      "Visit our web app\n",
      "University of Peradeniya\n",
      "Faculty of Engineering\n",
      "Department of Computer Engineering\n",
      "Project Contributors\n",
      "Name\n",
      "Virajani Dharmathilaka\n",
      "Tharushini Jayathilaka\n",
      "Chanika Madushanki\n",
      "Contact Details\n",
      "virajanidharmathilaka@gmail.com\n",
      "tharushinithiwanka@gmail.com\n",
      "cmkariyawasam10@gmail.com\n",
      "End of page\n",
      "\n",
      "\n",
      "Extracting smart infared shooting sport https://cepdnaclk.github.io/e16-3yp-smart-infared-shooting-sport\n",
      "\n",
      "\n",
      "e16-3yp-smart-infared-shooting-sport | The purpose of this project was to design, build, and test an infrared shooting sport from the ground up to shoot farther in low cost and most importantly make it smart and updatable\n",
      "e16-3yp-smart-infared-shooting-sport\n",
      "Team\n",
      "Group Members\n",
      "E/16/320 e16329@eng.pdn.ac.lk\n",
      "E/16/319 e16319@eng.pdn.ac.lk\n",
      "E/16/126 e16126@eng.pdn.ac.lk\n",
      "Supervisor\n",
      "* Dr. Isuru Navinna\n",
      "* Mr. Ziyan Marikkar\n",
      "* Prof. Roshan Ragel\n",
      "* Dr. Upul Jayasinghe\n",
      "Related links\n",
      "* Faculty website\n",
      "* Department website\n",
      "### IMAGE\n",
      "## TABLE OF CONTENT\n",
      "OVERVIEW\n",
      "GOALS\n",
      "SPECIFICATIONS\n",
      "SOLUTION ARCHITECTURE\n",
      "HARDWARE\n",
      "MOBILE APP.\n",
      "BACKEND\n",
      "TESTING\n",
      "BUDGET\n",
      "OVERVIEW\n",
      "X-tag is a Smart IR shooting sport.In currrent related product are,\n",
      "very expensive\n",
      "Companies with large indoor environments charge up to $10 for a single game.\n",
      "Not enough game modes/options.\n",
      "Not smart enough.\n",
      "Not updatable\n",
      "Therefore In this Project we build a tag system with a central server and a mobile application.In that manner we were able to\n",
      "Create a updatable ,smart IR tag system.Also the cost of our system will be very lower compare to current products in the market.\n",
      "GOALS\n",
      "Shoot father up to 100ft\n",
      "And make cheaper to produce\n",
      "And most importantly we want to make our system smart.\n",
      "SPECIFICATIONS\n",
      "There are mainly 3 parts in this project .Xtag gun and the headband to shoot and receive IR,Xtag mobile application to\n",
      "Choose game modes,initialize the game and a firebase server for communicate with in the game .\n",
      "Every gun has a cababilty of shooting more than 30m and many features like LCD screen,LED lights,vibration motors.\n",
      "The headband is connected to gun with a wired connection and it receive the IR signals shoots by other players.\n",
      "Also Headband has 3 LEDs to indiacate the Team colour and Another LED to blink when get shotted.Those IR receivers and LEDs are locate in every\n",
      "4 sides in the gun.\n",
      "Inizialize the gun before the match,selecting the team,battle mode are done with the help of the Xtag mobile application.Gun is connecting to the mobile using Bluetooth.\n",
      "Finding the shooter,giving scores,join to a battle are done with the help of the firebase server by connecting to it through the Xtag mobile application.\n",
      "Thanks to our system artchtecture this system is updatable(Can be added more modes more option without changing the hardware) and a smart one.\n",
      "SOLUTION ARTCHTECTURE\n",
      "Every player has a head to reserve IR shots and IR gun to shoot IR.\n",
      "when the platyer shoots he shoot with some data.They are,\n",
      "Team ID\n",
      "Damage\n",
      "Player ID\n",
      "Every players gun is connected to the mobile application through blutooth.\n",
      "Every phonr is connected to the our server.\n",
      "Using mobile application,\n",
      "gun is initilized.\n",
      "game mode is selected\n",
      "Server is used to,\n",
      "comunicate with the gamne.\n",
      "As a example Find who is the shooter and ,giving scores are done with the help of\n",
      "the backend.\n",
      "HARDWARE\n",
      "IR emitter\n",
      "This is the heart of the this project and it is very challenging when we use IR communication for this kind of\n",
      "purpose\n",
      "To shoot further we Planned used high power IR\n",
      "IR emitter - TSUS5202\n",
      "power=\n",
      "170mW , 150mA\n",
      "Since esp32 cant give 100 mA for the transistor is used\n",
      "BD139\n",
      "and a lens is used to focus\n",
      "Diameter about\n",
      "-\n",
      "38mm (1.5″)\n",
      "IR receiver\n",
      "* SM0038 - TSOP1738 - 38KHz IR receiver\n",
      "* This Moduile has built in\n",
      "*\n",
      "signal amplifier\n",
      "*\n",
      "2.5 V to 5.5 V\n",
      "LCD screen 16x2 with I2C module\n",
      "* standard HD44780\n",
      "* 5V\n",
      "sunder\n",
      "* Buzzer Piezo Bleeper Sounder\n",
      "* Frequency 4kHz\n",
      "* power - 10mA\n",
      "vibration motor\n",
      "* 10000RPM Metal Brush\n",
      "* DC 3.7V 5V\n",
      "135mA-180mA\n",
      "And also push button and RGB LED are used.\n",
      "IR circuit\n",
      "IR lens\n",
      "IR Receiver\n",
      "SM0038 - TSOP1738 IR Receiver\n",
      "3 pin\n",
      "38KHz\n",
      "-40 to +80C\n",
      "2.5 V to 5.5 V\n",
      "binary (data)\n",
      "CONTROLLER PLATFORMS\n",
      "NodeMCU esp32 duel core microtroller\n",
      "IR Library\n",
      "* Currently it is NEC IR protocol\n",
      "* 38 KHz\n",
      "* 8\n",
      "bit is used\n",
      "![](/e16-3yp-smart-infared-shooting-sport/images/irshot.png)\n",
      "implementation\n",
      "Design seperated into several parts for the ease of 3D printing\n",
      "Fabrication circuit\n",
      "Used small circuits that are connected to the main circuit for\n",
      "Switch buttons\n",
      "LEDs\n",
      "Vibrator motor\n",
      "IR emitter\n",
      "Buzzer\n",
      "Connections are done according to the NODE MCU esp32 datasheet\n",
      "BACKEND\n",
      "Access and authentication\n",
      "Using Email and a password players can register Xtag\n",
      "Players have to verify their\n",
      "Email before signed in\n",
      "More detail will be on testing report\n",
      "* It is ideal for our Xtag mobile app.\n",
      "* Cloud deployment -Firestore\n",
      "* database helps to store real-time and synchronize game data.\n",
      "* Firebase authentication library is used for authentication\n",
      "Storage\n",
      "Cloud Firestore\n",
      "Fast performance, high availability, and security\n",
      "Database\n",
      "Two main collections are used to store Player data and Match data.\n",
      "Player collection will store records as documents according to the Used ID.\n",
      "Match collection will store records as documents according to the Match ID.\n",
      "Players’ details of each match will be stored as a sub collection inside the relevent match document.\n",
      "Reasons behind the database\n",
      "When do a query search in a match, It will be efficient\n",
      "When player want see his paset, it will be efficient\n",
      "We can increase the efficiency of the system by deleting\n",
      "old match data.\n",
      "There Are Some data in the match,which are useless later\n",
      "Ex: isready,rescue code\n",
      "MOBILE APP.\n",
      "Main Functionalities\n",
      "How to refresh the screen when players are connected\n",
      "* Streams are used\n",
      "Syncing the game time counter\n",
      "How to set a tempid\n",
      "How to give a score to the shooter\n",
      "* Query searching is done by the killed player\n",
      "User Interface - Mobile Application\n",
      "Develop using Futter 1.17\n",
      "Home page\n",
      "User Profile\n",
      "SignIn and SignUp pages\n",
      "<width=\"100\"/>\n",
      "Connect gun and go to battle\n",
      "Create or join a battle\n",
      "TESTING\n",
      "Xtag application testing\n",
      "Authentication test (Integrated\n",
      "security test)\n",
      "Network compatibility testing\n",
      "Data Mapping testing\n",
      "Stored Procedures(Black box testing)\n",
      "Device compatibility testing\n",
      "software testing sumarry : https://docs.google.com/document/d/15QQ1ZPAIXyWhq7m–7BOh9n0jbu_8oZKydKhLDy0Gqo/edit?usp=sharing\n",
      "software testing report : https://docs.google.com/document/d/1bhaTQPnoYpXo6yQ9MJRpFDIS963kJpqcUUipNbIv-IE/edit?usp=sharing\n",
      "Embedded system testing\n",
      "Design level testing -\n",
      "to find best IR collecting method\n",
      "Unit tests\n",
      "Blutooth communication\n",
      "IR communication\n",
      "Physical test\n",
      "Fire range\n",
      "fire accuracy\n",
      "HArdware testing sumarry : https://docs.google.com/document/d/1yRsRNFsx3cfH2Z9USqZvHvry2KBjpZQ3aWNl-_fgJvw/edit?usp=sharing\n",
      "HArdware testing report : https://docs.google.com/document/d/1XJSeqUBuJQFIUvLsx5cCLyxi5nqX5FbRWItxmr5zCmQ/edit?usp=sharing\n",
      "BUDGET\n",
      "Demonstration\n",
      "The demonstration video :\n",
      "go to video\n",
      "\n",
      "\n",
      "Extracting smart meeting automaton https://cepdnaclk.github.io/e16-3yp-smart-meeting-automaton\n",
      "\n",
      "\n",
      "Smart Meeting Automaton\n",
      "Unified Project\n",
      "Menu\n",
      "About\n",
      "Overview\n",
      "Solution\n",
      "Design/Progress\n",
      "Budget\n",
      "Contacts\n",
      "SMART\n",
      "MEETING\n",
      "AUTOMATON\n",
      "Find More\n",
      "Solution for a Problem\n",
      "We have seen some meeting rooms with working AC machines and projectors unnecessarily without anyone in the room, causing a wastage of current. In some cases, it is quite different that the AC machines are not working even almost all the room is filled.\n",
      "Other than that, presence of a worker to the meeting venue at the time of meeting, is essential to control different devices of AC machines and projectors. This control process is sometimes complex as it has to be used various remote controllers to control different devices.\n",
      "Our solution \"SMART MEETING AUTOMATON\" resolves almost all the things addressed here.\n",
      "System Overview\n",
      "SMART MEETING AUTOMATON consists of two major streams.\n",
      "Client Application\n",
      "Control Unit\n",
      "These two streams are connected via AWS cloud.\n",
      "Solution Architecture\n",
      "Role of Main Control Unit\n",
      "Local server on Raspberry Pi is updated automatically for every 10 minutes according to data on remote AWS server.\n",
      "In case of Wi-Fi is disconnected, the Raspberry Pi storage can manage the operations.\n",
      "Based on direction data of AC machines, projectors, server motors rotates.\n",
      "Role of Extending Unit (Optional)\n",
      "Receive signals from Main Control Unit as Wi-Fi signals.\n",
      "Give signals to AC machines, projectors as IR signals.\n",
      "Entity Relationship Diagram\n",
      "System has administrator persons\n",
      "Administrators create accounts for users(Lecturers/meeting owners)\n",
      "Administrators reserves lecture rooms/meeting rooms\n",
      "Admins figure out how to control devices in meeting room/lecture room\n",
      "Devices within meeting rooms automatically operates according to schedules\n",
      "Users can also control devices within the meeting room.(Via mobile app)\n",
      "Front-end Software\n",
      "Design Architecture\n",
      "React\n",
      "Dynamic content\n",
      "React Hooks\n",
      "AXIOS\n",
      "Communication with the backend\n",
      "Context API\n",
      "State management\n",
      "Mobile Application\n",
      "Back-end Software\n",
      "Node.js Express\n",
      "Can build scalable, fast and non-blocking I-O backend server\n",
      "MongoDB Atlas\n",
      "Automatically scale increase cluster storage with the growth of data\n",
      "Storage can be maximized with auto-scaling features\n",
      "Security\n",
      "Password hashing\n",
      "Json Web Tokens(JWT) for user authorization\n",
      "Authenticated local strategy using email and password\n",
      "Authorization using JWT strategy to protect end points\n",
      "Access tokens and refresh tokens for user identification\n",
      "Data validation before sending them to database\n",
      "Software Testing\n",
      "Summary Report\n",
      "Area of testing\n",
      "What was tested\n",
      "How was the test done ?\n",
      "Purpose\n",
      "Expected Results\n",
      "Findings\n",
      "Server\n",
      "Login to the system\n",
      "User needs to give correct username and password\n",
      "Admin and user have separate authorization methods. So some route need to admin login it will check by The API (User or Admin that are logged in)\n",
      "Token is given, if user logged successfully\n",
      "Otherwise, anyone can not access the services of the system\n",
      "Token is valid for 30 minutes. If a person knows this token within that time, he can access the system. (except for critical operations)\n",
      "Server\n",
      "Adding user to system and verify\n",
      "User need to register for the system\n",
      "Need freshly logging of admin\n",
      "User needs the verification link that comes to email\n",
      "After successfully adding, user needs to login again\n",
      "User can be added to the system with an email verifification and only admin can add user\n",
      "On success : When admin adds a user to the system, verification email is sent\n",
      "New user can only login the system via that verification link\n",
      "User is uniquely identified by the email\n",
      "User is validated whether he has provided an correct email\n",
      "Server\n",
      "Adding room\n",
      "Delete room\n",
      "Delete user\n",
      "Need admin fresh login (It expires within 5 mins)\n",
      "These operations are allowed only for admin to avoid misbehaviours of the system\n",
      "On success : Status code - 200\n",
      "Failed operations : Status code - 401\n",
      "Admin should verify his login with his password each time when he does these operations\n",
      "Unit tests to verify outputs over inputs\n",
      "Embedded Systems Testing\n",
      "What to test ?\n",
      "Why is it important ?\n",
      "How will it be tested?\n",
      "Admin can add a meeting rooms to the system.\n",
      "When a control unit is established, he can add that meeting room to the system with devices giving all configuration data.\n",
      "Checking whether configuration data is properly reached to the database and relevant hardware nodes.\n",
      "Admin and users can add meeting schedules to the system\n",
      "The devices within a meeting room work according to the given schedules.\n",
      "Checking whether the projectors or ACs working properly according to schedules.\n",
      "Devices work properly with the configured data given by system admins\n",
      "The devices within a meeting room work according to the given config data.\n",
      "Checking whether the projectors or ACs can work properly.\n",
      "Hardware Designs\n",
      "Main control unit consists of two major parts.\n",
      "Base Part\n",
      "It mainly consists of Raspberry Pi\n",
      "Other components are LCD display, relay module, sockets to connect bulbs\n",
      "Upper Cover Part\n",
      "It has few sockets to connect IR transmittors\n",
      "So that IR transmittors can be directed exactly towards the projector or AC\n",
      "Extending Unit (Optional)\n",
      "Base Part\n",
      "It mainly consists of NodeMCU unit\n",
      "It forwards the signals comming from main control unit to projectors or ACs\n",
      "So that, we can give control signals for the devices, that can not be reached be main control unit\n",
      "Circuit Designs\n",
      "Schematic Designs\n",
      "PCB Designs\n",
      "Cloud Deployment\n",
      "Budget Report\n",
      "Find more details from our github project repository\n",
      "Visit Now\n",
      "Team Members\n",
      "Visit Our github Accounts\n",
      "Chamath Amarasinghe\n",
      "Diwanga Amasith\n",
      "Wishwa Madusanka\n",
      "Email\n",
      "e16022@eng.pdn.ac.lk\n",
      "e16025@eng.pdn.ac.lk\n",
      "e16222@eng.pdn.ac.lk\n",
      "Advisors\n",
      "Dr. Isuru Nawinne\n",
      "Mr. Ziyan Marikkar\n",
      "Essential Links\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "Copyright © Smart Meeting Automaton 2020\n",
      "\n",
      "\n",
      "Extracting smart payment system https://cepdnaclk.github.io/e16-3yp-smart-payment-system\n",
      "\n",
      "\n",
      "Smart-payment-system | e16-3yp-smart-payment-system\n",
      "e16-3yp-smart-payment-system\n",
      "Smart-payment-system\n",
      "This is the 3rd year embedded system project\n",
      "Group Members :\n",
      "Basnayake S.S. E/16/054\n",
      "Madusha shanaka E/16/351\n",
      "Nadun welikanda E/16/389\n",
      "Table of contents\n",
      "Problem\n",
      "Our solution\n",
      "Solution Architecture\n",
      "Hardware & Software Design\n",
      "Testing\n",
      "Detailed budget\n",
      "Links\n",
      "OVERVIEW\n",
      "As we all know gaming industry is growing day by day. As a result of this growth the concept of gaming centers has been popular lately. In a gaming center they normally use coins to play the games. The procedure is when a customer comes to the gaming center they have to buy coins from the cashier in order to use those as a paying method to the gaming machine. Once they put enough number of coins into the machine they are allowed to play the game.\n",
      "Problem\n",
      "The problems of this approach are the coins are simply hard to carry around the gaming center when the customer has large number of coins and also they have good chance to loose a coin or two. When we consider the gaming center’s point of view they have to collect coins every day at each machines and count it and keep the record.\n",
      "Our Solution\n",
      "As a solution for above problems we came up with a solution which completely replace coins system with a RFID and NFC technology. In our solution, when the customer arrives at the cashier and pay money they will be issued a RFID card or if they have NFC supported mobile device they can use our mobile app instead of coins. To play the game what they have to do is simply tap the RFID card or the mobile device into the reading area which is in the gaming machine. After the customer done playing he can go to the cashier and return the card. If there is any balance the cashier will return the balance.\n",
      "Solution Architecture\n",
      "Detailed Budget\n",
      "Hardware and Software designs\n",
      "3D model Design\n",
      "Cashier Node\n",
      "Gaming Node\n",
      "Hardware design\n",
      "Demonstration\n",
      "Cashier Node\n",
      "Gaming Node\n",
      "Software design\n",
      "1. Database\n",
      "2. Cashier Application\n",
      "3. Web Application\n",
      "Testing\n",
      "Under testing we checked for unit testing and intergration testing. In unit testing we checked all functions related to adding a card, refunding, return, scanning a card, issue a card, register and login.\n",
      "Under intergration testing we tested Basic route to see the server up and ruining and Route which send the 404 message\n",
      "Target Audience\n",
      "The target audience of this project is Gaming centers which is our primary target. As our next milestone, we are planning to update this system in a way that it can be used in any commercial market place such as casino, leisure world, etc.\n",
      "Links\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "Project website\n",
      "\n",
      "\n",
      "Extracting smart pharmaceutical warehousing https://cepdnaclk.github.io/e16-3yp-smart-pharmaceutical-warehousing\n",
      "\n",
      "\n",
      "Smart Pharmaceutical Warehousing | e16-3yp-smart-pharmaceutical-warehousing\n",
      "e16-3yp-smart-pharmaceutical-warehousing\n",
      "Smart Pharmaceutical Warehousing\n",
      "Group Members :\n",
      "K.R. De Silva E/16/068\n",
      "(e16069@eng.pdn.ac.lk)\n",
      "J.M.Praveen Dhananjaya E/16/081\n",
      "(e16081@eng.pdn.ac.lk)\n",
      "F.S Marzook E/16/232\n",
      "(e16232@eng.pdn.ac.lk)\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne\n",
      "Dr. Ziyan Maraikar\n",
      "Table Of Content\n",
      "Problem Overview\n",
      "Our solution\n",
      "Solution Architecture\n",
      "Hardware & Software Designs\n",
      "Testing\n",
      "Detailed budget\n",
      "Related Links\n",
      "Problem Overview\n",
      "Conventional pharmaceutical warehouses mostly use manpower to manage and handle goods inside their warehouse complexes. Some warahouses use small indoor vehicles. But all these conventional methods has some inevitable downsides. Most common suhc disadvantages are redundant activities, higher labor cost, suboptimal handling of goods and internal and external thefts. These downsides cause losses in both time and profitability and lead to inefficent warehouse management.\n",
      "Our Solution\n",
      "In this project, we are trying to address this issue by developing a fully automated warehouse management which will minimize the drawbacks while improving efficiency and profitability. We are implementing a warehouse managament system which consists two types of robots; robots arms - to handle loading/unloading of goods, automated guided vehicles(AGVs) to transport goods inside warehouse. Also an online shopping portal to make the purchases from the warehouse.\n",
      "Once a customer places an order, the order will be received, processed and will be delivered to the delivery station without any human involvement. The customer will then be informed to pickup his/her order from the warehouse.\n",
      "How It Works\n",
      "Our solution consists three components :-\n",
      "Fully automated warehouse\n",
      "Controller interface to control and override(if necessary) the autonomous operations\n",
      "Warehouse database with an online shopping portal, as an interface to retailers to make their purchases\n",
      "The warehouse has two base stations, the delivery post and receiving post, to deliver goods to the customers and receive any stocks to the warehouse respectively. In these base stations, two fixed robot arms are placed to do the loading and unloading process for goods.\n",
      "Inside the warehouse, movable robot arms are placed among shelves to load and unload the goods to AGVs.\n",
      "Once a client places an order, the database is updated and the computer fetches the relevant information about the goods and triggers up the local warehouse controller. The warehouse controller then generates instructions and are passed to the robot arm and the delivery robot to perform the task. Here, the local controller sends status messages like Insert, Takeout, Store etc. while they are processing the goods. Once the fetching of goods is done, they are delivered to the client.\n",
      "When more than one orders are received, a queueing algorithm will process them and will assign the automated guided robots (AGVs) nearby those relevant shelves in such a way that no collision will occur as well as no AGV will have an overloaded queue. This queueing algorithm will assure that all AGVs and robot arms are used efficiently. A separate algorithm will choose the shortest path for AGVs to reach their destination, minimizing the travel time.\n",
      "Hardware & Software Designs\n",
      "The current progress and the implementations of the project can be viewed from the following links:\n",
      "Hardware\n",
      "Software\n",
      "Network\n",
      "Bill of Material\n",
      "Related Links\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting smart pill manager https://cepdnaclk.github.io/e16-3yp-smart-pill-manager\n",
      "\n",
      "\n",
      "Home - BrandSmart Pill ManagerProblem & SolutionServicesProduct DesignSolution ArchitectureHardware Design & ComponentsNetwork ArchitectureUsed TechnologyTestingBuget ReportTeam\n",
      "Smart Pill Manager\n",
      "Fun and secure way to take your medicinesGitHub Repo link\n",
      "Real life Problem and the Solution!Most of the people forget to take their medicines according to the prescription details. Due to those reasons following problems occur.Drug OverdoseDrug IntoleranceDisease get worse Can caused deathThis device will inform you when to take medicines and which amount of pills you need to take at that time More about Problem & SolutionServicesWhat We OfferWeb applicationYou can enter all the medicine and routine details using the web applicationPush notificationGet a email whether your loved ones are taking medication properlyAuthenticationEvery patient has to authenticate himself before taking the medicines Medicine TrackingGet a full medicine history\n",
      "Design\n",
      "Product Design\n",
      "Architecture\n",
      "Solution Architecture\n",
      "Hardware & Components\n",
      "Circuit Design\n",
      "Hardware Components\n",
      "Arduino Mega 2560\n",
      "RFID Receiver\n",
      "Fingerprint Scanner\n",
      "Speaker\n",
      "ESP8266 WI-FI chip\n",
      "480x320 LCD Display\n",
      "More about Hardware\n",
      "CAD DESIGNThis is our Fusion design of the smart pill manager device.INSIDE VIEWThe inside of the device has two parts. First one is circuit part. It is in the in front of the device. And second one is containers set.FRONT VIEWThe display of the device is  touch display. The inside of the device has two parts. First one is circuit part. It is in the in front of the device. And second one is containers set.CONTAINERS VIEWThis is the containers view. In our device has maximum 12 containers . There are in the backward of the device. Every container has LED Identifier.PCB Design\n",
      "Architecture\n",
      "Network Architecture\n",
      "TechnologyReact React is a lightweight front end library and it has own build packNodeJS we use the API as the node js backend. Node js is very easy to handle.MongoDB For the database, we use the mongodb database. It is no sql database. Therefore we can easily make request and responce to apiAzureWe deploy the our front end and back end in azure cloud platform.TestingMore about TestingEmbedded Testing\n",
      "Budget Report\n",
      "Team UNIVERSITY OF PERADENIYAAruna Nuwanthaco-founderBSc. Computer Engineering(undergraduate), University of Peradeniyae16261@eng.pdn.ac.lkChandula JPDMco-founderBSc. Computer Engineering(undergraduate), University of Peradeniya e16061@eng.pdn.ac.lkIsuru Lakshanco-founderBSc. Computer Engineering(undergraduate), University of Peradeniya e16203@eng.pdn.ac.lkADVISORSDr. Isuru NawinneSenior lecturerMr. Ziyan MarikkarSenior LecturerRelated LinksDepartment of Computer EngineeringFaculty of EngineeringUniversity of PeradeniyaGitHub RepositoryHomeServicesAboutTermsPrivacy PolicyCopyright  © smart pill manager 2021\n",
      "\n",
      "\n",
      "Extracting smart shopping cart with automatic bill system https://cepdnaclk.github.io/e16-3yp-smart-shopping-cart-with-automatic-bill-system\n",
      "\n",
      "\n",
      "Smart shopping systemSearch this siteSmart shopping systemHomeProject introduction Shopping cartMobile/web appDesktop appDesignsSolution ArchitectureBackend\n",
      "and cloud deploymentTestingHardwareHardware programmingIntegrated SystemBudget TeamSmart shopping systemHomeProject introduction Shopping cartMobile/web appDesktop appDesignsSolution ArchitectureBackend\n",
      "and cloud deploymentTestingHardwareHardware programmingIntegrated SystemBudget TeamMoreHomeProject introduction Shopping cartMobile/web appDesktop appDesignsSolution ArchitectureBackend\n",
      "and cloud deploymentTestingHardwareHardware programmingIntegrated SystemBudget TeamSmart shopping cart with automatic bill system.-\n",
      "Let's\n",
      "have a better shopping\n",
      "experience\n",
      "Our MissionOur mission\n",
      "is to\n",
      "provide a more advanced\n",
      "shopping\n",
      "experience without\n",
      "congestion.Introduction definitions of the problem:Cashier takes time to billing so long queues at the counters in super markets.So that shoppers have to wait lot of time near the counter.Our the solution:smart shopping cart with automatic bill systemApp for online shoppingNowadays, shopping has become a mandatory part of everyone's life. The\n",
      "most unpleasant experience we have to face there is having to wait a long time in long queues\n",
      "to pay . Due to this , the congestion in the supermarket has also increased.\n",
      "As a solution to this, our team\n",
      "is introducing\n",
      "a smart shopping cart\n",
      "and a mobile app . The Smart shopping cart\n",
      "has the special ability of\n",
      "calculating its bill automatically .This is done by adding the value of the item to the current bill through the RFID readers in the cart when customers take it from the item rack and put it in the cart.The bill calculated in this manner has been given the opportunity to be paid in several ways . These include cash payments, credit or debit card payments and app payments . This saves customers time and gives customers a more convenient and attractive shopping experience . It also makes the supermarket a more pleasant place as it reduces congestion.\n",
      "In addition,customers can view product details ,get discount/ offers notifications ,make a shopping list ,view recent bill payments ,place online orders and do the bill payment through our mobile and web apps.\n",
      "We also provide a desktop application that allows supermarket management to add new items to the supermarket database ,manage customer online orders ,make customer bill payments and much more.Questions?Contact members with email,Ekanayake J.E.M.D.Y.\n",
      ":\n",
      "e16096@eng.pdn.ac.lk Parackrama G.T.W.\n",
      ": e16267@eng.pdn.ac.lk Prabodha U.A.K.\n",
      ": e16290@eng.pdn.ac.lk Visit our github repo\n",
      ",\n",
      "github repo Copyright © Hi5 | All Rights ReservedPage updated Google SitesReport abuse\n",
      "\n",
      "\n",
      "Extracting smart vending machine https://cepdnaclk.github.io/e16-3yp-smart-vending-machine\n",
      "\n",
      "\n",
      "Smart vending Home\n",
      "vending machine\n",
      "Store\n",
      "GithubRepo\n",
      "Sign In\n",
      "Close Menu\n",
      "Smart Vending Machine3rd year Project\n",
      "Home\n",
      "Solution\n",
      "Architecture\n",
      "User Interface\n",
      "Hardware Components\n",
      "Hardware Design\n",
      "Software Testing\n",
      "Datapath\n",
      "Designers\n",
      "Budget\n",
      "Contact\n",
      "Vending Machine Insight\n",
      "Solution.\n",
      "Problems in having a traditional vending machine are - Having to pay for the products with cash most of the time.Easy to hack Traditional vending machine.Prices and Expiry dates are not checked by the\n",
      "Traditional vending machine.\n",
      "the solution to all the problem is a Smart vending machine which has the (Gender ,Age ,generation wise) analysis , 24 hours Distribution and vending services , Transaction Database services.\n",
      "Which can be used to check the performance of a product in a specific market.Prices and expiry dates are real time because it is connected to the cloud.\n",
      "×\n",
      "Software Architecture.\n",
      "The software architecture works like the above mentioned picture First user accesses\n",
      "the web application and he chooses the products and the interface was made by the Python Django\n",
      "and the details are updated in to the database which is made by MongoDB And it is al so in the\n",
      "server which is The Amazon EC3 instance All the communications are done through https.\n",
      "There is an API in the machine which connects the sever to get the Validation requests.Finally the Machine dispences\n",
      "the item chose by the user\n",
      "Back End Tasks Done\n",
      "User Registration (User /Admin/Companies)\n",
      "Where users are classified into who they are according to their Credential. These Roles can determine the access given to a selected user.\n",
      "Payment Handling\n",
      "Payment Handling is done through PayPal Which is a secured Payment Gateway\n",
      "Add /Modify/Delete Items\n",
      "The admin can Edit any information about the items available\n",
      "Validation\n",
      "QR code is used for more security and also Django Rest API is used for validity\n",
      "Transactions\n",
      "Every Transaction Done can be Seen by an admin .The User can also see the previous Transactions done by him.\n",
      "Server\n",
      "Local server is made using Python Django\n",
      "The database is made in PostGreSQL\n",
      "Communication to AWS is done through HTTPS\n",
      "Cloud Server\n",
      "Host in amazon EC2 Instance\n",
      "Nginix Server is used because Nginx is built to offer low memory usage and high concurrency.\n",
      "Rather than creating new processes for each web request, Nginx uses an asynchronous, event-driven\n",
      "approach where requests are handled in a single thread. With Nginx, one master process can control multiple worker processes.\n",
      "Gunicorn is used and it internally hands the calling of our flask code. This is done by having workers ready to handle the requests instead of the sequential one-at-a-time model that the default flask server provides.\n",
      "The end result is our app can handle more requests per second\n",
      "Built with Python Django\n",
      "Used database PostGreSQL\n",
      "Rest API\n",
      "To authenticate we are using JSON web token because it securely transfers\n",
      "information between software and Hardware as an JSON file.It has 2 tokens one is access token which expires within 5 minutes .\n",
      "We are using Rate limit to make sure the hardware/Web Application\n",
      "does not get overloaded by API calls to the cloud and it is only 60 API calls per hour.It ensure the safety of the systems.We can do GET,PUT,POST,DELETE in the APIs that are available in the system.\n",
      "User Interface.\n",
      "The Website gets you to this Home page which Can be used to directly buy items or you can sign in and buy things If you sign in the company can give you discounts or other options.And also from the Homepage you can go to the cart which has the items you selected and the total amount.Other than that you can also go to the tab pending orders and use the QR codes to get the paid items to dispense.\n",
      "This Page is the page you get if you want to Login.You can type in your login credentials and get into the account where you can see your previous orders and etcs. Or If you don't have an account you can go to the Signup option and Sign up for a new account.There is an option to help you reset your password as well if you forget.\n",
      "This is the SignUp page where you can Sign up for a new Account.The creditentials can be created here and there is a email checker and the email should be legitimate to sign in\n",
      "After Signing in you will have a page similar to the home page but you can see your account and you can make changes to your account when you click on your profile picture.And also you will have an Profile Button on your webpage where you can go and change your account settings.\n",
      "After you added the items your Cart the cart looks like this and you can edit the items that you are going to add here also.If you click check out it will take to a page where your can pay for the Items.You can use continue shopping to go back and add more items to the cart.\n",
      "When you go to the checkout page you can see that it will ask for a name and an email. It is just for the invoice so you can use it for refunds and other proceeds.\n",
      "After giving the Email and the name You can choose the way to pay (Paypal / Debit Card /Credit card).After choosing the payment method you will be redirected to a dialog box which is going popup and you can give your details there and pay for the items and you will receive the items.\n",
      "pop up will redirect you to Paypal\n",
      "If you Login with the admin Credentials you can see all the transactions that have happened with the vending machine over the\n",
      "time. And you can check who has bought the items and their characteristics according to their accounts.And also you can check the pending transactions.\n",
      "If you Login as an Admin You can also change the number of products in the vending machine.If you see any miscalculations. And also you can search for items according to their places and the prices and also the names.\n",
      "The other page you can check are the QR codes of the customers who are going to buy the items.\n",
      "Online Demonstration Video\n",
      "Hardware Components\n",
      "Raspberry Pi 3\n",
      "Broadcom BCM2837 64bit ARMv7 Quad Core Processor powered Single Board Computer running at 1.2GHz\n",
      "1GB RAM\n",
      "BCM43143 WiFi on board Bluetooth Low Energy (BLE) on board\n",
      "40pin extended GPIO , 4 x USB 2 ports 4 pole\n",
      "Stereo output and Composite video port Full size HDMI\n",
      "CSI camera port for connecting the Raspberry Pi camera\n",
      "Upgraded switched Micro USB power source (now supports up to 2.4 Amps) Expected to have the same form factor has the Pi 2 Model B, however the LEDs will change position\n",
      "Stepper Motor\n",
      "Motor Type: Bipolar Stepper\n",
      "Step Angle: 1.8 deg.\n",
      "Holding Torque: 40N.cm (56oz.in)\n",
      "Rated Current/phase: 1.7A\n",
      "Phase Resistance: 1.5Ohm±10%\n",
      "Insulation Resistance: 100MΩ¸ Min, 500VDC\n",
      "Insulation Strength: 500VAC for one minute\n",
      "Stepper motor driver\n",
      "stepper motor provides a constant holding torque without the need for the motor to be powered.Steppers provide precise positioning and repeatability of movement since good stepper motors have an accuracy of 3 – 5% of a step and this error is non-cumulative from one step to the next.\n",
      "Driver Model: L298N 2A\n",
      "Driver Chip: Double H Bridge L298N\n",
      "Motor Supply Voltage (Maximum): 46V\n",
      "Motor Supply Current (Maximum): 2A\n",
      "Logic Voltage: 5V\n",
      "Driver Voltage: 5-35V\n",
      "Driver Current:2A\n",
      "Logical Current:0-36mA\n",
      "Maximum Power (W): 25W\n",
      "Current Sense for each motor\n",
      "Heatsink for better performance\n",
      "Camera Module V2 for Raspberry Pi\n",
      "5 megapixel native resolution sensor-capable of 2592 x 1944 pixel static images.\n",
      "Supports 1080p30, 720p60 and 640x480p60/90 video.\n",
      "Camera is supported in the latest version of Raspbian, Raspberry Pi's preferred operating system.\n",
      "Relay Module\n",
      "High-sensitivity (250 mW) and High-capacity (16 A) versions\n",
      "Rated voltage 12 V DC\n",
      "Rated current\n",
      "20.8 mA\n",
      "Coil resistance\n",
      "576 Ω\n",
      "Must operate voltage 75% max. of the rated voltage\n",
      "Must release voltage\n",
      "10% min. of the rated voltage\n",
      "Max. voltage\n",
      "180% of rated voltage (at 23°C)\n",
      "Power consumption\n",
      "Approx. 250 mW\n",
      "Weight Sensor\n",
      "Differential input voltage: ±40mV (Full-scale differential input voltage is ± 40mV)\n",
      "Data accuracy: 24 bit (24 bit A / D converter chip.)\n",
      "Refresh frequency: 10/80 Hz.\n",
      "Operating Voltage: 2.7V to 5V DC.\n",
      "Operating current: < 10 mA.\n",
      "Size: 24x16mm.\n",
      "PIR sensor\n",
      "Input voltage: DC 4.5~20V\n",
      "Static current: 50uA\n",
      "Output signal: 0,3V (Output high when\n",
      "motion detected)\n",
      "Sentry angle: 110 degree\n",
      "Sentry distance: max 7 m\n",
      "120 degree detection angle\n",
      "Low power consumption in idle mode only 50uA\n",
      "and 65mA in fully active mode.\n",
      "This is the physical interpretation of the circuit diagram Which shows how the components are connected\n",
      "Hardware Design\n",
      "For the Convenience of the user the design was made to demonstrate which has all the attributes and more of a vending machine\n",
      "In the picture you can see a screen which is used to communicate with the user and there is a proximity sensor to make sure the vending machine only works when\n",
      "someone is present\n",
      "PCB Design\n",
      "Hardware Demontration\n",
      "The Schematic View\n",
      "For Demonstration purposes we have used proteus simulation platform here firstly the\n",
      "Vending Machine circuit is in OFF state and then if any person comes near the vending machine\n",
      "the PIR sensor detects the person and all the system comes to the on state Then the LED display shows\n",
      "the Welcome message asks to input the QR code.If the user adds the QR code (which has the details of the Transaction).\n",
      "the Vending machine sends a Validation request through an API call.If the QR code is valid then\n",
      "according to the Item list the motors according to the Item will rotate and the Items are delivered.The weight sensor makes sure\n",
      "if the items are delivered and the system goes to the power off State\n",
      "Data Path.\n",
      "The flow of data is projected above normally a user signs in or signs up with the user app\n",
      "after that user app sends the server data through HTTPs\n",
      "requests and also the response from the server also\n",
      "is through HTTPs responses similarly the API in the vending machine also sends the request as HTTPs and the response is through\n",
      "HTTPs.\n",
      "ER Diagram\n",
      "The Main entities are User,Customer , Product, Order, Order Item And QR Code.Every Entity has unique\n",
      "primary Key. And if we go in to details Customer Makes an order or multiple orders so the relationship between\n",
      "Customer and the Order is one to many.Customer can get multiple QR codes so there will be a one to many relationship.likewise one order can have multiple\n",
      "order items that is also a one to many relationship.For Order to QR Address the relationship is 1 to 1.\n",
      "For products and Order Item its 1 to many.\n",
      "Software Testing.\n",
      "URL unit Testing\n",
      "We are checking to make sure every Url gets the reverse Match.By using the dummy http request\n",
      "POST/GET\n",
      "Request unit Testing\n",
      "CRUD operations are Checked using artifical AJAX API calls for that we are using Hard coded Json data\n",
      "We are sending in dummy data to check the reliability of the authendication\n",
      "Form Validation Testing\n",
      "Authetication form is\n",
      "checked\n",
      "We are creating a new user and database and checking the form\n",
      "Post request is sent and check if it is updated\n",
      "new products are created in example to check where all of them are being updated\n",
      "Testing Results\n",
      "22 checks were done for end point reverse matches all were passed.We failed to check the QR code at the first time but after some minor changes QR code got accepted by the test\n",
      "and also 15 tests were done one of them were checking QR codes\n",
      "Designers.\n",
      "Karikaran Vettirivel\n",
      "Girishikan Selvaratnam\n",
      "Bragadeeshan Suppusamy\n",
      "Budget.\n",
      "Contact.\n",
      "Do you want us to style your home? Fill out the form and fill me in with the details :) We love meeting new people!\n",
      "Name\n",
      "Email\n",
      "Message\n",
      "Send Message\n",
      "\n",
      "\n",
      "Extracting waiterbot system https://cepdnaclk.github.io/e16-3yp-waiterbot-system\n",
      "\n",
      "\n",
      "WaiterBot System\n",
      "WaiterBot System\n",
      "Home\n",
      "Solution Architecture\n",
      "Design\n",
      "and Progress\n",
      "WaiterBot\n",
      "WaiterBot API\n",
      "Mobile Application\n",
      "Web Application\n",
      "Desktop Application\n",
      "Demonstrations\n",
      "Documentation\n",
      "Testing\n",
      "and Deployment\n",
      "Software Testing\n",
      "Hardware Testing\n",
      "Cloud Deployment\n",
      "More\n",
      "Team\n",
      "Budget\n",
      "Github Repo\n",
      "WaiterBot System\n",
      "Dine with Technology!\n",
      "Robots have seen a wide array and continuous applications in various industries since their\n",
      "inception. The efficiency and versatility that robots possess can be molded into a vast area of\n",
      "services, and robots in restaurants can step up to be a huge breakthrough in terms of customer and\n",
      "owner satisfaction and improving the overall experience in diners.\n",
      "The WaiterBot System is an automated system designed for placing and delivering orders in a\n",
      "restaurant. This system will replace the human waiters with robot waiters for an efficient delivery\n",
      "process and also give customers a new experience. Customers can place orders via the mobile\n",
      "application and once the orders are ready, the WaiterBots will deliver the orders to the customer.\n",
      "Current Practice and the Problems\n",
      "Currently in restaurants food is delivered by human waiters. Even the order placing is done through a\n",
      "waiter. You may have encountered situations where the waiter takes a long time to take the order and\n",
      "deliver it. The customers may also keep complaining that the service is not satisfactory. There may\n",
      "also be instances where the waiters might mess up the orders or not deliver the order to the correct\n",
      "customer. Due to these situations the reputation of your restaurant might be tarnished, and worse,\n",
      "if a customer faces these problems he/she will not visit your restaurant again because the service\n",
      "is not satisfactory and hence you will lose customers.\n",
      "Usually a customer placing the order will have to select the food items using a traditional menu card\n",
      "and might have questions when selecting food items like whether the selected item is good enough in\n",
      "terms of taste, quality, etc... Also, once the orders are placed, if the ordered item is not\n",
      "available due to various reasons, the waiter will have to inform the customer and the customer will\n",
      "have to order some other item, resulting in irritation of the customer in some cases as well. This\n",
      "order placing and delivery process may not be much efficient especially if the restaurant is busy\n",
      "with customers.\n",
      "Our Solution\n",
      "Our solution is to replace the human waiter with a robot waiter and also to replace the traditional\n",
      "menu cards system with a more attractive and efficient order placing system. On an event where a\n",
      "customer visits the restaurant he/she can place the order via the order placing system and once the\n",
      "ordered items are ready, the items will be delivered to the customer. Our solution will help the\n",
      "customer to select the food items more efficiently with help of the reviews from previous customers\n",
      "and also if an item is unavailable that item will not be shown in the menu. The WaiterBot system\n",
      "will help the restaurant by providing an efficient delivery mechanism. WaiterBots will not mess up\n",
      "orders and they will deliver the food items to the correct table. Also this may be a new experience\n",
      "for the customers and the WaiterBot system will attract more customers to the restaurant.\n",
      "Links\n",
      "Home\n",
      "Solution Architecture\n",
      "WaiterBot\n",
      "WaiterBot API\n",
      "Mobile Application\n",
      "Web Application\n",
      "Desktop Application\n",
      "Demonstration\n",
      "Documentation\n",
      "Software Testing\n",
      "Hardware Testing\n",
      "Cloud Deployment\n",
      "Team\n",
      "Related Links\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "Univerity of Peradeniya\n",
      "© Copyright 2020 WaiterBot System\n",
      "\n",
      "\n",
      "Extracting water quality monitoring and usage monitoring system https://cepdnaclk.github.io/e16-3yp-water-quality-monitoring-and-usage-monitoring-system\n",
      "\n",
      "\n",
      "Project site\n",
      "Toggle navigation\n",
      "×\n",
      "Github Repo\n",
      "Water Quality and Usage Monitoring Device\n",
      "Check your tank with care\n",
      "Intro\n",
      "How It Works\n",
      "Team Members\n",
      "Components and Technology\n",
      "Advisors and Mentors\n",
      "Work Done So Far\n",
      "Intro\n",
      "Problem\n",
      "Water mismanagement and consumption of poluted water is a major challenge, the world is facing currently.\n",
      "Current market is yet to address this issue with an effective solution. The solutions that are currently\n",
      "present on the market are either too expensive for domestic usage or does not meet the user expectations.\n",
      "Solution\n",
      "To overcome these issues, we are propossing a device which can be used to measure the water quality of the\n",
      "inlet of a water tank and the water level inside the tank. We expect to target both domestic user requirments\n",
      "and industrial user requirements by a reasonable price (click here for budget) User can access to the data using a mobile application.\n",
      "Water level Monitoring\n",
      "By using an ultrasonic sensor, water level will be monitored and when the tank is nearing to finish filling, user\n",
      "will be notified. We use ultrasonic sensor because of it's high accuaracy and sensor is not easily effected by\n",
      "water. Also this will generate the usage reports of the water and allow user to observe the current water level\n",
      "in the tank if needed. This measurement also allows to rationing of water and user will be warned in case of overusage.\n",
      "Water Quality Monitoring\n",
      "TDS count – by electric conductivity of water\n",
      "The presence of dissolved solids in water may affect its taste.The palatability of drinking-\n",
      "water has been rated by panels of tasters in relation to its TDS level as follows:\n",
      "excellent, less than 300 mg/litre;\n",
      "good, between 300 and 600 mg/litre;\n",
      "fair, between 600 and 900 mg/litre;\n",
      "poor, between 900 and 1200 mg/litre;\n",
      "unacceptable, greater than 1200 mg/litre\n",
      "Water with extremely low concentrations of TDS may also be unacceptable because of its flat,\n",
      "insipid taste. Click here for see WHO guidelines for drinking water quality\n",
      "Turbidity – by measuring scattering of light in water\n",
      "Turbidity, which is caused by suspended chemical and biological particles, can have both water safety and aesthetic implications\n",
      "for drinking-water supplies. Turbidity itself does not always represent a direct risk to public health; however, it can indicate the\n",
      "presence of pathogenic microorganisms and be an effective indicator of hazardous events throughout the water supply system,\n",
      "from catchment to point of use. For example, high turbidity in source waters can harbour microbial pathogens, which can be\n",
      "attached to particles and impair disinfection; high turbidity in filtered water can indicate poor removal of pathogens; and an\n",
      "increase in turbidity in distribution systems can indicate sloughing of biofilms and oxide scales or ingress of contaminants through\n",
      "faults such as mains breaks.WHO says that for dinkable water turbidity must be below 5NTU and should be low as possible like 0.1NTU\n",
      "Click here to download the review done on the turbidity by WHO.\n",
      "For these 2 measurments, TDS sensors and Turbidity sensors will be used and their readings will be analyzed with ideal water\n",
      "quality levels and determine the water quality of the incoming water to the tank during a filling and notify the user if there\n",
      "is any contamination in the water. We use these 2 sensors because by using these 2 readings we can determine most of the\n",
      "characteristics of water.\n",
      "How It Works\n",
      "This diagram shows the overall implementation of the system.There are sensors to get the data, server to handle the clients.The system works as below steps.\n",
      "Sensors reads the data\n",
      "Sends the data to the server\n",
      "Server sends the data to the clients\n",
      "According to above steps, firstly sensors read the data. The ultra sonic sensor is situated inside the tank and the turbidity sensor is situated inside the water pipe which uses to fill\n",
      "the tank. The readings from these sensor are sent to the atmega chip and by using a wifi module those readings are sent to the server. From server, relavant data sends to clients accordingly.\n",
      "Client may be a mobile user or pc user. When consider the mobile users, by using the mobile app, clients can check the level of water filled to the tank and also can see the water purity percentage.\n",
      "When consider the pc users, they can log into the website and get the above details. There is an alarm module to function without any internet connection which is helpful when the client has no internet access.\n",
      "And it can be implemented according to the clients' desire. Clients can also get daily usage details via the website.\n",
      "Team Members\n",
      "Harshana Bandara\n",
      "E/16/049\n",
      "S.D.M.V.G.H.N.Bandara\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "Yasitha Herath\n",
      "E/16/134\n",
      "H.M.Y.B.Herath\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "Thushara Weerasundara\n",
      "E/16/388\n",
      "W.M.T.M.P.B.Weerasundara\n",
      "Department of Computer Engineering\n",
      "Faculty of Engineering\n",
      "University of Peradeniya\n",
      "click on images to visit github pages of the members\n",
      "See more..\n",
      "Components and Technology\n",
      "HTML , CSS and JS\n",
      "HTML is a simple and dominant language to formatting web pages.It supports every browser .HTML Combined with CSS and JS can be used to give client an elegant and yet fast experience\n",
      "Flutter\n",
      "Flutter is free and open source UI framefork which is able to cross platform developments.The language used in\n",
      "flutter is DART which is optimized for UI development.\n",
      "MQTT\n",
      "Protocol which allows efficient data distribution with lightweight overhead and with high sclabability\n",
      "Reduce bandwidth consumption so the client can have maximized available bandwidth.\n",
      "MongoDB\n",
      "High scalability and better for cloud services\n",
      "NodeMCU\n",
      "Provides the connectivity between the device and server.low cost which reduce the prie of the product and low energy consumption\n",
      "which is essential to a long battery life of the devise.\n",
      "Ultasonic Sensor\n",
      "Reliable hardware for measuring short distances with a sufficient accuracy\n",
      "Mentors\n",
      "Dr.Isuru Navinna\n",
      "Senior Lecturer\n",
      "Dr.Zian Marikkar\n",
      "Senior Lecturer\n",
      "Work Done So Far\n",
      "GUI prototype\n",
      "GUI was designed with the aid of figma.Click herefor experience the GUI\n",
      "Circuit Designs\n",
      "Click this link to see more about our Circuit Design\n",
      "Hardware Testing and Simulation\n",
      "Hardware Components are simulated in Tinkercad. click here to see more\n",
      "Our Front End Implementation\n",
      "Web Site\n",
      "Our web site UI is designed to give a user friendly experience to the customer in a very simple manner.\n",
      "It uses dynamic web pages to interact with users therefore fast responses can be obtained with less data\n",
      "usage.\n",
      "Role Based Access\n",
      "This offers different user expirience to the user depending on the role of a user.\n",
      "3 roles in our system are,\n",
      "Super Admin - Give access to Admin Users\n",
      "Admin - Supervise Users (Customers)\n",
      "User - Customers\n",
      "Implementation\n",
      "Uppon registration to the service, each user should confirm their account using their email account by clicking on a generated url\n",
      "User actions are based on their roles and authorization middleware monitor and control those ations accordingly.\n",
      "authorization middleware make sure,\n",
      "Verify / Idenify users and roles\n",
      "Users don't access unauthorized locations and perform unauthorized actions\n",
      "Redirect users on unauthorized locations and unauthorized actions\n",
      "Customers can login and monitor their devices. They can monitor,\n",
      "Daily Usage of water\n",
      "Monthly Water Usage reports\n",
      "Water Quality of their tanks\n",
      "Admins can monitor the system and manage customers, also they can provide customer support.\n",
      "Their tasks include,\n",
      "Send notices to users\n",
      "Edit and remove customers\n",
      "Monitor devices with issues\n",
      "Super Admins can allow access to the admin users to the system and remove admins.\n",
      "Web Site Views\n",
      "1. Customer UI\n",
      "Log In\n",
      "Daily Usage\n",
      "Monthly Usage\n",
      "Sign Up\n",
      "Getting User Details\n",
      "Demonstration\n",
      "2. Admin UI\n",
      "Admin View\n",
      "Delete a User\n",
      "Update a User\n",
      "Demonstration\n",
      "3. Super Admin UI\n",
      "Admin View\n",
      "Create Administrative User\n",
      "Delete an Admin\n",
      "Demonstration\n",
      "Mobile App\n",
      "App with limited access for customers\n",
      "App uses validate methods when a user does a login attempt to avoid un-necassary requests to the server\n",
      "Login Screen\n",
      "Home Screen\n",
      "Tank Details\n",
      "Invalid email\n",
      "Invalid Password\n",
      "Tank info\n",
      "Tests Conducted\n",
      "1. Penetration Testing\n",
      "Several Penetration Tests were carried out in order to check vulnerabilities in our backend\n",
      "system. Tools used on those tests are\n",
      "Wire Shark\n",
      "BURP Suite\n",
      "Dirb\n",
      "Nmap\n",
      "Sqlmap\n",
      "Nilto\n",
      "Results\n",
      "Using wire shark we conducted packet sniffing tests. As a result of that we observed information exposed in requests.\n",
      "Using Dirb we tested using a brute force attack to check vulnerabilities in every directory/object of our website and server.\n",
      "We managed to identify exposed endpoints by the test.\n",
      "Using BURP Suite and Sql map we tried to conduct a sql injection attack but attack was failed due to security measures in our\n",
      "server.\n",
      "Using nmap and nikto we tried to obtain information about the web server and it's components. We managed to get server type, OS,\n",
      "open ports, vulnerabilities in our content policies, server capabilities. These information could be used for DOS, DDOS, sql injections\n",
      "Packet Sniffing\n",
      "End Point Responses\n",
      "Security Headers\n",
      "OS information\n",
      "Security Headers\n",
      "2.Unit and integration Testing\n",
      "Unit test are carried out to check the functionality of the seperated functions and integration tests are used to test user creation and roles, to test sensor\n",
      "readings storing and validity.Below tools are used to test these.\n",
      "Mocha\n",
      "Chai\n",
      "Tests\n",
      "Results\n",
      "Conclusions\n",
      "Only the users with unique and valid credentials can sign up\n",
      "Only the admin can get the signup data, redirection to the adminSignup view\n",
      "Only the valid sensor data is stored , guarantee the quality of the sensors\n",
      "Any user with different roles can log by giving correct credentials\n",
      "We implemented our security measures using these results.\n",
      "Security Aspects\n",
      "https server\n",
      "Using self signed certificates using open ssl for devolepment purposes. This protects sensitive\n",
      "information by encrypting, thus protects from outsiders.\n",
      "Using Credentials to Authenticate Users\n",
      "Users are authenticated by using passwords. These passwords are hashed therefore even the database is\n",
      "compromised, passwords are safe therefore attacker cant use it.\n",
      "Using cookies for Track Sessions\n",
      "For successfull authentication of a user, user will be issued a jwt tocken. Using that token user will be\n",
      "authenticated. Since tocken is sent via https it is secured. Also secure tag and httponly tags are set therefore\n",
      "no one can manipulate the tockens from browsers and use undetected.\n",
      "Role Based Authorization\n",
      "Server uses middleware to authorise users in server. Therefore each user will be limited to actions pre defined\n",
      "for his corresponding role.\n",
      "Setting Rate Limits Per User\n",
      "By setting x rate headers, number of requests from a user are monitored and limited. If rate is overflowed 429 status\n",
      "is returned. Thus protecting from dos attacks.\n",
      "Request burst tracking\n",
      "Server tracks number of requests received in a given time. If the number of requests go pass that number, server will\n",
      "take predefined necessary actions. This gives protection from ddos attacks.\n",
      "Hiding Server Information\n",
      "By hiding server type, OS, database information and capabilities server has protection from attacks sepecially designed\n",
      "for our server. Also using content policies we can have protection from sql injection attacks.\n",
      "Embeded Hardware Designs\n",
      "Components List\n",
      "Ultra Sonic Sensor - U1\n",
      "Water Level Monitoring.\n",
      "ATMEGA328P chip - U2\n",
      "Microcontroller chip.\n",
      "DC-DC step down Buck converter - U3\n",
      "Voltage Controller.\n",
      "Li Battery Charger - U4\n",
      "Battery Charging module.\n",
      "Turbidity Sensor - U5\n",
      "Turbidity Measurement of Water.\n",
      "TDS Sensor - U6\n",
      "TDS Measurement of Water.\n",
      "Flow Meter - P1\n",
      "Water Usage Monitor.\n",
      "NODEMCU - MK1\n",
      "Internet Connection Module.\n",
      "Speaker - SP1\n",
      "Warning System.\n",
      "Reset Button - SW1\n",
      "Power Button - SW2\n",
      "Designs made for fabrication\n",
      "Embeded System\n",
      "Water Quality Monitoring Module\n",
      "Water will enter this module and Quality Measurements will be recorded. Readings will be taken as analog inputs.\n",
      "Water Usage Monitoring Module\n",
      "Water Usage will be recorded using this module. Readings will be taken by external inturrupts in microcontroller chip.\n",
      "User Expirience Optimization\n",
      "Using Solar Power\n",
      "Ability to Perfrom during Blackouts\n",
      "Protection from Environmental Conditions\n",
      "User Freindly UIs\n",
      "Faster Response time due to dynamic web pages\n",
      "Scalability\n",
      "Using Nginx to run multiple servers to load balancing.\n",
      "Using Proactive scalling features in MongoDB to scale database to support high traffic events.\n",
      "Each user can monitor multiple devices using a single app.\n",
      "Reliability\n",
      "In case of a server failure, another server will responds to requests.\n",
      "Thoroughly calibrated and tested sensors.\n",
      "Cross platform application.\n",
      "Plan For The Embeded Systems Testing\n",
      "There are two parts of our embedded system testing plan.Those parts are showed below.\n",
      "Hardware Testing\n",
      "Node Software Testing\n",
      "Aim is to ensure the reliability of our product by doing these tests.\n",
      "Hardware Testing\n",
      "In this we do tests when soldering and to test the functionality of the sensor devices.\n",
      "When soldering we do below steps,\n",
      "Soldering and testing the power sections one by one\n",
      "Solder the relavant wires from the sensors with microcontroller and test the basic functionality\n",
      "check the connectivity\n",
      "To check the connectivity we use oscilloscope or logic analyzers.\n",
      "To do the sensor testings for turbidity sensor and TDS count sensor we use glasses with water which desolved with different kind of substances as below.\n",
      "By dipping the sensors inside the water glasses we test the functionality of the sensors and how the readings change according to the difference of water. By those readings we can calibrate the sensor readings accordingly. And also we can detect if the sensors are deffected by checking the sensor readings.\n",
      "To test Ultrasonic sensor we can use above glasses with different water levels and do the same tests.\n",
      "Node Software Testing\n",
      "In this testing we do test to check variable overflows, compiler optimizations and typing mistakes.\n",
      "We use below techniques to do the debugging.\n",
      "Debug breakpoints\n",
      "Disassembly window\n",
      "Call stack window\n",
      "And also we are planning to check the real time sensor readings are showing on our web site and the app. By this we can make sure that the interaction between node software and backend works correctly.\n",
      "Embeded Software Explanation\n",
      "This device utilizes the services of Arduino UNO R3 board which has ATMEGA328P U chip and NodeMcu ESP-12E board for WiFi connection.\n",
      "Let's consider the working procedure of the device step by step.\n",
      "Device Initialization\n",
      "When the device is powered up, NodeMCU will creates a WiFi server on port 80 under the url of www.aquawatcher.com using \"DNS\" and \"WebServer\" modules. We can connect to that network and set up user details and tank details. Then we can enter our WiFi network details as well. Those details will be stored in EEPROM memory of the device until they are updated. Therefore user won't have to set those values again on reboot.\n",
      "We can reset the above details by pressing reset button and going through the same procedure as before.\n",
      "Thereafter, server will be closed down and normal procedure of the device will occur.\n",
      "Working Procedure\n",
      "Water Level will be measured using Ultra Sonic sensor using an analog input pin. This will be used to get tank size as well.\n",
      "Water Usage will be measured using a Flow Meter using external inturrupts.\n",
      "Water Quality will be measured using TDS and Turbidity Sensors using an analog input pins.\n",
      "All the above modules will use their own custom libraries.\n",
      "Readings will be taken periodically.\n",
      "When the water is contacted with the sensors, device will identify water is filling.\n",
      "Then the device will start sending new data to the server.\n",
      "When an issue occurs regarding water level or quality, an alarm will be set off using Tone function.\n",
      "Water quality standards are preseted values.\n",
      "Communication between 2 boards will be done using serial communication. Extra pins in NodeMCU board was set as serial pins using Softwareserial library.\n",
      "Solar panels are intergrated as power source.\n",
      "Device Installation\n",
      "Water Level Monitor\n",
      "Water Quality Monitor\n",
      "Water Level Monitor\n",
      "1st empty the tank\n",
      "Then Install the \"Water Level Monitor\" inside of the closing lid of the tank. Make sure it is levelled\n",
      "Water Quality Monitor\n",
      "1st remove the inlet of the tank.\n",
      "Then Install the \"Water Quality Monitor\" to the inlet and then insert inlet pipe to the back of the device.\n",
      "Make sure to expose the device to direct sun light if you choose to use our solar panel intergrated version..\n",
      "Getting Started\n",
      "There are two parts of setting up the device.\n",
      "Device Initialization\n",
      "Connect to WiFi network\n",
      "Device Initialization\n",
      "1st we need to store user email and tank number in the device. 1st connect the device to the power, then connect with \"AquaWatcher device Setup!\" wifi network. Then go to the address www.aquawatcher.com and provide information.\n",
      "It will be convinient to you if you installed our \"AquaWatcher\" app on your android/iOS device as well.\n",
      "Connecting to WiFi\n",
      "Then wifi network \"Aqua Watcher\" will be available and connect to it. Then go to manage wifi network and enter your wifi network information.\n",
      "Start Operation\n",
      "You can now start to fill the tank.\n",
      "You don't have to keep monitor the device. It will send notifications when,\n",
      "Tank is almost full\n",
      "Water pollution is detected\n",
      "Tank is nearly empty.\n",
      "Water cuts and relevant details regarding to water suplyer.\n",
      "You can monitor your devices via our website www.aquawatcher.ml as well.\n",
      "Our services will include direct interactions with National Water Supply and Drainage Board for your convinience as well.\n",
      "Cloud Deployment\n",
      "A Node.js based server is deployed in an aws ec2 instance.\n",
      "URL of the website is www.aquawatcher.ml .\n",
      "2 webservers are handling requests and they are configured using nginx. Round robin method is utilized.\n",
      "Admin access is restricted to certain ip addresses and ports to prevent unauthorized requests to admin endpoints.\n",
      "Database is a MongoDB implementation.\n",
      "Database access is restricted to unknown ip addresses.\n",
      "Database takes snapshots of it self to keep backups.\n",
      "Future Plans\n",
      "Water leakage detection functionalities.\n",
      "Extend the compatibility to other chemical types to install with chemical tanks.\n",
      "Set automatic valves.\n",
      "Improve app and server architecture.\n",
      "\n",
      "\n",
      "Extracting Accelerating Adaptive Banded Event Alignment Algorithm with OpenCL on FPGA https://cepdnaclk.github.io/e15-4yp-Accelerating-Adaptive-Banded-Event-Alignment-Algorithm-with-OpenCL-on-FPGA\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Accelerating-Adaptive-Banded-Event-Alignment-Algorithm-with-OpenCL-on-FPGA\n",
      "Team\n",
      "E/15/123, Wishma Herath, email\n",
      "E/15/280, Pubudu Premathilaka, email\n",
      "E/15/316, Suenth Samarasinghe, email\n",
      "Supervisors\n",
      "Prof Roshan Ragel, email\n",
      "Dr Hasindu Gamaarachchi , email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "Nanopore sequencing is a third-generation sequencing technology that can analyze long DNA, RNA fragments in real-time. It measures the change in electrical current as nucleic acids pass through a protein nanopore. The Nanopolish software package utilizes the aforementioned signal level changes to obtain useful results in oxford nanopore DNA sequencing. Adaptive Banded Event Alignment (ABEA) is a dynamic programming algorithm used in nanopolish software packages to polish sequencing data and identify nano-strand nucleotides such as measuring DNA methylation. Prior investigations show that ABEA consumes 70% of total CPU time in nanopolish. Thus, optimizing the ABEA algorithm is vital for nanopore sequencing applications. Previous work has deployed accelerated version of ABEA on GPUs using CUDA and has gained improvements on execution time but with high power requirement. With the advancements of HLS (High-Level Synthesis) tools, FPGAs (Field Programmable Gate Arrays) are emerging as accelerators in the field of high performance computing that gives reasonable runtime performance while consuming less power.In this work, we induce a modified version of ABEA for FPGAs using OpenCL. We experimentally identify and adapt optimization techniques to achieve better performance on DE5-net FPGA. We show that our implementation is able to archive\n",
      "energy consumption of 43% of the previous implementation of ABEA on GPU (f5c). Further, we present performance comparison of our implementations with other different implementations on different platforms in terms of execution time and energy consumption.\n",
      "Introduction\n",
      "DNA can be defined as molecules that encodes the genetic instruction of humans and almost all other organisms. DNA sequencing is the process of identifying the order of the four chemical building blocks called ‘bases’ that make up the DNA molecule. These four bases are adenine (A), thymine (T), cytosine (C) and guanine (G). A rapid DNA sequencing technology is beneficial in different applications including the ability to act preemptively before disease development and commence treatment.\n",
      "The latest sequencing technologies generate data in the order of terabytes. In particular, the MinION sequencer manufactured by Oxford nanopore technologies has the potential to generate around TB of raw signal data during a typical sequencing run. This higher data throughput of sequencers has become a crucial challenge since it requires high computational power to process data.\n",
      "Nanopore sequencing is a third-generation DNA sequencing technology that does not need sample amplification and it offers several advantages over other sequencing technologies. Some of the significant improvements are the ability of long-read sequencing, de novo sequencing and real-time analysis.\n",
      "Nanopore sequencing measures ionic current variation as the DNA molecule passes through the nanoscale pore. This ionic current variation is used to identify each base as it passes through the pore. The ‘base-calling’ is the process of converting the raw signal into character representations of DNA bases (e.g. A, C, G, T). To overcome the base-calling errors, the raw signal is aligned to a biological reference sequence and this process is called ‘polishing’. One of the pivotal algorithms used for polishing in nanopolish is Adaptive Banded Event Alignment (ABEA) which uses a dynamic programming strategy to align raw signal to a biological reference sequence.\n",
      "The GPU-based HPC systems are favorable architectures for data parallelism with higher memory bandwidth. In comparison to GPUs, modern FPGAs provide reasonable processing speed while consuming a fraction of GPUs’ operating power. Compared to multi-core CPUs, choosing an FPGA accelerator is favorable because of its broad performance improvement from one generation to another. Therefore, higher performance and superior power efficiency result in increased performance-to-power-efficiency of FPGAs compared to GPUs and CPUs.\n",
      "DNA sequencing is an emerging field. Therefore, it is crucial to reduce the total implementation time due to several factors like technological improvements. Traditional Hardware Description Languages (HDLs) such as Verilog hardware description language have been a design bottleneck for FPGA accelerators over the past years. Using an HLS tool like OpenCL massively reduces the designing and programming time.\n",
      "OpenCL platform model shown in below is an abstract hardware model for devices. One platform has a host and one or more devices connected to the host. Each device may have multiple Compute Units (CUs) with multiple Processing Elements (PEs).\n",
      "OpenCL Platform Model\n",
      "The OpenCL memory model can be divided into two major memories host and device. Host memory is accessible by only the host, and the device memory accessible by kernels executing on OpenCL devices. The device memory can be further divided into global memory (shared by all the work-groups), constant (read-only memory for the device) memory, local memory (shared by all the work-items in a work-group), and private memory (specific to each work-item).\n",
      "OpenCL Memory Model\n",
      "OpenCL supports two types of kernels, namely NDRange kernels and Single-Work-Item (SWI) kernels. In the NDRange kernel, OpenCL generates a deep pipeline as a computing unit. All the work-items from all the work-groups execute on that pipeline. The compiler automatically performs work-group pipelining. NDRange kernel has a similar thread hierarchy to CUDA. Each thread is called a work-item, and multiple work-items are grouped to form a work-group. In the SWI kernels, the entire kernel is run by a single work-item, and loop iterations are pipelined to achieve high performance. Initiation Interval (II) is the number of hardware clock cycles a pipeline must wait for before launching the successive loop iterations.\n",
      "Related works\n",
      "Previous research, which is done under the objective of accelerating ABEA, deployed an accelerated version of the algorithm on GPUs using CUDA. Their implementation is referred to as f5c-gpu. They have achieved 3-5x performance improvement on the CPU-GPU system compared to the original CPU version of the nanopolish software package. Rucci et al. has presented Smith-Waterman (SW) implementation, which is capable of aligning DNA sequences of unrestricted size. In this work, the kernel is implemented using the task parallel programming model. Rucci et al. SW kernel, has exploited inter-task parallelism. They have utilized the SIMD (Single Instruction Multiple Data) vector capability available in the FPGA.\n",
      "Methodology and Implementation\n",
      "The host program executes on the CPU and loads the dataset into the main memory. Then, it programs the FPGA, allocates buffers, sets kernel arguments and finally launches the kernels. When FPGA finishes the execution, the host program reads the results from FPGA and stores them in the main memory. The CPU and FPGA use direct memory access (DMA) to transfer data through PCI-e bus.\n",
      "OpenCL supports two types of kernels, namely NDRange kernels and Single-Work-Item (SWI) kernels. In the NDRange kernel, OpenCL generates a deep pipeline as a computing unit. All the work-items from all the work-groups execute on that pipeline. The compiler automatically performs work-group pipelining. NDRange kernel has a similar thread hierarchy to CUDA. Each thread is called a work-item, and multiple work-items are grouped to form a work-group. In the SWI kernels, the entire kernel is run by a single work-item, and loop iterations are pipelined to achieve high performance. Initiation Interval (II) is the number of hardware clock cycles a pipeline must wait for before launching the successive loop iterations.\n",
      "A. NDRange Kernel Implementation\n",
      "For our NDRange kernel implementation, we followed the GPU approach taken in f5c-gpu and re-engineered it to evaluate the performance of OpenCL implementation on FPGA. We broke the main kernel into three sub kernels, namely pre, core, and post. We tried to achieve the maximum benefit of hardware resources and optimal work-group configuration by splitting the kernel.\n",
      "B. Single-Work-Item (SWI) Kernel Implementation\n",
      "The implementation of SWI kernels is very similar to a typical C program written for CPU and they are best suited for implementing deeply pipelined algorithms. They contain loops. Each loop-iteration is used as the unit of execution of a kernel. Therefore, multiple loop-iterations are computed in different pipeline stage in parallel.The ABEA algorithm can be divided into three main steps. Initialization of first two bands, filling the cells with score value for the rest of the bands, and finally traceback step which finds the best event-space alignment. Out of these three, the second step is highly compute-intensive.\n",
      "The first step initializes bands and trace arrays, initializes the first two bands and fills an array called ‘kmer_ranks’. This array is required in later computations. Rank for each kmer in the sequence is determined by assigning a weight for each base and shifting according to the place of the base within a kmer. This for-loop can be pipelined with an initiation interval of 1 since there are no data or memory dependency between two iterations.\n",
      "The second step calculates the rest of the bands (b2, b3,..) while moving the adaptive band according to the Suzuki Kasahara rule. Calculation of the current band depends on the previous two bands results. Therefore, the loop has to be serially executed. An inner loop always goes through the band and fills the cells within a band. This loop can be pipelined with a minimum initiation interval of 1 due to the absence of data or memory dependency between loop iterations. The final traceback step consists of a loop with high data dependency between two loop iterations. This behavior results in pipelines with an initiation interval of almost the latency of the pipeline stage. Therefore, it is equivalent to serial execution, which is more suitable for running on a CPU than a SWI kernel on FPGA. According to the above observations, we merged the first step and second step to build a deeply pipelined SWI kernel. Then CPU performs the traceback step. Following figure shows a pipeline diagram including only the main for-loops in the kernel. Computations related to a new read starts its execution in every clock cycle, set of bands in a read executes in a serial manner due to unavoidable data dependencies, and a new cell inside a band starts its execution in every clock cycle.\n",
      "Pipeline Diagram\n",
      "Pseudo Code for SWI Implementation\n",
      "Experiments and Results\n",
      "Experiment Setup\n",
      "Table below shows specifications of hardware accelerators and the host PC used to obtain results.\n",
      "Dataset\n",
      "The experimental data set is a subset of publicly available reads aligned to a 2kb region in the E. coli draft assembly and publicly available NA12878 (human genome) ‘‘Nanopore WGS Consortium’’ sequencing data.\n",
      "The datasets used for the experiments, their statistics (number of reads, total bases, mean read length and maximum read length) are listed below.\n",
      "Performance Results\n",
      "Detailed analysis of all the loops in SWI kernel is shown below. Apart from the three of the main for-loops mentioned above, other loops are fully unrolled when the lower and upper bounds are constant for each iteration of its outer-loop. Rest of the loops are made to execute in a pipeline manner with an initiation interval of 1.\n",
      "Table below shows the estimated resources used by SWI kernel in the design, all channels, global interconnect, constant cache, and board interface compiled for DE5-net FPGA.\n",
      "Figures below show the execution time of each implementation and the power consumption of each implementation.\n",
      "The observations can be analyzed and justified as follows.\n",
      "Eventhough NDRange kernels on FPGA have a lesser power consumption than GPU implementations, they reported a higher execution time. Therefore, they are ranked at 7 and 8 in terms of the energy consumption.\n",
      "Usually, f5c-gpu allocate a set of very long reads selected according to a heuristic to be computed on the CPU and the rest of the reads on the GPU. It results in around 50 seconds of execution time on Tesla K40. But, here we force the f5c-gpu implementation to compute all the reads only on the GPU (cuda-k40). We observe that cuda-k40 and ocl-k40 perform almost at the same level.\n",
      "Unlike in FPGAs, in NVIDIA GPUs, Our NDrange OpenCL implementation executes in a similar programming model to CUDA, and it works as a SIMD. When considering CUDA and OpenCL, there are minor differences. The reason for slight execution time degradation in the ocl-k40 could be the kernel compilation during the execution time.\n",
      "Due to the lesser execution time of cuda-k40, it outperforms the energy advantage of cpu and gets ranks 4 and ocl-k40 gets rank 6.\n",
      "As mentioned, since the CPU’s power requirement is lesser than that of the GPU, based on the energy consumption, the cpu implementation gets rank 5.\n",
      "Among SWI implementations, kernels with suitable FPGA specific optimization techniques shows an improved the performance in execution time and power consumption which lead to less energy consumption. Hence, swi-opt-2 implementation is in rank 1 and others get rank 2 and 3.\n",
      "Among NDRange implementations on FPGA, decomposition of kernels into too many kernels results in poor execution time eventhough the power consumption (estimated for DE5-net) is the same.\n",
      "Among FPGA implementations, all SWI kernels (swi-) perform significantly better than NDRange kernels on FPGA (nd-) in terms of both execution time and power consumption. The best SWI kernel is 2x faster and consumes only 34% of the energy compared to the best NDRange kernel.\n",
      "As shown in Figure, In terms of execution time, GPU implementations (both cuda-k40 and ocl-k40) perform better and 4x faster than swi-opt-2 on DE5-net.\n",
      "However, In terms of the energy required to perform ABEA on the same dataset, SWI kernel implementations on FPGA are in lead. swi-opt-2 on DE5-net needs only 43% of the energy consumption of the GPU implementation on Tesla K40.\n",
      "Conclusion\n",
      "The Adaptive Banded Event Alignment algorithm is an improved version of DNA sequencing, which is extensively used in nanopore DNA sequencing. In the previous work, this algorithm has been parallelized and run efficiently on GPUs.\n",
      "In our work, we introduce several implementations of the ABEA algorithm using OpenCL to run on FPGA. We evaluate the performance of the implementations in terms of runtime and energy consumption.\n",
      "Among FPGA related implementations, SWI kernel with suitable FPGA specific optimization techniques performs better than other FPGA implementations including NDRange kernel.\n",
      "In terms of runtime, GPU implementations (both CUDA and OpenCL NDRange kernel) on Tesla K40 perform better and 4x faster than FPGA implementations on DE5-net.\n",
      "However, in terms of the energy consumption to perform ABEA on the same dataset FPGA implementations are in lead. FPGA implementation on DE5-net needs only 43% of the energy consumption of the GPU implementation on Tesla K40.\n",
      "Through out our work, we identified the potential and ease of using HLS over traditional methods for hardware programming. We used DE5-net FPGA with OpenCL 18.0 for experimenting and evaluation of results. It is a mid-range hardware compared to the state-of-the-art.\n",
      "The maximum predicted frequency we got for the kernels was around 250 Hz and it is even lesser at the execution. The kernel operating frequencies of FPGAs are significantly low compared to CPUs and GPUs. The absence of power sensors in the DE5-net board we had to estimate based on the circuit elements using Intel Quartus Early Power Estimator which they state gives a medium accuracy of the estimate. The true power consumption of kernels may differ due to many other reasons such as the environmental conditions.\n",
      "Therefore, we believe that with the advancement of FPGA hardware and HLS tools with better optimizations methods can provide better results.\n",
      "Publications\n",
      "Semester 7 report\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Brain Computer Interface for controlling virtual objects https://cepdnaclk.github.io/e15-4yp-Brain-Computer-Interface-for-controlling-virtual-objects\n",
      "\n",
      "\n",
      "Brain Computer Interface for controlling virtual objects using self-paced mind intent\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Brain Computer Interface for controlling virtual objects using self-paced mind intent\n",
      "Team\n",
      "E/15/023, Avishka Athapattu, email\n",
      "E/15/059, Prageeth Dassanayake, email\n",
      "E/15/238, Sewwandie Nanayakkara, email\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne, email\n",
      "Prof. Roshan Ragel, email\n",
      "Theekshana Dissanayake, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "Non-invasive EEG based Brain Computer Interface (BCI) systems have been an interesting research area for many fields. However most of the research done on this subject is synchronous, therefore the state of mind of the user is not similar to its natural behaviour. Considering to provide possible experience in practical applications, self-paced BCI systems started gaining popularity in recent years. However, there are certain challenges yet to be addressed when following this method. Out of the research done on self-paced BCI systems most of them are focused on motor-imagery control whereas research on nonmotor imagery mental tasks is limited. In this research, we analyse the possibility of using the techniques used in the motorimagery method for non-motor imagery mental tasks to be fed into virtual object controlling applications.\n",
      "Related works\n",
      "Both non-motor imagery EEG signals related to virtual object manipulation and motor imagery EEG signals are sensorimotor rhythms(SMR). These are specific brain waves over the sensorimotor cortex that are generated after MI or ME. In research by Faradji et.al research paper, they explored the idea of rotation of a virtual object in 3D space in a more natural way. They used auto scalar auto-regressive methods for feature extraction and the classification was done with quadratic discriminant analysis. They obtained a true positive rate (TPR) value of 54.6% TPR and 0.01% FPR. Although there are numerous researches on using motor imagery to control virtual objects that give us higher accuracy [2], research done by Faradji et al. explores the possibility of controlling objects in a more natural way. It was stated that although the TPR is relatively low compared to MI related research, this method is more preferable in real-time applications since this method requires less computational power.\n",
      "Methodology\n",
      "The procedure of self-paced BCI module for virtual object controlling consists of 8 steps\n",
      "The subject should know what are the activities that need to be done since it is important to induce brain waves related to those activities. Most of the research subjects practice to perform a minimum number of activities, for example in virtual object controlling, moving an object up and down, left and right.\n",
      "Subjects should train without feedback provided to acquire the required data as well as to analyze signal patterns Fig 1.\n",
      "Preprocessing the data by artifact reduction(Electrooculogram(EOG), Electromyogram(EMG)) and signal filterings methods such as low-pass/high pass or bandpass filter\n",
      "Feature extraction to find a suitable representation of the electrophysiology data that simplify the subsequent classification or detection of specific brain patterns.\n",
      "With the extracted features classifier being trained, the accuracy should be 70% or higher if not we have to recollect data and extract features and train a classifier model all over again.\n",
      "Training in real-time with the help of visual feedback Fig.2.\n",
      "Update the classifier if the frequency band or EEG pattern changes. (Post-processing)\n",
      "Feed the classification output into an application interface with virtual objects.\n",
      "Figure 1\n",
      "Figure 2\n",
      "Experiment Setup and Implementation\n",
      "First we trained the subject to train three mind intents which are left, right, and None without any visual aid. Afterwards,\n",
      "we trained the subject with GUI aid. We used an OpenBCI Cyton board to capture EEG data in the experimental setup and signals were processed using Python. EEG signals were fed for processing and denoising. We used the OpenBCI GUI to send EEG signals\n",
      "through LSL (Lab Streaming Layer) into a Python application where we extracted the features. Our subject was a male volunteer, of age 24. Initially the subject performed a mental task while watching a virtual object on a screen. This training was done in a limited time trial like 0 -10 seconds, because the performance of the mental task degrades over time.\n",
      "A. Cyton Board (Hardware platform)\n",
      "Cyton board is an Arduino compatible wireless device which is able to capture EEG signals. It consists of 8 biopotential input channels. It must be powered up with 3-6V DC battery only. It has the ability to send samples at 250Hz frequency. Each packet contains a header followed by a sample counter, followed by 8 ADS channel data, followed by the three axes values of the accelerometer, followed by a footer. The USB dongle is connected to the laptop where the cyton board communicates with it using Bluetooth to transfer data.\n",
      "Figure 3\n",
      "B. OpenBCI GUI and LSL\n",
      "OpenBCI GUI (fig 4)here is a powerful software that is used to visualize, record and stream data from OpenBCI boards. This GUI helps to visualize data coming from eight channels of Cyton board to understand if there are any faults in connections. If there are external disturbances that interfere with the visualization of EEG signals it can be recognized as well. It also visualizes the real-time representations of FFT, power spectral distribution and time series.\n",
      "Figure 4\n",
      "Lab Streaming Layer is a system developed for synchronising streaming data for real-time analysis and recording. This is used to send the raw EEG data as time series into a python application for signal processing. PyLSL library is used to input the data to the python application. We are taking in time series EEG data. Data is transferred at 250Hz. Each sample contains data of each channel as floats.\n",
      "C. Electrodes and electrode placement\n",
      "We used eight Golden cup electrodes to sample EEG data. We placed those on the subject according to the 10-20 method. The 10–20 system or International 10–20 system is an internationally recognized method to describe and apply the location of scalp electrodes in the context of an EEG exam. EEGs were placed in 10% and 20% spaces on the scalp as follows. The brain waves related to controlling virtual objects are induced in the motor cortex so electrode placement positions are chosen so as to extract the maximum amount of information. In our experiment, we placed electrodes as shown in Fig. 5.\n",
      "Figure 5\n",
      "D. Virtual Environment\n",
      "Virtual objects that were meant for controlling are created with Unity. The subject is trained on a virtual environment where the display is 15.6 inch, monitor resolution of 1920 x 1080 p and 60Hz. Data of mind intent will be recorded where the subject will focus on moving the objects along axes. Shown in Fig. 6 is the virtual environment we created.\n",
      "Figure 6\n",
      "Results and Analysis\n",
      "Frequency bin components extracted by FFT and Detailed coefficients extracted by wavelet transform were used as features for the classification purpose. All the classifications have the ability to perform in real time. We used Random Forest, QDA, KNN, Catboost and SVM for classifying. In Table II we have compared the accuracies between different classification models. Table III gives the TPR of each class with respect to the model. The confusion matrix of the KNN model is shown in Fig.7.Best hyper\n",
      "parameters combination for each model is determined by a grid search using 10 fold cross validation as evaluation method. KNN model with features obtained with FFT showed the\n",
      "highest accuracy. Overall accuracies obtained when using FFT is higher than when using WT. Since we have data collected over 5 days we used a 5-fold cross validation to get an estimation of the consistency of accuracies. This is shown in figure 8\n",
      "figure 7\n",
      "figure 8\n",
      "Demo\n",
      "Conclusion\n",
      "Filters that were used in EEG signal processing causes a phase shift that makes the usage of wavelet features impossible. Therefore we have used the FFT feature extraction method to provide frequency bins as features for our classification methods. But by substituting those filters (Butterworth filter) with others (zero phase filters) the effect of the phase shift can be removed. We can explore the possibility of using a combination of features provided by WT and FFT to train a more accurate classification model. With all the classification models that were trained KNN algorithm with FFT algorithm would be the ideal choice of features and classification combination. We were able to obtain around 55% TPR value. By implementing statistical analysis we can rectify the anatomical localization effects on EEG data would further increase accuracy of these models. Deep learning methods proved to have a lot of potential when it comes to MI based research in recent history. Possibility of using deep learning approaches in non motor imagery\n",
      "intent with self phased brain computer interfaces is something that can be explored as well.\n",
      "Publications\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Semester 8 slides\n",
      "Athapattu A.D., Dassanayake P.S.B., and Nanayakkara G.S.C., “Self Paced Brain Computer Interface On Sensoriomotor Rhythms For Virtual Objects Controlling” (2021). PDF.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Doppelganger Cartoon https://cepdnaclk.github.io/e15-4yp-Doppelganger-Cartoon\n",
      "\n",
      "\n",
      "Doppelganger Cartoon\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Team\n",
      "E/15/065, De Silva K.G.P.M., e15065@eng.pdn.ac.lk\n",
      "E/15/076, Dileka J.H.S., e15076@eng.pdn.ac.lk\n",
      "E/15/220, Maliththa K.H.H., e15220@eng.pdn.ac.lk\n",
      "Supervisors\n",
      "Dr. Asitha Bandaranayake, asithab@pdn.ac.lk\n",
      "Mr. Sampath Deegalla, dsdeegalla@pdn.ac.lk\n",
      "Mr. Ishan Gammampila\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "Human face recognition and feature extraction have been the most interesting technologies to study for many researchers. It allows a huge number of face images to be recognized in just a short amount of time and extract the face features very easily, rather than recognizing each image and it’s features individually through a normal human’s eyes.Using these technologies researches are being carried out to find the look-alike characters within humans. Using methods for real people, cartoon character faces can hardly be detected and recognized because the face features of cartoon characters differ greatly from those of real people in terms of size and shape. This research was conduct to find the techniques to face detection,feature extraction of a cartoon characters and recognize look-alike cartoon character for a given human image. We have created Disney cartoon repository including 800 images from 77 characters, 5 images from each character with mirror images. Also include face features marked by hand as 35 labeled coordinates. For cartoon face detection and feature extraction, landmark based model trained using feature marked dataset. Used distances and the areas between the landmarks as features. Total 92 features(50 areas and 42 distances) are stored as csv files along with the cartoon images. To compare features of a real image with all the cartoon image features euclidean distance was considered. To increase the accuracy we used landmark based model with hair extraction model and also include gender prediction model. This combined model improves the performance compared to basic landmark based model. Alternatively, we implemented a classification model to find the best matching cartoon character. It shows 84\\% accuracy on training data and 80\\% accuracy on validation after 100 epochs. Finally we were able to find the best matching Doppelganger Cartoon character with good accuracy. So we hope this research and the dataset created by us will be more useful to other researchers.\n",
      "Related works\n",
      "There is not any directly related project happening to find a machine learning algorithm that can find the cartoon character that best looks like you. But some websites published manually founded cartoon images with their matching human image\n",
      "[10][11][13][14]. Also, some websites provide the best matching celebrity image for your\n",
      "uploaded image.[12]Chase, Davis, and Amanda Jacquez did the research and reported\n",
      "it called Finding Your Celebrity Look Alike.[15] They found vector representation of\n",
      "faces and then used OpenCV HaarCascade classifier in order to detect faces. Images\n",
      "inputted to the system and images in IMDB-WIKI data set were represented as 2622\n",
      "dimensional vectors. Then IMDB-WIKI data set to compare with the inputted image\n",
      "and find the similarities between them. According to that, they find the best matching\n",
      "celebrity image/images using the Euclidean distance.\n",
      "Similarity Learning\n",
      "A similarity measure is defined as the distance between various data points. Measuring\n",
      "the similarity between two images is mostly used in image retrieval and computer vision\n",
      "Fields.\n",
      "SimNet[16] is a methodology proposed by Srikar Appalaraju and Vineet Chaoji,\n",
      "This deep siamese network is trained on pairs of positive and negative images using a\n",
      "novel online pair mining strategy inspired by Curriculum learning. Wang, J., Song, Y.,\n",
      "Leung, T., Rosenberg, C., Wang, J., Philbin, J., Chen, B. and Wu, Y. proposed a deep\n",
      "ranking model that learns the similarity metrics directly from images[17]. By comparing\n",
      "the models which are based on handcrafted features, this approach has higher learning\n",
      "capability. Their goal was to learn similarity models. Euclidean distance and nearest\n",
      "neighbor search problem concepts were used to rank similar images. For ranking the loss function, a triplet based network was proposed and image triplets were taken as\n",
      "the inputs. Because of the recent success of the ConvNet for image classification[18],\n",
      "they started a convolution network that contains convolution layers, max-pooling layers,\n",
      "local normalization layers, and fully-connected layers for each individual network. An\n",
      "asynchronized stochastic gradient algorithm[19] with a momentum algorithm[20] was\n",
      "used because training a deep neural network needs a large amount of data. The ImageNet\n",
      "ILSVRC-2012 data set was used as training data which contains roughly 1000 images in\n",
      "each of 1000 categories. A relevance training data which was generated in a bootstrap\n",
      "fashion was also used as a training data set.\n",
      "Face Detection & Recognition\n",
      "The computer technology that finds and identifies the human faces in digital images\n",
      "is called face detection. Feature -based approach and image-based approach are the\n",
      "two main approaches of detecting faces of real people[8]. Imager:: Anime Face is an\n",
      "image-based approach which is used to detect faces of cartoon images[21]. This method\n",
      "finds that the input images are faces or non-faces. As face detection, face recognition\n",
      "also can be classified into two categories called model-based approach and image-based\n",
      "approach. Kohei Takayama, Henry Johan and Tomoyuki Nishita proposed the first\n",
      "relevant work concerning face detection and face recognition of cartoon characters\n",
      "extracting the features[22]. In face detection the skin and the edges of the input image\n",
      "were extracted firstly. Edges were extracted using Canny Method and they considered\n",
      "that the skin color of the cartoon image has to be near to real people. Jaw contour and\n",
      "Face symmetry are used to face detection. For comparison, OpenCV Face Detection\n",
      "and Imager:: AnimeFace[21] are used as candidates and 493 various cartoon characters\n",
      "are given as inputs. By comparing the results, the proposed method is more accurate\n",
      "than the previous method. Feature extraction of the detected face and determination of\n",
      "the individuality of the face and Character search are the main two purposes of their\n",
      "face recognition system. Skin color, Hair color and the Hair quantity are the three\n",
      "features that they extracted to build the feature vector. Face similarity is calculated\n",
      "by measuring the distance between the features of two feature vectors of input image\n",
      "and images in the database. 71% of output images contain the same characters as input\n",
      "images(success) and 29% of the search are failure. Saurav Jha, Nikhil Agarwal and\n",
      "Suneeta Agrawal presented a methodology to improve the Cartoon Face Detection and\n",
      "Recognition systems. MTCNN architecture which offers a deep cascaded multi-task\n",
      "framework is used to face detection. This architecture has three sequential deep CNNs and they are Proposal Net, Residual Net and the Output Net. For securing the baseline\n",
      "results, Haar Features and HOGfeature are employed. Face recognition is experimented\n",
      "on two different techniques, inductive transfer using inception v3 + SVM/GB and their\n",
      "proposed method. The proposed method has two phases. The first phase consists of\n",
      "preprocessing ( converting the cartoon image to gray scale and normalized), landmark\n",
      "extraction(15 facial landmarks of 750 images of 50 characters) and landmark detection(5\n",
      "layer LetNet architecture). In phase 2, leverages the images using a hybrid CNN (HCNN)\n",
      "model. Benchmark IIIT-CFW database which contains 8,928 annotated cartoon images,\n",
      "is used as the dataset.\n",
      "Feature Extraction\n",
      "Feature extraction is important when finding a similar face to another face such as face\n",
      "recognition, face detection, and expression detection. Eyes, mouth, and nose are the most\n",
      "important features for face recognition[23]. Hua Gu, Guangda Su, and Cheng Du from\n",
      "Tsinghua University proposed a method to extract feature points from faces[3]. This\n",
      "approach is based on human visual characteristics. The features of the face are extracted\n",
      "with the properties by using the geometry and the symmetry of faces. Normalizing the\n",
      "image size before processing is not needed in this method. Integrating the local edge\n",
      "information is not easy when we extract the face features. In this method, the Smallest\n",
      "Univalue Segment Assimilating Nucleus(SUSAN) operator was chosen to extract the\n",
      "edge and corner points of the feature area. Feature points were located by using face\n",
      "similarity and geometry.\n",
      "Lilipta Kumar Bhatta and Debaraj Rana proposed a technique for extracting facial\n",
      "features from a color image through skin region extraction. Extracting the characteristics\n",
      "of human face color and face region using Sobel operator[24], Converting the image\n",
      "into YCbCr components and extracting skin region using morphological operation, and\n",
      "extracting the regions of the human eye, mouth, and nose by means of gray level intensity\n",
      "value were the three steps of their proposed technique. FEI face database[25] was used\n",
      "for their experiment. They normalized the image size to 640*480. Using this technique,\n",
      "they experimented and showed that the locating of the feature points is exact and fast,\n",
      "this technique increases the accuracy of face recognition.\n",
      "Face Landmark Detection\n",
      "Facial landmarks detection is used in many computer vision applications like face alignment, drowsiness detection, face recognition, facial expression analysis, facial animation,\n",
      "3D face reconstruction as well as facial beautification, etc.[26] The aim of face landmark\n",
      "detection is to detect the predefined key points like eyes, eyebrows, mouth, nose, etc. Yue\n",
      "Wu·Qiang Ji classified these detection algorithms into three methods like holistic methods, Constrained Local Model (CLM) methods, and regression-based methods depending\n",
      "on how they model the facial appearance and facial shape patterns. The holistic methods\n",
      "models represent the global facial appearance and shape information. The Constrained\n",
      "Local Model leverages the global shape model but builds the local appearance models.\n",
      "And the regression-based methods capture facial shape and appearance information. [27]\n",
      "Yongzhe Yan1,Xavier Naturel,Thierry Chateau, Stefan Duffner, Christophe Garcia,\n",
      "Christophe Blanc divided facial landmark detection algorithms mainly into two types,\n",
      "generative or discriminative. The generative types algorithms, which include the partbased generative models like ASM and holistic generative models like AAM, model the\n",
      "facial shape and facial appearance as probabilistic distributions. They have provided\n",
      "a comparison of different face alignment methods as well as different deep compression\n",
      "models. To this comparison, they included traditional cascaded regression methods and\n",
      "deep learning-based face alignment methods.[26]\n",
      "Zixuan Xu1, Banghuai Li2, Miao Geng3, Ye Yuan identified that face landmarks\n",
      "detection becomes a challenging task when dealing with faces in unconstrained scenarios,\n",
      "especially with large pose variations. They targeted the problem of facial landmark\n",
      "localization across large poses and give a solution based on a split-and-aggregate strategy.\n",
      "When splitting the search space, they proposed a set of anchor templates as references for\n",
      "regression, which well solved the problem which had with large variations of face poses.\n",
      "Then depending on the prediction of each anchor template, they proposed to aggregate\n",
      "the results, which reduce the landmark uncertainty due to the large poses.[28]\n",
      "Hair Segmentation\n",
      "Since the appearance of hair can vary between different people based on their gender, age,\n",
      "ethnicity, and the surrounding environment, automatic hair segmentation is challenging\n",
      "in general.\n",
      "Recently, there has been much success with deep neural networks (DNNs) and in many\n",
      "tasks, including semantic segmentation, DNN-based hair segmentation methods havebeen introduced. The work of Liuet al. [29] introduced a multi-objective learning method\n",
      "for deep convolutional networks that jointly models pixel-wise likelihoods and label\n",
      "dependencies. A nonparametric prior was used for additional regularization, resulting in\n",
      "better performance. Guo and Aarabi [30] presented a method for binary classification\n",
      "using neural networks that perform training and classification on the same data using the\n",
      "help of a pre-training heuristic classifier. They used a heuristic method to mine positive\n",
      "and negative hair patches from each image with high confidence and trained a separate\n",
      "DNN for each image, which was then used to classify the remaining pixels.\n",
      "Methodology\n",
      "Proposed Methodology\n",
      "A machine learning algorithm to find the doppelganger cartoon for a given image is the\n",
      "final outcome of this research. After reviewing previous works on face detection, feature\n",
      "extraction and feature comparison, the proposed methodology is under the following\n",
      "conditions.\n",
      "• Cartoon images are limited to only Disney characters.\n",
      "• Full body of cartoon images and real human images are not compared.\n",
      "• Real human images should be given as the input.\n",
      "Conceptual design\n",
      "There are more approaches done to detect faces, extract features and measure similarity of\n",
      "images of real images and cartoon images separately. But there are very few applications\n",
      "that compare cartoons and real humans using these concepts. After an extensive\n",
      "study of the work done by various approaches and experiments, we came up with a\n",
      "methodology. This application provides a number of analysis steps including preprocessing,\n",
      "face detection, feature extraction, measuring similarity and displaying the results with a\n",
      "user friendly web application. The web application is designed for users who want to\n",
      "find the doppelganger of him/her. The real image is obtained and the result is displayed\n",
      "through the web application. Image preprocessing, face detection, feature extraction and\n",
      "measuring similarity steps are done in the backend.\n",
      "Web Application\n",
      "Frontend of the web application is designed using React and the backend is developed\n",
      "using python Django. React is an efficient, flexible javascript library which is developed\n",
      "by Facebook for building interactive web applications. It lets us compose complex user\n",
      "interfaces from small pieces of codes.The web application basically provides two features.\n",
      "Users can upload a photograph of a person and see the resulting cartoon image. And\n",
      "also they can share it to social media sites like facebook, instagram etc. Django REST\n",
      "framework is a powerful and flexible toolkit for building Web APIs. Since we are building\n",
      "our machine learning model using python tensorflow and keras libraries having a python\n",
      "based backend is easy.\n",
      "Methodological approach\n",
      "Data Collection\n",
      "For image classification tasks there are some popular data sets that are used across research\n",
      "and industry applications. The most popular ones are Imagenet, CIFAR, MINST. But for\n",
      "tasks like cartoon-human image similarity checking there is no well-known dataset that\n",
      "can directly be used. There are some freely accessible comic and animated cartoon image\n",
      "repositories which differ more from human faces out there. Cartoon image repository in\n",
      "this research is only contained with Disney cartoon images which are more similar to\n",
      "human faces to simpler this approach as this is the beginning. Disney cartoon repository,\n",
      "created by our own and ibug 300-w Human repositories are used to train the landmarks\n",
      "detection model. For the classification model, the dataset contains 58 Disney cartoon characters with 406 images, 348 images for training, and 58 images for validation. To\n",
      "test each algorithm of predicting the doppelganger cartoon image, we used a test set\n",
      "contains 20 already known doppelgangers.\n",
      "Data Preprocessing\n",
      "Normalizing the images before feeding them into models is caused to give good results\n",
      "and specific sizes are required from most models. Image data normalization ensures that\n",
      "each pixel has a similar data distribution. This causes us to speed up the converging\n",
      "process. Data normalization can be done by subtracting the mean from each pixel value\n",
      "and dividing them by the standard deviation. So the normalized data is in the range of\n",
      "[0,1] or [0,255].\n",
      "As we were only considering 35 special landmarks on the face, we extracted that 35\n",
      "landmarks from the given 68 landmarks in the human dataset ibug 300-W dataset. The\n",
      "special 35 landmarks, considered in this research, is shown in the Figure 3.4.\n",
      "Face detection and Feature extraction\n",
      "After preprocessing images the next step is to extract features. This is the most important\n",
      "part of this project because the accuracy of the algorithm directly depends on the extracted\n",
      "features. Face detection and feature extraction can be done by various approaches. These\n",
      "approaches are discussed in the section Face detection and Feature extraction\n",
      "Store extracted features\n",
      "When comparing images going through all the images in the repository, extracting\n",
      "features and checking similarities will take a lot of time and need considerably huge\n",
      "performance. So to reduce the effect of above problems we stored the extracted features\n",
      "of cartoon images in a csv file with the image paths. So it is easy to go through the csv\n",
      "file and check similarities with features extracted from human images.\n",
      "Similarity\n",
      "Distance metric or matching criteria is the main tool for finding the similar images. Two\n",
      "vectors, a vector with extracted features of the real human image and a feature vector of a cartoon should be compared to find the similarity of the two images. The L1 metric\n",
      "(Manhattan Distance), the L2 metric (Euclidean Distance) which are main two distance\n",
      "metrics, have been proposed in the literature for measuring similarity between feature\n",
      "vectors.\n",
      "Euclidean Distance : If there is two points a and b have n dimensions such as\n",
      "a=(x1 ,x2,…,xn) and b=(y1,y2,…,yn) , the Euclidean distance between two points can be\n",
      "generalized as in Equation 3.1\n",
      "The calculated Euclidean distances of each cartoon feature vector with the real image\n",
      "feature vector are compared and the cartoon image with the least distance is selected as\n",
      "the best matching cartoon image for the real image.\n",
      "Experiment Setup and Implementation\n",
      "Research Tools\n",
      "In the purpose of implementing our project we have used several libraries and frameworks.\n",
      "• Numpy : This is a library for python programming which supports multidimensional arrays and matrices, with a large collection of high level mathematical\n",
      "functions.\n",
      "• Keras : This is an API designed to follow best practices for reducing cognitive\n",
      "loads and it offers consistent and simple APIs which minimizes the number of user\n",
      "actions for common use cases.\n",
      "• Tensorflow : Tensorflow is a open source library for machine learning. It can be\n",
      "used across a range of tasks which involve deep neural networks.\n",
      "• Cv2 : OpenCV is a library which is designed for solving computer vision problems.\n",
      "• MobileNetV1: A family of general purpose computer vision neural networks\n",
      "designed with mobile devices in mind to support classification, detection and more.\n",
      "This is pre-trained on the ImageNet dataset, a large dataset consisting of 1.4M\n",
      "images and 1000 classes.\n",
      "• Matplotlib : Matplotlib is a comprehensive library for creating static, animated,\n",
      "and interactive visualizations in Python. In our case it is very useful in displaying\n",
      "images.\n",
      "• os: This module provides a portable way of using operating system dependent\n",
      "functionality\n",
      "• Csv: This library helps to manipulate csv files writing and reading.\n",
      "• PIL: Pillow library adds fairly powerful image processing capabilities and provides\n",
      "extensive file format support, and efficient internal representation.\n",
      "• React: This is an open source front end development javascript library for building\n",
      "interactive user interfaces.\n",
      "• Django REST framework: This is a powerful and flexible toolkit for building\n",
      "restful web APIs.\n",
      "To run and test codes which are written in python, we used Google Colaboratory.\n",
      "It is a jupyter notebook which runs in the cloud and is integrated with google drive,\n",
      "making it easy to set up ,access and share. So the image repository is located in the\n",
      "shared google drive. By default this notebook runs on the CPU. But it supports GPU\n",
      "and TPU hardware acceleration for achieving higher performance.\n",
      "Data manipulation and Testing\n",
      "Our cartoon data sets is a repository containing Disney cartoon images. Though the\n",
      "pretrained models are not perfectly detecting the cartoon faces, this dataset is containing\n",
      "only frontal faces of cartoon images. Data manipulation for cartoon landmarks detection\n",
      "model is done by annotating the landmarks on the cartoon faces using a tool. The iBUG\n",
      "300-W dataset which has already annotated landmarks is used as the human dataset to\n",
      "train the model for landmarks detection.\n",
      "Pitfalls and workarounds\n",
      "During this project, one of the main challenges encountered was to get the background\n",
      "knowledge of the data set, feature extraction and face detection of images. As a remedy\n",
      "for that issue, we had to do lots of background research. Finding a strong data set with\n",
      "cartoon images is required for our task. At first, we could not properly understand the\n",
      "already existing data sets. After gaining knowledge about previous works, we understood\n",
      "that there are a number of data sets which contain various cartoon images but existing\n",
      "data sets are still lacking similarities compared to humans. As a solution, we decided to\n",
      "collect images to build a Disney cartoon image repository on our own as Disney cartoons\n",
      "are more similar to human images. But still the lack of data for training purposes has\n",
      "remained. A number of researches are done on face detection and feature extraction.\n",
      "But one issue with that was lack of documentation about feature extraction and face\n",
      "detection of cartoon images. After reviewing the research papers, we had to spend a\n",
      "considerable amount of time figuring out how the pretrained models work on cartoon\n",
      "images and human images to select a best model for our case. By analyzing the results\n",
      "given by the models, we figured out that the pretrained models are not performed well\n",
      "in cartoon face detection. But actually training a model from scratch is very expensive\n",
      "and requires huge data sets to achieve good generalization performance.\n",
      "The method landmarks detection, is required to detect the face first and detecting\n",
      "face of cartoon images is not similar to human face detection. We handled this by using\n",
      "the frontal face of cartoons and using the dlib frontal face detector as the detector.\n",
      "Also, when running the code on google colabs, due to the high throughput of the data\n",
      "set, we faced an issue of insufficient memory and low speed. We handled this problem by\n",
      "switching the run time mode to GPU from none in the Google Colabs environment.\n",
      "Results and Analysis\n",
      "Overall analysis\n",
      "All the algorithms we tried on this research are tested on the same test set which contains\n",
      "already known doppelgangers. To compare the models we ranked the resulted images\n",
      "according to the ascending order of euclidean distance. Table 5.2 Shows the summary of ranks for each cartoon. For some images, the models do not give an output because of\n",
      "some failures in the hair extraction model or gender prediction model for some cases. As\n",
      "an example, some female images can have short hair, then the gender prediction model\n",
      "wrongly predicted the gender and then our expected result is not within the resulted\n",
      "images.\n",
      "Figure 5.32 shows the variation of the ranks of each cartoon character for different\n",
      "weight values. By analyzing the graph, we can conclude that the rank varies for different\n",
      "weights. Some cartoons get better rank in w = 0.5 and someones get better at w=0.2.\n",
      "The graph of w=1 (landmarks-based model only) always gives higher ranks (far away\n",
      "from expected result) for all cartoons with respect to other models. According to the\n",
      "graph, w=0.2 and w=0.5 (combined model) gives some good ranks for all cartoons.\n",
      "But according to the classification results in the Table 5.2, the classification model\n",
      "gives the best results for all cartoons as all the expected outputs are within the top 5\n",
      "ranks.\n",
      "Conclusion\n",
      "During recent years, many researches have been carried out in various ways of feature\n",
      "extraction of human images, finding looks-alike twins, and so on. We entered the research\n",
      "using the pre-trained model based approach and after analyzing the results, we concluded\n",
      "that we should simplify this by considering only the Disney cartoons which are more\n",
      "similar to humans as this is the beginning and train our models for building the algorithm.\n",
      "In this paper, we mainly researched an approach that finds the best matching Cartoon\n",
      "character for human image based on landmarks model. Because lack of existing cartoon\n",
      "datasets, we have created a dataset with landmarks on the faces of cartoon characters\n",
      "for training a model and it will be more useful for future researchers. Combination of\n",
      "landmark based model with hair extraction model and gender prediction model has\n",
      "improved the performance. But the best cartoon image is resulted for different weights\n",
      "on the models for various images. Alternatively implemented classification model shows\n",
      "84% accuracy on training data and 80% accuracy on validation after 100 epochs. As\n",
      "features on cartoon faces such as eyes, nose are more differ from human features, the\n",
      "combined model is also not accurate like classification. So, the classification algorithm\n",
      "with a strong dataset will be the best model for this finding doppelganger task. Today’s\n",
      "society is interesting to compare their appearance with cartoons because it brings mental\n",
      "relaxation and fun for their minds. So we hope this research will be helpful for them.\n",
      "Publications\n",
      "Semester 7 report\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Semester 8 slides\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Explainable Machine Learning for Real World Resource Constrained Problems https://cepdnaclk.github.io/e15-4yp-Explainable-Machine-Learning-for-Real-World-Resource-Constrained-Problems\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Team\n",
      "E/15/092, Imesh Ekanayake, email\n",
      "E/15/187, Devin Kulanjith, email\n",
      "Supervisors\n",
      "Dr. Dhamayanthi Herath, email\n",
      "Dr. Upul Jayasinghe, email\n",
      "Dr. Kasun Amarasinghe, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "Machine Learning (ML) has contributed to many advances in science and technology.\n",
      "Recently a trend of applications in high-stake decision-making has been initiated. The development of ML made the decision-making process unclear with complex black-box models, especially the state-of-the-art models which have maximized the performance are more complex, inexplicable, and hard to explain. On the contrary, high-stakes settings as healthcare, finance, and criminal justice, have strict ethical concerns that made a mandatory requirement to explain each decision or the model as a whole. Besides, the acts and regulations like General Data Protection Regulation (GDPR)\n",
      "make it obligatory to explain the decisions made by computer systems and became a social right to explanation.One of the most pressing problems in this field is explainability and interpretability of the decisions which are made by the several algorithms Moreover, it is necessary to ensure the fairness and transparency of a decision to obtain the stakeholders’ trust. The theoretical knowledge of explainable machine learning is not well-tested on real-world problems with direct social impact. In this paper, we have identified a quandary that reflects the characteristics of a high-stakes machine learning problem in the public sector. An early warning system to predict and help the projects that could be unfunded in an educational crowdfunding platform in a resource-constrained environment has been presented.\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Even though the machine learning became one of the hot topics in current days in almost all the fields, trust, transparency and fairness of the predictive models has not been properly considered. In high stake settings, where it makes a direct impact on people’s lives or future of a business it is important to obtain the trust of the domain experts to use the model predictions in decision making process. In the above workflow, we have trained 8 machine learning algorithms in periodic manner using cohort concept and designed\n",
      "a grid search for the time series data to optimize without having a data leakage. Next, we\n",
      "obtained the overall performance of the predictions to select the best performing models. Once those models were selected the top-K (here we have taken K as 100) recall has been measured to select the best predictive model for the task and selected CatBoost model for further analysis.\n",
      "Next we have used explainable AI models (SHAP and LIME) analyse individual analysis of the predictions, there we obtained the importance of each attribute separately for the prediction of each instance. Once the top-k,\n",
      "middle-K and bottom-k importance of attributes are selected, then values are normalized for each instance (addition of importance become 1 in each instance).\n",
      "Finally the correlation, of the normalized importance with the actual values have been considered and identified the distribution of actual values along with the importance variation.\n",
      "In conclusion, the final machine learning model has adhere to the thinking pattern of users and domain experts can use the explanation to improve the project quality using the insights of the model.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Hand Gesture Recognition using sEMG https://cepdnaclk.github.io/e15-4yp-Hand-Gesture-Recognition-using-sEMG\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Visit Department Site\n",
      "Improved Gesture Recognition for sEMG based Human Machine Interface\n",
      "Team\n",
      "E/15/043, Yasiru Bhagya T.P., yasirubhagya@eng.pdn.ac.lk\n",
      "E/15/131, Hisni Mohammed M.H., hisnimohammed@eng.pdn.ac.lk\n",
      "E/15/348, Suhail S., suhailsajahan@eng.pdn.ac.lk\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne, isurunawinne@eng.pdn.ac.lk\n",
      "Prof. Roshan Ragel, roshanr@eng.pdn.ac.lk\n",
      "Mr. Theekshana Dissanayake, theekshanadis@eng.pdn.ac.lk\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "1. Abstract\n",
      "Identifying hand gestures using surface electromyography (sEMG) signals is vital in the development of next-generation human-machine interfaces (HMI). sEMG based HMIs provide users with a more natural and convenient way to communicate with computing systems. sEMG signals recorded from muscle tissues give information about the intended muscle movements triggered by the brain waves. Identifying these movements allows developing interfaces that can control computing devices. In this research, an attempt was made to improve a hand gesture recognition model that could be used as a human-machine interface using an online open dataset of sEMG signals. First sEMG signals were preprocessed using a bandpass filter and notch filter to remove noises in the signal. Then various time, frequency, and time-frequency domain features extracted and they were fed into machine learning algorithms such as random forest, support vector machines (SVM), K-nearest neighbors (K-NN), and recurrent neural networks. All the results were validated using 10-fold cross-validation. Maximum testing accuracy of 90.03% was obtained using an SVM classifier with root mean square, mean frequency, and median frequency of the signal as features for 24 channel data. Later an attempt was also made to use this result to control a simple game developed in Unity using sEMG signals collected from an 8-channel signal acquisition device.\n",
      "2. Related works\n",
      "Various approaches have been proposed in the area of EMG-based applications. As sEMG signals from different muscle groups exhibit different characteristics, different techniques have been employed to characterize muscle movement. But in general, it is all down to feature extraction to represent the signal as a vector of features, followed by feature selection to reduce the vector’s dimensionality, and finally, classification to determine each vector as belong to one of a fixed set of classes [5].\n",
      "Paleari et al. [6] have used the root mean square (RMS) feature with a neural network model to classify hand movements using 192 channel high-density sEMG (HD-sEMG) signals from the forearm. Stango et al. [7] have used the SVM classifier with variogram, which is a measure of the degree of spatial correlation to build a model to control upper limb prostheses using HD-sEMG signals. Liu et al. [8] proposed an invariant feature extraction (IFE) framework based on kernel fisher discriminant analysis to enhance the robustness of myoelectric pattern recognition. Tsai et al. [9] proposed multi-channel EMG-based motion pattern recognition. They have used the SVM classifier with STFT-ranking features based on short-time Fourier transform and principal component analysis to feature selection. Amma et al. [10] used HD-sEMG signals recorded by 192 electrodes to classify finger gestures using the RMS feature and a naive Bayes classifier. Most of these researches based on HD-sEMG signals and complex feature extraction with complex deep learning models that give higher accuracy are not suitable to implement in a real-time environment as they have higher latencies, expensive in terms of electrode configuration, and inconvenient for the user.\n",
      "3. Methodology\n",
      "3.1. Data Set\n",
      "An online open dataset “putEMG” [4] published by Kaczmarek et al. was used for our research. This dataset is a database of sEMG signals collected through an experiment conducted on a group of 45 subjects. This group consisted of 37 males and 8 females aged between 19 and 37 years old. To record sEMG signals, a signal acquisition device with 24 electrodes placed in 3 elastic bands such that 8 electrodes per elastic band was used. Signals were recorded from right forearm muscles. The signals were sampled at the rate of 5120 Hz, with a 12-bit analog to digital converter.\n",
      "The sEMG signals were recorded when subjects were not moving the hand-keeping the muscles relaxed (idle gesture), when hand fist, while flexion of the hand, while the extension of the hand, and while pinching the fingers (pinching with thumb and index finger, pinching with thumb and middle finger, pinching with thumb and ring finger, and pinching with thumb and small finger). Therefore, this dataset includes the idle gesture and 7 active gestures. Figure 1 shows all the gestures that are included in the dataset and Figure 2 shows the electrode placement configurations used to acquire signals.\n",
      "It is very important to record sEMG signals when subjects perform gestures repetitively as when doing the same gesture again and again subjects tend to perform gestures in a similar pattern [4]. putEMG dataset was created using an experiment that was conducted such that each data instance consists of 20 repetitions of each gesture. Therefore, this dataset allows us to develop and evaluate more robust algorithms for gesture recognition systems.\n",
      "3.2. Data Preprocessing\n",
      "putEMG data contains raw sEMG signals directly collected from the muscles therefore these signals contain noises. Due to the amplifier’s direct current offsets, the signals will have low-frequency noises and due to electronic devices (computers, radio broadcasts, etc.), the signal will have high-frequency noises [16]. Typically, sEMG signals are within the 10-700 Hz frequency range and signals beyond this range are considered not useful. Furthermore, sEMG signals may contain interference noises generated by the main power line and other equipment used during the acquisition of data. Therefore, a 5th order bandpass filter of range 20 and 700 Hz was used to filter out low, high-frequency noises, and an adaptive notch filter (ANF) was used to reduce interferences. Attenuating frequencies used for ANF were 30, 50, 90, 60, and 150 Hz. These filter parameters were determined using the suggestions made by the true authors of the dataset [4].\n",
      "Figure 3 shows the sEMG signals before and after using a bandpass and notch filter. Furthermore, each active gesture in the dataset is of 1 second or 3 seconds, separated by a 3-second idle gesture. Therefore, the dataset contains more ‘idle’ gestures than any other active gestures hence the dataset is unbalanced. Therefore, extra idle gestures were removed to balance the dataset.\n",
      "3.3. Feature Extraction\n",
      "For the classification using classic machine learning models, ten features from time, frequency, time-frequency domains were extracted from each channel. They were integral absolute value, mean absolute value, mean frequency, median frequency, root mean square, slope sign change, variance, waveform length, Willison amplitude, zero-crossing, and Mel-frequency cepstral coefficients. In previous works, it is found that these features give higher performance, high insensitivity to window size, and low computational complexity [17].\n",
      "Root mean square (RMS) which is a time-domain feature gives insights into the amplitude of the signals. The amplitude of the sEMG signal is related to the contraction level of muscles and muscle force involved during the movements. this feature was calculated as,\n",
      "sEMG signal frequencies vary with different muscle movements.\n",
      "Therefore, frequency domain features such as mean frequency (MNF) and median frequency (MDF) of the signal are also used in the feature vector that is fed into gesture recognition classifiers. These features were calculated as,\n",
      "Other time domain features mean absolute value (MAV), wave-length (WL), variance (VAR), slope sign change (SSC), and Willison amplitude (WAMP) were calculated as follows,\n",
      "To find Mel-frequency cepstral coefficients (MFCC), the mfcc function from the librosa python library is used. While calculating these features sliding windows size of 2048 and hop length size of 1024 is used. These extracted features were grouped into four separate sets and fed into classifiers separately. The first feature set consists of root mean square, mean frequency, and median frequency. The feature sets II and III were based on previous studies. The second feature set is based on the suggestion made by Hudgins et al. [18] which consists of features mean absolute value, wave-length, zero-crossing, slope sign change. The third feature set consists of integral absolute value, variance, wave-length, zero-crossing, slope sign change, and Willison amplitude was proposed by Du et al. [19]. Finally, feature set IV is made up of MFCC data. Moreover, both preprocessed data and MFCC data were used to train the neural network models.\n",
      "3.4. Classification\n",
      "Classic machine learning classifier models and deep learning were used to identify eight gestures: idle, fist, flexion, extension, pinching with thumb and index finger, pinching with thumb and middle finger, pinching with thumb and ring finger, and pinching with thumb and small finger. Classic machine learning models used are k-nearest neighbors (k-NN), random forest (RF), support vector machine (SVM), and linear discriminant analysis (LDA). Two sets of data, one with features extracted from all 24 channels data and another with features extracted from 8 channel data were fed into these classifiers.\n",
      "The grid search algorithm [20] is used for optimizing parameters for classifier models. To evaluate the classifier models, 10-Fold cross-validation was used. All of the classic machine learning algorithms, the grid search algorithm, and cross-validation used were taken from Python scikit-learn API [20].\n",
      "Furthermore, we experimented with two types of neural networks, the long-short-term memory (LSTM) model and the LSTM with convolutional neural network (CNN) model. Extracted MFCC data was fed to the neural network. Neural networks were implemented using TensorFlow with Keras in python language. The first model is a basic model with two LSTM layers and one dense layer to output each class. Here class labels were one-hot encoded and categorical cross-entropy was used as the error function. Figure 3.4 shows more details about the LSTM model. Figure 3.5 shows LSTM-CNN model parameters.\n",
      "4. Experiment Setup and Implementation\n",
      "4.1. Signal Acquisition Device\n",
      "Our device is inspired by the Backyard Brains’ Muscle SpikerShield device. Muscle SpikerShield has 6 channels of sEMG signal acquisition capability. To use it we have to connect it to an Arduino board. On the other hand, our device has 8 channels, a dedicated 8 channel ADC and a powerful STM32F103 microcontroller. Figure 3.6 shows the high-level view of our device and Figure 3.7 shows the circuit diagram for a single channel. Figure 3.8 and Figure 3.9 Illustrates the printed circuit board (PCB) layout of our device. Figure 3.10 shows our final signal acquisition device and Figure 3.11 shows the the 8 channel electrode band.\n",
      "4.2. The Game\n",
      "A game similar to the space invader game has been created to demonstrate the project. The device will recognize the gesture, then the gesture will be classified through the machine learning algorithms and then the movement of the spaceship can be changed according to the assigned gesture for each movement. The game has been created using the Pygame library, which is a python library mostly used to build games. To make the game interesting, we have created the game with an environment that is similar to the current pandemic situation. The covid19 viruses come towards the earth and the player has to protect the earth from the virus by shooting it from the spaceship. The spaceship can be moved in all 8 directions using the arrow keys and it can fire using the space key. If the covid19 virus reaches the earth or comes near to the spaceship then the game will be ended. Figure 3.12 shows the interface of our game.\n",
      "4.3. Real-Time Controlling\n",
      "An attempt was made to control the game using the 8 channel signal acquisition device\n",
      "developed by us. The first signal acquired by the device was filtered using 5th order\n",
      "bandpass filter of range 20 and 700 Hz. Then root mean square, mean frequency, and\n",
      "median frequency of the signal were extracted and fed to support vector machine classifiers\n",
      "as features to identify the gestures. Figure 3.13 shows our signal acquisition device while\n",
      "testing.\n",
      "5. Results and Analysis\n",
      "Feature Set I: root mean square, mean frequency, median frequency\n",
      "Feature Set II: mean absolute value, wave-length, zero-crossing, slope sign change.\n",
      "Feature Set III: integral absolute value, variance, wave-length, zero-crossing, slope sign change, and Willison amplitude\n",
      "Feature Set IV: Mel-frequency cepstral coefficients\n",
      "Classifier models: linear discriminant analysis, k-nearest neighbor, support vector machine, random forest\n",
      "Table 1 and Figure 8 illustrate the validation results obtained for different classifier models with different feature sets using 24 channel data. According to the results feature set I which consists of root mean square (RMS), mean frequency, and median frequency, gives the best result for all classifier models. Furthermore, the support vector machine (SVM) classifier gives the highest accuracy of 90.3% for 24 channel data. The linear discriminant analysis (LDA) model has the second-best accuracy of 89.92%. Feature set IV has the lowest accuracy for all the classifier models.\n",
      "Table 2 and Figure 9 illustrate the precision score for each gesture when different classifiers are used with feature set I and 24 channel data. Similarly, Table 3 and Figure 10 illustrate the recall value for each gesture when different classifiers are used with feature set I and 24 channel data. Results from Table 2 and Table 3 for we can see that idle, fist, flexion, and extension gestures have higher precision and recall scores, that is all the classifier models tend to predict more accurately these sets of gestures than pinching gestures. Idle gestures are correctly classified by the random forest classifier model with the highest recall score of 0.96 and fist gestures are correctly identified by the SVM classifier with the highest recall of 0.89. LDA has the highest recall for flexion and extension of hand with scores of 0.91 and 0.94 respectively. Pinching thumb with index finger have the lowest recall value for all the classifiers with the best recall score being 0.64 with the LDA classifiers. Other pinching gestures are also correctly identified by the LDA model with the highest recall values of 0.85, 0.86, and 0.88 for pinch thumb-middle, pinch thumb-ring, and pinch thumb-small gestures.\n",
      "Table 4 and Figure 11 illustrate the classifier results for 8 channel data. For classifying 8 gestures, the highest accuracy of 86.02% was achieved using the SVM classifier with feature set I. LDA model performed better with the feature set III achieving an accuracy of 85.47% and the random forest model also performed better with the feature set III with an accuracy of 85.17%.\n",
      "Table 5 and Table 6 illustrate the precision score and recall value respectively for each gesture when different classifiers are used with feature set I and 8 channel data. The same result is graphically illustrated in Figures 12 and 13. Similar to 24 channel data results pinching finger gestures had low precision and recall values compared to the other 4 gestures. Predicting idle, fist, and flexion of hand have the highest recall value when SVM classifier is used while k-nearest neighbor classifier predicts extension of hand more accurately with the recall value of 0.94. For pinching fingers, SVM predicted more accurately with the highest recall values of 0.52, 0.65, and 0.72 for pinch thumb-index, pinch thumb-middle, and pinch thumb-small gestures.\n",
      "Few researchers have worked on the putEMG dataset for different sEMG applications, and Table 6 illustrates the results obtained. Tsinganos et al. [21] have worked on data augmentation methods and with the use of these techniques, they have achieved a maximum testing accuracy of 96.97%. Our results do not match with their results but their research was mainly based on data augmentation techniques that are to create new data from existing data. The performance of machine learning models improves with the amount of data available. This could be the reason that they have achieved higher accuracy. Nacpil et al. [22] have worked on creating a model to control steering wheel for drivers with disabilities and they have achieved a precision score of 96% and 94% for extension and flexion of the hand. We have achieved a precision of 95% for both of these gestures using the SVM classifier with feature set I and also we are classifying eight gestures.\n",
      "6. Conclusion\n",
      "The objective of this research was to find a hand gestures recognition model that could be useful to interact with machine interfaces using sEMG signals. If we consider results obtained for 24 channel data, the difference in classification accuracies achieved by LDA and SVM are insignificant for feature set I. From precision and recall results also suggest that both LDA and SVM classifiers have similar results. If we consider results obtained for 8 channel data, the SVM classifier with the feature set I performed better. Precision and recall results also suggest that the SVM classifier gives a better result. In both cases, pinching gestures were not accurately classified compared to other gestures: idle, fist, flexion, and extension gestures. Therefore, a system that utilizes a support vector machine classifier with root mean square, mean frequency, and median frequency as features could be adopted to implement an end-user human-machine interface that utilizes limited gestures. This system might not be very useful for classifying pinching gestures as they have lower precision and recall values, and on average they are below 70%.\n",
      "sEMG signals characteristic from different muscle groups and characteristics of a single muscle group of different locations have variations. These results obtained depend on the muscle location where signals are acquired and the signal acquisition device used in the experiment. Therefore, when implementing a real-world end-user system these factors also need to be considered.\n",
      "References\n",
      "[1]\n",
      "T. M. M. V. M.A. Cavalcanti Garcia, “Surface electromyography: Why, when and how to use it,” Acta Médica Colomb., vol. 43, no. 2S, p. 176, 2019, doi: 10.36104/amc.2018.1400.\n",
      "[2]\n",
      "M. B. I. Reaz, M. S. Hussain, and F. Mohd-Yasin, “Techniques of EMG signal analysis: Detection, processing, classification and applications,” Biol. Proced. Online, vol. 8, no. 1, pp. 11–35, 2006, doi: 10.1251/bpo115.\n",
      "[3]\n",
      "W. Wei, Y. Wong, Y. Du, Y. Hu, M. Kankanhalli, and W. Geng, “A multi-stream convolutional neural network for sEMG-based gesture recognition in muscle-computer interface,” Pattern Recognit. Lett., vol. 119, pp. 131–138, 2019, doi: 10.1016/j.patrec.2017.12.005.\n",
      "[4]\n",
      "P. Kaczmarek, T. Mánkowski, and J. Tomczýnski, “PutEMG—A surface electromyography hand gesture recognition dataset,” Sensors (Switzerland), vol. 19, no. 16, 2019, doi: 10.3390/s19163548.\n",
      "[5]\n",
      "A. Jaramillo-Yánez, M. E. Benalcázar, and E. Mena-Maldonado, “Real-time hand gesture recognition using surface electromyography and machine learning: A systematic literature review,” Sensors (Switzerland), vol. 20, no. 9, pp. 1–36, 2020, doi: 10.3390/s20092467.\n",
      "[6]\n",
      "M. Atzori et al., “Characterization of a benchmark database for myoelectric movement classification,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 23, no. 1, pp. 73–83, 2015, doi: 10.1109/TNSRE.2014.2328495.\n",
      "[7]\n",
      "V. H. Cene, M. Tosin, J. Machado, and A. Balbinot, “Open database for accurate upper-limb intent detection using electromyography and reliable extreme learning machines,” Sensors (Switzerland), vol. 19, no. 8, 2019, doi: 10.3390/s19081864.\n",
      "[8]\n",
      "F. Giordaniello et al., “Megane Pro: Myo-electricity, visual and gaze tracking data acquisitions to improve hand prosthetics,” IEEE Int. Conf. Rehabil. Robot., pp. 1148–1153, 2017, doi: 10.1109/ICORR.2017.8009404.\n",
      "[9]\n",
      "Y. Du, W. Jin, W. Wei, Y. Hu, and W. Geng, “Surface EMG-based inter-session gesture recognition enhanced by deep domain adaptation,” Sensors (Switzerland), vol. 17, no. 3, pp. 6–9, 2017, doi: 10.3390/s17030458.\n",
      "[10]\tC. Amma, T. Krings, J. Böer, and T. Schultz, “Advancing muscle-computer interfaces with high-density electromyography,” Conf. Hum. Factors Comput. Syst. - Proc., vol. 2015-April, pp. 929–938, 2015, doi: 10.1145/2702123.2702501.\n",
      "[11]\tM. Paleari, M. Di Girolamo, N. Celadon, A. Favetto, and P. Ariano, “On optimal electrode configuration to estimate hand movements from forearm surface electromyography,” Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS, vol. 2015-Novem, pp. 6086–6089, 2015, doi: 10.1109/EMBC.2015.7319780.\n",
      "[12]\tA. Stango, F. Negro, and D. Farina, “Spatial Correlation of High Density EMG Signals Provides Features Robust to Electrode Number and Shift in Pattern Recognition for Myocontrol,” IEEE Trans. Neural Syst. Rehabil. Eng., vol. 23, no. 2, pp. 189–198, Mar. 2015, doi: 10.1109/TNSRE.2014.2366752.\n",
      "[13]\tJ. Liu, D. Zhang, X. Sheng, and X. Zhu, “Enhanced robustness of myoelectric pattern recognition to across-day variation through invariant feature extraction,” Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS, vol. 2015-Novem, no. 1, pp. 7262–7265, 2015, doi: 10.1109/EMBC.2015.7320068.\n",
      "[14]\tA. C. Tsai, J. J. Luh, and T. Te Lin, “A novel STFT-ranking feature of multi-channel EMG for motion pattern recognition,” Expert Syst. Appl., vol. 42, no. 7, pp. 3327–3341, 2015, doi: 10.1016/j.eswa.2014.11.044.\n",
      "[15]\tP. Kaczmarek, T. Mánkowski, and J. Tomczýnski, “putEMG: sEMG Gesture and Force Recognition Datasets – Biomedical Engineering and Biocybernetics Team.” https://biolab.put.poznan.pl/putemg-dataset/ (accessed Feb. 16, 2021).\n",
      "[16]\tH. A. Yousif et al., “Assessment of Muscles Fatigue Based on Surface EMG Signals Using Machine Learning and Statistical Approaches: A Review,” IOP Conf. Ser. Mater. Sci. Eng., vol. 705, p. 012010, Dec. 2019, doi: 10.1088/1757-899X/705/1/012010.\n",
      "[17]\tM. A. Oskoei and H. Hu, “Support vector machine-based classification scheme for myoelectric control applied to upper limb,” IEEE Trans. Biomed. Eng., vol. 55, no. 8, pp. 1956–1965, 2008, doi: 10.1109/TBME.2008.919734.\n",
      "[18]\tB. Hudgins, P. Parker, and R. N. Scott, “A New Strategy for Multifunction Myoelectric Control,” IEEE Trans. Biomed. Eng., vol. 40, no. 1, pp. 82–94, 1993, doi: 10.1109/10.204774.\n",
      "[19]\tY. C. Du, C. H. Lin, L. Y. Shyu, and T. Chen, “Portable hand motion classifier for multi-channel surface electromyography recognition using grey relational analysis,” Expert Syst. Appl., vol. 37, no. 6, pp. 4283–4291, 2010, doi: 10.1016/j.eswa.2009.11.072.\n",
      "[20]\tF. Pedregosa et al., “Scikit-learn: Machine learning in Python,” J. Mach. Learn. Res., vol. 12, no. May 2014, pp. 2825–2830, 2011.\n",
      "[21]\tP. Tsinganos, B. Cornelis, J. Cornelis, B. Jansen, and A. Skodras, “Data augmentation of surface electromyography for hand gesture recognition,” Sensors (Switzerland), vol. 20, no. 17, pp. 1–23, 2020, doi: 10.3390/s20174892.\n",
      "[22]\tE. J. Nacpil and K. Nakano, “Driving Simulator Validation of Machine Learning Classification for a Surface Electromyography-Based Steering Assistance Interface,” Adv. Intell. Syst. Comput., vol. 1206 AISC, pp. 143–149, 2021, doi: 10.1007/978-3-030-51064-0_19.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Identifying keywords in legal articles using ML techniques https://cepdnaclk.github.io/e15-4yp-Identifying-keywords-in-legal-articles-using-ML-techniques\n",
      "\n",
      "\n",
      "Identifying Keywords in Legal Articles using Machine Learning Techniques\n",
      "Identifying Keywords in Legal Articles using Machine Learning Techniques\n",
      "Abstract\n",
      "This paper presents a survey of strategies and approaches for keyword extraction task. The paper provides an in depth review of existing analysis, additionally to the organisation of strategies. Related work on keyword extraction is concerned for supervised and unsupervised learning strategies.\n",
      "Nowadays there are plenty of legal documents offered in electronic format. Therefore, legal scholars and professionals are in need of systems able to search and quantify connotative details of those documents. Legitimate information and customary laws are generally offered in raw form and onerous to know, since they are not in organized form. All legitimate information is nowadays processed since the legal information gets generated often in a large volume due to the rise of law courts. The objective of this analysis is to explore an associate economical way to implement an algorithm to identify keywords by predicting the connectedness of legal documents from an enormous classification system which is difficult to do manually.\n",
      "The system to analyze this legal knowledge will serve effectively for lawyers and law students, which might address a lawyer’s role and may even become powerful to unleash such a task in future. Designers\n",
      "of such systems face\n",
      "a key challenge\n",
      "that the bulk of those documents are\n",
      "in natural language streams which are\n",
      "lacking formal structure or different specific linguistics information. During this analysis, we tend to describe associate unsupervised learning approach for automatically distinguishing necessary details in each legal document.\n",
      "The machine learning and deep learning algorithms based mostly analysis systems apply these strategies in the main for document classification. Legal document classification, translation, account, data obtention are part of the goals obtained from this research. During this study, we tend to review the various strategies of deep learning employed in legal tasks like Legal knowledge search, Legal document analytics, and Legal perspective interface. Through this review, we tend to instituted that machine learning models are giving advanced performance.\n",
      "Everything from README.md\n",
      "The information that was added to README.md should be added here as well.\n",
      "Team members: Names, Email, Student ID, Links to profiles\n",
      "Project Supervisor/s: Names, Email, Links to profiles\n",
      "Links\n",
      "Publications\n",
      "Introduction\n",
      "Keywords are considered as important parameters in a given context. For example people, places, words, or ideas that provides the idea of the relevant context. In this research,\n",
      "legal documents are used to obtain keywords, and thus the keyword is expected to convey a considerable idea of the\n",
      "legal document. Then, the key is the quality measuring parameter, which represents the importance of the given context.\n",
      "Keywords can be single word or multi-word keywords, which is known as key phrases. Phrases can be made by combining words together , and they usually generate a new meaning which is not related to the meaning given by single keywords. Therefore, if we take only single words as keywords, then , it would sometimes miss the significant things in the document.\n",
      "There are two factors considered in the process of identifying keywords. First, if\n",
      "a word is more frequently occurs in the document, then it can take as a keyword. And second, if\n",
      "a word is more frequently\n",
      "occurs in a speech,it has a less chance to take as a keyword of any document. According to the second factor the words that very frequently use in a speech, such as prepositions, conjunctions or\n",
      "common nouns, cannot be considered as keywords.\n",
      "What is keyword extraction?\n",
      "Keyword extraction is one of the text analysis methods, extract the most important words in the document and express the idea of it. It helps to get a summarizing of\n",
      "the content of the document. A keyword is a important unique word that convey whole idea of a document,or a word which is used to find information when studying legal cases. They can express approximately the overall idea of the document. Keywords are also called as ‘Search Queries’, since they are the words or phrases that people use when they are searching. Keywords are important since they provide the connection between what people search for and what system they have.When there are thousands of documents, keyword extraction helps to find the best matching document for our purpose. Keywords may be considered as a summary for a document which lead to have information extraction, or\n",
      "to categorize a document collection. However, in our case , there are relatively few documents keywords are assigned. Therefore finding methods to automate the assignment is important thing in legal context.\n",
      "Reading legal documents is a very difficult task and sometimes it needs some domain knowledge related to that document. And also it is hard to read the full legal document without missing the key important sentences and it is a very time consuming task. With an increasing number of legal documents it would be convenient to get the essential information from the document without having to go through the whole document. Hence manual extraction of keywords is slow, expensive and prone to mistakes.\n",
      "Finding database and e-Resource that provide legal and legislative information is vital need for lawyers in Sri Lanka.There are current implementations but those systems does not come up with efficient solution.There also manual work is costly.We need to reduce man work from the beginning of the portal.To implement user friendly and a system which learn itself to categorize documents the keyword extraction is essential. Also part of this research important information is mined. Therefore, many algorithms and systems for automatic keyword extraction have been proposed in the recent past. Those experiments are the basic background for this\n",
      "project.\n",
      "Methodology\n",
      "Website will contain judgements, statutes and various other content. We need an intelligent system, which can identify those.\n",
      "For that, when go through the documents, We found that there are set of special words and\n",
      "phrases surrounding the previous judgment.\n",
      "By referring set of documents, we found that there are some patterns in each document. Those can be a single word, phrase or a preposition like here,\n",
      "the case of, vide, held, the judgement of, in\n",
      "that have been used to introduce previous judgements.\n",
      "Those patterns will precede and follow with the name of the statutes also.\n",
      "We will be able to develop a comprehensive list of words that precede and follow the names of judgements.\n",
      "When we are doing this project, We have used\n",
      "Black’s laws online legal dictionary to identify the key concepts in the judgments, because we should understand how judgments are published and what are the key concepts\n",
      "Developing a comprehensive list of word patterns precede and follow the wanted informations because in machine learning, the algorithm should be able to identify and extract the details.\n",
      "And also there are words, which are unique for the particular document. Those words do not refer any previous judgment, legal document or lawyer name.Those are called keywords.To extract keywords we used TF-IDF method and Text Rank method\n",
      "Experiment Setup and Implementation\n",
      "To extract keywords,we used two different algorithms as TF-IDF method and Text Rank method.Bsically we used python language and libraries related to algorithm. For the experiment we took two diffrent formats such as NLR and suprime court doucuments. For the project we used 50 documents from NLR and 25 documents from suprime court documets. Also by using TF-IDF method we extracted five keywords from each document and Text Rank method we extracted 10 keywords from each documet.\n",
      "Results and Analysis\n",
      "We could identify the above mentioned key information for a given document. When considering keyword extraction results, TF-IDF Method table shows that TF-IDF methods shows 0.4347 accuracy for NLR documents and 0.5666 accuracy for supreme court documents. Text-Rank Method table results shows the number of correctly and wrongly identified keywords accordingly. With respect to that the NLR data-set has achieved 0. 3742 accuracy and supreme court data-set has achieved 0. 3960 accuracy.\n",
      "To evaluate the results we had to use manual method because its not like assigning keywords to other documents, legal documents have different context and assigning keywords need prior knowledge for legal documents. When it comes to automate the keyword extraction, therefore we had to do evaluation by manually.\n",
      "Conclusion\n",
      "The goal of this research is to discover answers on the questions of keyword identifying process of legal domain, especially, legal documents vary\n",
      "from others. It is considered about what are the things that make a legal document unique, which features important most in each document, if the formation is important in the applicable prediction, and what mechanisms work best for applicable prediction in the legal domain.\n",
      "During the experiments on data, some ideas on enhancement of the relevance prediction were proposed. Our plan was to implement a method searching documents using a single keyword or keyword phrase. There are still chances for additional improvements , which might rapidly accelerate and simplify lawyer’s work.Expectantly, this research will help everyone who are involved in the legal domain\n",
      "and software developers in coming-up decisions to obtain these improvements.\\\\Besides the analysis, a concurring result of the research was additionally the process of making a system that uses the discussed methods and is integrated with Lawciter which is an E-discovery system. The system conferred all documents of law cases. If the user testing , confirms\n",
      "quality and usability\n",
      "of the add-ons, it will come\n",
      "the finishing deliverance.\n",
      "\n",
      "\n",
      "Extracting Microservice Based Edge Computing Architecture https://cepdnaclk.github.io/e15-4yp-Microservice-Based-Edge-Computing-Architecture\n",
      "\n",
      "\n",
      "Microservice Based Edge Computing Architecture\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Team\n",
      "E/15/048, Gayal Laksara, email\n",
      "E/15/243, Sewwandi Nisansala, email\n",
      "E/15/271, Sonali Prasadika, email\n",
      "Supervisors\n",
      "Dr.Upul Jayasinghe, email\n",
      "Dr. Isuru Nawinne, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "With technological advancement, the adoption of advanced Internet of Things (IoT) technologies has improved impressively in the past few years. These services place such services at the extreme edge of the network. With such improvements, speciﬁc Quality of Service (QoS) trade-offs are needed to be considered. Some of such trade-offs are, particularly in situations when workloads vary over time or when IoT devices are dynamically changing their geographic position or when the data is needed to be processed in real-time and so on. Recent research has given much emphasis on realizing AI computing at the edge in contrast to cloud computing approaches to support the delay-sensitive IoT applications, autonomic decision making, and smart service creation at the edge in comparison to traditional IoT solutions. However, existing solutions have limitations concerning distributed and simultaneous resource management for AI computation and data processing at the edge; concurrent and real-time application execution; and platform-independent deployment. In our research, we focus on developing a novel platform and relevant modules with integrated AI processing and edge computer paradigms considering issues related to scalability, heterogeneity, security, and interoperability of IoT services. Further, each component is designed to handle the control signals, data flows, microservice orchestration, and resource composition to match with the IoT application requirements.\n",
      "Related works\n",
      "Distributed Computing\n",
      "Distributed Edge and Fog address some challenging scenarios of traditional cloud computing architecture. Chao Gong et al. presented ICE computing architecture that combines AI techniques and edge computing. They have achieved lower latency and a higher caching hate ratio at the edge to achieve a smart IoT [10]. Muhammad Alam et al. proposed distributed architecture with cloud, fog and edge devices, which makes sure that the data gets collected and analyzed at the most\n",
      "efficient and logical layer [11]. Edge Computing is inbuilt with predictive algorithms that may make decisions autonomously without looking forward to the cloud [7]. Fog Computing extends device-centric approaches to IoT development by introducing support for edge processing, network processing, and integration with Cloud Computing. Consistent with the research paper [12], fog devices will be\n",
      "classified as edge, IO (Input/Output), and compute nodes. In [13], the authors have presented the results of the efficient utilization of resources in the network infrastructure by using\n",
      "fog, cloud architecture. Here Fog computing results in solving the problem of latency in time-critical IoT applications.\n",
      "Microservices Architecture\n",
      "Microservices is an architectural style that structures an application as a collection of services that are highly maintainable and testable, loosely coupled, and independently deployable. These services are purposely built to perform a cohesive business function and are an evolution of the standard service-oriented architecture style [7], [14], [15]. In a microservice architecture, interdependent software components are individually configured as a microservice, where each\n",
      "service is liable for its small purpose. During a monolithic architecture, all functional logics for handling demands operate within the same process [16]–[18] [19]. There are some advantages in microservice architecture which are independent deployment, and fault isolation, meaning we are able to fix the fault only within the corresponding microservice otherwise the complete monolith to be re-developed, mixed technology stack which means we will use different technologies in several\n",
      "microservices.\n",
      "Methodology\n",
      "Design the Algorithm with Neural Network\n",
      "The main purpose of the AI algorithm of the project is to create a neural network from scratch in Python, which is capable of solving multi-class classification problems and can be distributed over the three-level architecture ROOF, Fog and Cloud. Some parameters of the algorithm should be transferred between each layer, then a certain model is not suitable for this case since the model can not pass through APIs from one layer to another layer. Therefore weight matrices are considered as parameters that are transferred between each layer. Softmax and cross-entropy functions are used as activation function and loss functions for creating the neural networks for multi-class classification. The cross-entropy cost function is used for optimizing the cost with softmax activation function at the output layer. There are two algorithms in our project one for predicting the vehicle’s speed and another for predicting air condition state in the vehicle.\n",
      "Proposed Platform\n",
      "To facilitate real-time processing and distributed communication at the edge, we propose a three-layer architecture, namely ROOF, fog, and cloud. Edge consists of fog devices and ROOF devices to process data in real-time but with less computation power and memory size. Fog acts as an intermediate level between ROOF and Cloud. Fog consists of more computation power and memory power than ROOF but not as much as Cloud. And finally, we have Cloud level to do higher computations to achieve the desired goals. This proposed architecture is network independent since this is three-layered architecture. The ROOF is the closest layer to the IoT devices and it does the AI computing on the sensor data from IoT devices. Here the horizontal distribution is also used to delegate the computational power on several nodes at the same time on ROOF and Fog layers. Therefore we have reduced memory and computational issues at the ROOF and Fog layers. Apart from this, there are policies that implemented to get high accuracy on the AI model which are discussed in section III.\n",
      "Even though this hierarchical architecture provides a solution for the real-time data processing issue, we needed a system that can have components that we can reuse. With that intend we move to the microservice-based architecture rather than going with a monolithic architecture.\n",
      "Experiment Setup and Implementation\n",
      "From the theoretical view, the proposed hierarchy and reason for going such a hierarchy is explained in Section III. The system is designed for the use case, an autonomous car. To validate and run the system we took a testbed approach.\n",
      "Implementation of the Prototype\n",
      "Since the system is designed only on a software basis we need a method to generate data in a way that happens in a real vehicle. In real vehicles, we have a microcontroller to collect data from different sensors such as Lidars, GPS, speedometers, etc. The microcontroller sent these data to the desired processing units to process and get the desired output. This is where the testbed is coming from. In our system, the testbed acts as our microcontroller and it sends data in a manner which the microcontroller sent. The dataset is found from Kaggle, provided freely by Victor R. F. (Car trips data log). As the ROOF layer, easily obtainable hardware which is a total of three Raspberry Pi 3s (RPis) is used as ROOF nodes. RPis 3 are single-board computers (SBCs) with 1.2 GHz CPU and 1 GB RAM, 16 GB storage disk while also having integrated WiFi. Due to the hardware limitations of a single Raspberry Pi, the processing is delegated through the three ROOF nodes. Due to the less processing power of Raspberry pi and the focus is to improve the processing power by delegating between the three of them. The three ROOF nodes interact using WIFI. Two laptops were used as the Fog layer. One with Intel® Core™ i3-3227U CPU @ 1.90GHz × 4 and Ubuntu 18.04.4 LTS as the operating system and the other laptop with Intel(R) Core(TM) i7-4600 CPU @ 2.10 GHz and Windows 7 operating system.\n",
      "We have used the Google Cloud Platform to provide cloud computing services at the cloud level. For that a machine type of e2-medium (2 vCPUs, 4 GB memory) with Ubuntu 18.04.5 LTS as the operating system. To communicate with these three layers, the Restful API method is used.\n",
      "Dynamic offloading\n",
      "Dynamic offloading improves the performance of ROOF architecture since it has lower computational power. In [20], the authors proposed task-centric and data-centric algorithms to analyze the threshold when the dynamic offload is happening. In our case, since the data is sent to the upper levels (FOG and Cloud), the data are not stored at the ROOF. Therefore the data-centric method is not suitable for this case. Here the task-centric algorithm is considered to do the offloading. Since the Raspberry Pis have less computation the overload can happen and it gets too much time to process data\n",
      "even the processing is delegated horizontally on several nodes. The tasks which get larger processing times in the nodes are offloaded to the least overloading nodes. The utility function for calculating offloading algorithm is as follows.\n",
      "Meaning\n",
      "Symbol\n",
      "Max device factor\n",
      "αa\n",
      "Min device factor\n",
      "αb\n",
      "Number of connected edge nodes\n",
      "En\n",
      "Threshold\n",
      "T\n",
      "Time per offload service\n",
      "βi\n",
      "Total time\n",
      "βt\n",
      "αa = 1/(En)\n",
      "αa = 1/(En + 1)\n",
      "T = (βi / βt)\n",
      "Offload occurs when,\n",
      "T > αa\n",
      "### Microservices Implementation\n",
      "For developing this microservice-based edge computing architecture, we propose to use a three-level hierarchical system, Namely as ROOF, fog, and cloud. On each level to some extend the processing is happening and each level has AIbased microservices for doing specific tasks. Microservices we mainly used processing microservice, AC model training microservice, speed model training microservice, confusion matrix microservice, classification report microservice and accuracy microservice\n",
      "In our hierarchy, except AC Model Training Microservice and Speed Model Training Microservice, all the other microservices act as a shared resource to achieve their goals. The goal of the processing microservice is to get data from the testbed (for ROOF) and for other levels, lower-level processing\n",
      "microservice sent data to upper-level processing microservice. Further, the functionalities in the processing are splitting data to testing and training, and assigning separate APIs to respective results (e,g-: AC model x training data, Speed model x training data, etc). Speed model train microservice and AC model training microservice both are responsible for training the model for both the Speed and AC services. But all the accuracy, confusion matrix, and classification report microservices are responsible for providing accuracy, a classification report, and also a confusion matrix, and those results are used to validate the results. Here we have implemented a policy in a model train, which is it requests the accuracies from all the upper layers and if an upper layer has greater accuracy compared to its current accuracy, then the weight matrices of that corresponding upper layer are requested and replaced in the model. As a result of this, since the lower level has less computation and storage powers compared to its upper layer, there is a possibility that\n",
      "the upper layer may have achieved greater accuracy. So we can achieve the same accuracy level for lower layers by sharing the model in this way. The ROOF model can be seen in figure 1\n",
      "The whole hierarchy can be seen in Figure 2. All the functionalities happening in ROOF happens in fog and cloud. Additionally, we have a separate microservice called Global Accuracy at both fog and cloud levels. Global accuracy microservice is the one that responds for keeping the track of accuracy and weight matrices of near vehicles. It requests the accuracy from all the nearby vehicles and if a vehicle has higher accuracy, we update the global accuracy microservice with that vehicle’s accuracy and weight matrix data. A policy in this microservice is, at the start, we have seen with the\n",
      "lesser number of datasets we get about 100% accuracy. But this accuracy is not valid because it can not predict the correct outputs with the changing natures. The policy is, to update the global accuracy, the corresponding vehicle must have generated more than the size of 1000 data sets.\n",
      "As seen in figure 3, cloud level has some additional functionalities compared to its lower levels. Since the cloud is the topmost layer, all the input data coming from the testbed is saved in the cloud firestore for archiving reasons. The further initial plan is to use the cloud database service to act as a global accuracy saver, but since firestore does not allow us to save 2-D matrices we fall back to the strategy we used in the fog here. Further, we have developed a mobile app that is interconnected with a special service provided with the use of cloud functionalities. The service is to give a fuel consumption assumption for the user by combining speed and ac control data. The mobile app is for the user and the user can give the current location and destination with the available amount of fuel. Those data sent to a service running in the cloud which calculates the rough assumption of fuel consumption with the speed and ac data at cloud level, and the result is sent back\n",
      "to the mobile app\n",
      "lementation of the NN Algorithm\n",
      "As mentioned above, in the methodology section, the algorithms are divided into two sub-phases as the feed-forward phase and the backpropagation phase.\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "With the staunch objective of providing real-time processing at the edge, we have developed a microservice-based AI computational hierarchy. The processing happens in both vertical hierarchical manner(ROOF, Fog, Cloud) and also horizontal hierarchical manner(In the ROOF level). Each level has its own policies (Accuracy checking from upper levels…etc) to control the flow of data and how the process should be distributed.\n",
      "Publications\n",
      "Semester 7 report\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Semester 8 slides\n",
      "Author 1, Author 2 and Author 3 “Research paper title” (2021). PDF.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Mixed Reality based Simulation Platform for Swarm Robotics https://cepdnaclk.github.io/e15-4yp-Mixed-Reality-based-Simulation-Platform-for-Swarm-Robotics\n",
      "\n",
      "\n",
      "Mixed reality based simulation platform for Swarm Robotics\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Mixed reality based simulation platform for Swarm Robotics\n",
      "Team\n",
      "E/15/140, Jaliyagoda A.J.N.M., nuwanjaliyagoda@eng.pdn.ac.lk\n",
      "E/15/142, Jayalath A.H.G.D., ganindudananja@gmail.com\n",
      "E/15/173, Karunarathna S.D.D.D., dinelkadilshani95@gmail.com\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne, isurunawinne@eng.pdn.ac.lk\n",
      "Prof. Roshan Ragel, roshanr@eng.pdn.ac.lk\n",
      "Table of content\n",
      "Abstract\n",
      "Introduction\n",
      "Methodological Approach\n",
      "Implementation\n",
      "Experiments and Analysis\n",
      "Conclusion\n",
      "Links and References\n",
      "Abstract\n",
      "The term “Swarm Intelligence” is the collective behavior of a combination of many simple individuals, where they operate autonomously. “Swarm Robotics” is the application of swarm intelligence used in collective robotics. This has been a new approach to the coordination of mass of robots that are capable of local communication, decentralized controlling, autonomous and also operations based on biological inspiration senses. In order to achieve the highest effectiveness of swarm robotics applications, virtual reality has been used.\n",
      "Mixed Reality (MR) was originally derived from Virtual Reality (VR). When designing MR systems, users are provided with the illusion that digital objects are in the same space as physical ones. Mixed Reality is typically correlated with Virtual Reality by the solutions that have been made to address the problems related to robotic applications. However, the use of MR was clearly identified as very useful from just only VR implementations by its flexibility, scalability and availability with respect to each implementation.\n",
      "Testing and experimentation of robotic applications could be made far easier than VR with a significant increase of control over various environmental constraints and limitations. Hence, we combined both the virtual and physical robots and created a swarm robotics platform in mixed reality. Furthermore, we conducted some experiments to test the functionality of the system in the mixed reality environment and represent the behavior in the web-based simulator we developed.\n",
      "Introduction\n",
      "Swarm Robotics\n",
      "Over the past few decades technology has been evolving rapidly in so many aspects and fields to reach out to the human population in a more user-friendly manner. With these technological developments, one such industry that took a huge leap with an advanced improvement is the field of robotics. Even in robotics, swarm robotics has been a major breakthrough.\n",
      "The term “Swarm Intelligence” refers to sophisticated collective behavior that is being emerged from the combination of many simple individuals, each operating autonomously. It consists of a biologically inspired emphasis based on the emergence of global behavior, also on decentralized local control and local communication. “Swarm Robotics” is the application of swarm intelligence used in collective robotics.\n",
      "This has been a new approach to the coordination of mass of robots that are capable of local communication, not controlled centrally, autonomous and also operations based on biological inspiration senses.\n",
      "When it comes to swarm robots, this concept has been derived from the behavioral patterns of creatures like ants, wasps, locusts, termites, bees, fishes, turtles and birds (Figure 1.1). Swarming is seen as a behavioral pattern because they move together in search of food and shelter to survive from predator attacks. That is since the discrete individuals have a higher chance of surviving in the group than being alone. Swarming results in responding to the speed of their peers to avoid collisions within the swarm by communicating with each other while maintaining a decentralized network and exhibiting self-organized behavior. The goal of these creatures in swarms is basically to ensure the process of solving problems more efficiently through cooperation and division of labor which is being modified and infused into swarm robotic technology.\n",
      "Figure 1.1 Examples of diverse creatures in swarms\n",
      "One of the main advantages of swarm robots is to outperform individual robots as they accomplish tasks concurrently and faster than individual robots. Even if these tasks are too difficult for a single robot to accomplish, it would be very much convenient for the swarm robots.\n",
      "The main characteristics of a swarm robotics systems are as follows,\n",
      "Robustness: The system’s motionlessness or in other words not showing any biasing or emotion towards randomly occurring changes within its surrounding environment where it enables the system to perform its designated tasks despite any disturbances.\n",
      "Autonomous: It is the system being independent of each other while interacting with each other and its surrounding environment.\n",
      "Local Communication: Swarm robots do not have a comprehensive understanding of their environment. Due to that, the interaction between individuals is based on the concept of local communication which is termed as a stigmergy mode of communication.\n",
      "Cooperation: Swarm robots are not capable of completing an allocated task individually, it is needed for them to work together. Therefore, cooperation can be considered as a compulsory characteristic found in swarm robots because the tasks are too difficult to be carried out by a single robot.\n",
      "Flexibility: This is the ability of the system to perform different tasks at one time\n",
      "Aggregation: This is the process of grouping the individuals of the swarm into a cluster without using any external impact which is very crucial in swarm robots as it plays an important role in all three co-operation, communication and interaction aspects.\n",
      "Virtual Reality and Mixed Reality\n",
      "Virtual reality is another major part of the technical field which is experienced through sensory stimuli such as sights and sounds provided by a computer and partially determines what happens in the 3D computer-generated environment.\n",
      "Virtual reality describes the simulation of a synthetic environment similar to the actual environment. The term “virtual reality” was introduced by computer scientist, Jaron Lanier for the first time and he founded the first company (“VLP Research”) to develop VR products like VR goggles, joystick, data gloves, and “Bird 3D” electromagnetic tracker.\n",
      "Virtual reality has been used in flight simulation training for pilots, procedural training for surgeons, phobia treatments, disorders, gaming consoles, etc. When creating a virtual environment for these applications, the user should provide visual feedback by a head-mounted device, projection system, or a flat-screen to gain the virtual effect.\n",
      "The Virtual Fixture System which was invented by Armstrong Laboratory located in Arlington, Texas, USA presented a Mixed Reality (MR) incorporating features of the sight, sound, and touch. Later Milgram and Kishino introduced the “virtuality continuum” concept that linked the real and the virtual world (Figure 1.2). Milgram’s scale represents the real environment and the virtual environment at the ends while introducing a new concept known as Mixed Reality (MR) in the middle. According to Milgram’s diagram, there are two broad areas, Augmented Reality (AR) and Augmented Virtuality (AV) which belong to the MR. However, the medium that represented a combination of real and virtual environments mostly known as AR rather than MR.\n",
      "Figure 1.2 Milgram’s Reality–Virtuality continuum\n",
      "When it comes to Mixed Reality (MR), it has been originally derived from Virtual Reality (VR) not only conceptually but historically as well. Here, both the physical environment around them and digital elements presented are distinguished by users, for example, the use of semitransparent displays. When designing MR systems, users are provided with the illusion that digital objects are in the same space as physical ones. By sensing those physical interactions, it provides interactive feedback to the users.\n",
      "Figure 1.3 Milgram’s continuum with examples from Media Convergence Laboratory projects.\n",
      "Left to right: Physical reality, Augmented reality, Augmented virtuality, Virtual reality\n",
      "Challenges in Swarm Robots\n",
      "There are many possible reasons for the absence of robot swarms in the real world, for instance, the hardware limitations of the available robots. Here we have discussed some open problems.\n",
      "1. Scalability\n",
      "Swarm intelligence needs a considerable number of robots with the corresponding features to simulate the algorithms. So, we identified scalability as a major fallback of swarm intelligence-related research. Unless there is a large number of robots to test these algorithms it is difficult to do experiments in the real world. Building a group of robots takes a lot of time to build hardware components of particular robots. Not only that, as the required parts to build a single robot are very much expensive, when considering a bulk of robots to be built it will cost even much more than the affordable values.\n",
      "As a solution to this problem, implementing robots with hardware capabilities to run basic swarm intelligence-related algorithms will allow robots to be multifunctional. However, buying a set of pre-built robots does not solve the whole problem since it is too expensive yet. Another solution is to use computer-based simulation software. Nevertheless, the problem with that approach is that the simulators do not guarantee how robots act in an actual environment, how they react to complex physics, noisy sensor data, control loop delays, etc.\n",
      "2. Physical Execution\n",
      "Some applications like search and rescue, explorations in extreme regions and bomb disarming are too dangerous for human beings to be carried out. To avoid difficulties during these missions, swarm robots can be deployed.\n",
      "Even if swarm robots are used to complete these tasks, yet there is a high risk of swarm robots being destroyed during these extreme conditions. Therefore, building new robots each time will be even more of a misspending of money.\n",
      "In some swarm intelligence-related algorithms, the result mostly depends on the number of robots. Therefore the test result by using few physical robots can not be used to prove the correctness or scalability of the algorithm.\n",
      "In the development and testing life cycle, the actual operations in MR environments can be identified as much simpler with the ability to separate system components with ease and the transition of system components between each environment. Hence, the MR platform implementations are very useful for the applications of Multi-Robot or Swarm Robot architecture research topics and other fields as well for an instance; Embedded systems and IoT (Internet of Things) projects.\n",
      "Proposed Solution\n",
      "Virtual Swarm Robots\n",
      "Virtual swarm robots are often very useful to perform simulation prior to the investigation of real robots. Simulations are easier to set up, less expensive, normally faster and more convenient to use than physical swarms. Virtual swarm robots need a simulator to interpret the changes and the movements of each robot and also to test the swarm intelligence-based algorithms. The two main requirements in virtual swarm robot simulators are the flexibility to add new features and efficiency. There are many simulation platforms like Player, Stage, Gazebo etc.\n",
      "Mixed reality in Swarm Robots\n",
      "MR is a relatively refreshing and new area of technology although many implementations and experiments have been carried out over the past years. It can be categorized under an expanding field of expertise due to its promising potential for a large number of applications in various fields and purposes comprising testing state-of-the-art computer architectural systems, process optimizations, training and testing of hardware components for Machine Learning applications, etc. The immense interests in many researchers for MR are almost related to robotics, especially Multi-Robotic systems and Swarm Robotic systems. In particular, MR based robotic development will require additional attention to detail for tasks including collaboration between robots, additive manufacturing and other related manufacturing tasks to achieve interfacing, programming related outcomes in software level and functionalities.\n",
      "It is known for a fact that developing a physical robot that specializes in some certain production level functionality will have a higher bill of material to some extent because of certain advanced hardware components and devices. Hence, there exist certain limitations for development and testing physical robots. However, with the recent interests and advances in virtual sensing and related technologies, using MR is a promising solution for reducing the experimental and development costs. especially for scaling up swarm robots. Human-robot interaction due to the ability to separate between the physical and virtual robots with MR is considered safe. Hence, MR creates safer and low-risk environments for extensive testing of Swarm Robotic behaviors.\n",
      "MR implementations tend to merge virtual and physical realities where enabling a robot to sense both physical and virtual environments via augmented means, allows the ability to interact with both physical and virtual environments and experiment on robot behaviors on simulated environments with simplified addition and removal of obstacles to an extent. Their collaborative design patterns and individual functionalities could be accessible and monitored remotely for debugging and development. This remote accessibility is a more flexible feature than any of the functionalities that can be seen in other control system architectures. The so-called “spatial flexibility” allows the collaboration between the researchers, developers and the test subjects to be not limited by some parameters including geographical constraints. The work done by Freund and Rossman describes a mixed reality robotic representation in which a physical robot executes control commands propagated and translated from the virtual environment that is allowed to be operated by a human. This enables the use of an MR approach called “Tele-Immersive Environments”.\n",
      "MR environment allows adding or changing virtual features to robots that may be too costly, time-consuming, or impossible in reality. As an example, for the practical implementations, adding 8 or more bearing sensors for all the required directions is costly and not practical in small robots. However, with the aid of virtual sensing, it is possible to add that sensor as a virtual sensor by using the technology of mixed reality.\n",
      "All over the world, in the field of robotics, many applications with different approaches have been executed which were inspired by this exposition. MR based swarm robots have especially been one such advanced application implemented so far in the industry. The very same concept was used in this project of ours. First of all, a few physical swarm robots with basic functionalities were built and they were interpreted in a graphical user interface with other virtual robots.\n",
      "Deliverables and Milestones\n",
      "Mixed Reality Simulator\n",
      "There are many factors associated with the design of Mixed Reality-based Swarm Robotic applications that are considered as unique to that particular instance of implementation and use case. Many factors can be classified as predictable characteristics and unpredictable characteristics. Dealing with these characteristics in a systematic manner is a crucial part of such implementations.\n",
      "Regardless of the complexity of characteristics, a common challenge among the representations in swarm robotics is the interaction with the environment. These interactions can be visualized as characteristics which are measurements and sensor readings (thermal, sonar, IR, etc.) and behavioral events. Visualization of such interactions between software and hardware represented with a simulation using AR.\n",
      "AR provides a means with an extent and more accurate visualization of robots in the real world while many non-AR visualization or simulation provides a simpler visualization from ad hoc means. Proper monitoring (or potential controlling) is needed to work with these visualizations because working with predictable or unpredictable characteristics will eventually lead to inconsistencies and bugs in the system. With the accuracy provided by the AR, the system is also able to provide a real-time simulator environment and it was implemented web basely.\n",
      "Localization of physical robots\n",
      "A precise mapping between physical and virtual reality is required for mixed reality, so the system must know the position of relevant physical objects relative to the display system. To maintain this coexistence, the exact coordinates of the physical robots needed to be identified.\n",
      "Dead Reckoning is a common technique used for Differential Drive mobile robots to measure the offsets from the start coordinate. It uses a rotary encoder attached to its wheels to measure the angle of rotation of each wheel and calculate the offsets using simple trangiometry. However, this method has cumulative errors, due to erroneous sensor readings or precision of the sensors.\n",
      "Therefore, it is better to use a combination of localization methods, which can be able to eliminate the cumulative error. Followings are few approaches for ranging measurements, can be used for localization.\n",
      "GPS: A good solution for geographically spread swarms, but cannot be used indoors because precision is less due to interference by obstacles.\n",
      "RSSI: There are two problems with using RSSI (Received Signal Strength Indicator) as a ranging technique used with RF devices such as Bluetooth or ZigBee which are not stable since some protocol takes measures to ensure the higher quality link and it is dependent on the device orientation. RSSI for ranging might be applicable in a static environment with fixed device orientation but it is not adequate in a moving device system.\n",
      "Infrared: An array of Infrared distance sensors for each robot can measure relative distances between each robot/the environment and calculate the relative position using MEDUSA localization system. The problem with this approach is the interference from sunlight and measurable distance limitation.\n",
      "Laser Ranging sensor: This method uses a rotating laser distance sensor and measures the Acoustic Signal. This method is relatively low cost and the range is limited to 5m.\n",
      "Ultrasonic with RF pulse: This implementation uses an Ultrasonic pulse with a radio frequency pulse. The distance is measured by the receiver based on the delay between Radio pulse and Ultrasonic pulse. This approach is used in Cricket Localization systems.\n",
      "Image processing with an overhead camera: Can use an overhead camera and marker with a unique ID for each robot. Image processing based on marker identification is used as the tracking algorithm. This method is limited to small areas, based on the camera angle and the resolution.\n",
      "So, after considering all the advantages and disadvantages of the above-mentioned solutions, an overhead camera with markers was selected to identify the coordinates of the physical robots. It uses image processing with OpenCV and ARMarker support libraries.\n",
      "Communication\n",
      "The communication between each robotic instance and with the simulation platform in a mixed reality representation is crucial because frequent communication is a key part in representing the outcome of the simulation platform in the simulation server itself and the visualization system. The communication system is to be handled using MQTT because of its lightweight and event-driven functionality. A distributed system with repository data architecture is the approach of implementing the communication module for the simulation.\n",
      "Methodology\n",
      "As described in the previous sections, developing a large number of physical swarm robots is not practical within constraints such as budget and time. Also, simulating the swarm behavior in a purely virtual environment does not give a guarantee about the real-world execution. Hence, the solution we suggest is a hybrid method, by combining both the characteristics of physical and virtual robots with the aid of mixed reality technologies.\n",
      "Our proposed system consists of several parts as listed below;\n",
      "Physical Robots, which are integrated with real sensors and actuators.\n",
      "Virtual Robots, virtual representation of the physical robots, which can be added to the simulation arena by software level definition.\n",
      "Localization system, a system that recognizes the movements of the physical robots and maps them into virtual reality.\n",
      "Mixed Reality Simulator, a software application that can interface with both physical and virtual robots and model the functionality in a mixed reality environment.\n",
      "Visualization platform, a virtual environment, which can visually update the behaviors of both realities.\n",
      "In a nutshell, the overall Mixed Reality Simulation platform (Figure 2.1) is a collection of several decentralized and distributed components which are connected with each other by various aspects including reality, communication mode (synchronous or asynchronous), visualization, etc.\n",
      "Figure 2.1 Overall Abstract System Architecture\n",
      "A simple block diagram of the whole mixed reality simulator system is shown in Figure 2.2. Physical robots and Virtual robots communicate with the simulator back and forth via MQTT protocol. Also, both Physical and Virtual robots send their current states to the Visualizer to represent them in an MR environment. The visualizer renders the 3D view of the robots and obstacles of both realities. Visualizer is only a representative body and it can not take decisions and control the behaviors.\n",
      "Figure 2.2 Interactions between subsystems\n",
      "Conceptual design\n",
      "Physical and Virtual Robots\n",
      "The basic requirements of the physical robots are to be general-purpose swarm robots, which can be used for swarm intelligence behavior related experiments. Those robots should be able to move in the simulation platform and interact with other physical robots as well as with virtual robots.\n",
      "Virtual robots are designed to behave as the same as physical robots, but virtually. They can communicate with the virtual robots and also with physical robots with the aid of the simulator. Since virtual robots are generated as instances, it can be scalable to any number and the same algorithms which are running on the physical robots can run on the virtual robots as well.\n",
      "The architecture of virtual robots we have built is similar to the firmware architecture of physical robots to maintain consistency. Physical robots have real physical sensors and the virtual robots were provided augmented sensors, which reads the mixed reality environment measurements through the simulator using specific communication channels.\n",
      "Physical robots have physical motors and wheels. There are functions in robot firmware, which can control the speeds of the motors using PWM signals. Since there are no motors in the virtual robots, the movements with the given motor speeds are calculated using a mathematical model known as Dead Reckoning for differential drive robots, as shown in the Figure 2.3.\n",
      "dx = (R/2)(VR + VL)cos(Φ)\n",
      "dy = (R/2)(VR + VL)sin(Φ)\n",
      "dΦ = (R/2)*(VR - VL)\n",
      "Figure 2.3 X and Y coordinate change with given speeds for left and right motors\n",
      "Robot Localization\n",
      "We recognized that there must be an accurate and effective way to track the movements of the physical robots and map them into the mixed reality environment and represent them on a mixed reality visualizer. After considering a lot of possible options and as a result of the literature survey that we conducted, we came to the conclusion, that having an image processing-based localization system would be the best solution to this project. An abstract localization module was identified as a requirement for the simulation that is to be used in the simulation server, to keep the localization information of the robots of both realities, and also having the capability to customize and scale up in the future for any other mixed reality swarm robotic representations.\n",
      "Physical robots have an AR marker on top of them. An overhead camera was set up on top of the physical simulation environment as shown in the Figure 2.4. The localization data (x coordinate, y coordinate and the heading direction) are calculated based on the video feed and mapped into the MR simulator environment with the aid of the AR library of the OpenCV. Then the coordinate data will be sent to the simulator via a predefined MQTT topic, as an event-triggered update for each and every individual physical robot. This updated event will be triggered only if the robot moved or rotated than a given threshold value.\n",
      "Figure 2.4 Localization system on the physical arena\n",
      "Mixed Reality Simulator\n",
      "Mixed Reality Simulator is the most important part of the whole system. It helps the sub-components to interact with each other. As an example, the simulator can provide the possible distance sensor readings for a virtual robot, based on its own location. Here, the simulator will consider both physical obstacles in the physical simulation arena as well as the virtual robots and virtual obstacles when calculating the distance sensor reading for the virtual robot.\n",
      "The status of the robot entities is reflected in the simulator and vice versa using controllers and emulators that we have implemented [Figure 3.5]. The term “emulator” refers to a functional service that is responsible for providing virtual actuator/sensor support. For example, Virtual Robots do not have actual distance sensing capabilities, hence a distance emulator is required to mimic the functionality of distance sensors for the connected virtual robot instances. The emulators differ from controllers as they do not directly change or more generally, “manage” the characteristics of certain entities in the simulator as with controllers (eg: Obstacle Controller).\n",
      "Methodological Approach\n",
      "Obstacles in Mixed Reality\n",
      "When doing experiments with swarm behaviors, we need to have specific environment setups. For example, we want to have walls, specifically shaped obstacles, etc., based on the experiment.\n",
      "When simulating the robot behaviors in a Mixed Reality environment, we may have those obstacles in both physical and virtual realities, and the physical robots should ‘sense’ virtual obstacles as well as virtual robots should ‘sense’ both virtual and real obstacles.\n",
      "As previously mentioned, our one goal is to make the simulator modular, and flexible. So we came up with a special interface to represent the obstacles in a mixed reality environment via the support of the simulator.\n",
      "Different types of obstacles from primitive shapes such as boxes, cylinders, spheres can be designed by following the interfaces and users can implement the functions defined in the interface.\n",
      "For the defined obstacles, it is possible to implement the above-mentioned methods by modeling\n",
      "the behaviors using geometry.\n",
      "Figure 2.5 Obstacles in MR visualizer\n",
      "For example, to create a wall obstacle we need the start coordinate, orientation relating to that point and the length of the wall. When calculating the distance to the obstacle through the heading direction, first it is needed to calculate the heading angles relative to the two endpoints, P1 and P2 of the wall obstacle shown in the Figure 2.5.\n",
      "angle1 = Θ − α\n",
      "angle2 = Θ − β\n",
      "If one of them is positive and the other angle is negative we identified that the obstacle is in the front of the robot. The below logic will give true or false if this condition is satisfied.\n",
      "(|angle1|≤90 or|angle2|≤90) and (angle1 * angle2 ≤ 0)\n",
      "To calculate the distance, we need the line equation of the wall obstacle and also the line equation through the heading direction. It can be obtained by using this equation.\n",
      "sin(angle)x − cos(angle)y − x0  sin(angle)+y0  cos(angle)=0\n",
      "Then we can find the intersection point of two lines and can calculate the distance from the coordinate of the robot to the intersection point.\n",
      "x= (b1c2 - b2c1)/(a1b2-a2b1)\n",
      "y= (a2c1-a1c2)/(a1b2-a2b1)\n",
      "distance = √(xDiff2 + yDiff2)\n",
      "After modeling the obstacles using this method, it is possible to build the environment with the support of these obstacles. We can make virtual entities for physical existence obstacles and mark them as real obstacles, and add some virtual obstacles and mark them as virtual obstacles. Detailed explanation on how to use these obstacles with Robots will be explained in the Reality Integration Section.\n",
      "Apart from the user-defined obstacles, the server considered virtual and physical robots also as moving obstacles.\n",
      "Augmented sensing and Reality Integration\n",
      "Physical robots can not sense the virtual robots and virtual obstacles from their inbuilt hardware sensors. Similarly, the virtual robots do not have any sensor to sense physical robots, obstacles and also other virtual robots and virtual obstacles. So to give the effect of mixed reality, the simulator acts as a broker or interface between the entities. It keeps track of the robot coordinates, given by the localization system for physical robots, and coordinates of the virtual robots reported by individual robots themself.\n",
      "The simulator contains the data on both realities and feeds the required details to the robots. Physical robots get the physical sensor readings of physical obstacles by their inbuilt sensors and virtual sensor readings of virtual obstacles through the simulator. Then it takes the minimum of those readings and detects the closest obstacle as in the Figure 2.6. Besides, virtual robots will request the sensor reading of both realities and the simulator reacts accordingly.\n",
      "Figure 2.6 Augmented sensing in simulation\n",
      "Limitations and considerations\n",
      "When designing the methodological approach the simulator and the visualizer need to be updated in real-time in order to give the mixed reality effect effectively. However, there is a considerable amount of delay during the transmission and we neglected it as it was inconsiderable and cannot handle by ourselves.\n",
      "As we discussed earlier, we designed MQTT protocols for communication. Through that design, it ensured confidentiality, integrity and availability which are the main components of security, up to some level. However, apart from the QoS supported by MQTT, we did not consider the successful delivery of the MQTT packets. This is because it makes unnecessary complexity and generates blocking calls.\n",
      "Furthermore, we are concerned about the research aspect of the mixed reality environment and not about security. Therefore the communication protocols do not include special authentication. Since MQTT brokers are connected with robots through authentication and it shares the username and the password between every robot. There is no control after the connection since no implementation was provided from the MQTT. However, this can be continued as future work.\n",
      "Implementation\n",
      "Hardware Implementations\n",
      "We identified several types of sensors that help to identify the properties of the environment and the behaviors of the robot itself. After considering a lot of possible designs we selected the following design (Figure 3.1) for the swarm robots. The round shape helps robots to tolerate the collisions (no any entanglements possible) and the special flattened edge of the back helps to identify the orientation of the robot from any view.\n",
      "Figure 3.1 Overview of the Physical Robot\n",
      "The top cover contains a 6x6 pixel AR marker, which helps to track the robot’s coordinate and orientation from the overhead camera.\n",
      "There is a distance sensor and a color sensor in front of the robot, and those can be used to explore the distance to obstacles in front of the robot and the color of the obstacles if there are any nearby. The distance sensor can measure a point distance maximum of 200cm.\n",
      "The robot contains a compass and accelerometer module, which can be used to measure and calculate the orientation of the robot.\n",
      "Each robot contains 4 IR transmitters (one outgoing channel) and 4 IR receivers (4 separate incoming channels), which can transmit and receive 32bit binary values (can be extended until 64 bit) and possible to use those as a communication method between robots.\n",
      "Also, a robot has a ring of 20 RGB LEDs, which can be used to give a visual indication of the robot’s status. It can be used as a robot to a robot communication method, with the aid of the color sensor,\n",
      "The physical robots have two geared motors with optical encoders which can measure the amount of rotation or the distance traveled by the robot with a 3mm step.\n",
      "The microcontroller of the robot has inbuilt WiFi and Bluetooth communication facilities and WiFi is currently used for communication with the swarm simulator.\n",
      "Robots are powered by 2 Li-Ion batteries, and the power distribution circuit has an inbuilt battery protection circuit, which protects batteries from overcharging and over-discharging.\n",
      "In the front bottom of the robot, there is a DIP switch with 2 toggle switches. It can be used to switch between 4 different behavior algorithms defined by the firmware.\n",
      "Implementation of virtual robots\n",
      "Virtual robots were implemented as virtual swarm nodes using java language. The robot class constructor has two attributes, an Id and the reality to differentiate the two types by the simulator. Also, there are some methods as stated in the diagram below (Figure 3.2). We created virtual robots by extending those features and included other features such as sensor interrupts and communication interrupts which needed to be built only for virtual robots as an abstract interface in software level since physical robots have implemented them in the hardware level. Then those methods can be overridden and can be implemented with the desired functionality according to the requirements of different swarm algorithms.\n",
      "Figure 3.2 Class diagram of the virtual robot\n",
      "As in the Figure 3.2, there are two sensors which are color sensor and distance sensor. Since they are built virtually those sensors get updates from the simulator with the respective readings.\n",
      "We build a setup method and a loop method to imitate the hardware functionality of the physical robots. The loop acts as an event loop, which manages multiple events and behaviors such as interrupt checking, MQTT communication, etc., as similar to a physical robot. Inside the setup method, the necessary objects of sensors, indicators and communication were created.\n",
      "Furthermore, these virtual robots were implemented as a finite state machine with three states which are wait, run and begin. The transferring methods between those states were defined in the IRobotState interface, as start(), stop(), reset().\n",
      "In addition to testing the functionality of these robots, we implemented a few swarm algorithms like color ripple formation, discovering obstacles and obstacle avoidance algorithms in virtual robots. We will further discuss these in the Experiment Section.\n",
      "For each virtual robot instance, we created a separate thread and performed their functions in it, so that each instance will run parallelly.\n",
      "Apart from the Java implementation described above, we have considered a JavaScript implementation of a Virtual Robot instance realization in our early stage of the development to address the asynchronous feature in a given swarm experiment. It is more event-driven than traditional approaches and it also followed the same base approach with the Java realization as it is one of the major expected outcomes of real-life swarm robotic experiments.\n",
      "The JavaScript implementation consumes the modules and classes from the “pera-swarm” library and some are customized for specific control capabilities. However, the virtual sensor implementations required some sequential procedure calls that needed synchronous function calls instead of callbacks. Also, it required an additional overhead of customization for specific robot models. Therefore, we did not further develop the asynchronous JavaScript robot instance realization, whereas this experiment consisted of synchronous robot instances.\n",
      "Swarm Simulator Architecture\n",
      "As previously described in the above sections, it is required to implement an interaction server to handle the reality integration between physical and virtual swarm agents as well as other objects.\n",
      "Swarm Simulator contains two parts, a Mixed Reality Simulator and a Mixed Reality Visualizer. The simulator is a helper server to simulate things in a Mixed Reality environment and the Visualizer is used to visualize both realities in a single environment using a web-based virtual environment.\n",
      "Simulator Server\n",
      "Considering the possibility of easy modification, it was developed by following a modular approach. First, we implemented a general interface specifying the structure and some abstract methods. Then we created classes by implementing those interfaces since it was easy for us to define a protocol of behaviors that could be implemented anywhere in the class hierarchy and also to implement new features like virtual sensor emulators and helpers for swarm behavioral experiments.\n",
      "The simulator application uses the modules from the JavaScript libraries “pera-swarm” and “@pera-swarm/mqtt-router” (Library_Implementation Section) to address the swarm logic and other functional level requirements. The libraries were implemented for the general swarm robotic use case and are open for improvements to address specific swarm behavioral requirements for researchers.\n",
      "Figure 3.3 Swarm Simulator - UML Overview\n",
      "The Figure 3.3 describes the high level UML representation of the swarm simulator application. The Swarm class is associated with four modules from the “pera-swarm” library and they are further customized according to the use case of the experiments. The Robots module is attached with the Swarm class in a composition relation and it contains five modules namely, Color Sensor Emulator, Distance Sensor Emulator, Simple Communication, Directed Communication and NeoPixel Agent. These modules are again coming from the said library and they address robot-related functionality.\n",
      "The Following describes the high-level modules associated with the Swarm class.\n",
      "Scheduler Service: A service to manage the session timeout for robot pruning within the simulator so that inactive robot instances are filtered and removed from the simulator cache and a callback function to communicate with the other applications after the scheduler event.\n",
      "Localization Controller: A broker module which handles localization-related communication messages to propagate throughout the simulator and other applications.\n",
      "Environment Controller: A controller module which handles and manages the arena configurations and obstacles in a given instance throughout the experiment. This will consume a JSON configuration file that describes the environment configurations according to the experiment.\n",
      "MQTT Router: A customized MQTT Router module from the “@pera-swarm/mqtt-router” library to handle MQTT connection and routes each and every communication message to the related handler functions.\n",
      "The emulator modules that are composed in the Robot class are basically functional services responsible for providing virtual actuator/sensor support as described in the above sections. They do not directly take decisions and only provide virtual sensing capabilities. The Color Sensor Emulator and Distance Sensor Emulator implement a basic virtual sensing functionality based on the following concepts.\n",
      "Virtual Distance Sensing: A simple broker implementation of an actuator realization for distance sensing capabilities for virtual robot instances using the following MQTT communication topics. The module will calculate distances between the given robot instance and a selected obstacle or another robot instance for the following MQTT topics. - /sensor/distance/[robotID]/? - This will request distance sensor readings from a robot by the Simulator. - /sensor/distance/[robotID] - Simulator will inform Mixed Reality Environment readings to the robot, as a reply to the topic /sensor/distance. - /sensor/distance - Robots can request mixed-reality sensor reading from the simulator through this topic. There is an optional parameter, ‘reality’ is used to request the reading only on a specified reality. Reply from the simulator will be received through the topic /sensor/distance/{robotID}.\n",
      "Virtual Obstacle Sensing: The simulator contains emulators for various sensors and those sensors should feel the obstacles. Hence, we included several methods in these interfaces to support those emulated sensors. The Following are some of them.\n",
      "\\begin{itemize} - isInRange(heading, x, y): This will return a boolean value, true or false about the existence of the obstacle within the heading direction, from the given x,y coordinates. - getDistance(heading, x, y): This will return the distance to the obstacle, from x,y coordinates along heading direction.\n",
      "Mixed Reality Visualizer\n",
      "The simulator platform needed to be represented in a seamless way that the changes of each robot instance with their movements as well as the obstacles in the environment should be clearly identified for the users. Not only that, users should have the capability to filter these entities in the visualizer by the reality of choice for a given experiment. So, we chose the framework three.js (https://threejs.org/) to develop the Mixed Reality Visualizer with these functionalities:\n",
      "The movements of the robot instances are represented according to their reality in nearly real-time.\n",
      "The obstacles in the experiment environment are represented according to the configuration described in the Simulator with few considered limitations.\n",
      "The robot units and obstacles are given unique labels to distinguish each and every one of them.\n",
      "A control box to filter labels and entities according to their realities as well as choose whether or not to display robot snapshot information.\n",
      "A small statistical tool to display the performance metrics (e.g.: FPS counter, visual latency, etc.) of the visualizer application.\n",
      "Figure 3.4 A Screenshot of the Mixed Reality Visualizer\n",
      "The visualizer (Figure 3.4) represents the mixed reality information according to the simulator configuration and robot instance information. The application consumes an MQTT connection that follows the communication protocols that are described in the Communication Protocols Section}.\n",
      "Library implementation\n",
      "The realization of the simulator platform followed both a generalized architecture towards robot units and their behavior towards the environment while developing a specific simulation environment for the experiments. To address a general use case and encourage future work towards the mixed reality realization method, we wanted to develop a collection of open source libraries. The Swarm Server was implemented using Node.js (https://nodejs.org/) and the Visualizer was developed using a native stack (HTML, CSS, JavaScript), making Node.js our choice of platform for the libraries.\n",
      "The library “pera-swarm” (https://github.com/Pera-Swarm/pera-swarm) is the center of the library as it contains the modules that we have developed to address the general use case in Swarm Robotic Simulators and Robot instances. Each of these modules was identified and modeled according to real-life aspects and experiment considerations.\n",
      "The architecture of the “pera-swarm” library which was mentioned before is shown in the Figure 3.5. We developed this library using the design patterns described below.\n",
      "Facade Pattern: To manage the library architecture and attach each subsystem\n",
      "and module\n",
      "Abstract Factory Pattern: To create instances from each module\n",
      "Singleton Pattern: To make sure only one instance is available during the run time for certain modules (e.g.: ObstacleController instance)\n",
      "State Pattern: To provide the functionality of finite state machines in certain modules (e.g.: Robots)\n",
      "The library implementation followed the module abstraction to maintain coherence in each high-level module while providing the functionality to extend for further implementations in some of them. For example, one of them is the Robot module and it can be either import and use as it is or the underlying methods of the Robot module can be overridden by the developers or researchers easily. The documentation for each library module is available on the Pera-Swarm documentation website, listed in (https://pera-swarm.ce.pdn.ac.lk/docs/). Following is a brief description of a few important interfaces and abstract classes as shown in the Figure 3.5.\n",
      "Abstract Controller Class: An abstract class consists of the functions “publish()” for publishing certain messages, “defaultSubscriptions()” for handling MQTT Routes according to route definitions.\n",
      "Abstract Emulator Class: The Abstract Emulator class also contains the functions described in the above Abstract Controller class. Besides, it associates further, the Robots class in agent emulators whereas it does not include the said class in other child classes. This approach was chosen because we wanted to realize a real-life swarm behavioral model in the simulator.\n",
      "Abstract Environment Class: This class contains an association relation of the “EnvironmentConfig” and the “AbstractObstacleController” classes with “updated”: timestamp as well as their corresponding abstract getter functions. In addition to that, three more abstract functions namely; “readConfig()”, “updateConfig()” and “createObstacles()” to realize more control over the ease of arena configuration and management.\n",
      "Abstract Obstacle Builder and Controller Interfaces: The Abstract Obstacle Builder interface contains only the functions including “createWall()”, “createBox()” and “createCylinder()” for instantiating those obstacles as well as an additional “changeMaterial()” method to change their materials. On the other hand, Obstacle Controller Interface contains a list of Obstacles and following methods:\n",
      "createObstaclesJSON(): generates the JSON config data for the arena configuration.\n",
      "setMaterialById(): sets material by obstacle id.\n",
      "setColorById(): sets color by obstacle id.\n",
      "findObstacleById(): finds an obstacle by given id.\n",
      "findObstaclesByType(): finds obstacles by the obstacle type.\n",
      "removeObstacleById(): removes an obstacle by given id.\n",
      "visualizeObstacles(): returns a list of obstacles that are in the three.js supported format for visualizing.\n",
      "Abstract Obstacle Class: An abstract class for representing the required attributes for the general obstacle entities as well as their getter and setter functions. This class includes the properties: id, type, position, color, geometryType, materialType, debug, created, updated, reality as we identified these are general attributes for all obstacles in the simulated environment.\n",
      "In the inherited obstacle entities (Wall, Box, etc) there is a method named “geometric()”, which returns the geometric properties of the obstacle and a method named “visualize()” which returns how the obstacle should be rendered in the mixed reality visualizer, based on a predefined schema. Schema allows users to define a list of primitive objects with their own geometric properties, material properties and positioning options.\n",
      "Figure 3.5 “pera-swarm” - Library Architecture\n",
      "The above described abstract classes and interfaces were identified according to their real-world usability and flexibility for supporting wider use cases. In this way, a clear separation of these creation and manipulation methods is obtained that is required for future implementations for the developers and researchers to customize these individual interfaces according to their application purposes.\n",
      "In addition to the “pera-swarm” library, we have also developed an MQTT router implementation named “@pera-swarm/mqtt-router” (https://github.com/Pera-Swarm/mqtt-router). The communication between the swarm server and each virtual robot instance are to be handled via this library as it consists of a message queue implementation and flexible routing functionality to handle each relevant message endpoint in the protocol stack.\n",
      "Figure 3.6 “@pera-swarm/mqtt-router” Block Diagram\n",
      "As shown in the Figure 3.6, we have implemented three high-level modules namely, MQTT Router, Message Queue and Route with Wrapper to function an efficient MQTT router for handling communication within the dependent applications. The wrapper will add certain higher-level attributes to each route depending on the specific functionality in order to complete the relevant subscriber event for the selected MQTT topics. The Message Queue simply implements an efficient queue processing using the npm library “queue” (https://github.com/jessetane/queue) with the dispatcher function as the route subscriber event handler method as specified by the routes list. In the MQTT Router module, there are two services namely MQTT Client Service and Discovery Service and they provide low-level communication handling and a route discovery realization with a simple locking mechanism for a specific MQTT channel/route.\n",
      "Both of these libraries were developed using Typescript language and compiled into “ES5” standard ( https://en.wikipedia.org/wiki/ECMAScript) “CommonJS” module ecosystem for JavaScript and were published into npm directory with the library names. The final experiments were carried out on the following versions.\n",
      "“pera-swarm”: 1.2.3\n",
      "“@pera-swarm/mqtt-router”: 1.2.1\n",
      "We developed the above-described libraries for the Open Source Community with the conclusion that researchers and enthusiasts can quickly get started on developing a customizable mixed-reality swarm environment platform according to their specific requirements without the cost of overhead for implementing from the ground up to most general use cases.\n",
      "Communication\n",
      "Communication between Simulator Components\n",
      "Communication is an important part of the swarm simulation. Since we followed a distributed architecture, communication between each sub-component is very important and it should be in real-time. Also, the communication delay should be minimized. The distributed system contains various components with various resource allocation, including web servers, local servers as well as micro-controllers. Hence, the communication method should be able to run on all these sub-component.\n",
      "We chose MQTT (Message Queuing Telemetry Transport) as the primary way of communication. It is an OASIS standard messaging protocol for the internet of things, based on lightweight publish/subscribe messaging transport with support of the quality of service.\n",
      "The Figure 3.7 contains a few communication channels we implemented.\n",
      "Figure 3.7 MQTT Protocols on robot localization\n",
      "Communication between Swarm Agents\n",
      "Swarm communication is an important area of swarm behavioral research, considering inter-agent communication. Since there are both physical and virtual robots in our approach, communication between them should be modeled with the support of the swarm simulator server.\n",
      "Physical robots can have hardware support for the communication while virtual robots can have emulators for this purpose. However, with an aid of the simulator, we can easily define entire virtual communication methods, without depending on the expensive hardware modules, but more similar to the real hardware functionalities. Therefore, we implemented two entire virtual communication modules; simple communication and directed communication.\n",
      "Figure 3.8 Robot to robot simple communication\n",
      "In “simple communication”, robots can broadcast messages to the robots nearby within a defined radius. In the “directed communication”, the robots can communicate only with the robots in front of them, also until defined distance range.\n",
      "When a robot transmits a message in “simple communication”, it will send that message to the ‘communication-out’ channel of the simulator, and the server is listening to this channel (Figure 3.8). Once the simulator receives a message into this ‘communication-out’ channel, it will consider the robot’s coordinates and determine the robots who are eligible to receive this message. The radius or the distance it considers is determined by the robot that originates the message or the communication protocol implementation. Then the simulator will send this message into the ‘communication-in’ channels of the selected robots and the robots will receive this as a communication interrupt message.\n",
      "Testing Toolkit - Sandbox\n",
      "The components which have been described above are distributed and decentralized. Also, we needed to validate and test these components individually and collectively at different stages. So, we implemented a “SandBox” application to monitor the performance and validate their functionalities.\n",
      "The Pera-Swarm SandBox (v2.0 - the current stable version) is a cross-platform progressive web application (Figure 3.9) developed over a time frame to overcome these problems. The basic functionalities of the application are testing each communication protocol and validating responses, creating and managing virtual robot units within the application, building up the virtual environment with virtual obstacles, managing authentication for Visualizer so that the Visualizer will only be accessible via the generated URL.\n",
      "Figure 3.9 SandBox Application\n",
      "The SandBox application has the following views and routes for the described configurations and monitoring to provide the high-level functionality to administrate swarm robotic experiments.\n",
      "Settings route: to configure the basic settings (host, MQTT channel, path) for the swarm environment after authenticating to the system.\n",
      "Robot Route: to send and receive messages relevant to robot configuration protocols.\n",
      "Communication Route: to test communication protocols namely, simple communication and directed communication as described in inter-robot communication Section.\n",
      "Distance Sensor Route: to send and receive messages relevant to robot and server distance sensor protocols.\n",
      "Color Sensor Route: to send and receive messages relevant to robot and server color sensor protocols.\n",
      "NeoPixel Route: to monitor and control NeoPixel/RGB LED strip of robots.\n",
      "Environment Route: to configure and preview environment configurations and create, update and export a config file.\n",
      "Log View: contains all the intercepted communication through the MQTT channel.\n",
      "After authenticating, the users can conduct their own experiments and configure obstacles and set up environments through the SandBox application. Also, the intercepted communication history can be viewed and cleared in a given time. The application is a responsive, progressive web application implemented using Framework7 (https://www.framework7.io/) which is a cross-platform framework for developing web applications with the additional support of native features. In the Floating Action Button, the authorized URL for tokenized Visualizer application for the configured experiment can be found along with the pera-swarm documentation and supported communication protocols documentation.\n",
      "Experiments and Analysis\n",
      "Experiments\n",
      "The main objective of the designed experiments was to validate the functionality of the simulator and the possibility of running swarm behavior algorithms on a mixed reality environment. For that two behavioral experiments were designed. The first experiment was to test the communication and the interactions between robots and the second experiment was to validate the mixed reality-based sensing.\n",
      "Color Ripple Experiment\n",
      "In this experiment, the communication between robots and the interaction between robots (virtual/real) and the simulator were tested.\n",
      "First, all the robots were placed in different locations in the simulation environment. Physical robots were placed on the arena with an image-based localization system. Then we assigned some coordinations to the virtual robots and deployed them into the same environment through the mixed reality simulator.\n",
      "Then chose a robot at random and sent the initial message to that robot via the SandBox application as in the following format\n",
      "[HopID][r] [G][b]\n",
      "HopID: the number that indicates how many robots passed the message using a virtual communication protocol. For the first message, this is 0.\n",
      "R, G, B: values of the Red, Green and Blue components of the color should be shown in the robot. The value must be between 0 and 255.\n",
      "Example: 0 255 0 0 (Robots will show the red color)\\newline\n",
      "Then HopID of the robot was increased by one and re-transmitted the color values to nearby robots using its simple communication channel. Nearby robots also followed the same procedure and it made a color ripple-like behavior in the swarm of robots.\n",
      "The Figure 4.1 shows the results of one experiment done with 10 robots, which were placed in a circle. The starting message of “0 255 0 0” was given to robot number 2, and then it was indicated the Red color as shown in slide 2 of the figure. Then next two adjacent robots, robot number 3 and 1 were colored in red, as shown in slide 3, while robot 1 turned off its own red color. The same procedure was continued by other robots as shown in other slides.\n",
      "Figure 4.1 Results on Color Ripple Experiment\n",
      "Here, robots with IDs 0,1,2,6 and 7 were physical robots while the rest are virtual ones. In these experiments, the message initially transmitted by robot number 2 will propagate in two directions, clockwise and counterclockwise. When observing the message propagation, it shows messages propagate through the chain differently, by taking different amounts of times between each hop. We can assume it is because of propagation delays, querying delays and other delays in MQTT packet transmission.\n",
      "Discover an Object Experiment\n",
      "This experiment was specially designed to test the functionality of the distance and color sensors, the functionality of the localization system, and the interactive behaviors of robots in both realities.\n",
      "In this experiment, all ten robots were assigned into fixed coordinates and asked to discover a red-colored cylinder available in the simulation arena. We located one red color cylinder physically and one virtual red color cylinder placed in the arena on two fixed coordinates, as shown in the Figure 4.2. During this experiment, the robots moved in random directions and once they discover an obstacle (detect from the front distance sensor), it measured the color of the obstacle (using an RGB color sensor). If the color of the obstacle is equal to the color we assigned to discover, it informs the other robots that the discovery is completed, and other robots stop their movements and indicate the red color on their LED rings.\n",
      "Initially, this experiment was started with five physical robots and five virtual robots. Then for each next trial, one physical robot was removed and replaced by a virtual robot. The experiment was continued until all the robots in the experiment became virtual robots, and the behaviors of the robots were recorded for analytical purposes.\n",
      "Figure 4.2 Mixed reality and physical setups of the experiment\n",
      "Although these robots started from the same place, they followed random movements. Therefore, the time taken to complete this task for each experiment varied.\n",
      "During this experiment, we observed that sometimes physical robots moved through virtual obstacles and virtual robots moved through physical obstacles. We hypothesized that this was due to a transmission delay between the robots and the simulator.\n",
      "Most of the research works we observed, did not involve an experiment of swarm intelligence with both realities at once. However, we were able to run a few experiments with the robots in both realities side by side.\n",
      "As we mentioned earlier we did not consider the successful delivery of the MQTT packets. Therefore we experienced some robots missing the message that we were sending and had to re-transmit the message.\n",
      "Conclusions and Future Works\n",
      "Swarm Robotic experiments and applications are relatively expensive compared to other types of robotic representations including multi-robot environments which usually comprehend the physical environment. This study has introduced a method to reduce the cost as well as to avoid difficulties that occur in high-risk tasks using virtual robots and high-level implementation of a swarm robotic simulator platform with a collection of extensible libraries. To test the workability of the system and validate the integration of the whole architecture, a few physical robots have been built over the given period.\n",
      "Combining both virtual and physical robots, the mixed reality swarm robotics platform has been successfully validated with the ability for the robots (regardless of the reality) to move and navigate to a particular point and an experiment consisting of an exploration-based algorithm has been carried out. Finally, a web-based simulator has been implemented to visualize the movements and monitor the simulator’s behavior. This work has proven that the traditional limitations of swarm robotics could be further realized with the help of virtual reality integration including virtual robot units and a simulator to overcome the difficulties and to provide additional performances in more comprehensive and extended environmental configurations such as virtual reality and augmented reality.\n",
      "Introducing virtual robot units or instances to the swarm robotic environment for the conducted experiment was carried out using our local computer hardware configurations despite the fact that more scalability and performance could be achieved in a cloud computing environment to address the performance overhead. Our experiment was conducted on a smaller scale (5 to 10 robots) swarm including both physical and virtual robot units, because our specific experiment was sufficient of such a scale.\n",
      "Moreover, the work could be further expanded to integrate augmented reality environments that are helpful in such experiments to deliver promising results. The augmented reality functionalities are limitless given the fact that using our simulator platform, libraries could integrate much easily with such experiments. However, these experiments could also be expanded to more complex real-world applications such as worker robots for automated industrial environments, a swarm of robots to explore and analyze unreachable environments, etc.\n",
      "Links and References\n",
      "Website: pera-swarm.ce.pdn.ac.lk\n",
      "Pera-swarm - GitHub Organization\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Optimizing Mitochondria Genome Assembly And Annotation With Skim Sequencing Data https://cepdnaclk.github.io/e15-4yp-Optimizing-Mitochondria-Genome-Assembly-And-Annotation-With-Skim-Sequencing-Data\n",
      "\n",
      "\n",
      "Optimizing the procedure of mitochondrial genome assembly and annotation\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Team\n",
      "E/15/330, K.Sathurshan\n",
      "E/15/366, S.Thinesh\n",
      "E/15/373, R.Vaheesan\n",
      "Supervisors\n",
      "Dr. Asitha Bandaranayake, email\n",
      "Prof. Pradeepa Bandaranayake, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis-\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "Genome sequencing and genome assembly are the computational process of converting the sequence composition of the gene within the cell of an organism in a human readable form. Mitochondria is an important genome in the cell and there is a need to study this genome for various reasons.\n",
      "The process of determining the order of bases A,G,T,C in the genome is known as genome sequencing.While sequencing the genome the original genome is separated into huge number of small parts known as reads and the end results of sequencing is a huge pool of reads(strings of A,G,T,C).These reads must be assembled back in a computer so that a biologist can identify and annotate the functionality of it.\n",
      "There are several techniques were developed to sequence the genome,\n",
      "the modern approach is next generation sequencing.\n",
      "Ilumina sequencing is one of the broadly used next generation sequencing method and this method produce large number of high precision sequencing\n",
      "short reads whereas other older methods produce longer reads.So the computational complexity of assembling back this large amount of read is high but cost efficient.\n",
      "Here we mainly discuss on low coverage sequencing data assembly.The sequencing data consist of multiple copies of same genome in low coverage data the number of copies are relatively lower than high coverage data.\n",
      "In this project we examined the tools used for mitochondrial genome assembly by assembling differnt datasets and measured the parameters that make impact in the assembly process. From the results we obtained from the experiment we made decisions of doing mitochondrial genome assembly.\n",
      "Related works\n",
      "There are several assembly pipelines suggested for assembling genome, below are the narrow downed pipelines/ tools used for mitochondrial genome assembly. There are two common approaches for assembly genome one is De novo assembly another one is Reference based alignment.Some tools use one of these approaches and some use hybrid approach consisting both.\n",
      "Here let’s discuss the tools that are used specifically for mitochondrial genome assembly\n",
      "NovoPlasty\n",
      "In NOVOPlasty there is a way to assemble genome from skim sequenced data, we can either assemble a whole organelle genome or isolate mitochondrial genome first and assemble it later. The best strategy for assembling depends on available data-set,computational power and reference genome availability. This tool uses a new algorithm to do the de novo assembly which is known as seed-extension, by this method NOVOPlasty claims that it assemble genome as accurate as other reference based assemblers such as MITObim,MIRA,ARC,SOAPdenova2.\n",
      "NOVOPlasty decreases computational complexity by storing the reads in a hash table and seed-extend it. As this tool claims it took 11 minutes duration and 15 GB memory to assemble 99.98% of G.intermedia mitochondrion genome with 100 % accuracy where MITObim took 4777 minutes,63.4 GB memory to assemble 99.95% of genome with 99.93% accuracy and SOAPdenovo2 took\n",
      "19 minutes,27 GB memory to assemble 99.98% of genome with 99.98% accuracy.\n",
      "Norgal\n",
      "Norgal is a tool used to extract mitochondria genome from WGS data and assemble it using de nova assembly. In previous methods like in MToolBox there is a need for reference mtDNA either from database or user input, but in Norgal it identifies the high frequency kmers (string fragmentations of genome) from WGS data to extract and assemble the mtDNA. Norgal is able to extract mtDNA by calculate the read depth of genome and assume the reads that have more read depth (frequency) than a specified threshold (nuclear read depth) are from mtDNA. Then it performs de nova assembly on those reads to assemble the genome.\n",
      "The whole pipeline of Norgal is\n",
      "Pre-processing reads -> Estimating nuclear read depth threshold -> Remove reads based on k-mer occurrences -> Assembly with high-frequency k-mers -> Annotation and validation\n",
      "Norgal has more advantages than its earlier predecessors like MToolBox,MITOBim and NOVOPlasty. Still it has some flaws in its pipelines, like the high run time, Norgal is slower than above mention tools also it consume more memory (the peak usage was 38-48GB where MITOBim needs only 1-13 GB) and it cannot be applied to organisms that have low copy numbers of samples cause Norgal needs a high depth coverage of reads as the current project we are working mainly focus on extract and assemble genome with low coverage reads which will be an advancement to this tool. Overall as they claim Norgal is the current best when there are no reference genomes available.\n",
      "SMART: Statistical Mitogenome Assembly with Repeats\n",
      "Statistical Mitogenome Assembly with Repeats (SMART) is yet another proposed pipeline for automated assembly of complete circular mitochondrial genomes from WGS data. Reference based assembly tools are faster but they can’t be used to assemble completely new mtDNA, Norgal can assemble the completely new genome by using de nova assembly but it requires high coverage reads and cause high runtime and memory. In Norgal and tools like it they attempt to remove reads from the nuclear genome by performing an assembly of the full set of reads and then using the read coverage of the longest contigs to estimate the coverage of the nuclear genome but in SMART it estimates the mean and standard deviation of mtDNA k-mers in WGS reads based on a seed sequence (This is not widely used approach of sequencing), then select the reads which has k-mer counts falling within three standard deviations of the estimated mean.\n",
      "SMART claims that it provides better results than other tools like\n",
      "Norgal, NOVOPlasty, PlasmidSPAdes and MToolBox but the run time and memory usage of this pipeline is not yet discussed.\n",
      "Methodology\n",
      "Design Overview\n",
      "This chapter covers how the work flow of the mitochondrial genome assembly optimization is planned. From the literature review we could find\n",
      "the tools that are dedicated for mitochondrial genome assembly. We then analyze the tools by reading and short listed some of them for experimental analysis.\n",
      "Genome assembly remains a challenging computational problem, the next-generation sequencing technologies which generate a greater amount of data and\n",
      "make the assembly process more complex. There is a huge demand for a pipeline that will assemble a genome quickly and accurately.\n",
      "In this next-generation sequencing, the results are short reads, so we mainly focused on the tools that do short read assembly of mitochondria genome.\n",
      "Conceptual Design\n",
      "Experiment Setup and Implementation\n",
      "Prototype\n",
      "We design an experimental setup to compare the tools that are specifically build to do mitochondrial assembly. In our experiment we first shortlist 4 tools for analysis they are: NovoPlasty: seed and extend algorithm & De novo assembly, Norgal : De novo assembly(No need for seeds),SMART : seed-and-extend algorithm & De novo assembly and Mitobim : Reference based assembly.\n",
      "Data Collection\n",
      "We choose the seed and reference genome of the datasets by analyzing their phylogeny. Available closest relatives of the species are used as seeds and reference genome. Here we used Cinnamomum Verum which is 1.5GB, Solanum Melongena which is 5GB, Homosapien Sapien which is 12MB and Oncorhynchus mykiss which is 12GB. Here we used Cinnamon Verum, Arabidopsis Thaliana, Oryza sativa, Solanum Melongena and output from Norgal assembly as seeds for NovoPlasty while assembling Cinnamomum Verum and Solanum Melongena. We used Arabidopsis Thaliana as a seed for SMART while assembling Cinnamomum Verum. We used Pan troglodytes seed for NovaPlasty while assembling Homosapien Sapien. For the NovaPlasty assembly of Oncorhynchus mykiss, we used T.thymallus COI sequence as seed. For mitobim we didn’t use seeds but used references genome of close species so for Cinnamomum Verum only available closest species is Arabidopsis Thaliana mitochondrial genome, Solanum Melongena (egg plant) we used Solanum macrocarpon(African eggplant) mitochondrial genome, for Homosapien Sapien (human) we used Pan troglodytes(Chimpanzee) mitochondrial genome and for Oncorhynchus mykiss we used T.thymallus mitochondrial genome.\n",
      "Tools\n",
      "In our experiment we first shortlist 4 tools for analysis they are, NovoPlasty uses seed and extend algorithm where a seed input is given along the dataset so the assembly can begin with that seed. The de novo assembly starts from these seed contigs. Norgal uses De novo assembly so there are no need for seeds. SMART uses seed and extend algorithm and follows De novo assembly. Mitobim is a reference based assembly tool. These 4 tools have their own uniqueness in assembling mitochondrial genome.\n",
      "Server Details\n",
      "University of Peradeniya, Aiken Server(RAM - 252GB Number of CPU cores - 32 cores) and AgBC Server (RAM - 262GB Number of CPU cores - 48 cores)\n",
      "Configure MitoBim Tool\n",
      "We used docker image for MitoBim tool. MITObim image contains a stripped down version of Ubuntu 16.04 and all necessary executables and dependencies to run the latest version of MITObim. Here we show how to recover the complete mitochondrial genome of Thymallus thymallus using the mitochondrial genome of Salvelinus alpinus as a starting reference. We used AgBc server for run mitobim assembly.\n",
      "Step 1 - specified a working directory on the machine that will be synced with the /home/data directory in the image and enter the self contained shell environment to run MITObim\n",
      "WORKING_DIR=/your/desired/working/dir\n",
      "sudo docker run -i -t -v $WORKING_DIR/:/home/data\n",
      "chrishah/mitobim /bin/bash\n",
      "Step 2 - Test the wrapper script by doing\n",
      "~/PATH/TO/MITObim.pl\n",
      "Step 3 - Do the mapping assembly with MIRA 4. MIRA is a Sequence assembler and sequence mapping for whole genome shotgun and EST / RNASeq sequencing data.\n",
      "ln -s /PATH/TO/testdata1/Tthymallus-150bp-300sd50-interleaved.fastq\n",
      "reads.fastq\n",
      "ln -s /PATH/TO/testdata1/Salpinus-mt-genome-NC_000861.fasta reference.fa\n",
      "Step 4 - Create the manifest file and specifying the parameters for the MIRA assembly\n",
      "echo -e \"\\n#manifest file for basic mapping assembly with\n",
      "illumina data using\n",
      "MIRA 4\\n\\nproject =\n",
      "initial-mapping\n",
      "-testpool-to-Salpinus-mt\\n\\njob=genome,mapping,accurate\\n\\\n",
      "nparameters = -NW:mrnl=0 -AS:nop=1 SOLEXA_SETTINGS -CO:\n",
      "msr=no\\n\\nreadgroup\\nis_reference\\ndata = reference.fa\\nstrain =\n",
      "Salpinus-mt-genome\\n\\nreadgroup = reads\\ndata = reads.fastq\\\n",
      "ntechnology = solexa\\nstrain = testpool\\n\" > manifest.conf\n",
      "Step 5 - run MIRA 4\n",
      "mira manifest.conf\n",
      "Step 6 - Baiting and iterative mapping using the MITObim.pl script\n",
      "/PATH/TO/MITObim.pl -start 1 -end 10 -sample testpool -ref\n",
      "Salpinus_mt_genome -readpool reads.fastq -maf\n",
      "initial-mapping-testpool-to-Salpinus-mt_assembly\n",
      "/initial-mapping-testpool-to-Salpinus-mt_d_results\n",
      "/initial-mapping-testpool-to-Salpinus-mt_out.maf &> log\n",
      "Step 7 - After the process has finished looking into the log file\n",
      "tail log\n",
      "Configure Norgal Tool\n",
      "Norgal uses kmer frequencies to try to assemble the mitochondrial genome from NGS sequencing reads (currently only Illumina paired end reads are supported). It requires Python2.7+ or Python3, Java and matplotlib. The size of our input data determines how much memory we’ll use. Norgal has been tested on computers with 16GB, 32GB, and 64GB of RAM. In other words, if our reads are just a few GB each, it should work; but, if our reads are 12 GB each, and our machine only has 12 GB of RAM, it will almost certainly not work, and we’ll have to run it on a node or anything similar. But in our case, we used Aiken and Agbc server both are 256GB RAM. So we did not address any issue during the assembly.\n",
      "Step 1 - Download the program\n",
      "git clone https://github.com/kosaidtu/norgal.git\n",
      "Step 2 - Execute the norgal.py script\n",
      "python norgal/norgal.py -h\n",
      "Step 3 - Run the paired end data(f.fq and r.fq)\n",
      "python norgal.py -i f.fq r.fq -o norgal_output --blast\n",
      "Configure NOVOPlasty Tool\n",
      "NOVOPlasty is a de novo assembler and heteroplasmy/variance caller for short circular genomes. First, we have to find a suitable seed and the seed file should be formatted in the same way as a regular fasta file. We need to concern the seed sequences that are identical in mitochondrial and chloroplast genomes should be avoided. After that we have to create a configuration file, here we have to specify the path of the dataset, k-mer number, Reference sequence path and Seed inout path. Then finally we have to run the NOVOPlasty with configuration file.\n",
      "perl NOVOPlasty4.3.pl -c config.txt\n",
      "Configure SMART Web Interface\n",
      "The Figure below shows the SMART Web Interface here we have to input the paired end read data and seed file then it will output the assembly and annotation details.\n",
      "Results and Analysis\n",
      "Assembly Results\n",
      "As first part of the experiment a comparative analysis is done using NovoPlasty,NORGAL, MitoBim and SMART.\n",
      "Assembly Results of Cinnamomum Verum\n",
      "For the Cinnamomum Verum dataset we used 4 different seeds for assembling in NovaPlasty tool. When we used Cinnamon Verum(A small part of the dataset to be assembled) as the seed there were no N50 contigs present in the output file and it took less than 5 minutes run time. This assembly used 6.02 4GB ram and only one CPU core and one thread ran by the tool. When we used Arabidopsis Thaliana as the seed there were 3 contigs and 1 N5O contig present in the output file. The assembling process took 19 minutes to finish. This process used 6.024 GB ram and only one CPU core and one thread ran by the tool.When we used Oryza sativa as the seed there were 1 contig of length 5428 is present in the output file. The assembling process took 3 minutes to finish. This process used 6.024 GB ram and only one CPU core and one thread ran by the tool.When we used the norgal output as the seed there were 3 contigs and 1 N5O contig present in the output file. The assembling process took 21 minutes to finish. This process used 1 GB ram and only one CPU core and one thread ran by the tool.\n",
      "When we assembled Cinnamomum Verum using Norgal tool, there were no N50 contig present on the output file. It tooks 376 minutes to finish and it used 1GB ram. It took 2CPU cores and ran 3 threads.\n",
      "When we assembled Cinnamomum Verum using SMART, we used Arabidopsis Thaliana as the seed and no N50 contigs present in the output file. It approximately took 60 minutes to finish. After we submitted the data to the web server to assemble and annotate it choose 16 threads to run.\n",
      "When we asembled Cinnamomum Verum using MitoBim tool, there was only one N50 contig present in the output. It took approximately 45 minutes and used 2GB of RAM. It took 2CPU core and used 4 threads.\n",
      "Assembly Results of Solanum Melongena\n",
      "For the Solanum Melongena dataset we used 4 different seeds for assembling in NovaPlasty tool. When we used Solanum Melongena (A small part of the dataset to be assembled) as the seed there were no N50 contigs present in the output file and it took 15 minutes run time. This assembly used 20 4GB ram and only one CPU core and one thread ran by the tool. When we used Arabidopsis Thaliana as the seed there were no contigs in the output but it had hits while the annotation process. The assembling process took 31 minutes to finish. This process used 12 GB ram and only one CPU core and one thread ran by the tool.When we used Oryza sativa as the seed there were 1 contig with no hits present in the output file. The assembling process took 18 minutes to finish. This process used 17.5 GB ram and only one CPU core and one thread ran by the tool. When we used the norgal output as the seed there were 3 contigs and 1 N5O contig present in the output file. The assembling process took 42 minutes to finish. This process used 12.5 GB ram and only one CPU core and on thread ran by the tool.\n",
      "When we assembled Solanum Melongena using Norgal tool, there were intermediate contigs present on the output file. It tooks 780 minutes to finish and it used 10GB ram. It took 2CPU cores and ran 3 threads.\n",
      "When we assembled Solanum Melongena using SMART, one N50 contig present in the output file. It approximately took 90 minutes to finish. After we submitted the data to the web server to assemble and annotate it choose 16 threads to run.\n",
      "When we asembled Solanum Melongena using MitoBim tool, there was only one N50 contig present in the output. It took approximately 68 minutes and used 2GB of RAM. It took 2CPU core and used 4 threads.\n",
      "Assembly Results of Homosapien Sapien\n",
      "For the Homosapien Sapien dataset we used Pan troglodytes seed for assembling in NovaPlasty tool. We got Complete Circular genome in the output and it took 6 minutes to finish. It used 2GB ram and 1 core CPU and ran 1 thread.\n",
      "When we assembled Homosapien Sapien using Norgal tool, we got Complete Circular genome in the output and it took 50 minutes to finish. It used 1GB ram and 2 core CPUs and ran 3 threads.\n",
      "When we assembled Homosapien Sapien using SMART, we got Complete Circular genome in the output and it took 30 minutes to finish. After we submitted the data to the web server to assemble and annotate it choose 16 threads to run.\n",
      "When we asembled Homosapien Sapien using MitoBim tool, we got Complete Circular genome in the output and it took 8 minutes to finish. It used 2GB ram and 2 core CPUs and ran 4 threads.\n",
      "Assembly Results of Oncorhynchus mykiss\n",
      "For the Oncorhynchus mykiss dataset we used T.thymallus COI sequence as seed for assembling in NovaPlasty tool. We got 1N50 contig in the output and it took 70 minutes to finish. It used 2.772GB ram and 1 core CPU and ran 1 thread.\n",
      "When we assembled Oncorhynchus mykiss using Norgal tool, there were no N50 contigs in the output and it took 1080 minutes to finish. It used 2.016GB ram and 2 core CPUs and ran 3 threads.\n",
      "When we assembled Oncorhynchus mykiss using SMART, there were no N50 contigs in the output and it took 90 minutes to finish. After we submitted the data to the web server to assemble and annotate it choose 16 threads to run.\n",
      "When we asembled Oncorhynchus mykiss using MitoBim tool, we got Complete Circular genome in the output and it took 80 minutes to finish. It used 2GB ram and 2 core CPUs and ran 4 threads.\n",
      "Conclusion\n",
      "Assembling a mitochondrial genome very accurately and efficiently for all kind of datasets is what everyone involved with genomics are looking forwards and this study also going in that way. We have assembled 4 type of dataset with four tools and analyzed it’s performance and accuracy, from the results we obtained we can come to some conclusions on assembling mitochondrial genome. The conclusions we derived from the results can be divided into 3 scenarios which are Dataset based, Runtime based and Resource Requirement. From the 1st scenario we can conclude that all a good assembly needed is a good dataset, in the sense of dataset it means the seeds,reference genome and the size of the dataset. If the size is small the accuracy is much better.If the seeds are good enough we can get good acccurate and efficient assembly from NovoPlasty and SMART tools.But finding such seeds is a crucial task. The second scenario is the run time of the assembly , if there are neither reference genome nor seeds we can still assemble the dataset using Norgal but it consumes more time. As from these two scenarios a pipeline can be developed as shown in the below figure that in case if there are no good seeds we can use the Norgal assembly output of the same species as seed and it will give better assembly.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Optimizing chloroplast genome assembly and annotation with skim sequencing data https://cepdnaclk.github.io/e15-4yp-Optimizing-chloroplast-genome-assembly-and-annotation-with-skim-sequencing-data\n",
      "\n",
      "\n",
      "Optimizing chloroplast genome assembly and annotation with skim sequencing data\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Optimizing chloroplast genome assembly and annotation with skim sequencing data\n",
      "Team\n",
      "E/15/209, H. Kithma Madhushani, email\n",
      "E/15/233, Nipuni Muthucumarana, email\n",
      "E/15/325, Chalani Weerarathna, email\n",
      "Supervisors\n",
      "Dr. Asitha Bandaranayake, email\n",
      "Prof. Pradeepa Bandaranayake, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "Chloroplast genes and genomes play an important role in plant phylogeny and speciesidentification. Skim sequencing is getting low coverage genome sequencing data that has,nuclear, choloroplast and mitochondria genome sequences. Since the fast developmentof high throughput sequencing technologies, it’s low cost to urge the low coverage dataof the whole genome (usually concerning 20-30GB data), that is enough to assemblea whole chloroplast genome. To date, there are several assembly processes/pipelinesdesigned to assemble a whole chloroplast genome. However, what proportion knowledgeis required or really utilized in such analysis is a problem. Having such information canfacilitate biologists to style their experiments properly and cost-effectively. Biologistsexpect a straightforward, quick and easy procedure to assemble and annotate a circularchloroplast genome from Illumina NGS data.In this project, we’ll analysis the present procedures for chloroplast genome assemblyand annotation, and work on developing the strategies to spot and choose the best set(s)of data and the procedure(s) to assemble a given chloroplast genome as accurately andefficiently, by statistical, computational and heuristical strategies.\n",
      "Related works\n",
      "The process of chloroplast genomes assembly has different strategies. Consider WholeGenome Sequencing (WGS) data and there are two main steps required for the process.First one is the extraction of chloroplast reads from the sequencing data and the secondstep is resolution and assembly of the special circular structure including the IRs. Thefirst step can be achieved by mapping the reads to a chloroplast reference. To do thisprocess, assemblers can use k-mers. that are highly repeated in the chloroplast reads.Another method is to use the highly represented reads from the data set without usingreference-based approach. Apart from those two methods. There is another methodcalled NOVOPlasty, which combines the above two approaches by using a chloroplastreference as seed and then trying a simultaneous assemble of reads based on list of k-mers.\n",
      "Genome assembly process is called as a sequence assembly. There are two ways to do asequence assembly.\n",
      "De Novo assembly\n",
      "Reference mapping assembly\n",
      "‘De Novo’ means start from the beginning. As the name of it, ’De Novo’ assemblersare the type of program that assembling a large of short DNA sequence and create fullsequences of the original chromosomes from which the DNA originated without the useof a reference genome. As an example in ’De novo assemblers’ does not use any priorknowledge of the source DNA sequence length, layout, or composition.There are two common types of ’De Novo assemblers’ named as ’greedy algorithmassemblers’ which aim for local optima in alignments of smaller reads and ’graph methodassemblers’ which aim for global optima. String graph and De Bruijn graph [6] are twocommon graph methods. There is a common protocol for the De Novo assembly.\n",
      "There are several bioinformatic tools available for the De Novo genome assemblyprotocol [7]. Those tools can be used in three areas.\n",
      "Tools for reading and quality control\n",
      "FastQC\n",
      "NGS QC\n",
      "Trimmomatic\n",
      "Tools for assembly\n",
      "NOVOPlasty\n",
      "Velvet Optimizer\n",
      "Faster Statics\n",
      "Spades\n",
      "Soap-denovo\n",
      "Tools for determining the suitability of a draft set of contigs\n",
      "QUAST\n",
      "Manuve assembly metric\n",
      "CLC BioWorkbench\n",
      "On the other hand ‘reference mapping assemblers’ are a type of program that assem-bling reads against and existing backbone sequence. It builds a sequence that is similarbut not necessarily identical to the backbone sequence. In this assembly method, partswith multiple or no matches are usually left for another assembling technique to lookinto.Instead of using De Novo assembler and ‘Reference mapping assembler’ separately,the combination of these two methods provides an effective and powerful tool to improvegenome assembly by integrating information of a related genome. This method is calledReference-guided de novo assembly approach.\n",
      "Main Assembly Softwares\n",
      "1.GetOrganelle\n",
      "2.Fast-plast\n",
      "3.NovoPlasty\n",
      "Some factors were taken into consideration when testing the tools and those factors areassembly time, memory and CPU utilization. Time requirement for the assembly is agood measure as it shows huge differences from tool to tool. Variation in run time differsfrom few minutes to several hours. Input data and number of threads used also affectedfor the time requirement. In the experiment, tools are tested with a time limit of 48h.Some assemblies exceeded that time limit. According to the test results, IOGA andFast-Plast. followed by ORG.Asm and GetOrganelle took the longest time periodfor the assembly generation. ChloroExtractor can be considered as the most timeefficient tool and it was somewhat faster than NOVOPlasty and Chloroplast assemblyprotocol.Having access to multithreading is beneficial for the tools. Chloroplast assemblyprotocol, chloroExtractor, GetOrganelle and Fast-Plast methods profited from havingmultiple threads. But NOVOPlasty and ORG-Asm cannot be recognized independentlyby using multithreading because both of them required almost the same time to utilize 1,2, 4 or 8 threads.When considering the memory and CPU usage, for the same input data set and forthe same number of threads, disk usage and peak memory were recorded and also, meanand peak values of CPU usage recorded for each an every assembler. Although memoryusage patterns shown by ChloroExtractor and IOGA assemblers influenced a little bythe size of the input data, other assemblers’ peak memory usage influenced up to aconsiderable level. If the input date size is higher related to their memory and CPUusage, assemblers are profited from having higher number of threads. But disk usage ofall assemblers does not depend on either size of the input data or the number of threads.\n",
      "Methodology\n",
      "The main goal of this research is to find the most optimal chloroplast assembly tool toassemble whole genome sequencing data. As an example, we are going to assemble acinnamon data set using the best three tools which we identified from the research andthen the results from each tool will be compared. From the comparison we can identifythe weak points and strengths of each tool. Then we build a new pipeline includingall identified strengths, by combining different methods together. Using the new tool,we can assemble the same cinnamon data set and check whether the results are moreaccurate than the results obtained previously from each tool. We can repeat the sameprocess for different newly built pipelines with different strengths.\n",
      "Experiment Setup and Implementation\n",
      "We tested for several assembly tools for their run time, cpu usage and memory usage with different datasets considering their accuracy. Based on thee results\n",
      "given we develop a workflow for Optimizing chloroplast genome assembly and annotation with skim sequencing data.\n",
      "Results and Analysis\n",
      "We have attach our results and comparison in the root folder of the repository.\n",
      "Conclusion\n",
      "About nearly half of the analyzed WGS data without available chloroplast genome,complete assemblies can be generated using the assembly tools.There are many tools for genome assembly by the present. GetOrganelle , Fast-Plast , NOVOPlasty , ORG.Asm , IOGA and chloroExtractor are someof them. Scientsts tend to compare overall performance of the different chloroplastassemblers depending on the various assessment criteria.When we compared the general performance of the different chloroplast assemblingtools, we need to consider various criteria. The most straightforward assembler in general,both on recreated and genuine information, was accomplished by GetOrganelle. Fast-Plast performed almost likewise on most information. These two devices supplementeach other, together with the instrument can do successful assemblies of full chloroplastsin situations where the contrary instrument comes up short. GetOrgane is the onlytool that can generate assemblies for 15 different datasets . Fast-Plast can generateassemblies for only 3 datasets that vanquished every single other tool. NOVOPlasty was the sole another device that would produce a get together that wasn’t created withthe other constructing assembly tool. Fast- Plast, NOVOPlasty, and ORG.Asm delivered the most valuable outcomes, and along these lines, rerunning the device after afailed endeavor could be an authentic methodology. ChloroExtractor\n",
      "has producedvery few chloroplast assemblies, but requires few materials and is straightforward toinstall and use. Both IOGA and Chloroplast protocol protocols had unsatisfactoryperformance and did not return to reliable chloroplast conventions. These tools canreconstruct the chloroplast genome even without available reference genomes.\n",
      "Therefore, among the above-mentioned tools, GetOrganelle can be used as adefault option for chloroplast assemblies. Fast-Plast is the second option and the thirdoption can be NOVOPlasty.But all tools do not succeed in generating complete chloroplast assemblies andtherefore, we have to determine the strengths and weaknesses of the specific tools.Sometimes it may be necessary to combine different methods or manually explore theparameter space for generating complete chloroplast assemblies. But most of the time,reconstructing thousands of chloroplast genomes is feasible using the currently availabletools.When considering the annotation tools, most of the time, Dogma has been widelyused for gene prediction in chloroplasts. Until recently, it was the only tool specific tochloroplast genomes, that explains its success for the annotation of genomes. Now moreconsistent annotation of genes is produced with GeSeq when compared to the Dogmasuggesting that annotation of most of the previously annotated chloroplast genomesshould now be updated.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Pipeline for Isolation of Fast evolving ITS Regions from Skim Sequencing Data https://cepdnaclk.github.io/e15-4yp-Pipeline-for-Isolation-of-Fast-evolving-ITS-Regions-from-Skim-Sequencing-Data\n",
      "\n",
      "\n",
      "A User-friendly Pipeline for Isolation of Fast-evolving Internal Transcribed Spacer(ITS) Regions from Skim Sequencing Data\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "A User-friendly Pipeline for Isolation of Fast-evolving Internal Transcribed Spacer(ITS) Regions from Skim Sequencing Data\n",
      "Team\n",
      "E/15/016, Anojan S., email\n",
      "E/15/171, Kapilrajh R., email\n",
      "E/15/351, Thakshajini S., email\n",
      "Supervisors\n",
      "Dr. Asitha Bandaranayake, email\n",
      "Prof. Pradeepa Bandaranayake, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "DNA that resides within the nucleus of a cell is the primary genetic material that is responsible for genetic behaviours of various eukaryotic organisms such as plants, humans, animals, algae and fungi as well as prokaryotic organisms such as archaea and bacteria. Genome or DNA of an organism has several complex genomic regions. Specific genomic regions consist of several complex proteins. RNA is the replica of DNA involved in protein synthesis using these complex proteins and instructions carried from DNA. Ribosomes are small particles having these RNA molecules. Ribosomal DNAs are repeating units having fast-evolving as well as conserved subregions. Isolation of fast-evolving regions of rDNA is necessary for a more accurate and successful analysis of variation within and between species. ITS1 and ITS2 are the fast-evolving regions of rDNA that are widely preferred to differentiate various species including humans, plants and fungi. These regions have the highest probability of correct identification and ITS is the most frequently used molecular marker in species variation analysis. There are several computational tools and pipelines available in the literature to isolate ITS regions from different sequence datasets and to analyze the inter-species as well as intra-species variation using these fast-evolving genomic regions. Biologists don’t have a clear understanding on which is the most efficient and suitable computational tool or pipeline to extract and analyze the fast-evolving nuclear ribosomal ITS regions associated with various organisms since they don’t have sufficient computer knowledge. Hence, they find it difficult to select the best tool or technology required for the isolation and analysis process. Therefore, the purpose of our project is to compare the pros and cons of existing computational tools and pipelines based on various parameters such as the CPU time taken to run the software, CPU performance, accuracy, required computer memory and disk space and depending on other specifications to come up with an efficient procedure or pipeline to extract and analyze fast-evolving genomic regions from low coverage skim sequence data at a low cost. Hence, the primary objective of this project is to come up with a simple,user-friendly and efficient workflow or pipeline for the biologists to isolate fast-evolving genomic regions from skim sequencing data for phylogenetic studies.\n",
      "Related works\n",
      "According to our literature review, previous several researches related to ITS regions, prove that ITS is a standard accepted metabarcode marker for several species including plants, fungi and human fungal pathogens. These researches also emphasize that ITS subregions ITS1 and ITS2 have the highest probability of correct identification within and between above mentioned species.\n",
      "2.1 Justifications on ITS Regions\n",
      "One of the researches shows that it is possible to use the ITS2 region of rDNA to distinguish five different Cinnamomum species.\n",
      "Another review paper indicates that the ITS1 region is very useful for reliable identification of medicinal plants and phylogenetic analysis of Gambhari.\n",
      "One of the other articles related to DNA barcoding asserts\n",
      "ITS1 and ITS2 regions as the standard metabarcoding markers to identify fungi species such as Basidiomycota.\n",
      "One of ther papers shows the use of Inter Simple Sequence Repeat (ISSR) markers together with nrDNA ITS sequences incorporated with leaf morphological characteristics to describe cladistic relationships between twelve different Cinnamomum species in Taiwan.\n",
      "In another research paper, highly repeated units of ITS showed distinguishable variation between individual Cerastoderma species in the phylogenetic analysis.\n",
      "Another group of researchers proved a more close phylogenetic relationship between polypoid Elymus plant species and other organisms using ITS sequences.\n",
      "One of the researches approved that utilizing ITS regions as molecular targets provided the higher potential for the characterization of human fungal pathogens.\n",
      "2.2 Justifications on Software Tools and Pipelines\n",
      "According to our literature review, there are various computational tools and pipelines used in several previous researches over the last one and a half-decade to extract and analyze ITS regions from different fungal sequencing datasets. Here, we have provided justifications based on those tools and pipelines.\n",
      "One of the researches shows that ITSx is a software tool to isolate ITS1, 5.8S and ITS2 and also full-length ITS sequences from both Sanger and NGS sequencing datasets.\n",
      "One of the researches of Professor H. Kauserud shows that extracting ITS1 sequences from 12 486 raw pyrosequencing ITS1 dataset using ITSx detected 12 410 ITS1 fungal sequences and he found the low quality or short length reads when examining the rest of the 76 sequences.\n",
      "Research related to ITSxpress shows that it is an improved software tool from ITSx that extends its capability from marker gene studies which use Operational Taxonomic Units (OTUs) to studies that use Exact Sequence Variants (ESVs).\n",
      "This research further justifies that using 4 cores, ITSxpress trimmed ITS1 region samples by a median of 23 times speeder than ITSx. ITSxpress trimmed the ITS2 region 14 times speeder\n",
      "than ITSx. Clustering at 99.5 percent identity minimized the number of reads used for Hmmsearch by a median of 71 times for ITS1 region and 36 times for ITS2 region.\n",
      "Some researchers used\n",
      "ITScan as an automated software pipeline to identify and analyze the variation of fungal species using ITS sequences.\n",
      "Another research related to PIPITS shows that it is also an automated pipeline to analyze fungal ITS sequences. It uses ITSx to isolate ITS subregions and utilizes the RDP classifier for the classification of sequences with the UNITE fungal sequencing dataset.\n",
      "One of the literature uses CloVR-ITS as a portable pipeline to utilize the analysis of fungal communities using ITS amplicon pyrosequencing data.\n",
      "A review paper related to Illumina Metabarcoding Pipeline describes it as a flexible software pipeline to extract and analyze ITS rDNA from Illumina Miseq sequencing data having paired-end reads.\n",
      "One of the other review papers on PlutoF justifies it as a web-based tool that includes the software tool to isolate and classify ITS sequences obtained from high-throughput sequencing datasets.\n",
      "Research associated with CLOTU indicates that it is a software pipeline which helps to speed up the process of analyzing fungal ITS sequences by providing high performance.\n",
      "One of the other review papers emphasizes that another Perl-based software pipeline is also available to automate the BLAST process and to extract ITS subregions from various ITS sequence datasets to speed up the analysis process.\n",
      "Considering the above literature review justifications, these researches have focused on the importance of using ITS regions as a molecular marker for accurate fungal species variation analysis and the articles related to the software tool and pipelines to extract and analyze ITS regions mostly focusing on Fungal ITS sequences. Hence, these papers could not utilize these tools and pipelines to isolate ITS regions from plant and human skim sequence data. We have not found a review paper comparing the pros and cons of all the tools and pipelines. Therefore, through our research, we are going to do a comparative analysis between these software tools and pipelines to identify the best tool or technology or pipeline. Then, we are going to find whether they are applicable for plant and human skim sequence data and how much data is enough for the analysis.\n",
      "Methodology\n",
      "First, we analyzed the software and hardware requirements of the software tools and pipelines that we identified from our literature review such as\n",
      "ITSx, ITSxpress and PIPITS about how much RAM and disk space is needed to install each tool and what kind of input data is needed for each tool. Then, we identified whether we need to input skim data or contigs or scaffolds for these tools. After that, we installed these tools ITSx, ITSxpress and PIPITS with all the other required tools in our department aiken server using the anaconda environment.\n",
      "Next, we have collected the data that separately contains forward and reverse raw reads of different Cinnamomum species such as Cinnamomum Capparu Coronde, Cinnamomum Verum and Cinnamomum Zeylanicum. Then, we tested these tools using the given cinnamomum capparu coronde data containing the forward raw reads around 19 GB and reverse raw reads around 19 GB. We recorded the output and the CPU time for each tool.We earlier got empty files as output for the tools earlier and it took a very long time to obtain the output in akien server.\n",
      "As a result, we got some ITS regions and we verified those output ITS regions by blasting agianst NCBI nr/nt database to make sure we exactly got the ITS regions of cinnamomum species. We did a comparative analysis of the tools based on the CPU time and the similarity of the ITS regions to identify the better tool which is much efficient and accurate. Further, we analyzed the steps of the existing pipeline PIPITS to come up with a similar pipeline by improving it.\n",
      "We used the tool seqtk to partition different sizes of the collected data such as 1GB, 2GB,3GB and 5GB for both forward and reverse raw reads in order to test our pipeline. Earlier, We ran our pipeline in our department aiken server for 1GB and 2GB data of cinnamomum capparu coronde and recorded the respective run times of each tool that performs the relevant step. Then, we shifted to agbc server later because the aiken server was responding too slow. As a result, we have experienced much improved performance for each tool of our pipeline in agbc server compared to aiken server. Hence, we tested the same 1GB and 2GB data in agbc server and recorded the improved run times with respect to each tools of the pipeline.\n",
      "In the first step of our pipeline, we have done the quality checking of the reads to find the GC content, no of low quality reads and other relevant characteristics of the reads.Then, we filtered out the low quality reads using fastqc. However, we couldn’t filter out both forward and reverse reads simultaneously using that tool. Therefore, we found another tool afterqc to filter out both forward and reverse reads at the same time and tested it successfully.\n",
      "After quality filtering, we ran ITSx by directly using the good quality forward and reverse raw reads as input to extract ITS regions. However, we failed in the process and we found that the read length 150bp is not sufficient to extract ITS regions using ITSx. Therefore, we needed to assemble the forward and reverse reads to get contigs in order to maximize the read length. Hence, we used the assembler Spades to obtain the contigs in fasta format. In the next step, we ran ITSx using the resultant contigs in fasta format for the aforementioned different sizes of data separately.\n",
      "Meanwhile, we also converted the obtained contigs from fasta format to fastq format using the tool seqtk since ITSxpress only accepts fastq format input files. Then, we used the resultant contigs in fastq format as input to ITSxpress to extract ITS regions. Here, we looked for more tools associated with fasta to fastq conversion and found the tool bbmap(reformat.sh) in addition to seqtk. Then, we compared the performance between seqtk and bbmap(reformat.sh) for 3GB and 5GB cinnamomum capparu coronde data and observed the difference in the recorded run times. Thereafter, we input the resultant fastq files obtained form both seqtk and bbmap(reformat.sh) to ITSxpress and compared the run times taken to get the output.\n",
      "Earlier, when we ran ITSx using contigs as input for 1GB data, we got empty output file. Then, we merged the forward and reverse reads using the tool vsearch and ran ITSx again using the obtained merged reads as input. As a result, we got some ITS sequences as output. Then, we have checked the quality of the output and blasted to ensure that we got the exact ITS regions of cinnamomum species. However, we identified multiple sequences in the output.\n",
      "Further, we found that some of the sequences in contigs which are greater than 100kbp in read length is the reason behind getting these multiple sequences in the output. Therefore, we filtered out those sequences that are greater than 100kbp from the contigs file using the tool bbmap(reformat.sh). After that, we ran ITSx using the filtered contigs to extract ITS regions and we ended up getting some ITS sequences as output for cinnamomum capparu coronde 1GB data. When we checked the quality of the output this time, we found that there were no multiple sequences.\n",
      "Earlier, we ran ITS using the default mumber of threads which is only one CPU thread and later we increased the number of CPU threads from one to sixteen to run the ITSx. As a result, we found much improvement in the performance of ITSx. After that, we tried with different thread sizes for 1GB cinnamomum capparu coronde data and observed the deviation in the performance of ITSX with respect the increasing or decreasing thread sizes.\n",
      "Meanwhile, we faced no problem when directly using contigs obtained from spades as input to run ITSxpress and we got an ITS sequence as the output from ITSxpress for the same data. Then, we checked the quality of the ITSxpress output and blasted it to verify that the obtained ITS sequence belongs to cinnamomum species. Next, we compared the ITSxpress output with the ITSx output by doing multiple alignment to find whether both of them are same.\n",
      "Further, we tested our pipeline for 1GB cinnamomum verum and cinnamomum zeylanicum data as well using the same process and compared all the results of both ITSx and ITSxpress for the three cinnamomum species based on the performance and quality of the output obtained by blasting the output sequences and doing multiple alignment to obtain the distance matrix.\n",
      "Results and Analysis\n",
      "We have obtained separate results from ITSx and ITSxpress for different sizes of data associated with different cinnamomum species such as cinnamomum capparu coronde and cinnamomum zeylanicum. Then, we blasted those outputs separately against NCBI/nr/nt database to find and verify whether that the obtained blasted results contain ITS regions of cinnamomum species. After that, we compared the ITS output sequence/sequences\n",
      "that contain ITS regions of cinnamomum species obtained from ITSx with the ITSxpress output sequence/sequences which also contain the ITS regions of cinnamomum species by doing multiple alignment using MAFFT algorithm to check whether both are exactly same sequences or not using the created distance matrix.\n",
      "The results are as follows:\n",
      "Comparison 1\n",
      "Comparison 2\n",
      "Comparison 3\n",
      "Comparison 4\n",
      "Conclusion\n",
      "We conclude that if the input for ITSx are the merged sequences of reverse and forward reads having the sequence length between 150bp-300bp and the actual ITS region is greater than 300bp, then the extracted ITS region is more likely to be a partial sequence. On the other hand, if the input sequences to the ITSxpress are contigs assembled from Spades, then, there is a high probability to have a complete ITS region.\n",
      "If the blast results of the ITSx output sequences for a given data size against the NCBI nr/nt database contain the ITS regions of a relevant species and the blast results of the ITSxpress output sequences for the same data size against the NCBI nr/nt database also contain the ITS regions of the same species, then when we compare both these ITSx and ITSxpress sequences using multiple alignment, we can conclude the both the ITSx and ITSxpress output are exactly same for a given data size if the created distance matrix shows no difference.\n",
      "In future, we suggest to test our pipeline for different datasets associated with different species such as wild rice and strobilathes. Overall, we believe that our work will be very helpful for the biologists to provide them a clear idea on the\n",
      "isolation of ITS regions as efficiently and as accurately as possible from skim sequencing data for their phylogenetic studies.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Real Time Data processing and AI for Distributed IoT https://cepdnaclk.github.io/e15-4yp-Real-Time-Data-processing-and-AI-for-Distributed-IoT\n",
      "\n",
      "\n",
      "Real-Time Data processing and AI for Distributed IoT\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Real-Time Data processing and AI for Distributed IoT\n",
      "Team\n",
      "E/15/246,Rajitha Opanayaka, email\n",
      "E/15/385,Amila Weerasinghe, email\n",
      "E/15/363, Rashmi Thilakarathne, email\n",
      "Supervisors\n",
      "Dr. Upul Jayasinghe, email\n",
      "Dr. Damayanthi Herath, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "Artificial Intelligence has impacted in a variety of\n",
      "industries, leading the world towards revolutionary applications\n",
      "and services that are primarily driven by high-performance\n",
      "computation and storage facilities in the cloud. This is mainly due\n",
      "to the advantage of having higher computational power, larger\n",
      "storage capacity and scalability. But with the increase of millions\n",
      "of IoT devices, a huge amount of data is being generated by\n",
      "end devices. To process such data, the distributed end devices\n",
      "have to communicate with the cloud servers making it difficult\n",
      "to generate real-time decisions though it consumes a lot of\n",
      "resources including bandwidth, processing and storage facilities\n",
      "at the cloud. On the other hand, Edge computing architectures\n",
      "enable a distributed way to process data near the sources of\n",
      "data which leads to facilitate real-time processing. But with the\n",
      "limited resources in the end devices, it is quite challenging to\n",
      "perform complex AI algorithms. Hence to facilitate such services\n",
      "and to enable real time processing at the edge,a novel approach\n",
      "is proposed base on computation distribution, vectorization,\n",
      "computation offloading, parallelization and federated learning\n",
      "techniques.\n",
      "Related works\n",
      "Use of Map Reduce to distribute the computation\n",
      "The distribution of computation can be categorised basically under three main scenarios:\n",
      "• When the training data is large.\n",
      "• When data to be classified is large.\n",
      "• When the Neural network consists of a huge number of nodes.\n",
      "When the training data set is larger training data has to be divided using mapper function\n",
      "is Map reduce. Because training a huge volume of data costs high computational\n",
      "resources as well as a high amount of time. So different sets of data will be provided to\n",
      "each node in the cluster and the whole portion of data to be classified will be provided to\n",
      "every node, because the volume of data to be classified is small compared to the volume of\n",
      "training data. When each node in the cluster is trained with different chunks of training\n",
      "data. That will generate different AI models at the different nodes of the cluster. So\n",
      "federated learning techniques should be used in order to define the suitable training\n",
      "model out of the different models that will be generated.\n",
      "When data to be classified is huge that particular data will be distributed to all the\n",
      "nodes using the mapper function. For each node in the cluster the same chunk of training\n",
      "data will be provided because the training data is small compared to data to be classified\n",
      "in this scenario. Each node will generate its output and the reducer function will make\n",
      "the final output from all of these results.\n",
      "When the neural network consists of a large number of neurons, computation cost\n",
      "increases. So using map reduce the neural network can be distributed over multiple\n",
      "nodes. There are a number of iterations involved with the feedforward process while\n",
      "the backpropagation is done in the last iteration. In each iteration reducer collects the\n",
      "outputs and merges all outputs from each mapper. For this approach computers with\n",
      "high computation power are used. In this work clusters consist of low computation power\n",
      "nodes.\n",
      "Top Down based approach\n",
      "Basically in top down approach the AI model is trained or developed at the cloud\n",
      "computing level using the high computational resources.Then the model is deployed to\n",
      "the edge devices.There are various techniques used in the scenarios. The whole process\n",
      "can be considered as a tree like structure. Root is considered as the central cloud and\n",
      "the leaves of the tree are the edge devices. A technique to look at the AI application\n",
      "built is that it is considered as the Cognitive Processing Elements(CPE). Then build a\n",
      "chain of CPE. A CPE is operated in basic four phases:\n",
      "• Discover phase\n",
      "• Deploy phase\n",
      "• Operate phase\n",
      "• Retain phase\n",
      "Basically in the discovery phase the basic idea is to develop the model using automated\n",
      "or user defined technique. In some scenarios multiple models might be generated and\n",
      "there should be methods to decide and select the best models out of those. After the\n",
      "model is developed they should be added into edges using the Deploy phase. Here the\n",
      "model is packed into docker containers and placed in a shared repository. Therefore edges\n",
      "can access that particular repository. Above mentioned chain of CPE is implemented as\n",
      "a Node-Red flow.\n",
      "Under the operation phase microservices are implemented on edges which are respon-\n",
      "sible for instantiating the chain of CPE flow. Docker containers in the shared repository\n",
      "will be executed at the edges by their microservices. Retaining phase is designed such\n",
      "that feedback mechanisms will be provided towards the cloud and then models can be\n",
      "updated in the cloud computing level.\n",
      "This top down approach uses high computational resources available at the cloud\n",
      "level and then deploys the models to edges. In contrast what we propose is to use the\n",
      "limited resources available at the edges, so our solution is a bottom up approach.\n",
      "Vectorization\n",
      "There are different types of approaches that have been taken to improve the performance\n",
      "of CNNs. Some are pruning, quantization and vectorization. Pruning removes the\n",
      "number of connections of a CNN. This method weakens the CNN as some weights are\n",
      "removed in this process. In quantization approach word length of weights and activations\n",
      "are reduced. FFT based convolution and Winograd convolution are some other approaches\n",
      "which improve the CNN performance. In FFT convolution operations perform in\n",
      "frequency domain. This method is suitable for larger filter sizes. For the FFT based\n",
      "convolution additional transformations are required which is a down side of a FFT\n",
      "convolution. Winograd Convolution also involves the transformation of input matrices\n",
      "and kernel matrices to perform the convolution. In vectorization approach input\n",
      "matrices and kernels are transformed inorder to perform the matrix multiplication which\n",
      "improves the performance of the convolutional operations. As the input matrices\n",
      "and kernels are transformed this method requires more memory.\n",
      "Computation offloading\n",
      "There are different studies involved in computation offloading. In offloading process\n",
      "computation is immigrated to the resourceful server or device from the limited resource\n",
      "device. This migration involves communication delays and energy consumptions so\n",
      "in order to perform the migration need to make decisions. Different approaches are\n",
      "proposed in different studies for this scenario. Some are Q learning based approaches,\n",
      "linear programming based approaches, and approaches based on defining cost functions\n",
      "for the transmission delays.\n",
      "Q learning based implementation requires additional computation power in order\n",
      "to make the decisions. Linear programming and cost function approaches transmission\n",
      "time and energy consumption for each convolution layer need be calculated before the\n",
      "decision making process. Which is an additional overhead for the decision making process.\n",
      "Simple policy based approach is discussed in these papers. By defining a simple\n",
      "policy, limited resource devices can make decisions based on the computation time and\n",
      "the transmission delays. The calculation of the computation time of the convolution\n",
      "operation using CPI gives some disadvantages. As the different devices have different\n",
      "CPIs with different pipelines and different architectures. GFLOPs base approach gives\n",
      "the advantage over the CPI methods as the manufacturers provide the information of\n",
      "the GFLOPs of the devices.\n",
      "Methodology\n",
      "Vectorization using im2col technique\n",
      "When consider the CNN network, the major operations are,\n",
      "• Convolutional operation\n",
      "• Pooling operation\n",
      "In convolution operation, the input matrix is multiplied by the kernel. As shown in figure\n",
      "3.2 the kernel needs to move through the whole input matrix based on the given stride\n",
      "which defines how many columns or rows the kernel should move next. To move the\n",
      "kernel through the whole matrix consumes time which slows down the operation. Im2col\n",
      "technique can be used to overcome this problem which basically removes the need of\n",
      "moving the kernel through the whole input matrix. We represent input matrices and\n",
      "kernels using numpy matrices. So the implementation of the im2col technique is done\n",
      "using the numpy strides. Which gave the ability to reshape the matrices in order to do\n",
      "the convolution operation in a vectorized manner.\n",
      "Using numpy strides each receptive field is turned into a column. As shown in the\n",
      "figure 1.1 2x2 receptive field is converted to a column matrix and each kernel is reshaped\n",
      "into a row matrix. Figure 3.3 shows the converted input matrix where each receptive\n",
      "field is stacked side by side in a single matrix, Then the output is multiplied by the\n",
      "kernel matrix which is reshaped into row matrices. For the pooling operation the same\n",
      "procedure is used where for a given kernel shape input matrix is reshaped and gets the\n",
      "output which depends on whether max pooling or average pooling.\n",
      "Multi threads for computation\n",
      "Raspberry pi have four cores,so any computation in a raspberry pi can be utilized to compute using all the four cores.Quad core device contains four cores.Here\n",
      "multi threads can be applied on the computational costly parts like OpenMP but available only for C,C++ and FORTRAN.\n",
      "But Python Global Interpreter Lock lets only one thread at a time to be executed.\n",
      "As OpenMP can create threads on C ,Cython converts to a separate executed c file but again the code conversion is expensive.\n",
      "Therefore we use PyMP . It uses the Fork and join model enabling use of multiple threads. Using PyMP most computationally costly parts of the algorithm is executed parallel using threads to utilize the four available cores within a raspberry pi node. While the rest of the algorithm is executed sequentially. While the threads make certain parts of the convolutional network the shared variables of certain threads should be considered. Assigning too many threads causes overhead . Therefore optimal number of threads should be assigned. The most computationally costly parts of the YOLO algorithm are selected and then different number of threads were applied. Then the optimal number of threads were selected by measuring the best execution time.\n",
      "Vectorization with multi threads\n",
      "When we combine the two approaches used to optimize the computations we had to use multi threads to compute vectorized CNN computations. Here we used an optimized BLAS library. So vectorized CNN will be performed using multi threads in OpenBLAS.This methodology combines both resource utilization using multi threads and performance improvement using vectorization techniques together which we used for the optimization.\n",
      "Computation Offloading\n",
      "Most of the IoT devices have limited resources compared to the cloud. When it comes\n",
      "to the AI and ML processing it requires more computation power and resources. Even\n",
      "though the computation distribution, vectorization and parallelization techniques apply\n",
      "some times it may not give the maximum benefits. We used offloading techniques to get\n",
      "the advantage of more resource full servers.We compared the execution time in raspberry\n",
      "pis with the execution time on the server and the communication delays based on that\n",
      "we defined a policy to determine whether to offload or execute locally.\n",
      "We compute the amount of computation using the number of floating point operations\n",
      "and GFLOPs of the executing device. When multiplying to vectors of n elements there\n",
      "involves 2n-1 arithmetic operations, then we divided it by the GFLOPs and compute\n",
      "computation time. Then we use equation (3.3) with the communications delays to\n",
      "determine the offloading decisions. As these IoT devices (Raspberry pies) have limited\n",
      "amounts of memory we also considered the memory usage.\n",
      "As shown in the equation (3.4), given a threshold value, we computed the memory\n",
      "usage of the operation and if the above equation satisfies then we offload the computation\n",
      "to the upper layers.\n",
      "Federated Learning\n",
      "The main advantage of the Federated learning is, it helps to train a model while preserving the privacy of the model data. In here\n",
      "model is train though model aggregation other than data aggression by keeping the local data private (within the local device )\n",
      "Since all the data is collected from an edge device, this is a better approach for doing computer vision tasks. Because all the annotations are done on the edge devices but the model parameters are aggregated in a central cloud server.\n",
      "This method ensures the privacy of the users. Once the model parameters are aggregated, then the global model is pushed to the user’s devices. So there is low latency in the predictions. As this is going to be a collaborative training process, the model gets smarter over time.\n",
      "Experiment Setup and Implementation\n",
      "Prototype\n",
      "In this work we choose object detection as our use case which needs high computation\n",
      "power for the training and prediction phases. Raspberry pis are used as the end devices,\n",
      "Which runs the YOLO algorithm. YOLO algorithm is based on convolutional neural\n",
      "networks. Given an image, it feeds to an convolutional network and get an output based\n",
      "on partitioning make on the image and number class. Figure 4.1 shows a input and output\n",
      "example where 600x600x3 input is feed into the CNN where output is 19x19x425.In this\n",
      "example number of predicting classes are 80 while 5 anchor boxes are used for each grid\n",
      "cell.\n",
      "The convolutional neural network consists of multiple filters in each layer so\n",
      "by dividing kernels among multiple raspberry pis, the computation can be distributed\n",
      "and parallelized. After computation done parallely then the output is merged and\n",
      "forward to the next layer. We use the kernels with the shape of (h, w, nCprev, nC) where\n",
      "the h and w represent the height and the width and the nCprev represent the number of\n",
      "channels of the input matrix and the nC represent the number of kernel of the shape\n",
      "of (h ,w, nCprev). So the computation distribution we partition the nCprev depending\n",
      "on the available nodes and then perform the convolution on the input matrix and then\n",
      "combine the each output of the each node.\n",
      "For the pooling layers we distribute the input matrix between the available nodes\n",
      "and perform the pooling operation. As shown in the figure 4.1 the master gets the input\n",
      "image and it distributes the computation among the slave nodes.\n",
      "Figure 4.1\n",
      "Master acts as a client where the slave nodes act as servers. So we use client server\n",
      "architecture to communicate between the slave nodes and the master nodes. Server nodes\n",
      "are always listening to the incoming data , when the master node receives an image\n",
      "then it distributes the computation to the slave nodes which are always listening for the\n",
      "requests.\n",
      "For convolution operations each node uses vectorization techniques and parallelization\n",
      "techniques. For matrix implementation we used numpy matrices. For the vectorization\n",
      "we used im2col technique and we got the advantage of numpy strides to manipulate the\n",
      "matrices in order to perform the convolution operations in a vectorized manner.\n",
      "Federated learning methods are used for the training network and object detection,\n",
      "Where each raspberry pi or a raspberry pi cluster trains a model based on local data and\n",
      "then the learned parameters are sent to higher layers (Fog, ROOF). Then the aggregation\n",
      "done on that layer to train a global model.\n",
      "For the data set we used We randomly captured these images of different scenes at\n",
      "different times from 26 street monitoring videos with 704×576 pixels. Eventually, we\n",
      "select a total of 2,544 items from these images with 7 object categories. Each image has\n",
      "at least one labeled object, and may have multiple labels of this same category in one\n",
      "image. The object labels are basket, carton, chair ,electromobile, gas tank,sunshade and\n",
      "table.\n",
      "while training YOLOv3 was via Adam with an initialization learning rate of 1e-3.\n",
      "We adapt the original Federated Averaging (FedAvg) algorithm to framework, we\n",
      "modified FedAvg algorithm to a pseudo FedAvg algorithm because there is an effect of\n",
      "data division for the Federated learning\n",
      "Results and Analysis\n",
      "Results\n",
      "The Darknet’s different YOLO versions were instatiated on a single Raspberry Pi node.\n",
      "The Segmentation faults occur when the program tries to access memory beyond its\n",
      "reach. That implies Darknet’s YOLO is computationally excessive for Raspberry Pi\n",
      "devices. Also YOLOv3 stops at calculating weights while Tiny YOLOv3 stops at CNN.\n",
      "Which shows optimized version can do better computation, but even Tiny YOLO can\n",
      "not complete its task.\n",
      "Then our custom YOLO implementation was tested on single node with Map reduced\n",
      "version on multiple nodes.\n",
      "The distribution of computation with multiple nodes reduces execution time. After\n",
      "the computation is divided among the cluster nodes using the Map Reduce techniques,\n",
      "we used multi threads to utilize the resources.The computation is parallized within the\n",
      "cores of each device.\n",
      "Here a variation of total execution time can be seen with respect to the number of\n",
      "threads. Therefore to find the optimal number of number of threads the results were\n",
      "tabulated.\n",
      "Fig. 5.1 Number of threads Vs the Total execution time\n",
      "Here increasing the number of threads reduces the execution time. But after a point\n",
      "the execution time increases, because the synchronization overhead happens in a limited\n",
      "cores available environment. According to the diagram the optimal number of threads\n",
      "per node is 10. Then the optimized code was compared with the same algorithm tested\n",
      "on Cloud with very high resources.\n",
      "The resource utilization with multi threads was combined with the vectorization\n",
      "approach and measured the performance gain in the distributed computation in raspberry\n",
      "Pi.\n",
      "Fig. 5.2 Total execution time vs input size for Pymp multi threads and vectorization\n",
      "with OpenBLAS optimization.\n",
      "From figure 5.2 ,with the increase of the input size, the total execution time for\n",
      "increases for both approaches. But for all the input sizes the vectorization optimized\n",
      "with OpenBLAS performs better than as it utilizes the resources efficiently.This approach\n",
      "further enables the real time computations.\n",
      "We used the equation (3.3) to make offloading decisions in the raspberry pi. The\n",
      "computation time is calculated using the GFLOPs in the given device. For the amount\n",
      "of computation, the number of floating point operations in the given convolution is\n",
      "considered and then it divided by the GFLOPs of the device. Fig. 5.3 shows the results\n",
      "of the estimation with actual time.\n",
      "Fig. 5.3 Actual processing time vs Estimated processing time with the varying channel\n",
      "size.Input matrix (64, 64, channels) with kernel shape (9, 9,channels, 256).\n",
      "Analysis\n",
      "Based on the results it is evident that the object detection algorithm we choose, YOLO\n",
      "which has a complex Convolutional Neural Network cannot be run on a single raspberry\n",
      "pi 3 board due to resource constraints. Both Darknet’s YOLO and Tiny YOLO cannot\n",
      "perform their computations on a single Raspberry Pi board. We have implemented\n",
      "a custom YOLO to run on a less-resourced environment. In a High resource enabled\n",
      "environment like Google Colab Cloud. Also, This custom YOLO implementation can\n",
      "be run on a single raspberry Pi board but the time for execution is comparatively high.\n",
      "The custom implementation was focused on the core CNN computation of YOLO. In the Cloud environment, the GPU and CPU which have capabilities up to 12 GB YOLO perform in separate efficiency. We ran our custom optimized YOLO algorithm in the High computationally capable CPU and GPU.\n",
      "Our YOLO Object detection algorithm performs nearly 9 times better than in\n",
      "GPU enabled cloud than Raspberry Pi. At the next instance, we implemented the\n",
      "optimized algorithm in distributed cluster of Raspberry Pi nodes. Here we distributed\n",
      "the computation to a cluster of two raspberry pi nodes. When the execution time in the\n",
      "Colab cloud is compared with execution time is any raspberry Pi implementation Colab\n",
      "cloud performs well. Because of the availability of high computational resources. But\n",
      "the goal is to perform the complex CNN operations at the edge. So we have successfully\n",
      "deployed our YOLO implementation which consists of the optimized CNN and performed\n",
      "the tasks with the very constrained and resource-limited environment of the Raspberry\n",
      "Pi.\n",
      "The reason YOLO performs better at the Colab Cloud is that Colab Loud provides\n",
      "around 24 times better Computational resources compared to a single edge Raspberry Pi.\n",
      "But our implementation of YOLO with the optimized CNN performed within around\n",
      "270.51 seconds even in the very resource-constrained environment. Further, the optimized\n",
      "YOLO algorithm was distributed to two parallel Raspberry Pis.\n",
      "With the parallel implementation, the Execution time is reduced nearly by a factor\n",
      "of two. This parallel implementation which distributes the computation among the Edge\n",
      "nodes performs better even with the very constrained and limited resources available at the\n",
      "edge devices. For further optimization, we used multi-threads to perform computation\n",
      "utilizing each raspberry pi cores. To find the optimal number of threads to use we\n",
      "tabulated the number of threads vs total execution time in Fig 5.1. The optimal number\n",
      "of threads per raspberry pi node was 10. With the optimal number of threads applied\n",
      "with the distributed computation using Map reduce we achieved the total execution time\n",
      "to 41.74 seconds.\n",
      "We could achieve nearly the same performance at edge when we apply distributed\n",
      "computing together with optimization using multi threads. Furthermore we applied\n",
      "vectorization for CNN which also improves the performance. Then to combine both\n",
      "of these optimization techniques we used multi threads upon vectorized CNN. Here to\n",
      "enable multi core resource utilization on raspberry pi when using vectorization, we used\n",
      "the OpenBLAS, an optimized Basic Linear Algebra Subprograms library. From Fig Fig\n",
      "5.2 we can see that for any given input size the execution time for vectorization with\n",
      "OpenBLAS is less than multi threading with PyMP implementation. Therefore we used\n",
      "vectorization with OpenBLAS for the core CNN computation of YOLO to enable real\n",
      "time computations.\n",
      "As previously explained we use the policy defined by the equation (3.3) to make the\n",
      "offloading decisions. For that we needed to calculate the execution time on the raspberry\n",
      "pis. We used GFLOPs based approach with the number of floating point operations to\n",
      "calculate the execution time. Figure 5.3 shows the execution time with different input\n",
      "matrices. Estimated times are shown in the red columns, when compare with the actual\n",
      "execution time our GFLOPs based method was able to estimate the execution time close\n",
      "to the actual execution time.\n",
      "Table 5.1 shows the vectorized convolution execution time with the non vectorized\n",
      "implementation.For the input matrix (64,64, channels) with the kernel shape (3,3,chan-\n",
      "nels,256). There is a high improvement with the vectorization. When consider the\n",
      "channel size of 128,\n",
      "Vectorization improved the convolution operation by a factor of 85.\n",
      "Conclusion\n",
      "The aim of the project is to enable real time processing at the edge with limited\n",
      "resources.So with combining above mentioned techniques, real time processing at the\n",
      "edge is achievable. In this study we have developed a distributed CNN using map reduce\n",
      "which can be used to implement YOLO.Furthermore, we propose a novel approach where\n",
      "end devices consisting limited resources can train and generate real time decision in\n",
      "distributed manner, where their computations are distributed among other multiple\n",
      "nodes or offload the computation to the upper layer when the resources run out. We\n",
      "have distributed the CNN over multiple Raspberry Pis.The performance of the CNN has\n",
      "been measured under different conditions and platforms. Based on the results it can be\n",
      "concluded that by distributing CNN over multiple nodes the computation latency can be\n",
      "reduced.Then we optimized our implementation using vectorization and multi threads\n",
      "together so the execution time is reduced further enabling the real time computations\n",
      "using limited resources.\n",
      "Offloading decisions were taken using a policy where the computation time and\n",
      "network transmissions delays were considered. Also we considered the memory usage for\n",
      "the computation which also affected the offloading decisions. We also apply federated\n",
      "learning to train a global model where each device is able to train a local model which\n",
      "addresses the privacy issues. These techniques provide the path to achieve better results\n",
      "using limited resource devices.\n",
      "Publications\n",
      "Semester 7 report\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Semester 8 slides\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Real Time Emotion Recognition using Electrocardiogram Analysis https://cepdnaclk.github.io/e15-4yp-Real-Time-Emotion-Recognition-using-Electrocardiogram-Analysis\n",
      "\n",
      "\n",
      "Real Time Emotion Recognition using Electrocardiogram Analysis\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Team\n",
      "E/15/139, Ishanthi D.S. , e15139@eng.pdn.ac.lk\n",
      "E/15/249, Pamoda W.A.D. , dasunip2@gmail.com\n",
      "E/15/299, Ranushka L.M. , e15299@eng.pdn.ac.lk\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne, isurunawinne@eng.pdn.ac.lk\n",
      "Prof. Roshan Ragel, roshanr@eng.pdn.ac.lk\n",
      "Dr. Suranji Wijekoon, suranjisk@gmail.com\n",
      "Mr. Theekshana Dissanayake, theekshanadis@eng.pdn.ac.lk\n",
      "Table of content\n",
      "Abstract\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "Most of the ECG analysis based human emotion recognition studies use different types of machine learning techniques. Main problem with these methods is lack of accuracy and not having the ability to classify emotions real-time. The proposed method uses a large public dataset to increase accuracy and implements a Convolutional Neural Network to identify emotions. ECG data signals are preprocessed to increase the number of instances and important features are extracted using feature extraction methods and then features are fed to the CNN. Three CNN models are trained to predict the valence, arousal and the dominance values of the ECG signal, which are used to finalize the emotion by mapping those values to the valence-arousal-dominance 3D plane.\n",
      "The classification CNN models implemented in this proposed method result in a maximum accuracy of 80%.\n",
      "Methodology\n",
      "This research is planned to do in 2 phases to implement the human emotion recognition model and to do a preliminary analysis on animal emotion recognition.\n",
      "Phase 1 - Human Emotion Recognition\n",
      "As the first phase of the research, human emotion recognition model was implemented using ECG signals. The bio signals such as ECG signals are nonlinear, complex and contain noises. Since neural networks handle such data in a more efficient way than machine learning methods, neural network is a more suitable method for the classification of emotions using ECG signals.\n",
      "In neural networks, convolutional neural networks (CNN) are more suitable for time series analyzing since they identify and extract important features that support the classification process from raw input data. Therefore, the model for the recognition of human emotions using ECG signals was implemented using CNNs.\n",
      "For the human emotion recognition model, a public dataset, which consists of ECG signal data of human subjects was used. These data signals are preprocessed to increase the number of instances and to extract the important features to feed to the CNN. The CNN is trained to predict the valence, arousal and the dominance values of the ECG signal, which is used to finalize the emotion by mapping those values on the valence-arousal-dominance 3D plane.\n",
      "Experiment Setup and Implementation\n",
      "Dataset\n",
      "For the training of a neural network, a large amount of ECG signal data was needed. Therefore, the DREAMER dataset, which is a multi-model dataset for emotion recognition through ECG and EEG signals, was used for this research.\n",
      "This dataset consists of the ECG signals of 23 human subjects, each subject’s ECG signals have been recorded using 2 ECG channels under 256 Hz sampling rate while watching 18 video clips. They have been asked to score their emotions using valence, arousal and dominance values in a range of 0 to 5. Therefore, the total number of 414 labeled signals were obtained from this dataset.\n",
      "To get an initial idea of the ECG signals, signals with different valence-arousal-dominance values are visualized. The output graphs\n",
      "indicate that the ECG signal changes over a 5 seconds period 8 different valence, arousal, dominance value combinations. Each combination of these values are related to a different emotion of the human subject. It is visible that the amplitude, shape and the pattern of the signal are different for different emotional states.\n",
      "Preprocessing\n",
      "To increase the number of instances fed to the CNN, some preprocessing steps were done on the above mentioned ECG data signals.\n",
      "Therefore, as the first step, those signals were split into sub segments. The emotion changes of a subject can be identified within a period of 3 – 15 seconds. Considering this fact, the above 414 signals were split into segments of 10 seconds period considering 1 second overlapping time. This process created 82 018 input instances for the CNN.\n",
      "Feature Extraction\n",
      "To extract the unique features of these ECG signals, Mel frequency cepstral coefficients (MFCC) algorithm, which is an efficient technique for signal processing based on Discrete Fourier Transform (DFT), was used. This calculates a MFCC feature vector with coefficient values for the input signal.\n",
      "Each signal consisted of 2 ECG channels therefore each segment of the signal also consisted of 2 ECG channels and the MFCC feature extraction was done for both channels.\n",
      "13 MFCC coefficients were extracted and this calculated feature vectors of size (853 x 13) for each segment. Since these segments have 2 channels, the input instance shape was (853 x 13 x 2). Both the input instances and the array of valence, arousal and dominance values were normalized. Each normalized input instance and the relevant normalized valence, arousal and dominance values were stored in separate files before training the CNN.\n",
      "CNN\n",
      "Finally, 82018 data instances of shape (853 x 13 x 2) were fed to CNN to predict the values of valence, arousal and dominance.\n",
      "The dataset that was used had 2 channels for the ECG signal. And as the MFCC feature extraction method creates a 2D output of coefficients of time and frequency variation, a 2D convolutional Neural Network is used for the classification of ECG time series data.\n",
      "Neural Network structure:\n",
      "Convolutional Neural Network\n",
      "Conv2d - Input\n",
      "MaxPooling2d\n",
      "Dropout – 20%\n",
      "Conv2d\n",
      "MaxPooling2d\n",
      "Conv2d\n",
      "MaxPooling2d\n",
      "Flatten\n",
      "Dense layer - 200 nodes with ReLu activation\n",
      "Dense layer - 150 nodes with ReLu activation\n",
      "Dense layer - 75 nodes with ReLu activation\n",
      "Dense layer - 25 nodes with ReLu activation\n",
      "Dense layer - 3nodes with ReLu activation\n",
      "Convolution Layers:\n",
      "Convolution is a linear operation and it is done in parallel in the Conv2D layers. Conv2D layers are used for feature Mapping. Each Emotion elicited ECG signals are transformed into a set of 2D Coefficients and those coefficients contain the patterns related to the emotion. Therefore, in the training phase the filters of the convolution layers are trained to map the features so that they will act as the feature detectors.\n",
      "MaxPooling Layers:\n",
      "Pooling layers are used to down sample the given input to extract the features in another position. MaxPooling is used to extract the most activated feature among several features. Therefore before a convolutional layer a MaxPooling layer is placed.\n",
      "Dropout Layer:\n",
      "Dropout layers are used to delete some trained neurons. This process is done to train a model more accurately. It is expected to have a better training when 20% of trained neurons are reset to initial state.\n",
      "Flatten layer:\n",
      "This layer is used to prepare the inputs to the dense input layer.\n",
      "Dense layer:\n",
      "These layers are used to classify the inputs into 3 classes. Final dense layer has 3 output neurons. One or more hidden dense layers are expected to be used until a better accuracy is gained.\n",
      "3 types of CNNs using regression CNN models and classification CNN models were implemented as different approaches to predict valence, arousal and dominance values.\n",
      "Single Regression CNN model\n",
      "In this approach, a single regression CNN model was implemented to predict 3 values of valence, arousal and dominance at the same time. Three labels of valence arousal and dominance in the range of 1-5 were used. The output of each model will be three normalized values in the range of 0-1 which describes valence, arousal and dominance values accordingly.\n",
      "Separate Regression CNN models\n",
      "In this approach, 3 separate regression CNN models were implemented to predict valence, arousal and dominance. The labels of valence arousal and dominance in the range of 1-5 were normalized into the values of 0.00 , 0.25, 0.50, 0.75, 1.00. The output of each model will be a normalized value in the range of 0-1 which describes valence, arousal and dominance values accordingly.\n",
      "Separate Classification CNN models\n",
      "In this approach, 3 separate classification CNN models were implemented to predict valence, arousal and dominance. The labels of valence arousal and dominance in the range of 1-5 were one hot encoded. The output of each model will be a value in the range of 0-4 which describes valence, arousal and dominance values accordingly.\n",
      "Discrete emotional model\n",
      "To identify and label the emotions related to predicted arousal, valence and dominance values, 3D- valence-arousal-dominance-plane is used. 4 negative discrete emotions as angry, fear, unconcerned, sad and 4 positive emotions as happy, surprise, satisfied and protected can be classified using this model.\n",
      "Pitfalls and workarounds\n",
      "This dataset was a large dataset with 82 018 instances. Initially we tried to load the whole datasets at once, but it required a lot of processing. Therefore, instead of having one large dataset, we created single data files for each instance and used python data generators to load data to the CNN.\n",
      "When training the neural network we faced an issue of insufficient memory and low speed in the machine. This problem was solved by handling the training of the CNN on the GPU of the kepler server.\n",
      "Phase 2 - Preliminary Analysis of Animal ECG data\n",
      "Heart rate variability (HRV) is the physiological event of the variation in the time interval between consecutive heartbeats in milliseconds using ECG signals. Normally heart rate variability measure rises when a person is engaged in a relaxing activity and it reduces when a person is under stress. Therefore, HRV can be used as a measurement to assess the emotions of a person by evaluating his or her autonomic nervous system. Therefore, for this preliminary study of animal ECG signals, HRV parameters were used. Typically, HRV is analysed using time domain, frequency domain and non linear metrics.\n",
      "Background\n",
      "Time-Domain Parameters\n",
      "In this method, QRS complex is identified and the heart rate at any point in time or the intervals between successive normal complexes are determined and the following parameters are calculated.\n",
      "Some of the most widely calculated time domain parameters are:\n",
      "mean_nni: Mean time interval between two heartbeats, here normal heartbeats are considered.\n",
      "sdnn: the standard deviation of all the NN intervals. It can be described as a total variability or total power.\n",
      "sdsd: the standard deviation of the differences between successive NN intervals\n",
      "nni_50: the number of pairs of successive NN intervals that differ by more than 50 ms in the entire recording\n",
      "pnni_50: the percentage of successive intervals that differ by more than 50 ms (higher values indicate increased parasympathetic activity)\n",
      "rmssd: the square root of the root mean square of the sum of all differences between successive NN intervals\n",
      "median_nni : Median Absolute values of the successive differences between the RR-intervals.\n",
      "range_nni: difference between the maximum and minimum nn_interval.\n",
      "Frequency-Domain Parameters\n",
      "In frequency domain analysis, frequency components of the ECG signals are obtained as VLF (Very Low Frequency – 0.00 Hz- 0.04 Hz), LF (Low Frequency– 0.04 Hz- 0.15 Hz) and HF (High Frequency– 0.15 Hz- 0.40 Hz). This is performed by decomposing RR intervals of an ECG signal using Fast Fourier Transformation (FFT).\n",
      "Dataset\n",
      "The PhysioZoo database consists of ECG signal recordings taken from multiple types of mammals such as dogs, rabbits, mice, etc. It has dog ECG recordings of an average length 05.31 (min:sec), rabbit ECG recordings of an average length 10.34 (min:sec) and mouse ECG recordings of an average length 29.44 (min:sec). It has recorded these ECG data at a sampling rate of 500Hz for dog subjects, 1000 Hz for mouse and rabbit subjects.\n",
      "Methodological approach\n",
      "For animal ECG analysis, ECG signal data of dog subjects, mouse subjects and rabbit subjects were used from the above mentioned publicly available dataset. Initially they were downsampled to a frequency of 256 Hz. Then the HRV parameters were extracted from 134 s duration of ECG signals using time domain and frequency domain methods using python hrv-analysis library.\n",
      "Then these parameters were compared with the human HRV parameters.\n",
      "Data visualization\n",
      "Initially the data was visualized to get a basic idea of the QRS complex and the shape of ECG signal recordings of each animal type.\n",
      "Results and Analysis\n",
      "The CNN was trained using\n",
      "60000 instances and 20000 testing data. The results were taken by training the model changing its parameters as well as the hyper-parameters such as batch size, steps per epoch, epochs etc.\n",
      "CNN for classification of Arousal. Valence and Dominance Values\n",
      "The dataset consisted of 82000 samples of MFCC features of ECG signals with 5 labels for Arousal category. The dataset was divided as follows,\n",
      "Training Set - 70%\t\tValidation Set - 20%\n",
      "Test Set - 10%\n",
      "In each three figures above has two graphs representing Model accuracy and Loss. If the Accuracy graphs (Top graph) are considered the orange line which represents the validation set accuracy has come to an instance which is called a valley after 1000 epochs. This implies that the model accuracy will not considerably increase further. All the three models show this kind of variation.\n",
      "On the other hand, If the start of the graphs were considered, there has been no change in accuracy or loss in the first 180 epochs approximately. The optimizer used for the models was Adam optimizer. In general, in the search for the solution for a Machine learning problem, the models come across with many solution points which are seemingly better. But only one of them is the best solution. That solution is also called the “Global Minimum”. At that point the loss is minimum.\n",
      "The other solutions are called “Local Minimas”. Therefore, the model must be able to travel in the path of global minima for a successful result. Following figure (Figure: 03) describes the difference between the global and local minimas. Therefore, It is clear that there is one global minimum and there could be one or more local minimas.\n",
      "Clearly, the model tries to find the path for global minima in the beginning of the training time. As a result there will not be any change in the accuracy and the loss during that time. This is performed by the optimizer. Therefore, better optimizers must be used according to the model. There are different types of optimizers and each one has different properties. Adam optimizer is better for all the cases. Therefore it is used here.\n",
      "Finally, The loss variation of each graph shows another great fact. As you can see the validation loss (Orange line) started reducing when the model has found the global minima and after a long time it starts to increase. But the loss of the training set never decreases. This instance shows the overfitting of the model. As the training loss decreases the test loss or the validation loss increases. By the end of the 1000th epoch the model has been trained only for the training set. Therefore, the moment the test loss starts to increase can be used as the end of the training if the model is going to be used for ECG data recorded by other devices. Therefore the models may actually have lesser accuracy than mentioned here. For example, The model developed for Dominance may have an accuracy of 70% instead of 80.87%.\n",
      "Conclusion\n",
      "Emotion recognition is a powerful and very useful technique in the modern world since it has a large\n",
      "scale of uses in various areas. We can say a lot of research has been conducted on this\n",
      "subject using different methods.\n",
      "Some methods give higher accuracy but some do not. Scientists have\n",
      "come up with new techniques to increase the accuracy by inventing new feature extraction methods,\n",
      "classification methods, machine learning models and neural networks. Even though some methods give\n",
      "higher accuracy they may be practically hard to use because of the non- wearable nature of the\n",
      "hardware implementation. Since emotion recognition is a key feature of Human Computer Interaction, as the field grows\n",
      "in sophistication people need easily usable methods. That is why the combined bio signal method is not\n",
      "so used even though it has a good accuracy. In the near future by these emotion recognition methods the Human Computer Interaction would be\n",
      "more effective and by that the productivity will increase in every computer using field including\n",
      "healthcare, education, production industry, entertainment and automotive industry etc, making human\n",
      "and animal lives better and easier.\n",
      "The highest emotion classification accuracy obtained by this study is 80.87%. This was achieved by overfitting the model of that dataset. Although the model was overfitted the model showed considerable accuracy before it overfits. MFCC features of the ECG signal were extracted. That produced a 2D feature vector of time and frequency. However, different feature extraction methods should be tried to increase the accuracy.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Revealing miRNA Biomarkers for Alzheimer s Disease using NGS https://cepdnaclk.github.io/e15-4yp-Revealing-miRNA-Biomarkers-for-Alzheimer-s-Disease-using-NGS\n",
      "\n",
      "\n",
      "Revealing miRNA Biomarkers for Alzheimer's Disease using Next Generation Sequencing data\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Revealing MicroRNA Biomarkers for Alzheimer’s Disease Using Next Generation Sequencing Data\n",
      "Team\n",
      "e15362, Hasini Thilakarathna, email\n",
      "e15345, Vidwa Sripadi, email\n",
      "e15081, Imalsha Dinuwanthi, email\n",
      "Supervisors\n",
      "Dr. Damayanthi Herath, email\n",
      "Prof. Roshan Ragel, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "Alzheimer’s disease is recognized as one of the\n",
      "common diseases found among older people, which still has no\n",
      "successful cure. In this study, our goal is to determine the best set\n",
      "of miRNA biomarkers which are highly differentially expressed\n",
      "in Alzheimer’s disease. Using statistical analysis followed by\n",
      "machine learning techniques, we establish 25 microRNAs as\n",
      "biomarkers for AD. Furthermore, we provide an analysis of the\n",
      "selected 25 microRNAs with area under the receiver operating\n",
      "curve and classification algorithms.\n",
      "Related works\n",
      "Sample selection\n",
      "When detecting biomarkers for Alzheimer’s disease, initially we have to select a sample for\n",
      "performing analysis. Mostly blood samples are used due to the high availability. Different\n",
      "types of blood samples including whole blood, serum and plasma\n",
      "are used by many previous researchers where they have tried to find miRNA biomarkers.\n",
      "If we use brain samples it would give most accurate results than blood samples since\n",
      "AD is most prominently active in brain. We would be able to give more accurate\n",
      "results if both blood and brain samples are used. Samples can be taken from participants\n",
      "generally as, AD and controls and also they can be taken considering the\n",
      "different stages as severe, moderate, mild AD and controls. Another approach in\n",
      "collecting samples is taking then from participants with HC, MCI and AD. The\n",
      "number of samples used when developing a diagnosis method can be identified as one of\n",
      "the main factors which could affect the final results. Next generation sequencing platform\n",
      "is the most trending method used for gathering samples for various disease diagnosis\n",
      "researches. Many techniques like Illumina sequencing technique are\n",
      "introduced for working with NGS data. Preprocessing the raw sequence counts can be\n",
      "done using a bioinformatic pipeline, which gives the read counts for each miRNA as the\n",
      "final outcome.\n",
      "Normalization\n",
      "Normalization of sequencing read counts can be performed using several normalization\n",
      "methods. Quantile normalization is one way that we can do normalization when we are\n",
      "having a high dimensional dataset. It excludes selected samples to minimize noise.\n",
      "Mean normalized read counts also can be used to filter out the miRNAs. Also we can\n",
      "follow a stepwise procedure to do normalization as below.\n",
      "From all the samples, find sequences which are common.\n",
      "Build a reference dataset using those common sequences.\n",
      "Apply logarithmic transformation\n",
      "Calculate the logarithmic difference between each sample and reference dataset.\n",
      "Form a subset by taking sequences which has a difference<2.\n",
      "Perform linear regression.\n",
      "Calculate the mid value\n",
      "Looking at the results obtained from the study which used the above normalization\n",
      "method, it can conclude that this type of step wise normalization method can be used\n",
      "for obtaining the best set of miRNAs. Data visualization can be used for selecting which\n",
      "normalization method is best suit for a given dataset.\n",
      "Statistical Analysis\n",
      "Initial detection of miRNA can be done by initially calculating a significance value(p\n",
      "value). P value is a value between 0 and 1, which shows the level of statistical significance.\n",
      "If a p value is less than the significance level (0.05), it is considered as a nominally\n",
      "significant p value and we can select those miRNA as the most impacting miRNAs.\n",
      "WMW test, Wald test and Fisher’s exact test can be used to calculate the p\n",
      "values and these p values can be adjusted for multiple testing using an approach like\n",
      "Benjamini-Hochberg approach. Other than that, t test and kruskal test can also\n",
      "be used to calculate significance values.\n",
      "Validation of samples\n",
      "Validation of the samples makes it easier for the next steps in the investigation and\n",
      "also it makes the final results more accurate. After the statistical analysis process,\n",
      "for validating the obtained samples, quantitative real time-polymerase chain reaction\n",
      "(qRT-PCR) method is used by many researchers. It analyzes the expression of single\n",
      "miRNAs by applying the method on previously used samples for sequencing.\n",
      "But in a previous study, they have additionally included patients with AD and also\n",
      "patients with other neurological disorders in the validation step, to analyze the the set\n",
      "of miRNAs they obtained in the previous step. After the validation is carried out, the\n",
      "miRNAs can be further filtered out to obtain the most significant miRNAs.\n",
      "Receiver operating characteristic curves\n",
      "Receiver operating characteristic curve analysis is used to evaluate the performance or\n",
      "accuracy of a classification model. ROC is a plot of sensitivity against specificity for\n",
      "selected samples. It is also used to initially detect the dysregulation of miRNAs and\n",
      "to discriminate between AD and NC sample groups. The area under the curve is the\n",
      "degree of separability. If the AUC is high, that means that particular miRNA is better\n",
      "to distinguish patients with AD and control.\n",
      "Feature selection and Classification\n",
      "If we use a classification model without using feature selection, it will take more run time\n",
      "due to the huge size with redundant features. Therefore it is required to apply some\n",
      "feature selection method to reduce those redundant features. Hierarchical clustering\n",
      "is a feature selection method which can be used to statistically analyze the dataset.\n",
      "It will build clusters of miRNAs having similar patterns. Principal\n",
      "Component Analysis is another approach which can be used for the feature selection.\n",
      "Machine learning classifier models are used to predict whether a sample belongs\n",
      "to AD or control. AdaboostM1, J48 decision tree, random forest and support vector\n",
      "machines and radial basis SVM are some machine learning approaches that can be used\n",
      "for building prediction models. In a previously done study, they have built a separate\n",
      "model by performing 7-way cross validation using 7 randomly picked partitions of 5\n",
      "positive and 5 negative samples each for the feature selection.\n",
      "Summary\n",
      "According to the review we have done, we identified how we can use miRNAs to diagnosis\n",
      "AD and what are the miRNA diagnostic biomarkers which can be found in AD patients.\n",
      "In each study, for filtering out the candidate miRNA, step wise procedures including\n",
      "initial detection and statistical analysis have performed. When consider about previous\n",
      "studies, there are several limitations. The most common limitation of most of the research\n",
      "is they used a limited number of the cohort to their experiments. It is hard to find a large\n",
      "number of Alzheimer’s disease patients to do massive experiments. But we can obtain\n",
      "better results if we expand the cohort size. In many studies, samples with analyzed\n",
      "dementia and controls have used. But not discussing about the possibility to discover\n",
      "pre-clinical biomarkers for Alzheimer disease is a limitation of most of the previous\n",
      "studies. A model which was built in a one previously done study, does not develop\n",
      "to anticipate movement from HC to MCI or MCI to AD. Also, this model was incapable\n",
      "of applying for late-stage AD findings. In another study, they have mentioned that\n",
      "they were unable to recognize a mechanism to identify the variation of miRNAs in serum\n",
      "samples. Considering all the drawbacks, limitations and also the developments found in\n",
      "the previous studies, in this research, we are focusing on finding a more accurate solution\n",
      "for detecting AD biomarkers.\n",
      "Following Figure shows a summary of different methods used andthe results obtained in previous studies. According to this diagram, only 4 studies haveused machine learning algorithms and only 5 studies have used statistical methods intheir studies. Out of the results obtained from above mentioned 9 studies, 7 miRNAswere identified as common for those 9 studies.\n",
      "Methodology\n",
      "Data collection\n",
      "We used a data set available in National Center for Biotechnology Information (NCBI) database under the access number\n",
      "GSE46579. It includes 70 samples with 22 control and 48 AD\n",
      "and 2652 miRNAs.\n",
      "Preprocessing\n",
      "The Next Generation Sequencing data preprocessing was\n",
      "done using the Galaxy platform. Galaxy is a web-based,\n",
      "opensource platform for scientific data analysis. First, the quality\n",
      "report of sequencing data was generated using the FastQC\n",
      "tool. Then, using the tool Trim Galore, data trimming was\n",
      "performed. The package Trim Galore allows both quality\n",
      "trimming and adapter trimming at once. Low-quality reads and\n",
      "adapters were removed from sequence read in the trimming\n",
      "procedure. Trimming increases the quality of sequences. Next,\n",
      "the data filtering procedure was performed using the Filter\n",
      "FASTQ tool. Short read sequences and low-quality sequences\n",
      "were removed in filtering. After that, the NGS reads were\n",
      "mapped against a reference genome (h38) using Bowtie2.\n",
      "Bowtie2 tool aligns sequences to the long reference sequences.\n",
      "Then, the reads were mapped against the hsa.gff3 miRNA\n",
      "precursor sequences from the miRBase database (v22) and\n",
      "the number of read counts of each miRNA was found using\n",
      "the htseq-count tool. This preprocessing procedure was done\n",
      "for every sample using the galaxy platform and then the\n",
      "summarized dataset was created with miRNA read counts of\n",
      "each sample. For the analysis purposes we used a data set with\n",
      "highly abundant miRNAs. To do that we considered miRNAs\n",
      "with read counts less than 50 across all samples of AD and\n",
      "control separately, as lowly abundant and removed them from\n",
      "the data set. Considering the mean distribution of the data\n",
      "set, we normalized the data set using quantile normalization\n",
      "technique instead of general normalization technique.\n",
      "Statistical Analysis\n",
      "Normalized data set obtained from the previous stage was\n",
      "further analyzed with significance value and fold change to\n",
      "reduce the number of features. We calculated the pValues for\n",
      "each miRNA using Wilicoxon-Mann-Whitney (WMW) test.\n",
      "Generally, fold change is a technique which is used to get\n",
      "an idea of how much change occurs going from one value\n",
      "to another. In this project we tried to get fold change values\n",
      "(log2) for each miRNA, to check the significant changes of\n",
      "each miRNA across AD and control samples. We used cut\n",
      "off values for pValues and fold changes values as 0.05 and\n",
      "1 respectively, to obtain the highly expressed set of miRNAs.\n",
      "For each of those filtered features, we calculated the AUC\n",
      "values. Using those AUC values, another set of features were\n",
      "filtered out. Features with AUC score less than or equal to 0.5\n",
      "were ignored as they don’t make a significant impact on the\n",
      "classification of the data set.\n",
      "Feature Selection\n",
      "Initially we used two different methods as PCA and Random\n",
      "Forest for selecting the best set of features. For the data\n",
      "set we obtained from the previous stage, we separately did\n",
      "PCA analysis and Random Forest analysis. Univariate feature\n",
      "selection method was used to decide how many features we\n",
      "needed to select from each. Features which have a significant\n",
      "relationship with the class value were identified from this\n",
      "univariate feature selection method. Next, the set of overlapped\n",
      "miRNAs from those two methods was identified as the best set\n",
      "of features which could be obtained from this part of feature\n",
      "selection. In the next part of the feature selection stage, we\n",
      "used correlation coefficient. As the correlation coefficient, we\n",
      "used Pearson correlation coefficient.\n",
      "Classification\n",
      "Classification accuracy was used to see how accurate our\n",
      "predictions were. A set of machine learning algorithms were\n",
      "modelled for the initial data set and out of those the most\n",
      "accurate algorithms were identified. Those each pre-identified\n",
      "algorithms were used for obtaining the classification accuracy\n",
      "of the final data set with biomarker miRNAs.\n",
      "Validation\n",
      "For validating the results we used Human MiRNA Disease\n",
      "Database version 3.2 (HMDD v3.2). HMDD contains a large\n",
      "set of miRNAs and related diseases collected from the literature. There are 35547 miRNA-disease associations in version\n",
      "3.2 and it includes 1206 miRNAs, 893 diseases from 19280\n",
      "related publications.\n",
      "Results and Analysis\n",
      "At the end of the preprocessing stage, a data set with\n",
      "513 highly abundant miRNAs was obtained after removing\n",
      "miRNAs with less than 50 read counts across all samples.\n",
      "Considering the cut-off significance value as 0.05 and fold\n",
      "change (log2) as 1, the number of features were reduced up to 228.\n",
      "With the AUC analysis we further reduced the number of\n",
      "miRNAs and at the end of the statistical analysis, we identified\n",
      "219 miRNAs as a set of highly expressed miRNAs. From the\n",
      "univariate feature selection method, we identified 50 miRNAs\n",
      "which have a significance relationship with class value. We\n",
      "identified 14 common miRNAs from two sets of miRNAs\n",
      "selected from PCA and random forest analysis.\n",
      "They are hsa-miR-186-5p, hsa-miR-144-3p, hsa-miR-151a-3p,\n",
      "hsa-miR-99b-5p, hsa-miR-98, hsa-miR-148a-3p, hsa-let-7g-5p,\n",
      "hsa-let-7f-5p, hsa-let-7a-5p, hsa-miR-30d-5p, hsa-miR-15a-5p,\n",
      "hsa-miR-589-5p, hsa-miR-144-5p, and hsa-let-7f-5p.\n",
      "We used heat maps for making a judgement on the correlation of each features obtained from previously mentioned two\n",
      "methods. Figure 2 and Figure 3 show how different features obtained from PCA and Random Forest analysis, are correlated.\n",
      "With the help of the heat maps, we decided to use 36 less\n",
      "correlated features for further analysis using correlation coefficients. Out of the different machine learning algorithms which\n",
      "we modelled for our initial data set, we identified the three\n",
      "most accurate algorithms namely, Support Vector Machine,\n",
      "Logistic Regression and Random Forest. For the data set with\n",
      "the 36 miRNAs, we calculated classification accuracy using\n",
      "those three models by varying the correlation coefficients. For\n",
      "each model we identified a correlation coefficient which gave\n",
      "the highest accuracy. Fig. 4 shows the plots with correlation\n",
      "coefficient against the classification accuracy of three models The three correlation coefficients were 0.9975, 0.5875 and\n",
      "0.5300 for SVM, Logistic Regression and Random Forest\n",
      "respectively. Using those 3 correlation coefficients, three sub\n",
      "sets of miRNAs were obtained from the earlier used 36. As we\n",
      "calculated classification accuracy for the previously mentioned\n",
      "three subsets, we identified 11 miRNAs which provided the\n",
      "highest classification accuracy. They are, hsa-miR-4781-3p, brain-miR-112, hsa-let-7a-5p,\n",
      "hsa-miR-148b-5p, hsa-miR-29b-3p, brain-miR-431, hsa-miR-378a-5p, hsa-miR-548h-5p, hsa-miR-3909,\n",
      "hsa-miR-625-5p, and hsa-miR-24-3p.\n",
      "Conclusion\n",
      "In this report we have discussed about how to detect miRNA biomarkers for Alzheimer’s disease using next generation sequencing. Initially we have discussed about the need of a solution to identify Alzheimer’s disease in the early stage. Then we have mentioned about the literature review we have done. When we were doing the literature review, we have identified several miRNA biomarkers in different studies which used NGS. In these studies there were some limitations.\n",
      "In our approach so far, initially we have taken samples from participants with AD and control. Then samples were preprocessed and statistically analyzed. Significance values were calculated using Wilcoxon-Mann-Whitney (WMW) test. Also we have used ROC analysis. Using this procedure, here we have identified a set of significant miRNAs for AD. Using PCA, Random Forests and Correlation coefficient we identified 25 biomarker miRNAs for AD. In the next phase we validated the the result using HMDD v3.2.\n",
      "Leidinger et al., who have carried out a different method to find biomarkers using the same data set, have stated that they have obtained an accuracy of 93.3\\% where we obtained an accuracy of 95.24\\%. Addition to that we evaluated the results with specificity, sensitivity and AUC values as discussed previously. In addition to diagnosis of AD patients with the final set of biomarkers, the followed methodology can be used to identify different cures for other neurological diseases including AD, by effortlessly analyzing various data sets.\n",
      "Publications\n",
      "Semester 7 report\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Semester 8 slides\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting anonymous authentication https://cepdnaclk.github.io/e15-4yp-anonymous-authentication\n",
      "\n",
      "\n",
      "Anonymous and Distributed Authentication for Peer to Peer Networks\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Anonymous and Distributed Authentication for Peer to Peer Networks\n",
      "Team\n",
      "E/15/350, Pasan Tennakoon, email\n",
      "E/15/180, Supipi Karunathilaka, email\n",
      "Supervisors\n",
      "Dr. Janaka Alawathugoda, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "The traditional authentication mechanisms like PKI and ID-PKC are difficult to integrate\n",
      "with a P2P like decentralized network environment. This task becomes even more difficult\n",
      "in an anonymous P2P environment. This research proposes three novel authentication\n",
      "protocols such that users can authenticate themselves in an anonymous P2P network\n",
      "without revealing his/her identity. First, we suggest a way to use existing ring signature\n",
      "schemes to obtain anonymous authentication. Then we propose an anonymous authen\u0002tication scheme utilizing secret sharing schemes. Finally, we propose a zero-knowledge\n",
      "proof based anonymous authentication protocol. We provide security proofs of the three\n",
      "protocols including anonymity, completeness, soundness, resilience to impersonation and\n",
      "resilient to replay attacks. Then we compare the performance of the new protocols. We\n",
      "deploy these protocols in a P2P environment build using the .Net framework. We utilize\n",
      "Shamir’s secret sharing algorithm to manage certificates in the distributed environment.\n",
      "Introduction\n",
      "The concept of Peer to peer (P2P) communication has gained significant attention in the network community over the years. Since the release of Napster in 1998 many P2P applications have been introduced. Bitcoin[1], BitTorrent, TOR[2], Freenet[3], etc are some of the more popular P2P applications. The absence of centralized authority is the main reason behind the popularity of P2P applications. This eliminates the need for an expensive central server. Also removes the vulnerability of a single point of failure. P2P networks are considered to be more efficient and scalable than traditional client-server applications.\n",
      "The decentralized nature of P2P networks makes it difficult to integrate traditional authentication mechanisms. Due to this many such networks focus on providing user anonymity rather than authentication. The reduced security of these networks has created a lot of possible threats [4]. These threats can vary from uploading malicious files to famous Sybil attacks [5]. Also, the anonymity feature of these networks has created a safe house for cyber criminals [6]. Not being accountable for his/her actions, held responsible and punished for malicious actions, P2P users have the freedom to misbehave. This can cause harm to the network and its users.\n",
      "We suggest that even in an anonymous network there should be some level of accountability to protect the network and its users. Accountability is achieved through authentication.\n",
      "To integrate an authentication mechanism into an anonymous P2P environment we need to solve two main challenges.\n",
      "•Authenticate in a decentralized environment.\n",
      "•Authenticate without revealing identity.\n",
      "These two points have been discussed separately since the start of the internet. Each point has its own difficulties and challenges. Authentication needs to tackle problems like the absence of a central server, certificate management in a distributed environment, the semi-trusted nature of peers, the unpredictable availability of peers, etc. Authentication needs to solve problems like not revealing sensitive information about authenticating party’s identity, secure against misbehaving parties (cheating verifiers and cheating provers), unlinkability of authentication sessions, practicality, etc.\n",
      "In this paper, we propose three new approaches for anonymous authentication in P2Pnetworks to solve the above problems.\n",
      "Ring signature based approach.\n",
      "Authenticated key sharing based approach.\n",
      "Zero knowledge proof based approach.\n",
      "We deploy these protocol in a P2P environment where certificates are managed by peers with elevated privileges (super peers). To solve the problems of semi-trusted nature and unpredictable availability of peers we utilize Shamir’s secret sharing[7] technique. Amore detailed explanation of these cryptographic primitives is given in section 3. Then we test the performance of these ideas in a practical environment developed using the.Net framework.\n",
      "Related works\n",
      "2.1 Authentication in P2P\n",
      "Absence of a central server makes authentication in peer to peer (P2P) networks complex.\n",
      "Traditional cryptographic principles like Public Key Infrastructure (PKI) or Identity\n",
      "based Public Key Certificates (ID-PKC) are based on a trusted third party. Establishing\n",
      "a trusted third party in a semi-trusted network like P2P is a questionable task. Many\n",
      "P2P networks propose trust and reputation management schemes to solve this problem.[8]\n",
      ",[9], [10] use trust and reputation schemes to discover peers that can be considered as\n",
      "trusted peers of the network. These trusted peers are used in authentication as trusted\n",
      "third parties.\n",
      "The idea of reputation management systems is to evaluate a peer’s trustworthiness\n",
      "based on its interactions with other peers. There exist plenty of research in this area;\n",
      "EigenTurst [11], NICE[12], Regret [13], PeerTurst[14], FuzzyTrust [15].\n",
      "P2P systems that use reputation managements schemes to assist in authentication\n",
      "suffer from an obvious flow. These schemes assume that the reputation system is intelligent\n",
      "enough not to select malicious users as trusted peers. Trusting malicious peers to protect\n",
      "sensitive information can harm the system. For example, CST [? ] elect a set of peers as\n",
      "RPs (Reputed Peers) using EigenTrust. CST creates a pseudo-identity to hide the real\n",
      "identity of the user. The link between the identity and the pseudo-identity is broken into\n",
      "parts and stored in randomly selected RPs to protect users’ privacy. CST trusts RPs to\n",
      "protect the users’ identity. However, EigenTrust is vulnerable to collaborative attacks\n",
      "and therefore there exist a possibility that malicious peers are elected as RPs. Malicious\n",
      "RPs can reveal the identity of a user and exploit their privacy.\n",
      "Some researches suggest using a modified PKI for authentication in P2P networks\n",
      "[16], [17]. Rather than having a single centralized authority, the responsibility of the\n",
      "Certificate Authority (CA) is distributed across multiple peers in the network. This\n",
      "improves the scalability and robustness of the authentication process.\n",
      "The downside of using PKI in P2P is certificate management becomes complex. The\n",
      "authentication process becomes difficult to implement effectively. [17] use a set of peers as\n",
      "Authentication Servers (ASs). Even though this improves the scalability of the network,\n",
      "introduce new security risks like unreliability in certificate access and verification.\n",
      "To solve the problem of the absence of a centralized authority and at the same\n",
      "time keep the authentication process reliable, modern authentication schemes utilize\n",
      "blockchain technology. There is a lot of literature that proposes the idea of using\n",
      "blockchain technology to create a Distributed PKI [18], [19], [20], [21]. This seems to be a\n",
      "good solution to overcome the limitations of having a central trusted certificate authority.\n",
      "Blockchain can make the process of a CA distributed, immutable and transparent.\n",
      "Therefore can successfully solve the problems of malicious CAs, MITM attacks and single\n",
      "point of failure. Blockchain is used as a distributed key-value data storage. The data\n",
      "is public and readable to everyone.[22] propose the idea of using smart contracts to\n",
      "certificate management.\n",
      "The DPKI is only secure as long as honest nodes control collectively more than 51%\n",
      "of computing power. Also some argues the need of blockchain to decentralized PKI since\n",
      "the technology of blockchain is still new to the industry.\n",
      "The PGP Web of Trust [23] is another way to navigate the problem of not having a\n",
      "trusted central authority. WoT distribute the responsibility of a CA among users. The\n",
      "core concept of WoT is trust chains. For a simpler explanation, assume A wants to\n",
      "authenticate himself to B. There is a user C who trusts B. C can sign A’s certificate\n",
      "after verifying its authenticity. Then A can send the signed certificate to B. Since C\n",
      "has signed A’s certificate and B trusts C. B can trust A’s certificate is authentic. Using\n",
      "indirect trust chains WoT creates a community of trusted users. However WoT is not\n",
      "suitable P2P networks since, it is difficult for a new peer to join the network without\n",
      "personally knowing a existing user of the network.\n",
      "2.2 Anonymous Authentication in P2P\n",
      "The concept of anonymous authentication has been around for sometime. Pseudo\n",
      "Trust[24] has been one of the more popular publications of this topic. Pseudo Trust\n",
      "(PT) utilize the concept of double pseudonyms combine with zero knowledge proofs to\n",
      "authenticate users anonymously. PT also uses onion routing[2] and EigenTrust[11] trust\n",
      "management to provide a complete file delivery system with anonymous authentication.\n",
      "The anonymity comes from the one way property of the cryptographic hash functions. PT\n",
      "neglect one important feature of using the concept of pseudonyms to obtain anonymity.\n",
      "PT does not change PI (pseudo identity) prior to each authentication process. The PT\n",
      "protocol requires PIC (certificate of pseudo identity) to be send to the other party to\n",
      "start the authentication. Since PIC is same for a user, an eavesdropper can link two\n",
      "communication sessions to a specific user.\n",
      "[25] proposes an similar authentication scheme to PT for Internet of Vehicles (IoV).\n",
      "The only difference is the slight change of the zero knowledge proof and absence of onion\n",
      "routing the trust management. This also suffers from the same vulnerabilities as PT.\n",
      "[10] present an interesting approach to anonymous authentication. PPAA uses tags\n",
      "to obtain anonymity and at the same time link communication sessions. The idea is\n",
      "to use IDs of the two parties involved in the communication session create a tag. The\n",
      "two parties will not learn any knowledge other than the tag from running the protocol.\n",
      "To avoid having the same tag for different communication sessions between the same\n",
      "parties PPAA propose to include an event id into the tag design. Therefore only a party\n",
      "involved in the communication will be able to link a communication session to a previous\n",
      "session with the same party. The PPAA is secure in random oracle model if eXternal\n",
      "Diffie-Hellmam (XDH) and q-SDH assumption holds.\n",
      "CST[9] uses collaboration signature to authenticate users anonymously. As mentioned\n",
      "in section 2.1 CST uses EigenTrust[11] reputation system to select trusted peers (RPs).\n",
      "This is not safe in a semi-trusted environment like P2P networks. Other than that CST\n",
      "is said to be resilient against impersonate attacks, traceability and collaboration attacks.\n",
      "[26] presents a similar method as CST. They use FBST[27][Fair Blind Signatures] to\n",
      "present novel authentication scheme that keep the anonymity of honest users. Similar to\n",
      "CST this uses a trust management system called SOBIE to elect peers as super peers\n",
      "(SPs) and reputed peers (RPs). They are assumed to be trust worthy and play and\n",
      "important role in authentication. However, as mentioned previously trust management\n",
      "systems are not perfect. Malicious peers can get elected as SPs and RPs and they are\n",
      "able to revoke users’ anonymity. Similar to CST, [26] uses the concept of Shamir’s secret\n",
      "sharing [7] to reduce the vulnerability of exposed RPs. [7][How to share a secret] present\n",
      "a way to break a key and store it in multiple places and recreate the key when required.\n",
      "[26] use this technique to break the key (link between ID and pseudo ID) and store it\n",
      "among multiple RPs. Therefore even if few RPs got compromise it does not reveal user’s\n",
      "identity. Also a user use anonymous multicast to communicate with a SP. This makes it\n",
      "impossible for a SP to reveal an identity of a user.\n",
      "[28] uses an combination of Merkle’s puzzles[29] and zero knowledge proofs to provide\n",
      "anonymous authentication.\n",
      "Methodology\n",
      "3.1 Cryptographic Primitives\n",
      "3.1.1 Zero Knowledge Proof\n",
      "Zero knowledge Proof (ZKP) is a protocol that allows a prover to prove the possession of some secret to a verifier without revealing the secret or any information related to the secret. The first idea of ZKP was introduced by Shafi Goldwasser, Silvio Micali, and Charles Rackoff in [30]. Since then many different ZKPs have been published [31], [32], [33], [34]. ZKPs are widely used in cryptography to implement cryptographic protocols due to its privacy, authentication and low complexity.\n",
      "A zero knowledge proof consists of a prover and verifier. In a zero knowledge protocol, a prover must prove the knowledge of some secret using an interactive challenge-response scheme. The protocol must not reveal any information regarding the secret other than the knowledge of prover has the secret. A secure zkp must satisfy soundness, completeness and zero knowledge properties.\n",
      "There are two types of zero knowledge systems; interactive zero knowledge proofs and non-interactive zero knowledge proofs [35]. Our proposed protocol uses a zkp that utilize quadratic residues in modular arithmetic.\n",
      "3.1.2 Ring Signatures\n",
      "The notion of ring signature was first introduced in 2001 by Ron Rivest, Adi Shamir and Yael Tauman Kalai in [36]. Ring signatures are used to digitally sign messages on behalf of a group. At the same time, makes it computationally difficult to find the exact signer.\n",
      "Ring signatures are designed to provide anonymity to the message signer. The same functionality is provided by group signatures [37]. The only difference in group signature is that it needs an authoritative entity to generate the signature. Therefore that entity can revoke the anonymity of the signer. Ring signatures do not depend on a third party to generate a signature. Ring signatures are spontaneous and provide unconditional anonymity.\n",
      "Over the years different ring signature schemes have been published with different features; threshold ring signatures [38], linkable ring signatures[39], revocable ring signatures[40], traceable ring signatures[41].\n",
      "Consider a scenario where a group of k entities where each entity has a public key Pi and a corresponding secret key Si. An entity r can generate a ring signature on a message m using (m, P1, . . . , Pk, Sr). Anyone with the knowledge of m, P1, . . . , Pk can verify the ring signature. No one outside the group (without a secret key Si) can generate a valid ring signature for the same group.\n",
      "3.1.3 Shamir’s Secret Sharing\n",
      "In 1979 Adi Shamir introduced the concept of Shamir’s secret sharing[7][How to Share a Secret]. This allows a secret to be divided into n parts. The secret can be reconstructed with atleast t parts where (1 ≤ t ≤ n). No knowledge about the secret can be learnt with (t-1) parts. The concept is based on polynomial interpolation. The idea is to generate a polynomial f(x) of (t-1) points. First we select (t-1) random positive integers such that (a1, a2, .., at−1). Then set a0 to the secret we want to share. These points are used to generate the polynomial f(x). f(x) = a0 + a1x + a2x2 + … + at−1xt−1 Then we get n points (xi , yi) corresponding to the polynomial. Given any subset of t points a0 can be found by lagrange basis interpolation.\n",
      "li =\n",
      "{x − x0} {xi − x0} </box> /times \\frac{x − x1} {xi − x1} \\times ... \\times \\frac{x − xt−1} {xi − xt−1}\n",
      "f(x) = X t−1 i=0 yili(x)\n",
      "The idea of Shamir’s secret sharing is a popular concept in p2p systems. A p2p network does not have an centralized database to store peers’ keys. Storing keys in a selected set of peers might not be a good idea since p2p is a semi-trusted environment. For an example when a peer request a key from another peer, he might not respond. Therefore keys need to be broken into parts and distributed among multiple peers. A peer should be able to reconstruct a key without the knowledge of all the parts. [9], [26] are p2p anonymous authentication mechanisms that use the concept of Shamir’s secret sharing.\n",
      "3.2 Conceptual design\n",
      "3.2.1 P2P network design\n",
      "Using the .Net framework we implemented a hybrid P2P network[42]. A traditional hybrid peer to peer network consists of peers and super peers. Hybrid P2P systems is a combination of purely distributed P2P systems and mediated P2P systems. Hybrid systems are designed to overcome the problems of the two mentioned systems. These systems provide search efficiency of mediated P2P systems while maintaining the reliability of decentralization similar to pure P2P systems[43].\n",
      "Our P2P network consists of three types of entities; the main server, ordinary peers (hereafter mentioned as peers) and super peers. A peer communicates with the main server only at the time of registration. Users join the network as peers. Peers are ordinary service requestors. They are connected to the system through super peers. Every peer is assumed to be behind a NAT environment. Peers with public IP addresses and higher computational power are promoted to be super peers.\n",
      "Super peers have more responsibility for the system. A super peer is connected to one or more other super peers in the network and responsible for one or more peers. They can communicate among other super peers using the super network. Super peers can join or leave the network at any time. Dynamic behaviour of super peers should not affect the connectivity of the network. Our design of the network is able to change the topology according to this dynamic behaviour of peers and maintain connectivity among existing super peers.\n",
      "A super peer is only responsible for nodes under his scope and does not know any information regarding other peers of the system. Therefore a node discovery process becomes an exhaustive task. This can be accomplished in two ways; flooding search and random walk. We utilize flooding search in this project since the random walk is not guaranteed to produce results[44].\n",
      "3.2.2 Distributed Certificate Management\n",
      "The decentralized environment of the P2P network does not allow traditional methods of authentication. It’s difficult to maintain a centralized database of certificates where the availability of peers cannot be predicted. Distributing certificates among super peers is not a viable solution since super peers are not always available. Therefore all the certificates under this super peer remains not accessible. Also, malicious super peers might delete certificates from the network. The obvious solution is to keep multiple copies of the certificates. We propose a different solution by using Shamir’s secret sharing algorithm. The idea is to break the certificates into multiple parts and distribute across the P2P network. When needed, the certificates can be reconstructed from a minimal subset of the parts. A more detailed explanation of the implementation is given in section 3.3.1 .\n",
      "3.2.3 Proposed Authentication Schemes\n",
      "Ring Signature Based approach\n",
      "The characteristics of ring signatures make it an interesting primitive in obtaining anonymous authentication. Ring signatures allows a message to be signed by a group of public keys. Making it impossible to identify the exact signer. The original ring signature scheme[36] and most of the proposed ring signatures provide complete anonymity. This is not suitable for authentication. This make it impossible to revoke the anonymity of malicious peers. Therefore we used the revocable ring signature scheme proposed in [40] to create a simple authentication protocol that protect users’ privacy. This is just a simple suggestion, of a way to obtain anonymous authentication using existing ring signature schemes. The idea is to challenge prover to generate a ring signature using a random nonce generated by a verifier. If the prover is able to accomplish this he can successfully authenticate himself.\n",
      "Authenticated key sharing based approach\n",
      "We propose a novel authentication mechanism that allows a peer to authenticate without revealing their identity. The basic idea of the protocol is to present prover a set of public keys and challenge to prove the knowledge of atleast one secret key corresponding to a public key from the set. This idea is simple but the protocol should not reveal any information related to the prover’s identity. Also a prover without a valid key pair should not be able to authenticate himself. To accomplish that we employ a authenticated key sharing scheme introduced in [45].\n",
      "Zero Knowledge Proof Based Approach\n",
      "Zkp is a popular approach to obtain anonymous authentication in p2p networks. This technique has been utilized in [24], [25] and [10]. Many of these approaches relies on pseudonyms to hide the identity. We propose a new authentication protocol that uses zero knowledge proofs to hide the identity among a group of users. The protocol achieves properties similar to ring signatures. This is an modification of the Schnorr’s zero knowledge proof [46]. The method is similar to the authenticated key sharing based approach in the sense that the challenge is to prove the knowledge of a secret key in a set of public keys. However unlike previous method, we use zero knowledge proofs to do that. Therefore this method achieve k anonymity.\n",
      "3.3 Methodological approach\n",
      "3.3.1 Distributed Certificate Management\n",
      "During the initial interaction of a peer, the corresponding super peer obtains the peer’s certificate. The super peer breaks the certificate into n parts using Shamir’s algorithm. The super peer then floods these parts across the network. Once a request to recreate the certificate(s) received. Super peer again floods a request(s) to collect the parts of the certificate. The super peers that are holding these parts will send them to the corresponding super peers. The original certificate can be recreated as long as r parts are received by the super peer (r ≤ n).\n",
      "This technique allows distributing certificates in a more dynamic way. As long as r super peers can be accessed, the certificate can be recreated. This method only requires minimal storage. That is, the size of a single part does not exceed the size of the certificate. This is also the more flexible approach. n and r can be changed for each certificate without affecting other certificates. However, then there needs to be a way to identify n and r for each certificate.\n",
      "n and r are performance metrics. Increasing n will increase the average key storage size in super peers. In section 6 we analyze the performance of increasing r while n is kept as a constant.\n",
      "3.3.2 Proposed Authentication Schemes\n",
      "Ring Signature Based approach\n",
      "The protocol starts by the prover collecting a set of certificates from the super peer. Prover then randomly select a subset of the certificates. Then he verify the authenticity of the certificates and obtains the set of public keys from the subset of certificates using main server’s public key. Prover hides his own certificate among this subset of certificates and send them to the verifier to initiate the authentication. After authenticating the certificates, verifier obtains the set of public keys using main server’s public key. Then verifier generates a random nonce and challenge prover to generate a ring signature for this random nonce, using the above set of public keys. Prover use his secret key, the set of public keys and main server’s public key to generate a ring signature according to the algorithm proposed in [40]. Prover then sends the ring signature to the verifier. Verifier verifies the authenticity of the ring signature according to the random nonce he sent at the previous step. If the verification is successful, authentication is complete. Otherwise verifier sends a fail message. Authenticated key sharing based approach As same as the previous approach prover collects a set of certificates from the super peer. Then randomly select a subset out of them. After verifying the authenticity of the certificates prover extract the corresponding public keys. Prover mix his certificate into the subset of certificates and send them to the verifier. Verifier obtains the public keys after verifying the authenticity of the certificates. Then generate X = gx by selecting a random x. Then use the set of public keys to encrypt X. Thus creating a set of ciphertexts where each corresponds to a different public key from the set. Since one of the public key is prover’s, he will be able decrypt X with his secret key. After decrypting X, prover selects a random y and calculates Y = gy . Then generate K = Xy . K is the shared key. Then he sends Y to the verifier encrypted with verifier’s public key. Verifier decrypts Y. Then compute K = Yx . At this stage both parties have the same shared key K. Verifier encrypts a random number R using a symmetric key encryption scheme using K as the key. Then challenge prover to decrypt this and send R back. If the prover generated the correct K at the previous steps, he will be able to decrypt R. Therefore prover can successfully authenticate himself. Otherwise verifier sends a fail message.\n",
      "Authenticated key sharing based approach\n",
      "As same as the previous approach prover collects a set of certificates from the super peer. Then randomly select a subset out of them. After verifying the authenticity of the certificates prover extract the corresponding public keys. Prover mix his certificate into the subset of certificates and send them to the verifier. Verifier obtains the public keys after verifying the authenticity of the certificates. Then generate X = gx by selecting a random x. Then use the set of public keys to encrypt X. Thus creating a set of ciphertexts where each corresponds to a different public key from the set. Since one of the public key is prover’s, he will be able decrypt X with his secret key. After decrypting X, prover selects a random y and calculates Y = gy . Then generate K = Xy . K is the shared key. Then he sends Y to the verifier encrypted with verifier’s public key. Verifier decrypts Y. Then compute K = Yx . At this stage both parties have the same shared key K. Verifier encrypts a random number R using a symmetric key encryption scheme using K as the key. Then challenge prover to decrypt this and send R back. If the prover generated the correct K at the previous steps, he will be able to decrypt R. Therefore prover can successfully authenticate himself. Otherwise verifier sends a fail message.\n",
      "Zero Knowledge Proof Based Approach\n",
      "As same as the above two methods prover collects k certificates from the super peer. Then randomly select n-1 certificates and create C and P vectors as the above methods. However in this method public key is Au = gap where au is the private key. Similar to Schnorr’s protocol prover generates U. The difference is U contains factors of Avii where vi is a random number. This is generated only using the collected public keys (Prover’s public key is not in U). Prover then send U to the verifier. Verifier sends a challenge c to the prover. Prover xor all elements of vi with c to obtain vp. Then mix vp among the set of vi s and send them along with the set of public keys (including prover’s public key) to the verifier. Prover also sends r which is s − apvpmodp. Then prover does two steps of verification. First he xor vi s and check if it’s equal to c. If it is not terminate the authentication. Otherwise generate U′ using r, A and vi s. If U = U′ authentication is successful. Otherwise sends a fail message to the prover. A more detailed explanation is given in section 4.1.3 .\n",
      "Experiment Setup and Implementation\n",
      "4.1 Proposed Schemes\n",
      "4.1.1 Ring Signature Based approach\n",
      "Registration\n",
      "A user has an ID which can be anything related to the identity of the user. Selects\n",
      "a random number ru. Then generate a public key Pu such that\n",
      "Pu = H1(ID, ru)\n",
      "User then generates the private key Su corresponding to Pu\n",
      "User sends the registration request along with his ID, Pu to the main server.\n",
      "Main server verifies the identity of the user. Then the server signs Pu with his\n",
      "private key Ss to generate Certu. Then sends Certu to the user.\n",
      "Authentication\n",
      "Prover collects k certificates from the super peer. Then randomly selects n-1\n",
      "certificates from the the set. After verifying the authenticity of the selected\n",
      "certificates prover generates C = {Cert1, Cert2, .., Certn} which includes prover’s\n",
      "certificate Certp as well. Prover then obtain each corresponding public key from the\n",
      "certificates to generate P = {P1, P2, .., Pn}. Then send C to the verifier, encrypted\n",
      "with verifier’s public key Pv.\n",
      "Verifier decrypts the message to obtain C. After verifying the authenticity of each\n",
      "Certi\n",
      ", verifier generates each Pi using main servers public key Ps. Then generate\n",
      "H = Hash(P). Then sends H and a random nonce N to the prover.\n",
      "Prover generate H′ = Hash(P) and if H ̸= H′\n",
      "terminate the authentication.\n",
      "Otherwise use his secret key Sp, P and Ps to sign N and generate ring signature\n",
      "σ using [40] ring signature scheme. Then send σ to the verifier, encrypted with\n",
      "verifier’s public key Pv.\n",
      "Verifier decrypts the message to obtain σ. Then verify whether σ corresponds to N\n",
      "using P set of public keys (obtained in step 2). If the verification is success prover\n",
      "is successfully authenticated. Otherwise verifier sends a fail message.\n",
      "4.1.2 Authenticated key sharing based approach\n",
      "Registration\n",
      "A user has an ID which can be anything related to the identity of the user. Selects\n",
      "a public ru. Then generate\n",
      "Pu = H1(ID, ru)\n",
      "Pu is the public key of the user. User then generates the private key Su corresponding\n",
      "to Pu\n",
      "User sends the registration request along with his ID, Pu to the main server.\n",
      "Main server verifies the identity of the user. Then the server signs Pu with his\n",
      "private key Ss to generate Certu. Then sends Certu to the user.\n",
      "Authentication\n",
      "Prover collects k certificates from the super peer. Then randomly selects n-1\n",
      "certificates from the the set. After verifying the authenticity of the selected\n",
      "certificates prover generates C = {Cert1, Cert2, .., Certn} | C includes Certp as\n",
      "well. Then send C to the verifier, encrypted with verifier’s public key (Pv).\n",
      "Verifier decrypts P using his secret key (Sv). Generate H = Hash(P). Then\n",
      "generate a random number x and obtain X = gx. Then generate n ciphertexts\n",
      "CT = {C1, C2, …, Cn}|Ci = EPi\n",
      "(X|H). Verifier sends CT to the prover.\n",
      "Prover selects the Ci corresponding to his public key. Decrypt it using his secret\n",
      "key (Sp) to obtain X and H. Generate H′ = Hash(P). Check if H = H′\n",
      ". If not\n",
      "terminate the session. Otherwise select a random number y to generate Y = gy\n",
      ".\n",
      "Then compute K = Xy\n",
      ". Prover sends Y back to the verifier encrypted with Pv.\n",
      "Verifier decrypts Y. Compute K = Yx\n",
      ". Then generate another random number R,\n",
      "generate E1K(R). E1(.) is a symmetric key encryption scheme. Then generate\n",
      "H1 = Hash(R|K). Then send E1k(R) and H1 to the prover.\n",
      "Prover decrypts the message with his knowledge of K to obtain R. Then use R and\n",
      "his K to generate H1′ = Hash(R|K). If H1 = H1′ , prover sends R back to the\n",
      "verifier. Otherwise terminate the authentication session.\n",
      "Authentication is successful if the verifier obtains the same R. If not verifier sends\n",
      "a fail message to the prover.\n",
      "4.1.3 Zero Knowledge Proof Based Approach\n",
      "Setup\n",
      "P and Q are two large prime number where P-1 |Q.gisageneratorof acyclicgroupofZ∗p\n",
      "where order of the group is Q. P, Q and g are group parameters.\n",
      "Registration\n",
      "A user has an ID which can be anything related to the identity of the user. Selects\n",
      "a random integer ru. Then generate au\n",
      "au = H1(ID, ru)\n",
      "such that au is from [0, Q-1]. au is the private key of the user. Then to generate\n",
      "the public key Au user calculates\n",
      "Au = gaumodp\n",
      "User sends the registration request along with his ID, Au to the main server.\n",
      "Main server verifies the identity of the user. Then the server signs Au with his\n",
      "private key Ks to generate Certu. Then sends Certu to the user.\n",
      "Authentication\n",
      "Prover collects k certificates from the super peer. Then randomly selects n-1\n",
      "certificates from the the set. After verifying the authenticity of the selected certificates prover generates C = {Cert1, Cert2, .., Certn−1}. Prover then obtain each\n",
      "corresponding public key from the certificates to generate P = {A1, A2, . . . An−1}.\n",
      "Prover then selects a random number s from the range [0, Q-1]. Then selects another\n",
      "n-1 random numbers from the range [0, Q-1] to generate the V = {v1, v2, . . . , vn−1}.\n",
      "Prover calculates\n",
      "U = gsAv1Av2\n",
      ". . . Avn−1\n",
      "Prover sends U to the verifier to initiate the authentication.\n",
      "Verifier selects a random number c from the range [0, Q-1] and sends it to the\n",
      "prover.\n",
      "Prover calculates\n",
      "vp = v1 ⊕ v2 ⊕ . . . vn−1 ⊕ c\n",
      "Then insert vp to the vector V such that V = {v1, . . . vp, . . . vn−1}. Prover also\n",
      "update C = {Cert1, …, Certp, …, Certn−1} where Certp is prover’s certificate. Then\n",
      "calculates\n",
      "r = s − apvpmodp\n",
      "Prover sends r, V, C to the verifier.\n",
      "After verifying the authenticity of the certificates in C. Verifier calculates\n",
      "c′ = v1 ⊕ v2 ⊕ . . . ⊕ vn\n",
      "If c ̸= c′\n",
      ", terminate the authentication session. Otherwise calculates\n",
      "U′ = grAv1Av2. . . Avn\n",
      "If U = U′\n",
      ", authentication is successful. Otherwise terminate the authentication.\n",
      "4.2 Testing\n",
      "Testing of the system was done to understand the capabilities of the system. The testing was done cloud servers located in different countries. Intention was to mimic a world wide distributed network. Although a simulation environment would be ideal to do load testing on the system, absence of open-source platforms to simulate network environments which could run c sharp scripts was a problem. However, a real-world environment helps to understand the system performance in its operating environment. The tests were done to find the limitations of key sharing mechanism and to compare the performance of the three authentication protocols in a real environment. The first test was done to understand the performance of the key sharing mechanism.\n",
      "4.2.1 Performance of key sharing\n",
      "Key sharing technique is an integral part of our implementation. The number of parts the key can be broken into (n) and the number of parts required to reconstruct a certificate (r) decides the availability of certificates. A high n value and low r value obtains a higher availability. Since distributing the parts of the certificates happens only once, in this experiment we measure the latency of the certificate reconstruction. Specifically, the experiment was done to identify how the latency of a successful certificate reconstruction varies with increasing n and r. The experiment was done by setting n = r. That is all parts of the certificate are required to reconstruct the certificate. First we break a randomly created certificate into n parts and distribute across the P2P network. Then we floods a SEARCH message requesting the parts of the certificate. The time was measured from the time of flooding the SEARCH message until the successful reconstruction of the certificate. We started with breaking the certificate into 2 parts and at each step we increased n by 2. We continued the experiment until n reached 20. For each n the experiment was done three times and we measured the average time. We also removed any outliers that could affect the results. Due to limited resources, we used only four publicly available servers each in a different country. The selected servers were located in Singapore, India, America and France. Multiple super-node instances were created at each server and super-nodes 20 were connected so that no two neighbour-nodes reside in the same country. This is to intentionally increase the latency of communication.\n",
      "4.2.2 Performance of authentication protocols\n",
      "The anonymity of the authentication protocols depends on the number of certificates.\n",
      "Higher the number of certificates used in the protocol higher the anonymity of the prover.\n",
      "Therefore it is important that a protocol can handle a higher number of certificates. This\n",
      "experiment was done to measure the latency of a complete successful authentication\n",
      "session between a prover and a verifier. At each step, we increased the number of\n",
      "certificates used in the protocol to measure how the latency varies. The experiment was\n",
      "done for the three proposed protocols in the hope to compare the performance. The time\n",
      "was measured from moment that the prover received the requested keys and successful\n",
      "finish the authentication protocol at the verifier’s side. The experiment was started using\n",
      "only 10 keys and at each step, we increased the number of keys by 10. The experiment\n",
      "was carried out until 200 keys are used in the authentication protocols. Similar to the\n",
      "previous test, the experiment was done three times and we measured the average time.\n",
      "We also removed any outliers that could affect the results.\n",
      "Due to limited resources, we used only four publicly available servers each in a\n",
      "different country. The selected servers were located in Singapore, India, America and\n",
      "France. Multiple super-node instances were created at each server and super-nodes\n",
      "were connected so that no two neighbour-nodes reside in the same country. This is to\n",
      "intentionally increase the latency of communication.\n",
      "Results and Analysis\n",
      "5.1 Proofs of security\n",
      "5.1.1 Ring Signature Based approach\n",
      "The security of the protocol depends on the security of the ring\n",
      "signature scheme[40]. The authors have proven the correctness,\n",
      "revocation correctness, unforgeability and signer anonymity of the\n",
      "signature scheme. They directly corresponds to the anonymity,\n",
      "completeness, soundness of our suggested protocol.\n",
      "Anonymity\n",
      "Anonymity of the protocol depends on the properties of the ring\n",
      "signature scheme. The scheme proves it obtains signer anonymity. The\n",
      "proposed protocol does not reveal any information other than the set of\n",
      "public keys P. The only information verifier can deduce is prover’s\n",
      "public key Pp is among the set P. Therefore this obtains k\n",
      "anonymity.\n",
      "Completeness\n",
      "If a protocol has completeness, the protocol is said to be\n",
      "comprehensive; an honest verifier will always be able to authenticate\n",
      "himself.\n",
      "The completeness of the protocol comes from the correctness of the ring\n",
      "signature scheme[40]. The authors of the paper have mathematically\n",
      "proven the correctness of the ring signature scheme. Therefore our\n",
      "protocol is complete.\n",
      "soundness\n",
      "If a protocol has soundness property, the protocol is said to be\n",
      "truthful; a cheating prover will never be able to authenticate himself.\n",
      "Since the ring signature scheme has proven it’s unforgeability, a\n",
      "cheating prover will not be able to forge a ring signature. The proposed\n",
      "protocol obtains soundness.\n",
      "Impersonation\n",
      "Impersonation is when a malicious user (M) impersonates another user. A\n",
      "protocol that accomplish soundness and completeness is secure against\n",
      "impersonation attacks. Therefore this protocol is secure against\n",
      "impersonation.\n",
      "Replay Attacks\n",
      "A replay attack is when an adversary saves a previously sent message(s)\n",
      "and replay it later to gain an advantage. Let’s assume a scenario where\n",
      "a malicious user (hereafter mentioned as M) is eavesdropping on a\n",
      "authentication session. M can save message in step 1 (Msg1) and message\n",
      "in step 3 (Msg3), replay it later in the hope to authenticate himself.\n",
      "Msg1 is encrypted. Therefore M will not be able to reveal it’s content.\n",
      "When Msg1 is replayed, verifier will respond with a random N and H.\n",
      "Without the knowledge of P or C prover will not be able to generate the\n",
      "correct ring signature. Therefore will not be able to authenticate\n",
      "himself. Replaying Msg3 will not gain anything unless verifier generates\n",
      "the same N as the original authentication. Probability of this scenario\n",
      "is 1/N, which can be reduced by increasing the domain of N.\n",
      "5.1.2 Authenticated key sharing based approach\n",
      "Anonymity\n",
      "The protocol hides the identity of the prover among a group of selected\n",
      "peers. The group is selected by the prover at random. Therefore verifier\n",
      "cannot manipulate P to obtain a knowledge about the prover.\n",
      "A cheating verifier may use different x values to obtain prover’s\n",
      "identity. Verifier will generate a set of x = {x1, x2, …, xn} and\n",
      "generate X = {X1, X2, …, Xn} | Xi = gxi. Then\n",
      "verifier can generate CT = {C1, C2, …, Cn} |\n",
      "Ci = Epi(Xi | H). By doing so, verifier hope to identify\n",
      "which Ci prover was able to decrypt. Then verifier can link that\n",
      "Ci to corresponding Pi to reveal provers identity.\n",
      "However, this will not allow verifier to reveal prover’s identity since\n",
      "at step 4 verifier needs to generate K without the knowledge of exact X\n",
      "the verifier received. Therefore will not reveal any information about\n",
      "the prover unless verifier can successfully guess the Xi prover\n",
      "decrypted. Successfully random guessing Xi has a probability of 1/n.\n",
      "Another possibility is using the above method and generating a vector of\n",
      "K = {K1, K2, …, Kn} where each Ki correspond to a different\n",
      "xi. Then at step 4 select a random Kv and send E1kv(R). By\n",
      "this verifier hopes to find which Ki the prover generated. This can\n",
      "be done by replicating the decryption process using the elements of K\n",
      "vector. Then check what Ki generate a similar output. However this is\n",
      "not possible due to H1 hash. Since this must include the correct key,\n",
      "prover will know the malicious intentions of the verifier and terminate\n",
      "the authentication process.\n",
      "This methods does not provide k anonymity. Since prover always terminate\n",
      "the authentication whenever the protocol was not correctly followed,\n",
      "verifier can use this knowledge to reduce the scope of prover’s\n",
      "identity. For an example, verifier generate CT as half of the Ci are\n",
      "incorrectly formed and other half is correctly formed. If the prover\n",
      "terminate the authentication process, prover’s public key is one of the\n",
      "misformed public keys. If the prover continues the authentication\n",
      "process, prover’s public key is one of the correctly formed public keys.\n",
      "Completeness\n",
      "If the prover indeed has a secret key corresponding to any one of the\n",
      "public keys in set P, prover can successfully decrypt X. Therefore can\n",
      "obtain the correct key (k) for step 5.\n",
      "K’ = Xy\n",
      "K’ = (gx)y\n",
      "K’ = (gy)x\n",
      "K’ = K\n",
      "Since prover generate the correct key (K). He can successfully decrypt\n",
      "R. Therefore can successfully authenticate himself.\n",
      "Soundness\n",
      "A cheating prover does not have a secret key corresponding to any of the\n",
      "public keys in P. To authenticate himself as a member he has to\n",
      "correctly guess X at step 3 or correctly guess R at step 5. Both it is\n",
      "statistically impossible since X and R are generated randomly by the\n",
      "verifier for each communication session.\n",
      "Therefore unless prover can obtain a secret key and a corresponding\n",
      "public key from a another registered user, it is not possible to\n",
      "authenticate himself.\n",
      "Impersonation\n",
      "Since protocol accomplish both soundness and completeness, this protocol\n",
      "is secure against impersonation attacks.\n",
      "Replay Attacks\n",
      "A replay attack is when an adversary saves a previously sent message(s)\n",
      "and uses it again to gain an advantage. Let’s assume a scenario where a\n",
      "malicious user (hereafter mentioned as M) is eavesdropping on a\n",
      "communication session. M can save message in step 1 (Msg1) , message in\n",
      "step 3 (Msg3) and/or message in step 5 (Msg5), replay it later in the\n",
      "hope to authenticate himself.\n",
      "If Msg1 was replayed this will not gain any advantage for M. Since M\n",
      "does not know any secret key corresponding to the set P, he will not be\n",
      "able to authenticate unless by random guessing X or R in step 3 and step 5.\n",
      "Storing Msg3 will not help since without the knowledge of y, M will\n",
      "not able to generate K. Only possibility of succeeding in a replay\n",
      "attack is if the verifier generate the same R as the original\n",
      "authentication. Then M can replay Msg5 to successfully authenticate\n",
      "himself as a valid prover.\n",
      "5.1.3 Zero Knowledge Proof Based Approach\n",
      "Anonymity\n",
      "The only information the protocol reveals is that the prover has the\n",
      "knowledge of an ap. Protocol hides the Ap (public key) corresponds\n",
      "to that ap among the set of P public keys. Identifying the exact\n",
      "public key of the prover is not feasible. Therefore the protocol obtains\n",
      "k anonymity.\n",
      "Completeness\n",
      "If the prover possesses the correct ap; the secret key corresponding\n",
      "to Ap, only then the prover will be able to generate r such that the\n",
      "U generated by the verifier will be equal to the U received to the\n",
      "verifier at step 1.\n",
      "U’ = gr Av1 … Avp … Avn-1\n",
      "U’ = g(s - apvp) Av1 … Avp … Avn-1\n",
      "U’ = gs g-apvp Av1 … (gap)vp … Avn-1\n",
      "U’ = gs g-apvp … gapvp … Avn-1\n",
      "U’ = gs Av1 … Avn-1\n",
      "U’ = U\n",
      "Soundness\n",
      "Let’s consider a cheating prover as a prover who does not possess a\n",
      "private key ap corresponding to a public key Ap.\n",
      "Without a ap a prover will not be able to generate\n",
      "r = s - apvp mod p.\n",
      "At step 3, prover is required to generate vp by xoring elements of V\n",
      "with the challenge c. This operation ensures that xoring elements in V\n",
      "vector (including vp) at the verifier’s side would generate c.\n",
      "Therefore to pass the first step of verification V must be well formed.\n",
      "Without the knowledge of the valid ap a prover will not be able to\n",
      "generate r to cancel out the gapvp component at the last step of\n",
      "the verification.\n",
      "The only possibility is random guessing. The probability of guessing\n",
      "$a_p$ without any information is 1/Q. Since Q is selected to be a large\n",
      "prime number, probability of that happening is statistically\n",
      "insignificant.\n",
      "Impersonation\n",
      "As we explained previously a protocol that accomplish soundness and\n",
      "completeness is secure against impersonation attacks. Therefore this\n",
      "protocol is secure against impersonation.\n",
      "Replay Attacks\n",
      "Let’s assume a scenario where a malicious user (hereafter mentioned as\n",
      "M) is eavesdropping on a communication session. M can save Msg1 at step\n",
      "1 and Msg3 at step 3, and replay the messages later in the hope to\n",
      "authenticate himself.\n",
      "When M replays Msg1 verifier will respond with a random challenge.\n",
      "Without the knowledge of s, ap, V and P vectors M will not able to\n",
      "continue further. Therefore only replaying Msg1 will not be successful.\n",
      "Replaying Msg3 as the response for the challenge will cause the first\n",
      "step of the verification to fail. Since c is chosen randomly by the\n",
      "verifier, the old vp will not correspond to the new c. Therefore\n",
      "xoring elements of V will not be equal to c and verifier will terminate\n",
      "the authentication process. This will only be successful if the same c\n",
      "is chosen at the two authentication processes. The probability of this\n",
      "happening is 1/Q. As mentioned in previous cases this is statistically\n",
      "insignificant.\n",
      "Modifying the Msg3 will not gain any advantage to M. As mentioned under\n",
      "soundness proof, without a valid ap authenticating will be\n",
      "infeasible.\n",
      "5.2 Performance Testing\n",
      "5.2.1 Performance of key sharing\n",
      "The test was carried out by increasing the number of parts the key is broken into and\n",
      "measuring the latency of successful key reconstruction.\n",
      "Number of parts per key\n",
      "Average Latency (ms)\n",
      "2\n",
      "540.26\n",
      "4\n",
      "559.08\n",
      "6\n",
      "591.55\n",
      "8\n",
      "712.93\n",
      "10\n",
      "1012.48\n",
      "12\n",
      "1120.95\n",
      "14\n",
      "1323.59\n",
      "16\n",
      "1718.33\n",
      "18\n",
      "1404.40\n",
      "20\n",
      "1404.40\n",
      "Table 5.1 Latency of the key reconstruction with increasing number of parts per key\n",
      "5.2.2 Performance of authentication protocols\n",
      "The test was carried out by increasing the number of keys used in the authentication\n",
      "process and measuring the latency of a successful authentication process. The test was\n",
      "carried out separately for the three authentication protocols in similar environments.\n",
      "Number of parts per key\n",
      "Latency in Authenticated key sharing based approach (ms)\n",
      "Latency in Zero knowledge proof based approach (ms)\n",
      "Latency in Ring signature based approach (ms)\n",
      "10\n",
      "82.00\n",
      "58.33\n",
      "98.67\n",
      "20\n",
      "87.00\n",
      "56.33\n",
      "107.00\n",
      "30\n",
      "88.00\n",
      "62.00\n",
      "104.00\n",
      "40\n",
      "89.33\n",
      "80.00\n",
      "106.67\n",
      "50\n",
      "99.67\n",
      "58.00\n",
      "114.67\n",
      "60\n",
      "99.67\n",
      "56.33\n",
      "109.33\n",
      "70\n",
      "105.00\n",
      "58.67\n",
      "119.67\n",
      "80\n",
      "111.33\n",
      "68.33\n",
      "121.33\n",
      "90\n",
      "112.67\n",
      "63.67\n",
      "127.33\n",
      "100\n",
      "116.00\n",
      "57.67\n",
      "120.67\n",
      "110\n",
      "105.33\n",
      "59.33\n",
      "124.33\n",
      "120\n",
      "115.00\n",
      "64.33\n",
      "127.33\n",
      "130\n",
      "119.67\n",
      "55.67\n",
      "142.67\n",
      "140\n",
      "124.67\n",
      "58.67\n",
      "144.33\n",
      "150\n",
      "127.33\n",
      "56.33\n",
      "144.67\n",
      "160\n",
      "113.33\n",
      "67.33\n",
      "138.67\n",
      "170\n",
      "134.33\n",
      "58.67\n",
      "140.00\n",
      "180\n",
      "128.00\n",
      "58.33\n",
      "144.00\n",
      "190\n",
      "125.67\n",
      "56.00\n",
      "142.00\n",
      "200\n",
      "133.00\n",
      "63.33\n",
      "144.00\n",
      "Table 5.2 Latency of the authentication protocols with increasing number of keys.\n",
      "Fig. 5.2 Performance comparison of the three authentication protocols\n",
      "5.3 Performance Analysis\n",
      "According to Fig. 5.1, the latency of the key reconstruction exponentially increases\n",
      "with an increasing number of key parts. The maximum number of possible parts per\n",
      "key without increasing a threshold of 5 seconds is 20. The reason for such exponential\n",
      "increment is due to the linear distribution of unique keys. That is to request the mth part\n",
      "of the key, the request needs to travel through m supernodes. Increasing the number of\n",
      "parts per key will increase the overall distance the request message has to travel through.\n",
      "Increasing the number of key parts increases the overall latency of the authentication\n",
      "process. The higher the parts the key is broken to, the higher the availability of the keys.\n",
      "Therefore need to understand the optimal trade-off between the availability of keys and\n",
      "the latency of the key reconstruction process.\n",
      "It is also important to notice that the network congestion at the time of the experiment,\n",
      "the physical location of super-nodes, the performance of the super-nodes can have an\n",
      "effect on the results. Nonetheless, the experiment is still essential to get an overall idea\n",
      "of the performance of the key reconstruction mechanism.\n",
      "Fig 5.2 compare the performance of the three authentication protocols with respect\n",
      "to time. The latency of the authenticated key sharing based approach and the ring\n",
      "signature-based approach increases with the increasing number of keys. However, the\n",
      "latency of the zero-knowledge proof-based approach remains constant. The reason is the\n",
      "encryption and decryption steps of the first two protocols. Higher the number of keys,\n",
      "the higher the number of encryptions and decryptions the protocol has to done. The\n",
      "zero-knowledge proof-based approach has no explicit encryption and decryption steps.\n",
      "Thus it is faster and no visible increment in the latency with the increasing number of\n",
      "keys compared to the other two approaches.\n",
      "Higher the number of keys used in the authentication process higher the anonymity.\n",
      "Since the zero-knowledge proof-based approach can increase the number of keys used\n",
      "in the protocol without increasing the latency of the authentication process it is more\n",
      "efficient compared to the other two protocols.\n",
      "Conclusions and Future Works\n",
      "We have proposed three novel protocols to achieve anonymous authentication in peer to\n",
      "peer networks. The ring signature-based approach provides a suggestion of how to utilized\n",
      "already implemented ring signatures to obtain anonymous authentication. Then we propose an\n",
      "authentication method that utilizes a key sharing mechanism. This method does\n",
      "not provide zero-knowledge. That is a verifier can obtain some knowledge of the prover\n",
      "identity. To solve this we introduce a zero-knowledge proof-based approach that utilizes\n",
      "Schnorr’s protocol to achieve anonymous authentication. This method is more efficient,\n",
      "secure and most importantly achieve zero knowledge. We have proven the security of each\n",
      "protocol including anonymity, completeness, soundness, resilience to impersonation and\n",
      "resilience to replay attacks. The protocols were tested in a peer to peer overlay network\n",
      "build using the .Net framework. The peer to peer network utilizes a distributed certificate\n",
      "management mechanism build using Shamir’s secret sharing algorithm. This allows\n",
      "us to access certificates in a more efficient manner compared to the traditional approaches.\n",
      "As for future works, we hope to modify the zero-knowledge proof-based approach for\n",
      "certificate revocation. That is, give an authoritative entity the privilege to revoke the\n",
      "anonymity of a user when required. We also hope to integrate the proposed authentication\n",
      "protocols in real-world peer to peer transactions.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting cricket analysis https://cepdnaclk.github.io/e15-4yp-cricket-analysis\n",
      "\n",
      "\n",
      "Data Mining System for Selecting a Winning Cricket Team\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "Data Mining System for Selecting a Winning Cricket Team\n",
      "Team\n",
      "E/15/119, Dinithi Hasanika, dinithiliyanage.95@gmail.com\n",
      "E/15/202, Dulanjali Liyanage, preethi.du1995@gmail.com\n",
      "E/15/208, Roshani Dilhara, roshanidilhara7@gmail.com\n",
      "Supervisors\n",
      "Dr. Asitha Bandaranayake, asithab@eng.pdn.ac.lk\n",
      "Sampath Deegalla, sampath@eng.pdn.ac.lk\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "Cricket is a two-team game which was originated in south-east England and developed globally in the 19th century. This world’s second most popular game is played for a limited number of overs as twenty20 for twenty overs and ODI(One Day International) matches for 50 overs. Test matches are played for five days. Due to the availability of ball-by-ball data of this bat-and-ball game, researchers were able to do statistical analysis of data for pattern recognition, to find factors affecting the game and for outcome prediction of a match. But due to the high uncertainty of the game, it has become very difficult to come up with a stable and accurate model for the predictions. Outcome model also depends on the number of overs, match type, considering time period and players combination. This research focus only the ODI matches and considering only the ICC full members; England, Australia, New Zealand, Sri Lanka, Bangladesh, Pakistan, India, Zimbabwe, West Indies, Afghanistan, South Africa\n",
      "and Ireland. This outcome prediction is based on players performances in a team and some features specific to the team and the match. The individual performance of batsmen, bowlers and fielders are analysed separately considering all-time ODI data. Combined performance of batsmen and bowlers were analysed and compared with individual performances using statistical method. Association rule mining method was used to find frequent winning player combinations. Match data from 2015 to 2020 were considered for the combined performance analysis and outcome prediction. For all these predictions we use data mining and machine learning techniques.\n",
      "Related works\n",
      "1. Player Performance\n",
      "Each cricket team is a combination of batsmen, bowlers, fielders, and all-rounders including the wicket-keeper. For the winnability of the team, individual batsmen should score maximum runs, individual bowlers should take the maximum wickets possible while restricting the opponent team from scoring either by runs or offering extras. For the victory, the wicket keeper should also contribute as a batsman, other than playing behind the wickets. All-rounders contribute by scoring runs and taking wickets since they have the ability of both batting and bowling. Fielders should contribute to the team by getting the batsmen out of the game or by limiting the scoring of batsmen.\n",
      "Individual players’ performance has a significant impact on the winnability of a cricket team. So, the accurate metrics that affect the winnability of a specific team should be found to evaluate the individual players. The basis of modeling the strength of a team is enhancing the strength of batting and bowling of individual players. Many researchers have analyzed different methods for this player performance evaluation, and the below sections will go through them.\n",
      "2. All-Rounder Performance\n",
      "The players who show talents in both batting and bowling are called all-rounders in a match. This also can be categorized into two as bowl all-rounders who are more skilled for bowling than batting and batting all-rounders who are more skilled for batting than bowling. It is better to have at least one all-rounder for one team.\n",
      "3. Player Ranking and Player Order\n",
      "Cricket player ranking is an important point when directing a match towards winning. Since batting order and bowling order matters in winning. Open batsmen and bowlers who bowl the maiden overs and last overs are also considered as important factors that can be influenced to the final outcome of the match. Open batsmen do not need to be the best players but need to be the experienced players in open batting. From positions, 3 to 6 should consist of the best batsmen from better to poor. Most of the time 7th position is for the wicket keeper. Positions 8 to 11 for bowlers.\n",
      "P. Premkumar et al. came up with a model to rank batsman and bowlers according to their performance in ODI matches. They considered runs scored by a batsman on a match-by-match basis and took the average for the considered time duration. They considered wickets taken by a bowler when ranking bowlers. Other than that they considered location impact, pitch impact, Batting innings impact, Opposition impact, team impact, and strike rate impact when ranking both the batsmen and bowlers.\n",
      "V. Kanungo et al. visualized data of best-performed players in IPL. They ranked players considering four factors; the number of man of the matches, number of centuries recorded batsmen with top strike rates, top 10 players with maximum total runs.\n",
      "T. B. Swartz et al. developed a model for the Indian team to find optimal or nearly optimal batting orders to play in ODI matches. It used a simulated annealing approach and developed an algorithm to select the optimal batting team. They considered features like batsmen, the number of wickets lost, the number of balls bowled, the bowler, the opposing team, and the condition of the pitch. This method suggested some batting orders that have never been tried by the Indian team.\n",
      "J. M. Norman et al. came up with two models to find the optimal batting order for the Australian team. Model 1 is for limited-overs matches and Model 2 is for unlimited overs matches. They categorized player positions 1 to 3 as the top, 4 to 6 as good, 7 to 9 as average, and 10 to 11 as slogger. When grouping Australian players to the above-mentioned categories, they considered average runs, run rate, and dismissal probability. They built a model to decide when there is a sudden dismissal. They found that it is more advantageous than having a fixed batting order.\n",
      "Harsha Perera et al. built up an algorithm using simulated annealing to determine the optimal player for the Twenty20 matches. They created models for India and South Africa. And this model selects two separate player orders as the optimal batting order and optimal bowling order.\n",
      "4. Team Performance\n",
      "Cricket is played by 2 teams against each other. A team consists of 11 players. But it is not a fixed team. Players in a team can be changed over time and also team may change match by match. In that case, it is important to consider the influence of team performance in the final outcome of a match. The performance of a team is mainly based on each individual player’s performance and some other factors. Researchers have attempted to include evaluations of team performance in predicting the outcome of a cricket match. So the following sections discuss the various methods used by past researches to evaluate team performance.\n",
      "5. Team Performance metrics and overall performance\n",
      "Better performance of a team is mainly affected by each individual player’s performance in it. These factors impact on predicting the outcome of the match.\n",
      "Madan Gopal Jhawar et al. has addressed this situation in their research using ODI match results. They have suggested that the relative team strength is a distinctive feature in predicting the outcome of a cricket match. Since a team can be changed due to various reasons, they have suggested a parameter to express the team performance. That is the relative strength of a team. Means strength of team A against team B. To calculate this they have used two factors as batting and bowling to model each individual player. Then depending on related factors, they have given a score for each of them. Since these scores have different ranges they have been normalized to lie in the same range. Then the batting strength of a team is calculated as the summation of batting scores of all the players in the team. The bowling strength of a team is calculated as the summation of bowling scores of all the players in the team. Depending on these scores, the strength of team A against team B is calculated. Where A and B are the two opposing teams playing the match. This calculation is used as one of the attributes to predict the outcome of the match.\n",
      "N. Siva et al. has proposed a method to evaluate a team based on their past data, without considering its players. In this evaluation, they have considered 556 matches played from 2006 to 2017. The analysis has been done only on the Sri Lankan cricket team. To evaluate the team performance they have considered ten attributes with categorical values. Those attributes are city, venue, match type, outcomes, number of overs, player of the match, opposition, toss winner, toss decision, and winner. Using these attributes they have come up with a classification based model to predict the outcome of a match. They have used machine learning algorithms in predicting the outcome of a match using the overall performance of a team.\n",
      "N. Pathak et al. has used the factors analyzed by A. Bandulasiri in creating a model for each team to predict the outcome of an ODI cricket match from the time duration of 2001 to 2015. Those factors are Toss outcome, Day/Night effect, Home game advantage, and bat first. In this analysis, they have not considered individual player performance. The Naïve Bayesian classification technique has shown the best results.\n",
      "A. C. Kaluarachchi et al. have selected the attributes team, opponent team, home/away, day/night, toss, bat first and result to predict the outcome of an ODI cricket match. They have considered all the ODI matches from 1971 up to 2010. The outcome was displayed through a software tool called CricAI. Since Bayesian classifiers have shown the best results, it has been used in this tool. This analysis also has not considered the impact of individual player performance on the team performances.\n",
      "M. Bailey et al. has considered the factors home ground advantage, past performance, match experience, performance at a specific venue, performance against a specific opposition, experience at the specific venue, and current form, in predicting the ODI match outcome while the match is in progress. They have considered 2200 ODI matches prior to 2005. Using these results they have created models to predict Margin of Victory(MOV) and the team totals. For the prediction of team totals, only 100 ODI matches of 2015 have been used. For the rain-interrupted matches DL method has been used in predicting the team total. Team totals are compared using AAE(Absolute Average Error) between the actual and predicted values. Results are obtained as totals for the team batting first and totals for the team batting second. From that first innings, totals were more accurate and the second innings totals predictions were more accurate as the game reached the end.\n",
      "B. Morley et al. has focused on the team’s decision on whether to bat first or second considering factors of home-field effect and winning the toss. They have considered only the English ODI match data during the period 1996 to 1997 league season. 57\\% of matches have been won by the home team and 51\\% of matches have been won by the team winning the toss. 56\\% of matches have been won by the home team where they have won the toss and chooses the batting order. Only 43\\% of matches have been won by the away team where they won the toss and decide the batting order. Therefore this suggests that winning the toss and deciding the batting order is of great advantage for the home team. But the effect of winning the toss can be nullified by adding the team quality and match importance and these factors are more important in predicting the outcome of a match.\n",
      "S. A. D. P. Subasingha et al. has proposed a novel method in predicting the outcome of an ODI cricket match. They have used two sub-data models in predicting the outcome of the match. One model is used in predicting the outcome of a match, based on pre-match data. And the other model is used in predicting the outcome of the match using the batting partnership of both teams. The first model is team-based. They have considered the attributes toss effect, ground condition, day/night effect, and opponent in the first model. A Naïve Bayes algorithm has been used to predict the final outcome.\n",
      "A statistical analysis has been proposed by A. Nimmagadda et al. predicted the result of a Twenty20 match while in progress. In this analysis they have not considered the number of wickets fallen, venue of the match, and the toss at the first phase. Instead of that their prediction of\n",
      "scores for a team was\n",
      "based on runs scored, and looking at different totals at the end of innings and various run rates. But since considering only run rates did not give good results, they also have estimated the batting and bowling potentials of 22 players using their career statics and active participation in recent games. These player potentials have been used to get the relative dominance one team has over the other. Prediction modeled using Multiple linear regression and has included the batsman increase, bowler, wickets, and run rates as attributes.\n",
      "K. Kapadia et al. have used IPL match data to come up with a machine learning model to predict the result of a match, based on historical match data. Based on features related to home ground and toss decision of team, two sets of different models have been obtained. Naïve Bayes has shown 57\\% accuracy and 60.5\\% precision and Model Trees has a 68.6\\% recall rate, when the home team is the winner of the match when considering only the home team feature sets. kNN model has shown 62\\% accuracy, 64.2\\% precision, 58.4\\% recall rate when the toss winning team is the winner of the match when considering only the toss winner feature set.\n",
      "P. Somaskandhan et al. has considered IPL matches from 2008 to 2016, 350 matches and 700 innings included to their consideration. They have considered 23 features like total runs scored in an innings, the total number of wickets in an innings, highest individual score in an innings, runs in the power-play of the innings which affect on the team performance of a IPL match.They used feature selection techniques in machine learning to identify\n",
      "the\n",
      "best set of features which impose significant impact on the end results of the match.\n",
      "P.A. Gregory et al. have chosen the IPL match details as their domain since it provided them with a satisfactory amount of data for their analysis in predicting the outcome of a match based on a specific feature set. Their data set was comprised of 501 instances of IPL matches and have used relational mapping framework to store data in a database. Their main component of the analysis was the feature set which includes 14 different features. Namely Number of Wickets Lost, Four Hitting Frequency, Six Hitting Frequency, Boundary Run Percentage, Dot Ball Percentage, Dot Ball to Runs Ratio, Run Rate, Average Partnership Score, Number of Batting Segments, Batting Segment to Wicket Ratio, Average Runs in a Batting Segment, Average Pressure Factor, Pressure of Wickets, Final Score. First they have obtain an optimum subset of attributes for first and second innings of an IPL match separately. For first inning Dot Ball to Runs Ratio, Dot Ball Percentage, Number of Wickets Lost has been chosen with 70.46\\% accuracy and for the second inning Pressure of Losing Wickets has been chosen with 88.82\\% accuracy. They also have obtained optimum features by dividing innings to three segments as Powerplay, Middle and Death. Then by combining these segments with complete inning, an optimum set of features have been derived with 71.65\\% accuracy. The optimum subset of attributes that they have selected for first inning are Four Frequency, Number of Batting Segments, Final Score, Batting Segment to Wicket Ratio (PP), Six Hitting Frequency (PP), Boundary Run Percentage (Middle), Average Runs in Batting Segment (Middle), Average Pressure Factor (Middle), Dot Ball Percentage (Middle), Run Rate (Middle).\n",
      "6.Outcome Prediction\n",
      "A cricket match has four possible outcomes; a win, loss, draw, tie. But in ODI matches it is impossible to end the match in a draw.\n",
      "If the second batting team scores more than the first batting team, the match will be won by the second batting team. In such a case the match may end without completing the overs limit and with some wickets on the hand of the second batting team. When the second batting team is unable to score more than the first batting team, the first batting team is won by some runs. A match is said to be tied when both the teams score the same amount of runs. In either case, the match ends with all the ten batsmen being out or completing the overs limit. In some tournaments when a match is tied with the overs limit, both the teams get a chance of a super over. If the super over is again tied, then the team with the highest number of boundaries wins the match. A number of researches have been conducted to predict the outcome of the cricket match.\n",
      "V. V. Sankaranarayanan et al. came up with a 68\\% - 70\\% accurate data mining approach to predict the future state and predict the winner of an on-going ODI match. Predicting the future state of the game included predicting the number of runs scored for the next segment. They used two separate models to predict home runs and non-home runs. They considered six historical features and five instantaneous features. The considered historical features are average runs scored by the team in an innings, the average number of wickets lost in an innings, frequency of being all-out, average runs conceded in an innings, the average number of opponent wickets taken in an innings, and Frequency of getting opposition all-out. The considered instantaneous features are home or away, powerplay, target, batsmen performance features, and game snapshot (current score and fallen wickets).\n",
      "M. Bailey et al. also developed a similar model to the above model to predict the outcome of an on-going ODI match. The factors they considered are a home ground advantage, past performance, match experience, performance at a specific venue, and current form. To predict the match outcome they weighted those factors according to the statistical significance of them. They used the Duckworth-Lewis method to determine resources remaining at the end of each over and used that result to predict the final score of the batting team.\n",
      "M. Gopal Jhanwar et al. developed a 71\\% accurate model to predict the outcome of an ODI match using a team composition based supervised learning approach. First, it modeled the potentials of batsmen and bowlers in both the teams. The model then predicted the winning team of the match using the player performance, toss decision, venue, and relative team strength. The model also showed that both the historical data of the players and instantaneous data are needed to predict the outcome of a match.\n",
      "S. A. D. P. Subasingha et al. came up with a tool to predict the outcome of an ODI match. Their run rate is the only considering factor to predict the final score of the team.\n",
      "Neeraj Pathak et al. developed a tool COP (Cricket Outcome Predictor) which outputs the probability of winning an ODI match. The model used instantaneous factors analyzed by Ananda Bandulasiri. Those factors were toss outcome, day/night effect, home game advantage, and bat first. They analyzed ten full member nations of ICC and prepared a separate model for each team considering their opposition teams separately. This tool gives the prediction before the match is started Since factors considered in this approach do not change after the match started. The critical tool developed by A. C. Kaluarachchi et al. to predict the outcome of an ODI match is also similar to the COP tool. They also considered the features analyzed by Ananda Bandulasiri. But they revealed that toss winning does not have a major impact on match outcome. But They found that losing the toss and batting second increases the chance of winning while winning the toss and batting second reduces the chance of winning.\n",
      "A. Nimmagadda et al. proposed a model to predict the winner of the Twenty20 match while the match is in progress. The proposed model projects run scored by the batting team considering the current run rate and other different run rates. They considered relative team strength and venue since the run rate is not enough to predict the final outcome.\n",
      "7. Sentiment Analysis\n",
      "Sentiment analysis is analyzing positive, negative, or neutral mentions within text data using text analysis techniques. Apart from the text analysis, this refers to computational linguistics, natural language processing and systematically identifying, extracting, quantifying, and studying affective states and subjective information. Sentimental analysis is also known as name opinion mining. Emotions of cricket fans change when their home country scores run, taking wickets and when losing wickets. Sentiment analysis can be performed with a number of related keywords to analyze cricket fan’s emotions. This can be done using social media platforms like Twitter, Facebook. This approach used to evaluate the popularity of a team.\n",
      "N. Rodrigues et al. used twitter data and distinguished tweets as positive, negative, and neutral and obtained the popularity of each player. They included that as an IPL franchise league player selecting metrics in their model. The same criteria used in the IPL dream team software developed by Jayshree Hajgude et al. for the use of IPL franchise team owners for the selection of players.\n",
      "Dinesh Samariya et al. illustrated Indian cricket team fans mood change continuously during the cricket match using the twitter data. They proposed an approach which is a combination of corpus-based and dictionary-based techniques. They visualized emotion changes of Indian cricket team fans in separate graphs when the India team is playing with other selected opposite teams.\n",
      "S. Arafin Mahtab et al. analyzed facebook Bangladesh cricket fan group comments in the Bengali language to analyze the fan emotions of the Bangladesh team. They used a machine learning approach and prepared three sentiment classes about Bangladesh cricket as praise, criticism, and sadness.\n",
      "P. Lakkaraju et al. used SAS (Sentiment Analysis Studio) to extract textual opinions about cricketers. Using this method they ranked players according to the number of times they mentioned in the considered textual data.\n",
      "8. Methodologies\n",
      "Analyzing and coming up with the different techniques to model the cricket game made easy by the availability of ball by ball data of matches in the public domain. Some popular sites that provide these data are ESPN CricInfo, Cricsheet, kaggle and Statsguru. These sites are updated for every match. From this data, many types of research have been carried out from time to time and come up with different types of models to evaluate the performances of a player and a team, and predict the outcome of a match. They have used data mining techniques, machine learning techniques, etc. to model the game cricket.\n",
      "M. M. Rahman et al. has provided an analysis of Bangladesh ODI cricket data of the time period 2005 to 2015. They have collected all these data records from the ESPN CricInfo website. In this analysis, they have used decision tree algorithm C5.0 to predict the outcome of the match while the game is in progress. 10\\% of the data have been randomly selected to predict the result(or the test data) and the remaining data have been used in creating the model.\n",
      "V. V. Sankaranarayanan et al. have used the ODI cricket data from January 2011 to July 2012 in their analysis. All these records have been taken from the ESPN CricInfo website. They have used these data in creating a model to predict the future states while the game is in progress. But 20 matches with rain interruption have been removed from the analysis. In creating the model they have used only data mining techniques and some formula. They have not used any machine learning algorithms.\n",
      "Madan Gopal Jhawar et al. has proposed a team composition based supervised learning approach to predict the outcome of a match. They also have obtained data of ODI matches from 2010 to 2014 from the ESPN CricInfo website. Since they have restricted their study to the top 9 ODI playing teams some data have been excluded. And they have 109 matches that were interrupted by rain. They have used Binary classifiers like SVM(Support Vector Machine), Random Forest, Logistic Regression, Decision Tree, and kNN(k- Nearest Neighbour) with sweep features and no cross-validation in their modeling. The kNN algorithm has shown the best accuracy.\n",
      "N. Pathak et al. have used classification techniques in predicting the outcome of the ODI cricket match. They also have considered ODI data from the ESPN CricInfo website in the time duration of 2001 to 2015. 80\\% of data is used for training the models and 20\\% to test. Naïve Bayesian, Random Forest, SVM, classifiers used in modeling, and Naïve Bayesian have shown better performance. Kappa statistics and balanced accuracy has been used for better classification performances. Higher values of these have increased the performances of classification.\n",
      "A. C. Kaluarachchi et al. has used Bayesian classifiers, Decision Tree Classifiers using C4.5, Bagging, and Boosting to predict the winning team of an ODI cricket match. Since Bayesian classifiers have shown the best results, it was used to develop a software tool called CricAI to output the probability of victory. They have used machine learning techniques like association rule mining, clustering, and classification. They have considered data from 1971 to 2010 of ODI matches obtained from the ESPN CricInfo website.\n",
      "P. Somaskandhan et al. has used machine learning techniques to come up with an optimal set of attributes that impose a high impact on the end result of a match. In this analysis, they have used IPL ball by ball data from 2008 to 2016. They have trained Extra-tree, Naïve Bayes, and Support Vector Machine (SVM) machine learning algorithms with 80\\% of data, and the remaining 20\\% have been used for testing. SVM has shown the best results in their analysis.\n",
      "M. Bailey et al. has used a multiple linear regression model to predict the outcome of an ODI match while the game is in progress. Prior to predicting they have numerically weighted the variables according to their statistical significance. The Margin of Victory(MOV) has been obtained by the multiple linear regression model. This model has shown 71\\% of accuracy. Then for 100 matches from 2015 ODI, AAE(Absolute Average Error) between actual and predicted MOV of the team batting first and team batting second has been considered. According to the obtained results, first-innings totals are more accurate than the second innings. But the reduction in AAE has increased in the second inning when the game draws nearer to the end.\n",
      "A. Bandulasiri predicted the winner of an ODI match using a logistic regression model. They have considered World Cup matches from 1995 to 2007.\n",
      "B. Morley et al. also used a logistic regression model to investigate home advantage and other factors affecting the outcomes in English ODI matches. Logistic regression and graphical “classification and regression tree” approach are used by K. P. Jayalath in his analysis of predicting the outcome of an ODI cricket match.\n",
      "T. B. Swartz et al. have used a non-machine learning approach called simulated annealing in searching for optimal or nearly optimal batting orders in an ODI match. They have considered only the performance of the Indian cricket team in an ODI match.\n",
      "N. Siva et al. have used the data mining and machine learning approach in performance analysis of the Sri Lankan cricket team. They have considered only IPL and Twenty20 match data obtained from Cricsheet, ESPNcricinfo, and online data mining community Kaggle. K. Passi et al. also has used a machine learning approach to predict the player performance in an ODI match. And the data source is ESPNcricinfo. They also have used the WEKA tool.\n",
      "S. A. D. P. Subasingha et al. has used data mining techniques to predict the outcome of an ODI cricket match. They have used data from ESPNcricinfo and sites. WEKA tool has been used to build the classifier models.\n",
      "P. Shah et al. have used exponentially decaying average (EDMA) to evaluate individual player performances. It is a statistical approach to measure the form of an individual player. In calculating the form, simple logic of short term and long term EDMA has been used. The form of a batsman is depicted as a percentage of the ratio of short term EDMA and long term EDMA.\n",
      "Concepts of Multiple Random Forest Regression have been used by N. Rodrigues et al. in predicting a score for a batsman or a bowler in a given match. This has been used to model the ODI match data.\n",
      "P. Premkumar et al. proposed a dynamic approach using factor analysis to rank the batsman and bowlers using the data obtained from 2015 ODI matches. In this dynamic model, factor scores are calculated for players using\n",
      "Principal Component Analysis techniques. Since performance metrics of players are highly correlated they have obtained only one factor consisting of all the variables.\n",
      "P.A. Gregory et al. has used an iterative approach to obtain an optimum set of attributes to which can predict the outcome of IPL cricket matches (501 instances) . Analysis have been carried out using two different approaches. In first approach they have ranked the features using a specific mathematical model. In the second approach accuracies are calculated for different subset of features against a classification algorithm. Feature selection and modeling analysis has been carried out using Filter method. There were three attribute selection algortihms namely CfsSubsetEval (selecting attributes with high ccorrelation and low inter-correlatio), InfoGainAttributeEval (ranking attributes according to information gain and then selecting attibutes) and ReliefFAttributeEval (Selects attributes by repeated sampling). Classification model\n",
      "J48 decision tree algorithm with 10-fold cross validation was trained using the above selected subset of features and accuracies were improved by combining various attributes of a given subset of features. Then they have used both wrapper and filter methods with J48 classifier to analyze and obtain the optimum set of features by segmenting innings. Finally WrapperSubsetEval selection algorithm has return the subset with highest accuracy when combining\n",
      "segmented innings with complete innings.\n",
      "As discussed above there are many types of research that have been carried out by data mining and machine learning approaches in team and player evaluations and predicting the outcome of the match. Although most of them have used the data mining and machine learning approaches the final model to predict the results have shown some differences due to the different attributes used or due to the difference in considered time period and type of match.\n",
      "Methodology\n",
      "Proposed Methodology\n",
      "The main objectives of this research are recognizing patterns of player combinations that result in the match outcome and predicting the match outcome when the players of two teams and match conditions are provided.\n",
      "This research is carried under five perspectives.\n",
      "Identify features impact on the individual performance\n",
      "In this, the features affecting the individual performance of a player is considered. This research considered new features that were not used in earlier researches. This is carried under three divisions as batsmen, bowlers, and fielders. Using machine learning regression models the feature importance was obtained.\\par\n",
      "Ranking players considering their individual performance\n",
      "The ranking of players is carried under three divisions as batsmen, bowlers, and fielders. Wicket-keepers also considered as fielders. All-rounders are considered under all three divisions. Considering the features impact on player’s performance a score is calculated for each player. Based on the calculated score player is ranked.\n",
      "Identify the combined effect of players\n",
      "Not only the individual performance but also the combined effect of players also impacts the match outcome. This approach is a statistical approach to find beautiful combinations of players where their combined effect is better than the combination of their individual performances. This approach considers batsmen and bowlers separately. This considers n-grams of players like 2-grams, 3-grams.\n",
      "Identify frequent player combinations\n",
      "This is an association rule mining approach to find frequent combinations, frequent winning combinations in ODI matches. The combinations obtained by this approach is further compared with the beautiful combinations obtained by considering combined effect of players.\n",
      "Predict the match outcome\n",
      "This approach is to build a machine learning model which predicts the outcome of a given match. This model predicts the outcome of a given ODI cricket match under following conditions.\n",
      "Two teams should be one of these countries: England, Australia, New Zealand, Sri Lanka, Bangladesh, Pakistan, India, Zimbabwe, West Indies, Afghanistan\n",
      "and Ireland\n",
      "The team combination should be given.\n",
      "Toss won team should be given.\n",
      "Ground should be given.\n",
      "Match time should be given as day or day-night match or night match.\n",
      "In this approach we used the results obtained from the above 1st and 2nd perspectives.\n",
      "Data Collection\n",
      "In the first phase of our project we used the career details of batsman and bowlers. And in this phase, second phase, we collected the fielders data, and all the runs scored by all players in each match. So do all these we obtained the data sets from kaggle and ESPN Cricinfo. Those sources included most of the data but there were some required details which were not included there. So we had to enter them manually. Since there were a lot of data it was a very tiring task to gather all those data.\n",
      "In the first phase, although we gathered data for match details form 2010 to 2020, here we shorten that time span to 2015 to 2020. All these data are gathered only for selected number of countries.\n",
      "Selected countries - ICC full member countries: England, Australia, New Zealand, Sri Lanka, Bangladesh, Pakistan, India, Zimbabwe, West Indies, Afghanistan, South Africa\n",
      "and Ireland\n",
      "Data Preprocessing\n",
      "Gathered data sets have a very large amount of samples which makes it difficult to track the missing or any garbage values. Although we have collected number of features, some features are not really important. So in this stage our aim is to transform the raw data that we gathered from various sources into a useful format so that it is ready to use for analysing.\n",
      "Following are some of the things that we had to face when preprocessing the raw dataset.\n",
      "The height of some players was not stated in data sources. Therefore we treated them as missing values and replaced them with class mean of the attribute.\n",
      "Similar situation happen with the man of the match feature of a player. So we had to replace those missing values with 0.\n",
      "Missing data of batting style and bowling style were replaced using class mode of that attribute.\n",
      "Bowlers and fielders first dataset had many missing career details. So we had to remove about a lot of players since we can not predict some required features.\n",
      "Removed the matches that did not have a final result or tied matches.\n",
      "Individual Player Performance\n",
      "Individual performance of players is considered separately as batsmen, bowlers, and fielders. Different features contribute in different priorities when comparing the players. Some features show different importance levels in different match types. In prior to rank the players, the features were weighted according to their priorities among each other. For that, we used AHP(Analytic Hierarchy Process).\n",
      "Following are the steps we followed in calculating the weights for each feature after selecting the feature importance values from the model which gave highest accuracy.\n",
      "Using the feature importance, we did a pairwise comparison between each feature importance with all other features’ importance. There we created a matrix to compare each of the features.\n",
      "Then, we found the priorities of each attributes when compared to the other attributes with the help of the matrix created. Following equation was used to find priorities.\n",
      "Score Prediction\n",
      "We needed to do a comparison between the players. So, we calculated a new feature ‘score’ for each player; a score for each batsman and a score for each bowler as batsman, bowler and fielder. All-rounders get three ranks because of this. This new feature was derived using the values of previously used features; using carrier features and all features corresponding to each player and the weights of each feature calculated.\n",
      "When ranking batsmen, bowlers and fielders we considered the score predicted by the above mentioned methods. We considered three features to obtain three different scores for same fielder. We followed same approach to score batsmen and bowlers. Then the best score can be choose by considering the other factors affect on the match and the team. The three features considered for fielders are number of dismissals, average dismissals per inning, average dismissals per inning of winning matches.The three features considered for batsmen are overall runs, average and winning average. The three class attributes considered for bowlers are overall wickets, average wickets and winning average wickets. Following equation was used for this considering importance of features.\n",
      "Combined Player Performance\n",
      "For combined player performance, we did a comparative analysis of it with the sum of individual player performances.\n",
      "Players in a team are considered in batsman and bowler categories. Their combined performances were taken considering different combinations like 2-grams, 3-grams and 4-grams for a specific feature in each category.Then we took the sum of individual performances from specific feature from each category which matches the combination type of combined performances. Using those two values, we did a comparative analysis.\n",
      "Frequent Player Combinations\n",
      "For this analysis we used Association Rules. This depicted how frequent a player combination has occurred together, in a team and led the team to victory. Association rules use the support and the confidence to interpret this situation.\n",
      "Itemset :\n",
      "All items occurring in a rule\n",
      "Antecedent : Contains the different player combinations (number of players in a combination is always greater than 1). Generally we called it as the items found within the data.\n",
      "Consequent :\n",
      "In a particular rule this will always be the “won” (means the result of the considered match). Generally this means the output that happens if a particular itemset occurred.\n",
      "Confidence : Number of correct rules with the considered player combination and won the match\n",
      "Outcome Prediction\n",
      "For outcome prediction of a ODI match we build a outcome prediction model using machine learning classification models. This is a binary classification problem, since we are predicting won or loss result of the match. The draw matches and abandoned matches were excluded from the dataset. Both existing match features and derived features from the individual player performances considered for this outcome prediction. 70% of data used as the training set and other 30% used as the test set. The data set was balanced dataset.\n",
      "Experiment Setup and Implementation\n",
      "Research Tools\n",
      "To achieve our goal we have used machine learning libraries used in python.\n",
      "scikit learn - A machine learning library for python which includes algortihms of different\n",
      "classifiers, regressors etc.\n",
      "Pandas - Used for data manipulation and analysis.Handling data structures and operations\n",
      "Numpy - Supports for multidimensional arrays and matrices. Contains a large number of high-level mathematical functions\n",
      "Matplotlib - A plotting library. Helpful in visualising relations between features.\n",
      "Apriori - An algorithm for frequent itemset mining and association rule learning.\n",
      "Inorder to collabaratively work on the codes, we used Google Colab; an online tool with jupyter notebook environment.It was very helpful Since it contains all the required machine learning libraries for python.\n",
      "Data manipulation and Testing\n",
      "Our initial data sets were already in .csv which is a format that we can use in building up our models and tested. But, as mentioned before, we were not able to find all the required fields in one source. So we had to go through manual process to add the players height, and man of the match and number of hat-tricks of bowlers features to these data sets. Even after filling all the required fields there were some missing values. So first we had to go through data preprocessing process.\n",
      "Regression and Feature Importance Selection Methods\n",
      "All the class attributes we considered for the batsmen and bowlers with different feature combinations were numeric type. Therefore we had to use regression to build up machine learning models. The regressors used in our study are random forest regression, Decision tree regression, XGBoost regression, k-neighbours regression and linear regression.\n",
      "Random Forest Regression\n",
      "Random forests use ensemble learning methods to build up the regression model and construct multitude of decision trees at training time. After fitting the model feature importances property can be used to take importance of input features.\n",
      "CART - Decision Tree Regression\n",
      "Decision tree regression builds regression model in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. After fitting the model feature importances property can be used to take importance of input features.\n",
      "XGBoost regression\n",
      "XGBoost is a library that provides an efficient and effective implementation of the stochastic gradient boosting algorithm. XGBRegressor is the class in the XGBoost that can be used for regression. After fitting data to the model there is a property in model called feature importances which can be use to find the importances of features used to build up the model.\n",
      "k-neighbours regression\n",
      "k-NN regression, the k-NN algorithm is used for estimating continuous variables and the permutation testing canbe used to get the feature importance of each input feature.\n",
      "Linear Regression\n",
      "Linear Regression is in sklearn.linear model and after fitting this regression model the coeff property includes the importance in each feature that is used to build the model.\n",
      "Features Considered\n",
      "Batsmen\n",
      "Man of the match - Number of man of the match awards won by the player\n",
      "Last 4 matches runs mean - Average of runs taken by player in his last 4 matches\n",
      "Height(cm) - Height of the player\n",
      "Batting Style - Whether batsman is right handed or not\n",
      "Average - Batting average throughout his carrear\n",
      "NO - number of notouts\n",
      "HS - Highest score\n",
      "HS_NO - Whether highest score played, and out or not\n",
      "SR - Strike rate\n",
      "100s - number of 100s scored\n",
      "50s - number of 50s scored\n",
      "0s - number of times that batsmen out for 0\n",
      "Mat - Number of matches\n",
      "Inns - Number of innings\n",
      "Bowlers\n",
      "Man of the match - Number of man of the match awards won by the player\n",
      "4 - number of times 4 wickets were taken\n",
      "5 - number of times 5 wickets were taken\n",
      "Height(cm) - Height of the player\n",
      "Bowling style\n",
      "Econ - Economy of the bowler\n",
      "Hattricks - number of times 3 wickets were taken on a row\n",
      "SR - Strike rate\n",
      "Average - Batting average throughout his carrear\n",
      "BBI - Best bowling\n",
      "Mat - Number of matches\n",
      "Inns - Number of innings\n",
      "Fielders\n",
      "Man of the match - Number of man of the match awards won by the player\n",
      "Dis - Number of dismissals taken by the player\n",
      "Height(cm) - Height of the player\n",
      "Ct - Number of catches\n",
      "St - Number of stumps\n",
      "Ct Wk - Number of catches as wicket-keeper\n",
      "Ct Fi - Number of catches as fielder\n",
      "MD - Maximum number of dismissals recorded by the player in a match\n",
      "MDct - Maximum number of catches recorded by the player in a match\n",
      "Inns - Number of innings\n",
      "MDst - Maximum number of stumps recorded by the player in a match\n",
      "Outcome Prediction\n",
      "Team - Name of the country from the considered 12 ICC full member countries\n",
      "Day-Night - Whether match is a day match or day and night match or night match\n",
      "Home - Whether match is playing in the country which team belongs to or not\n",
      "Ground - Name of the ground where match is playing\n",
      "Toss - Toss result, whether toss won or loss\n",
      "Bat - Whether bat first or second\n",
      "Opposition - Opposition team name\n",
      "Batsmen Score - Sum of individual batsmen score of players of the team. This individual batsmen score is refers to the batsmen score obtained in this research’s individual performance section.\n",
      "Bowlers Score - Sum of individual bowlers score of players of the team. This individual bowlers score is refers to the bowlers score obtained in this research’s individual performance section.\n",
      "Fielders Score - Sum of individual fielders score of players of the team. This individual fielders score is refers to the fielders score obtained in this research’s individual performance section.\n",
      "Opposite Batsmen Score - Sum of individual batsmen score of players of the opposition team. This individual batsmen score is refers to the batsmen score obtained in this research’s individual performance section.\n",
      "Opposite Bowlers Score - Sum of individual bowlers score of players of the opposition team. This individual bowlers score is refers to the bowlers score obtained in this research’s individual performance section.\n",
      "Opposite Fielders Score - Sum of individual fielders score of players of the opposition team. This individual fielders score is refers to the fielders score obtained in this research’s individual performance section.\n",
      "Pitfalls and workarounds\n",
      "There were several pitfalls that we had to face during the project. The first thing was that we had to gather some background knowledge about cricket since we were not much familiar with the game and not experienced with it. Also we had to find out how different features affect a player or a team, what is measured or depicted by each feature and what features affect each cricket game type. For example, in bowling, strike rate would become an important feature for limited over matches since scoring as much as possible is very important in those matches.\n",
      "Even there was sources to collect data, data organization in the required format, new features creation according to the needs of the our method was the biggest challenge.\n",
      "One challenge was to come up with a method to find values for the new feature ‘scores’ of each player. So for that we followed some papers and their methods. In those methods, there was no way to find the feature importance comparison matrix. For that, we got the feature importance given by the highest accuracy model that we trained as an input and found the importance comparison matrix. When finding scores for bowlers, for some class values, we got nan values for priorities and weights for some models that we selected. So we had to change the model that we selected.\n",
      "For the statistical method of frequent player combination comparison, we tried to find combinations of players up to 11-grams. But we did not have enough CPU performance power to do that. Therefore we only considered 2,3,4 grams of players.\n",
      "When building the outcome prediction model, we considered the sum of scores that we calculated for the players considering their individual performance. Since we calculated several scores for each player, there were huge number of combinations of batsmen,bowler and fielder scores to consider. Therefore selection of good combination of bating, bowling, fielding scores as attributes for final model was a problem. We\n",
      "selected few scores with different behaviors and selected the best combination considering the outcome prediction model accuracy.\n",
      "Results and Analysis\n",
      "Results\n",
      "We used several methods to obtain several values for same player considering two feature combinations and different class attributes. Feature importance of each method took from the feature importance for the best accuracy model of each method. Then got pairwise feature importance matrix for each followed method for batsmen and bowlers.\n",
      "Individual Performance\n",
      "1.Batsmen\n",
      "We considered several feature combinations and different class attributes to obtain score for batsmen. But for the final outcome prediction model we used the scores set obtained using the career features and the class attribute : Overall Runs.\n",
      "Feature Importance: All Features combination Batsmen and class attribute: Overall Runs\n",
      "Feature Importance: All Features combination Batsmen and class attribute: Batting Average\n",
      "Feature Importance: All Features combination Batsmen and class attribute: Winning Average\n",
      "Feature Importance: Career Features combination Batsmen and class attribute: overall runs\n",
      "Feature Importance: Career Features combination Batsmen and class attribute: batting average\n",
      "Feature Importance: Career Features combination Batsmen and class attribute: Winning Average\n",
      "2.Bowlers\n",
      "We considered several feature combinations and different class attributes to obtain score for bowlers. But for the final outcome prediction model we used the scores set obtained using the all features and the class attribute : Overall Wickets.\n",
      "Feature Importance: All Features combination Bowlers and class attribute: Wickets\n",
      "Feature Importance: All Features combination Bowlers and class attribute: Bowling Average\n",
      "Feature Importance: All Features combination Bowlers and class attribute: Economy\n",
      "Feature Importance: Carrier Features combination Bowlers and class attribute: Wickets\n",
      "Feature Importance: Carrier Features combination Bowlers and class attribute: Bowling Average\n",
      "Feature Importance: Career Features combination Bowlers and class attribute: Economy\n",
      "3.Fielders\n",
      "-Class Attribute : Dismissals per innings\n",
      "XGBoost had the best accuracy. Therefore XGBoostalgorithm was used in calculating feature importance for each of the features,relevent to all the other features. Eventually these values are used in prioritiz-ing and assigning weights on the features. Then this weights used to calculate the fielders scores.\n",
      "-Class Attribute : Winning dismissals per innings\n",
      "Again the highest accurate model was XGBoost. Weights and priorities for this model was then calculated and took the scores of the players.\n",
      "-Class Attribute : Dismissals(Dis)\n",
      "andom Forest Regressor model was used in calculating feature importance for each of the features relevant to all the other features.Then these values were used in prioritizing and assigning weights on thefeatures. Then these weights were used to calculate the fielders scores.\n",
      "Feature Importance of Fielders and class attribute: Dismissals per Innings\n",
      "Feature Importance of Fielders and class attribute: Winning dismissals per Innings\n",
      "Feature Importance of Fielders and class attribute: Dismissals\n",
      "Impact of all the features for the outcome prediction model build using all the features\n",
      "Impact of the features for the final outcome prediction model\n",
      "From the above two fielder score sets we selected score set in Class Attribute : Dismissals(Dis) for the calculation of fielders score and opposite fielders score features for final outcome prediction model. This feature set was selected considering the accuracy of thefinal outcome prediction model.\n",
      "Team Performance\n",
      "1.Combined Average\n",
      "For the combined average, we considered both win and lose matches and only winmatches of all 12 ICC full member countries. This was found for batsmen andbowlers.\n",
      "-Batsmen\n",
      "Here, we are considering the average of runs.\n",
      "i. Win and lose Match results\n",
      "ii. Win match results\n",
      "-Bowlers\n",
      "For the bowlers the combined results were taken considering three approaches.Here, we considered the average runs conceded and wickets taken by thebowlers.\n",
      "Combinations of players that satisfy combined averages of runs given bythe considering n-gram of bowlers < Addition of their individual averages ofruns given by them\n",
      "Combinations of players that satisfy combined averages of wickets >Addition of their individual Wickets\n",
      "Combinations of players that satisfy both the 1 and 2 conditions above\n",
      "Win and lose Match results for batsmen\n",
      "Frequent Combinations\n",
      "We analysed different winning player combinations occurred in 12 countries using association rules.\n",
      "-Without Player Position\n",
      "Distribution of India association rules\n",
      "Distribution of Ireland association rules\n",
      "Distribution of South Africa association rules\n",
      "Distribution of West Indies association rules\n",
      "-With Player Position\n",
      "Comparing Frequent Combinations Rules with Batsman Combined Av-erage\n",
      "Association rules that we have obtained for wining player combinations in teamswere compared with the previously obtained batsman combined averages. Thiswas compared for 2-grams, 3-grams etc. of player combinations.\n",
      "Distribution of Confidence in India association rules against Batsman combined average\n",
      "Distribution of Support in India association rules against Batsman combined average\n",
      "Conclusion\n",
      "Cricket is a sport with a huge fan base. So winning a cricket match has become a great honor for some countries. With this popularity, there are a number of bets on predicting the outcome of a cricket match. Therefore it has become a challenge to form a cricket team with best performance player ultimately which lead the cricket team to win. So in this study our aim was to model ODI playing batsmen and bowlers and score their performances accordingly. This study has presented priorities of each\n",
      "features of players and their weights. We considered five new features which were not considered before. Namely player’s height, the number of times they have won the man of the match, not out state when playing highest score and for bowlers number of hat-tricks they have taken and the BBI. Most of the other features considered in this study have used in previous researches. From this study we can conclude that man of the match, height, not out state when playing highest score, hat-tricks and BBI features has comparatively lesser weights in all of the different methods that we used to model batsmen and bowlers. From our results up to now different co-relations among different features have given higher weights on those features.\n",
      "As for the frequent player combinations, what we can conclude is that we cannot predict that having a certain player combination in a team will win the match.\n",
      "Our outcome prediction model was considered six new features which was not used in earlier researches. The importance of these six features is, those features were derived considering the individual performance of the players. The newly introduced six features are batsmen score, bowlers score, fielders score, opposite batsmen score, opposite bowlers score, opposite fielders score. These six features showed very much considerable impact on the final model.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting human behavior prediction using cctv https://cepdnaclk.github.io/e15-4yp-human-behavior-prediction-using-cctv\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Adaptive people movement and action prediction using CCTV to control appliances\n",
      "Team\n",
      "E/15/010, Ruchika Alwis, email\n",
      "E/15/265, Risith Perera, email\n",
      "E/15/347, Isuru Sudasinghe, email\n",
      "Supervisors\n",
      "Eng. (Dr.) Kamalanath Samarakoon, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Links\n",
      "Abstract\n",
      "With the availability of high-performance processors\n",
      "and GPUs, the demand for Machine learning, Deep learning\n",
      "algorithms is growing exponentially. It has become more and\n",
      "more possible to explore the depths of fields like Computer\n",
      "vision with these trends. Detecting humans in video footage using\n",
      "computer vision is one such area. Although human detection is\n",
      "somewhat primitive when compared to today’s technology, using\n",
      "that data to produce various results like recognizing postures,\n",
      "predicting behaviors, predicting paths are very advanced fields\n",
      "and they have very much room left to grow. Various algorithms,\n",
      "approaches are available today to accomplish the above kind of\n",
      "tasks, from classical machine learning, neural networks to statistical\n",
      "approaches like Bayes theorem, Hidden Markov Models,\n",
      "Time series, etc. This paper summarize the result of a system\n",
      "that combines above technologies in order to control electric\n",
      "appliances through predictions. These predictions are deducted\n",
      "by analyzing CCTV footages of the user using computer vision.\n",
      "Related works\n",
      "various approaches to analyze video footage in order to produce results like human tracking, path prediction, action recognition, action/behavior prediction, etc. as well as used existing data to make behavior predictions as well. There are many inbuilt libraries that are widely used in these researches such as Alpha pose, Open pose, Vent that produce very good results. It can be noticed that\n",
      "most methods used to detect involves some sort of machine learning or deep learning algorithms. These models, therefore, have to be trained with a reasonable amount of data in order to get good results. Therefore, it can be observed that many propose using already trained algorithms unless the paper is about improving or proposing new algorithms itself. Another observable factor is that many approaches use various other techniques prior to the use of a machine learning or deep learning algorithm in the end. There are instances where saliency maps are used to enhance the prediction of path detection algorithms, use of separate feature extraction algorithms, etc. On the other hand, prediction is the most difficult part out of the two aspects mentioned above. Prediction algorithms are very sensitive to variation in tiny details and produce considerable deviations. Even the position of camera placement\n",
      "has a drastic impact on the final result in prediction scenarios. For prediction approaches it can observe that researchers have successfully attempted techniques like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN)all the way to algorithms like Markov Chains, Hidden Markov\n",
      "Models (HMM), Hierarchical Representation, Time Series Analysis.\n",
      "Methodology\n",
      "As mentioned in the introduction, the complete system consists of three separate components that can be run on three separate PCs if required. These components are Human Identification, Behavior Extraction, and Behavior Prediction. Within these subsystems, there are four software components as face recognition, human detection and tracking, action recognition, and behavior prediction.\n",
      "A. Face recognition\n",
      "Different methods of image processing and machine learning techniques have been used in this component. More weight was taken on improving the accuracy and the execution time. Initially, the python face-recognition package was used which has been implemented on top of dib, which is a C++\n",
      "toolkit containing machine learning algorithms. But it has low accuracy and less performance. In order to obtain the desired outcome, the desired outcome python package is used to perform face detection using MTCNN and face identification using an Inception Resnet model. It is pre-trained on the\n",
      "VGGFace2 dataset. More advanced implementation details can be found on the GitHub Repository - GitHub the whole process is separated into three parts which are face detection, getting face embeddings, and finally, identifying faces by measuring the distance between embeddings\n",
      "in a specific frame. Face identification can be easily applied to raw images by first detecting faces using MTCNN before calculating embedding or probabilities using a before calculating model. It gives huge performance improvement rather than sending the entire frame to the Resnet model for getting\n",
      "face embeddings.\n",
      "B. Human detection and tracking\n",
      "Here YOLO v3 is used to detect humans. YOLO v3 is\n",
      "selected for the detection due to its speed while giving fairly accurate results at the same time. Although it is possible to detect humans using and track them using a model possible to, that approach was discarded due to the overhead created when running such heavy models’ side by side. Therefore, the current implementation is, first detect and crop each person in the frame using the YOLO object classification model. And then send each cropped person image to the Reid model. Since this Reid model was implemented sunporch, proper Porch implementation of YOLO has to be\n",
      "used instead of TensorFlow implementation. Because when different implementations of TensorFlow adaptors run at the same time, the GPU memory can be crashed. Further details of that Porch YOLO implementation can be found on the GitHub Repository - PyTorch-YOLOv3. The Porch Reid model is based on the works by Zheng et al. There is a Reid model Baseline (PCB) that conducts uniform partition on the conv-layer for learning part-level features. It does not explicitly partition the images. PCB takes a whole image as the input and outputs a convolutional feature. Being classification net, the architecture of PCB is concise, with slight modifications on the backbone network. The training\n",
      "procedure is standard and requires no bells and whistles. It shows that the convolutional descriptor has a much higher discriminative ability than the commonly used fully-connected (FC) descriptor. In order to identify the same person from different perspectives, it is required to have a collection of all persons’ images that we are going to identify in our domain. That’s where the face identification section comes into place. Once a person has identified from his face through the entrance camera, that person’s full-body image is saved in the human database under the current date folder. This is done because the same person can wear different clothes on different days. Then periodically generates features of every person in the current day folder and saves it as a single matrix file. Now in the human tracking part, first, the feature matrix file is loaded from the folder corresponding to the current day. Then humans in the current frame are detected using YOLO and features are extracted from the Reid model. These features are compared with each individual feature within the file collection and find the person tag. This implementation is somewhat similar to the approach we used in face identification.\n",
      "C. Action Recognition\n",
      "To identify actions performed by each individual person of the frame, first, the pose or the skeleton of the person has tube estimated. To do that, Porch implementation of opposes used. It produces 18 joint points of the person. Further implementation details can be found in the GitHub Repository- GitHub. Once the joints points are obtained then itis sent to an action classifier to determine the action. A window of five frames is used to extract features of body velocity, normalized joint positions, and joint velocities. Then mean filtering the prediction scores between 2 frames. Get a label of the person if the score is larger than a certain threshold. Here, a pre-trained action classifier provided by the GitHub Repository - Realtime-Action-Recognition is used to obtain the action identification.\n",
      "Behavior Data Extraction Interface\n",
      "D. Behavior prediction\n",
      "There are two Machine learning algorithms used in the prediction model. One Algorithm is used to get the next location while the other algorithm is used to determine the state of the electric bulbs. Due to the constraints in the timeframe to create a totally new database from scratch, a mock database has to be created for this. The Final data-set needs tube of the structure in Table I. The public data-set we selected to create the mock data set has the structure in Table II. This dataset consists of readings taken from motion sensors, pressure sensors that were taken in fixed time intervals. This raw data is then used to predict the movement of the owner inside the house. After processing the data-set based on multiple assumptions, a mock data-set is created that has the required data structure as in Table I.\n",
      "processed gain before feeding into the classifier. First of all, multiple sets of sequences of locations are made using the following inferences. To predict the state of the electric appliance, a cat Boost Classifier is used. And the above sequences, along with the result from HMM is used to make the prediction on the state of the device.\n",
      "Experiment Setup and Implementation\n",
      "Camera distortion removal\n",
      "Camera distortion removal is carried out by calculating the camera matrix that is\n",
      "described in the chapter 3. Implementation of this procedure to find the camera matrix\n",
      "is carried out as following.\n",
      "In the process of calibration, we calculate the camera parameters by a set of know 3D\n",
      "points (Xu, Xu) and their corresponding pixel location (u, v) in the image.\n",
      "For the 3D points, checkerboard pattern with known dimensions at many different\n",
      "orientations are photographed using the IP camera. Here a checkerboard pattern is used\n",
      "because Checkerboard patterns are distinct and easy to detect in an image. Not only\n",
      "that, the corners of squares on the checkerboard are ideal for localizing them because\n",
      "they have sharp gradients in two directions. In addition, these corners are also related by\n",
      "the fact that they are at the intersection of checkerboard lines. All these facts are used to\n",
      "robustly locate the corners of the squares in a checkerboard pattern\n",
      "Face Identification\n",
      "Different methods of image processing and machine learning techniques are used in this\n",
      "section. More weight is taken on improving the accuracy and the execution time. Initially\n",
      "we used face recognition python package which is implemented on top of dib that is\n",
      "a C++ toolkit containing machine learning algorithms. But it has low accuracy and\n",
      "less performance. In order to obtain our desired outcome, the dib python\n",
      "package is used to perform face detection using MTCNN and face identification using\n",
      "an Inception Resnet model. It is pre-trained on VGGFace2 dataset. More advanced\n",
      "implementation details can be found on the GitHub Repository - GitHub.\n",
      "Human detection and tracking\n",
      "In this section we want to give the same tag number to each individual person anytime\n",
      "he travels through the field of view of the CCTV camera. To do that our early plan\n",
      "was to get a bounding box using YOLO and track the person using Deep Sort and If a\n",
      "person’s track was broken then we find his previous track number using the above Reid\n",
      "model. But when looking at the performance of this Reid model we decided to get rid of\n",
      "Deep sort and use Reid to identify each person exactly in each frame.\n",
      "Therefore, the current implementation is, first detect and crop each person in the\n",
      "frame using YOLO object classification model. And then send each cropped person\n",
      "image to Reid. Since this Reid was implemented using porch, we had to use a proper\n",
      "porch implementation of YOLO instead of TensorFlow. Because when both run at the\n",
      "4.1 Design & Implementation of Prototype 30\n",
      "same time, the GPU memory can be crashed. Further details of that porch YOLO\n",
      "implementation can be found on the GitHub Repository - PyTorch-YOLOv3.\n",
      "Prediction Model\n",
      "There are two Machine learning algorithms used in the prediction model. One Algorithm\n",
      "is used to get the next location while the other algorithm is used to determine the state\n",
      "of the electric bulbs. Due to the constraints in the time frame to create a totally new\n",
      "database from scratch, a mock database has to be created for this. The Final data-set\n",
      "needs to be of the structure in table x. The public data-set we selected to create the\n",
      "mock data set has the structure in table y. This data-set consists of readings taken from\n",
      "motion sensors, pressure sensors that were taken in fixed time intervals. This raw data is\n",
      "then used to predict the movement of the owner inside the house.\n",
      "A sequence of locations would start after one trigger point to the start of another\n",
      "trigger point.\n",
      "• A set of sequences will always belong to the same day.\n",
      "• A trigger point will be described as following\n",
      "– An instance where the state of an electric appliance changes.\n",
      "– An instance where the person’s location changes to the Bed.\n",
      "These sequences are then used to train the HMM (Hidden Markov Model). The\n",
      "HMM used for this model is imported from the ‘homeland’ python package\n",
      "Overalll Design Diagram\n",
      "Results and analysis\n",
      "results obtained through the prediction model. Furthermore, this section presents some comparisons between few other models with the main models well. The main model that is used to predict the next location of an individual is a Hidden Markov Model (HMM) that has 3 hidden internal states. This prediction is then used to predict if an electric appliance should be turned on or not. When considering the results of the HMM, three types of HMMs were compared in the beginning\n",
      "Furthermore, the same data-set was tested with few other models as well. A random\n",
      "forest classifier, A basic CNN (Convolutional Neural Network), and an LSTM (Long Short-\n",
      "Term Memory) model were tested and the best performance of each model is presented\n",
      "in the following table in this comparison, the data from a single person over\n",
      "the course of six months is being used.\n",
      "In order to obtain the optimum results for each of the models, various steps had to be\n",
      "taken. It included changing the number of features that are used as input, normalization\n",
      "of the data, and fine-tuning the parameters such as the batch size and a number of\n",
      "iterations. However, a detailed explanation is excluded as the change in their performance\n",
      "with respect to varying the parameters was very insignificant.\n",
      "Location Prediction Accuracy\n",
      "After the next location is predicted, then a Cat Boost classifier is used to determine\n",
      "which electric appliances should be turned on? The model was trained to predict the\n",
      "electric bulbs of the Kitchen, Bathroom, and Television. The accuracy of the Cat Boost\n",
      "classification is as follows\n",
      "Table\n",
      "Appliance Prediction Accuracy\n",
      "Conclusion\n",
      "The main result for the lack of accuracy is due to the mock data set that was created to train the model. The original dataset was consisting of random sensor data that was taken in fixed time intervals. This raw dataset was then modified to create sequences of movements that would end up specific tasks such as sleeping in the bed, turning lights on/off, etc. However, it seems that the resultant sequences have deviated significantly from a natural routine of a human. This has resulted in a low accuracy even when an HMM is used to predict the next location. Also, it can be observed that the accuracy of the HMM\n",
      "keeps increasing when the number of hidden states in the Multinomial HMM kept increasing. But the complexity of the transformation matrix increases exponentially when the hidden states are increased. After 20 hidden states, the time to fit the model for a system with 30 hidden states takes a duration\n",
      "recorded in hours, which is a huge drawback to a real-time system that needs to be trained periodically. Therefore, the model was selected when it showed the highest accuracy of53% under 19 hidden states. The reason for obtaining low accuracy even when an Stims used is because of the nature of the dataset. This resultant dataset lacks fixed time steps between adjacent data. And lots of such redundant data was removed during data preprocessing. However, it can be assumed that an LSTM would yield much better results if the data can be recorded in fixed intervals. Itis cleared that after the data pre-processing, the problem has deviated from the context of a time series analysis. The aim of this project was to practically attempt the automation of control of basic electric appliances through the data obtained by processing CCTV footage data. Even Though the primary focus was to develop a model with the capability to successfully do the predictions, it became clear that the system to extract the data from video footage plays an important role as well. Therefore, the main focus for this project during this time-frame was to develop a robust system to extract the required data from a CCTV camera network in real-time. Finally, for future works, we would like to summarize what we have discussed above. This project clearly proves the possibility to automate household electric appliances just by observing human behavior. However, in order to implement system at the domestic level, all the existing components\n",
      "have to be further fine-tuned. And in order to achieve that goal, each component has to be optimized separately. We like to state that this project can be used as the foundation for such an attempt so that the components of this system can be separated into parts, developed, and then combined together for a better, much more accurate system in the future. And all the models used here can be trained with custom datasets as well. Therefore, the fastest way to improve the performance would be to train each component with custom datasets that are specifically designed for this system.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting nearIR spectroscopy https://cepdnaclk.github.io/e15-4yp-nearIR-spectroscopy\n",
      "\n",
      "\n",
      "NearIR Spectroscopy\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Near-IR Spectroscopy\n",
      "Team\n",
      "E/15/383, Keshara Weerasinghe, email\n",
      "E/15/349, Shamal Tennakoon, email\n",
      "E/15/188, Nithya Kularatne, email\n",
      "Supervisors\n",
      "Dr. Isuru Nawinne, email\n",
      "Prof. Roshan Ragel, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion\n",
      "Publications\n",
      "Links\n",
      "Abstract\n",
      "Near-Infrared spectroscopy is used for better vein visualization to make the venipuncture process more efficient. While there exist a few models which use the said mechanism, these models are costly, have accuracy issues, and are limited only to certain types of skin tones. Some of the available devices use image-guided venipuncture technique and the others use projection.\n",
      "We propose a low-cost mechanism of obtaining near-infrared spectroscopy by using the image-guided technique. We decided on using this technique after assessing both the available techniques. The low-cost is achieved by optimizing the image processing algorithms and adjusting the illumination method. We have tested and optimized the algorithms accordingly.\n",
      "We use near-infrared LEDs as the source of illumination, and a CMOS camera for image acquisition. Images are processed using OpenCV, and Histogram equalization and CLAHE algorithms are used in preprocessing. Initially, we processed the still images and later on developed the model to process the live video stream and display the processed video footage that visualizes the veins in real-time. We display the vein map on a 7 inch IPS LCD screen.\n",
      "We have tested the prototype using different combinations of light sources with different intensities and have analyzed the results. We have also analyzed how the results vary based on body fat. In order to quantitatively analyze, we have obtained a count of the number of visible veins and depicted the comparison in a graph. We have concluded that a higher intensity does not always increase the visibility of veins. Our plan is to conduct a clinical trial and test the device on human subjects and get the feedback from both the patients and phlebotomists and improve the model so that those final users are satisfied.\n",
      "Methodology\n",
      "3.1 Conceptual design\n",
      "Our task is to design and develop a device capable of detecting veins belonging to a particular region and display them on a portable screen accurately. The entire process – detection and display occur in real-time. The overall procedure can be divided into a few basic sub-components.\n",
      "3.1.1 Identifying the optimum wave length for lighting and obtain the appropriate light sources\n",
      "We obtained a variety of different sources of the near IR region. Here, we determined parameters such as the optimum wavelength, intensity,\n",
      "and lighting conditions, thereby the environment where image capturing should occur and the placement of the object. This step is a prerequisite for image capturing.\n",
      "3.1.2 Image capturing\n",
      "Once the light sources were selected, we proceeded with the capturing of images. For this purpose, we use a modified CMOS camera and, with the help of the light source, illuminate the object of interest and capture it.\n",
      "Later on, we progress to capturing a live stream instead of a still image.\n",
      "3.1.3 Preprocessing of the images\n",
      "Once an image is acquired, preprocessing steps are applied. These steps utilize image processing techniques to enhance the region of interest in a captured image (for example, the vein pattern in hand).\n",
      "The main objective is to create a visible contrast between the Region of Interest and its surroundings. The same preprocessing procedures are implemented for video capturing as well.\n",
      "3.1.4 Applying a formulated algorithm to clearly visualize and extract the vein patterns\n",
      "After preprocessing, we focus on extracting the region of interest from the image. Here, we isolate only the vein pattern from the body part captured in the image and that will be used as the image that is displayed on the screen. This task is a bit complex as we need to develop an algorithm that is capable of performing this task both efficiently and accurately. The algorithm contains several fundamental steps that are discussed under the methodological approach and extensively under the Implementation section.\n",
      "3.1.5 Designing a interface to display the live stream obtained from the camera\n",
      "A user interface is created in order to display the live video stream captured from the image sensor. It is capable of showing the video footage that has gone through image processing to clearly portray the veins real time. More details regarding this is stated under the implementation segment.\n",
      "3.2 Methodological approach\n",
      "We were able to assemble pieces of hardware to form a fully functioning hardware setup which captures the image and feeds it to a microprocessor where all the image processing is handled, and is displayed on the screen in real-time. As a final step we planned to do a clinical trial and get the feedback from the actual final users.\n",
      "3.2.1 Hardware setup, modifications and assembly\n",
      "NIR light source – These light sources fall under 760 – 940 nm waveband and the emitted light is absorbed by deoxygenated hemoglobin that circulates within the peripheral veins.\n",
      "Attention is given to the arrangement of the NIR LEDs, the number of LEDs used, their positioning and distance. In our setup they are fixed in concentric circles with the camera\n",
      "located at the center of the circle. The wavelength of a NIR source can be precisely measured with the use of a spectrometer which we were able to build and calibrate.\n",
      "Image sensor – This part of the setup captures the image that is illuminated by the light source. The image sensor that we are using currently is a NOIR image sensor that has no IR filter attached to it. The sensor captures an image of the object that is illuminated by the NIR sources and the resulting image displays highlighted (mildly) vein patterns. A high-pass filter is used to cutoff the radiation below 750 nm.\n",
      "Microprocessor – This is where the processing of the acquired image takes place. A raspberry pi 3 is used, and all the hardware components are interfaced with it. The image processing is executed by the microprocessor and the result is sent to be streamed live that will be displayed on the screen.\n",
      "Image display – The Image that is acquired and processed, is displayed on a 7 inch IPS LCD panel so that the phlebotomist can be guided by showing the positions of the veins accurately.\n",
      "3.2.2 Image processing\n",
      "Image processing is performing operations on an image/set of images to get an enhanced image or to extract some useful information from it. Our objective is to use image processing techniques to identify the vein patterns of an image and its extraction. The Open CV python package along with some basic applications of machine learning (classification and clustering algorithms) are used for vein detection and extraction. The entire process comprises of 3 important phases.\n",
      "• Background removal : This is the initial phase. For our application, we need only the region of the hand (or some specific body part) where veins are located, and the rest can be considered as noise and therefore eliminated. More details on how this is implemented is discussed under implementation section.\n",
      "• Preprocessing : This is the initial phase where the raw image is enhanced to show the vein patterns clearly with comparison to the tissue. More details on how this is implemented is discussed under implementation section.\n",
      "• Algorithm Development and Optimization : This is the most crucial phase of the entire process. It involves developing an algorithm to distinguish and derive the vein pattern from the image with a good accuracy. The general functionality of the algorithm can be expressed by following elementary steps.\n",
      "Eliminate the background of the image and isolate only the region of interest\n",
      "Increase the contrast of the image with the use of histogram equalization and CLAHE algorithm\n",
      "Use morphological transformations on the resulting image to tone down lines and edges.\n",
      "Smoothen and noise reduction using techniques such as median blur, bilateral filters.\n",
      "Segregate the pixels of the image into clusters based on the color of each pixel. Colors are assigned to each cluster to help identify and distinguish the components of the image from one another.\n",
      "Use Edge detection to separate the vein patterns - canny edge detection, Laplacian gradients, Sobel combined.\n",
      "Use adaptive thresholding to get the processed image.\n",
      "Separate the vein from the processed image, color them, and overlay the pattern onto the original image to see a clear and contrasting vein pattern.\n",
      "3.3 Assumptions and constraints\n",
      "Some problems arose when trying to find/verify the wavelength of the IR sources with\n",
      "the spectrometer and we were not able buy a variety of sources with different wave\n",
      "lengths due to the prevailing situation of the country. Therefore, we assumed that the\n",
      "wavelength of the sources that we currently have are accurate.\n",
      "Since the NOIR image sensor has no IR filter, it acquires all bands of light instead\n",
      "of just IR which affects the contrast of the image that is due to undergo processing.\n",
      "Therefore, we use a high-pass filter so that only the radiation above 750 nm is allowed to\n",
      "pass through.\n",
      "When trying to remove the background of an image, the current implementation relies\n",
      "on the color of each pixel to identify possible edges from the changes in the hsv values\n",
      "(hue, saturation, value). This approach might result in part of the region of interest being\n",
      "removed along with the background. Also it is quite difficult to automate this process\n",
      "where the program implicitly detects the region of interest and detaches the remaining\n",
      "part.\n",
      "During the pre-processing stage of an image CLAHE contrasting algorithm is used to\n",
      "increase the contrast. This results in spots or color marks on the image which are not\n",
      "veins, to be enhanced as well. Therefore, we are trying to increase the contrast of only\n",
      "the vein pattern while the rest of the image remains as it is.\n",
      "Experimental Setup and Implementation\n",
      "This section is covered under three main parts: hardware design and implementation, Image processing, and interface design.\n",
      "Hardware design and implementation\n",
      "Near-Infrared Spectroscopy to identify veins and display on a screen.\n",
      "Veins contain oxygenated hemoglobin-rich blood that almost completely absorbs light at near-infrared wavelengths (750 nm–950 nm) up to several millimeters. Using this phenomenon, we can illuminate the skin using infrared-emitting light sources within the specified spectrum and capture the images using an infrared-sensitive image sensor. By further processing of such acquired images, we can extract the vein pattern. We also display the live stream obtained from the camera in order to guide the phlebotomist. He will be shown the detected vein map of the puncture site. He will also be guided by the live stream and will not lose the normal vision on the puncture site by this mechanism. This can resolve many issues faced by venipuncture.\n",
      "However, depending on the region, skin color, weight the effectiveness of the selected wavelength can vary. Therefore, our study is about coming up with the best wavelength combination and effective image processing algorithm to identify the vein map irrespective of the above conditions.\n",
      "Initially, we got 3 light sources emitting at 3 different wavelengths. Namely 750nm, 850nm, and 950nm. Controlling the intensity of these light sources is not a concern at this stage. To verify the light sources that they emit such wavelengths we needed an infrared light spectrometer.\n",
      "However, such a device was not available to us at that moment. So we planned to build a spectrometer to do our study.\n",
      "Optical spectrometer is an instrument used to measure properties of light over a specific portion of the electromagnetic spectrum, typically used in spectroscopic analysis to identify materials. The independent variable is usually the wavelength of the light or a unit directly proportional to the photon energy, such as reciprocal centimeters or electron volts, which has a reciprocal relationship to wavelength.\n",
      "A monochromatic light beam that is incident on a grating gives rise to a transmitted beam and various diffracted beams, at angles that depend on the ratio between the distance between the lines of the grating and the wavelength of the light. So, if the light beam is composed of multiple wavelengths, the decomposition of the beam into its components is obtained.\n",
      "The light with a longer wavelength is deflected to a larger angle with respect to the incident direction (angle of diffraction ) . For each wavelength more rows can be observed. The number of rows that are counted from the middle line, which is not skewed with respect to the incident beam and is taken as a reference , it is said “order” and is often denoted by the letter m.\n",
      "The goals of the build were as follows:\n",
      "item Having at least 5 nm spectral resolution.\n",
      "item Covering the entire visible spectral region and the near-infrared spectral region.\n",
      "item Low cost and convenience to calibrate.\n",
      "The initial prototype for the spectrometer was designed using CAD software with the required dimensions and built by using 3D printed parts and was designed using CAD software.\n",
      "Initial prototype for the spectrometer\n",
      "The modal overview is as follows.\n",
      "The key optical principle in a spectrometer is diffraction. The slit was constructed with thin sheets of aluminum with sharpened edges. This allows a very limited amount of light to the sensor as a large amount can overwhelm the sensor and lead to inaccurate readings. To collimate the light, a biconvex lens was kept at its focal length away from the slit. This will ensure the light will enter the diffraction grating in a parallel manner. The diffraction grating is really important in this setup. Initially, we were not able to get ahold of quality diffraction grating. So we carefully removed the diffraction material in the DVD disk and used it in our first attempt.\n",
      "However, our first attempt was not successful because the DVD did not serve well as a true diffraction grating inside the first prototype. Moreover, a collimating biconvex lens was not included in the first prototype.\n",
      "We were able to find high quality 1000 lines per mm grating from the Faculty of Science and rebuilt the spectrometer. Therefore, we redesigned the spectrometer with the true diffraction grating and a collimating lens fixed at its proper focal length. The second prototype proved to be much more accurate.\n",
      "To analyze the light, we used a Logitech C270 image sensor (Web Camera) with its inbuilt IR Filter removed (In order to let the IR light enter the sensor). The software was an open-source software and to calibrate we used a Mercury Lamp which emits specific peak wavelengths at 4 different points and used 2 points to calibrate. The two points used for calibration were Mercury 2: 436 nm and Mercury 3: 546 nm.\n",
      "After calibrating the spectrometer, we analyzed our two IR sources in a controlled environment to avoid unnecessary light entering the spectrometer. The first source used was had a wavelength of 950 nm. The analyzed result gave us a reading of 945 nm and it was satisfactory.\n",
      "The second source had a nominal wavelength of 850 nm and it was read as 840 nm. This was also acceptable since these light sources were not high-quality ones.\n",
      "Initial prototype to capture images\n",
      "The prototype was designed to be composed of the following components.\n",
      "Light source setup\n",
      "IR Sensitive Camera\n",
      "Single-Board computer\n",
      "We designed the prototype to be able to hold 3 light sources at a time where each light source can be turned on and off. The light sources were powered with a 12V power supply which provides 5Amps on load. The single-board computer is a Raspberry Pi Model 3. Raspberry Pi is running a Lightweight version of Raspberry Pi OS which is a Debian-based operating system for Raspberry Pi. OpenCV was compiled and setup on the computer, in order to handle the image processing part of the study. The IR sensitive camera is a product from the same manufacturers of the Raspberry Pi, named NoIR camera which uses a Sony IMX219 image sensor with no inbuilt IR Filters. This is a CMOS sensor. However, CCD works best with Infrared imaging, but, at this point, we could not get ahold of a CCD Sensor.\n",
      "The prototype is designed so as the height of the camera and light sources are manually adjustable so that we are able to adjust the focus and determine the best distance for proper illumination and capturing images. The camera comes with a fixed focal distance. However, it sits within the region we require.\n",
      "The light sources can be turned on either individually or as a combination during the image acquiring procedure. Following figure displays the actual prototype with 2 IR light sources namely 940 nm and 850 nm. The images were taken using an IR sensitive camera to see the observe the functionality of IR sources.\n",
      "https://user-images.githubusercontent.com/62101605/115156034-1441cc00-a0a0-11eb-9768-5ec665f267ee.png\n",
      "Second prototype to detect and display veins\n",
      "The second prototype consists of the following components.\n",
      "Light source setup\n",
      "IR Sensitive Camera\n",
      "Single-Board computer\n",
      "Display screen\n",
      "As the light source, we used 48 LEDs emitting at wavelength of 940nm. We arranged IR LEDs in a circular array. This illumination setup uses a total power of 18W. The intensity of the LEDs is controlled by Pulse Width Modulation (PWM).\n",
      "We use the same camera we used in the initial prototype with an IR sensitive image sensor - SONY IMX219. A high-pass filter is used so that the radiation above 750 nm is let to pass through and those below that are cut off.\n",
      "image processing is done on a single board computer raspberry pi 3b which has a Quad Core 1.2GHz Broadcom BCM2837 64bit CPU with a 1GB ram.\n",
      "We use a 7 inch IPS LCD panel with a resolution of 1024x600 for the display of veins. It is powered by a set of li-ion cells with a capacity of 37Wh.\n",
      "Following figures give few different views of the second prototype.\n",
      "Final prototype\n",
      "The final prototype was implemented with suggestions from the medical personnel and considering ease of use and accessibility. The image capturing module was separated from the previous inbuilt design to make it easier for accessing difficult and sensitive venipuncture locations.\n",
      "Following figure shows an overall view of the final prototype including the image capturing module and display module.\n",
      "The final prototype consists of the following components and an updated IR source with higher intensity.\n",
      "IR light source\n",
      "IR Sensitive Camera\n",
      "Optical High Pass filter\n",
      "Battery System\n",
      "Single-Board computer\n",
      "Display screen\n",
      "The IR source consists of 96 LEDs emitting infrared light at 850 nm with a total power of 18 Watts. If we compare it with the second prototype, it consists of 48 LEDs of 940 nm. After analyzing the intensity and determining the wavelength we decided to go with 96 LEDs of 850 nm.\n",
      "Thefinal prototype can be seen in the pictures below.\n",
      "Image processing\n",
      "Several image processing techniques are utilized to get the vein map as the final output, but they can be broadly categorized into 3 main parts as described in the methodology section. In this section, we will explore how each phase can be explored and implemented in a programming environment.\n",
      "Background removal\n",
      "This stage removes the background of a particular image and isolates only the region of interest. This is accomplished by considering the HSV (hue, saturation, value) values of the image and thereby create an upper and a lower matrix to form the image free without its background. The values of the two matrices are found by using a track bar that executes in the runtime.\n",
      "Original image with the track bar is shown below.\n",
      "Image after background elimination is as follows —\n",
      "Preprocessing\n",
      "The primary constituents that we consider as preprocessing for our application are contrasting / equalization and smoothening. The sequence in which these techniques are implemented is: contrasting first, then morphological transformation, followed by smoothening. Contrasting is implemented using two widely used techniques - Histogram equalization and CLAHE.\n",
      "Contrasting using Histogram equalization\n",
      "A histogram is a graphical representation of the intensity distribution of an image. In simple terms, it represents the number of pixels for each intensity value considered. Histogram Equalization is a computer image processing technique used to improve contrast in images. It accomplishes this by effectively spreading out the most frequent intensity values, i.e. stretching out the intensity range of the image. This method usually increases the global contrast of images when its user data is represented by close contrast values. This allows for areas of lower local contrast to gain a higher contrast. Following image shows the equalized image compared with the original image.\n",
      "We can observe that the vein pattern of the hand is enhanced in the second image. If\n",
      "we plot a histogram for each of the images the outputs would be as follows.\n",
      "Contrasting using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
      "CLAHE is an improvement on histogram equalization. It limits the contrast amplification to reduce amplified noise by distributing that part of the histogram that exceeds the clip limit equally across all histograms. In general, there are some features in the near-infrared superficial vein images such as high noise and low contrast. CLAHE comes in handy for a situation where the edges of veins in the image are blurred and the vascular lines are not obvious. We can use the CLAHE algorithm iteratively even though it is not ideal in every situation.\n",
      "We can see that the image on which CLAHE is done provides more contrast than the equalized image. The veins appear to be highlighted better. The problem is that the veins seem to be a little bit thicker than that in the original image. These are rectified in the latter stages of preprocessing when morphing and smoothening are done.\n",
      "Morphological transformation\n",
      "Under morphological transformation, we have only used “dilation” and “closing” so far. Additionally, there are few others namely, “closing”, “opening”, and “top-hat gradients”. Opening and closing were used to make the contrasted image from CLAHE appear closer to the original image in terms of the size of the veins.\n",
      "Since the CLAHE algorithm appears to thicken the veins, we need to narrow them down. The technique that is proved to be most useful in this case is “dilation”.\n",
      "The below images show the input (CLAHE image of the vein pattern) to the dilation method and output generated from it. Following figure depicts the comparison of the above approach and for ease of comparison, the same image is used.\n",
      "Smoothening\n",
      "This is the final stage of image preprocessing. As we saw previously the dilated CLAHE image still contains a small amount of noise and is slightly pixelated. We’ve tried out 3 types of blurring (smoothening) techniques – Gaussian Blur, Median Blur, and Bilateral Filtering.\n",
      "We saw that all the operations smoothen the image while maintaining the same level of detail. Also, we observed that bilateral filtering provides the most smoothened image. Therefore, we opted to go for bilateral filtering. Following figure depicts the comparison of these blurring techniques along with the dilated CLAHE image.\n",
      "We can see that all the operations smoothen the image while maintaining the same\n",
      "level of detail. Also, we see that bilateral filtering provides the most smoothened image.\n",
      "Therefore, we opted to go for bilateral filtering\n",
      "Algorithm Development\n",
      "This is the most complicated part of image processing that we have currently encountered. The entire algorithm can be summarized into 8 steps which were stated previously.\n",
      "The first 4 steps were discussed under background removal and preprocessing. The next involves a procedure called clustering. It is an Unsupervised Machine Learning technique which we can apply to find new patterns in our data. What’s interesting about this algorithm is that we can also use it for image processing tasks as well. In the same manner as with other types of data, we can find pixel patterns in our images that will allow us to process them in a faster and more efficient way. Though there are many clustering methods, we used K-means clustering which is quite straightforward and efficient. How this algorithm works is explained below.\n",
      "K-Means is a data clustering algorithm that tries to assign every data point in a data set to exactly one of K possible clusters which is defined according to the users requirement. The main idea here is that the algorithm tries to build the clusters in such way that two data points from the same cluster are as similar as possible, while two data points from two different clusters are as different as possible. The algorithm will iterate through the data set many times and we need to find a proper condition for it to stop.\n",
      "An important notion related to Kmeans is the term “centeroid”. The centroid of a cluster is the mean value of all the values present in that cluster. The algorithm operates in a way that it makes sure that the sum of squared distance between the data points in a cluster and the centroid of that cluster is minimum. The centroid of the cluster is the mean value of all the values in the cluster. To elaborate even further the algorithm can be broken down into few basic steps. They are as follows.\n",
      "Assign the K number of clusters (this can be found using the elbow method) \\item Shuffle the data and randomly assign each data point to one of the K clusters and assign initial random centroids.\n",
      "Calculate the squared sum between each data point and all centroids.\n",
      "Reassign each data point to the closest centroid based on the computation for step 3.\n",
      "Reassign the centroid by calculating the mean value for every cluster.\n",
      "Repeat steps 3, 4, 5 until we no longer have to change anything in the clusters.\n",
      "In our application we use K-means clustering to group the pixels in the image so that more pixels with similar colors are in the same cluster, while pixels with different colors are placed in different clusters. Ultimately since the veins belong to a particular color range, this enables us to separate the pixels that belong to veins as a collection from the rest of the image. We tested the K-means algorithm on the smoothened image using different number of clusters on different images to determine the optimum value. The results are shown below in the figure.\n",
      "We saw that when the number of clusters increase, the image more and more similar to the original image. Since we need to separate the veins from the rest, resorting to small number of clusters seems ideal but it must not be too small because if that is the case, it could end up eliminating part of the veins that are slightly less visible. For example, here we can see a clear distinction between the veins and the rest when the number of clusters = 2. But we see that part of the veins which have low intensity have disappeared since the program interpolates those pixels to the cluster which holds the light coloured pixels. The output when the number of clusters = 5 provides a good balance and seems to be the best result.\n",
      "In the sixth step, we perform edge detection on the clustered image to obtain the edges of the vein patterns in the segmented image. Open CV offers several edge detection methods such as laplacian gradient, Sobel combined, and Canny edge detection. Laplacian gradient method proved to be ineffective as it showed no visible edges of veins but only managed to show the edge along with the hand (outline of the hand). Sobel combined method was able to separate the veins but also showed a lot of unwanted detail in the process. Canny edge detection was satisfactory as well. But it wasn’t capable of showing all the edges of the visible vein pattern but was able to provide a portion of it. The following figure depicts the comparison between the smoothened image, Sobel combined, and Canny edge detection.\n",
      "The next step of the algorithms uses thresholding. In conventional binary thresholding, each pixel of the image is considered and based on a threshold value the color of the pixel is converted to either black or white. When considering the colors of the pixel, the RGB values are the key aspects. In a grayscale image, the RGB values are scaled down to one particular value, so the thresholding algorithm checks that value with the threshold and based on that decide which to color to assign. For example, if the threshold is 127, then every pixel that has the value below 127 is converted to black, and the rest become white.\n",
      "But this approach didn’t yield good results, and therefore we had to resort to a more refined method of thresholding named adaptive thresholding.\n",
      "Here instead of one global threshold value, the function splits the image into segments of equal size, and each segment assigns a threshold value depending on the pixel color values which belong to that particular segment. This provides much better results as shown in the figure below.\n",
      "The final step is the coloring process. The processed image shows the vein patterns in black whereas the surrounding features are shown in white. This makes it possible to color only the veins by changing the RGB values of the pixels that are colored in black. After the colored image has been obtained it is then overlayed on top of the original image to form the final output as shown below.\n",
      "This algorithm works on a satisfactory level, but for some captured images the results were not as good. Therefore, we are working on how to improve the algorithm, what changes we need to make, how to optimize in terms of computational speed, and to increase the overall accuracy for any type of image that includes vein patterns.\n",
      "Algorithm optimization using multi-threading\n",
      "Multiple threads are used for parallel processing of the frame. The raspberry pi has 4 cores, and so we created 3 separate threads which are executed in parallel. The parent thread captures a frame, and displays the final output in the user interface. The 3 threads process 3 individual frame segments allowing them to be processed simultaneously without any dependency. The parent process splits the captured frame into 3 segments and feeds them so that each thread has only 1 segment to process at a given instance. Then the parent thread waits for all 3 threads to return their respective frames which have undergone the processing steps specified by the algorithm. Once all the threads have returned, the parent process continues from where it had paused. The frames are joined together in their original order to compose the output frame which is displayed in the user interface. An important thing to note is that all of this (from capturing a frame, dissecting it to segments, processing each segment in each thread, returning them to main thread for display) takes place real time. With this approach the latency that was present earlier without threads, is substantially reduced even when there is a lot of movement.\n",
      "Interface design\n",
      "After designing the algorithm the next step is to actually create a user interface to display the processed output to the user on a real time basis. This is still in a development stage, but the process occurs according to two phases.\n",
      "Designing the interface to display still images.\n",
      "Enable to interface to display a processed live stream.\n",
      "Designing the interface to display still images\n",
      "Initially the GUI was designed to be able to show still images while providing few other features like rotation, zooming, transition from base image to processed image and then to the colored image, as well as full screen viewing.\n",
      "These features are shown in the figure below.\n",
      "The python tkinter package along with openCV is used to create the widgets and the overall functionality of the graphical user interface.\n",
      "Configuring the interface to display a processed live stream\n",
      "This is the most significant phase of the GUI. We were able to get a live stream up on the GUI and displaying the processed stream with the use of multi-threading. The latency issues which we faced previously were resolved and we are able to produce a processed live stream that is crisp and clear. The veins are displayed vividly and the contrast difference and the smoothness enables the user to identify the veins precisely.\n",
      "Results and Analysis\n",
      "Testing the light intensities\n",
      "As mentioned before we used 2 separate NIR LED arrays corresponding to two intensities(18W and 60W) as the light sources and obtained their outputs. The base images and the outputs gained\n",
      "from each light source are shown in the figures below.\n",
      "The output obtained from the 18 watts source is quite accurate at visualizing the veins even managing to show very thin subcutaneous veins. The contrast is high and the image is smooth as well. We’ve obtained a lot of images using this lighting source and most of them were able to display clearly visible vein patterns. When looking at the output of the 60 watts LED source we can observe the vein patterns up to some extent. But the very thin veins are barely visible. Also the image has a glare which is caused by the light reflecting from the tissue.\n",
      "This was the case for most of the images that we took. The output from the 18 watts LEDs gave the better results in terms of accuracy, contrast and clarity.\n",
      "If the subject has a lot of body fat then the light emitted from the 18 watts source may not be able to penetrate through the subcutaneous fat and reach the underlying veins. This may cause veins in some regions to not be visible in the captured image. We hoped that the 60 watts light source would provide sufficient penetration in order pass through the layer of fat within the Hypodermis and resolve this issue. But the results were not as we expected. Even though the intensity is high, it was not enough to penetrate the tissue and the fat probably due to a large portion of the light being deflected from the epidermis and dermis. Thus we observed that having a higher intensity does not guarantee better results. In fact between the 2 sources, the 18 watts light source proved to be the better one. For further analysis lets take a look at the histograms generated for the processed images corresponding to each intensity.\n",
      "The above figure shows the differences between the two outputs. The histogram of the low\n",
      "intensity output is uniformly distributed unlike the histogram of the high intensity output.\n",
      "There are spikes in histogram of the high intensity output for some gray scale values.\n",
      "This indicates the presence of color spots in certain regions. If we look at corresponding\n",
      "image, we can see patches of white in the hand and dark patches in the background. To\n",
      "compare the two intensities even further, we’ve taken set of images and took the count\n",
      "of the clearly visible veins for a set of images obtained using both intensities. The results\n",
      "are shown in the figure below.\n",
      "Testing the algorithm\n",
      "We tested several sample images that were captured by the prototype we built, with the algorithm that we developed and got their outputs.\n",
      "Shown below are sets of images pertaining to different regions of the hand. Each figure illustrates the outputs of each step in the algorithm starting from the raw base image to the final processed image.\n",
      "Looking at each set we can see that the final image highlights the veins which are not so clearly visible in the raw image. An issue that can be noted here is background elimination. For some images, the background is properly eliminated, but for some, the entire background is not eliminated. Also in the final image, we see some dark spots which are not veins. This is due to the contrasting effect and noise created by the CLAHE algorithm. Also, the algorithm falls short when detecting narrow veins but only gives a good depiction of the larger and more prominent veins.\n",
      "Histogram analysis is a good method of identifying how the colors of an image are distributed based on their RGB values. We want the distribution to have concentrated clusters rather than a even distribution which makes is difficult to differentiate between colors. The following figure shows the histograms throughout each processing stage of the base image.\n",
      "The most recent addition to the image processing algorithm is K-means clustering, which was discussed in length in the previous chapter. In this case, the number of peaks in the histogram indicates the number different clusters. Therefore, all of the pixels fall under one of the peaks which means all the pixels pertaining to veins fall under one peak/cluster.\n",
      "When the number of clusters = 2, we can assume from the histogram that the pixels that form veins fall under the lower cluster () whereas the rest fall into the upper cluster. While this is convenient it doesn’t give the best result as some of lightly colored veins end up in the upper cluster and so some of the veins will not be present in the final image. When the number of clusters are high (8, 10), the image becomes too detailed, with many contrasting colors and if we look closely at the histograms the peaks located quite close to one another. This creates the issue of multiple clusters having similar colors. This is not ideal as we need the cluster which contains pixels of the veins to be separated from the rest. The ideal situation is when one cluster (to which the veins belong) is further as possible from the rest and the number of clusters need to be moderate. Hence we came to the conclusion that the amount of clusters to use for a given image, is a number between 4 to 6.\n",
      "Performance testing after multi-threading\n",
      "As mentioned under implementation the addition of multiple threads to achieve parallel processing of a frame increases the performance of the algorithm significantly. To explain the improvement we’ve obtained the processing times of frames in both (single threaded and multi threaded) implementations.\n",
      "There is a clear difference between the processing times of the two methods. Based on these values, the mean processing time for a frame while using multiple threads is around 27ms (37FPS) having a clear margin over the mean time of the basic implementation which is around 130ms (8FPS). It is apparent that the multi-threaded application is almost 5 times faster that the basic one. This made a huge difference in the overall delivery of the output and enhanced the performance of the algorithm substantially. If the number of cores in the microprocessor had been larger, then the results would be even greater.\n",
      "Video demonstration can be seen below.\n",
      "Conclusion and Future Work\n",
      "We have created a prototype for image capturing and perform preprocessing on the image.We have constructed an algorithm to obtain an output that shows the vein patterns and have optimized the algorithm to provide a clearer and more accurate depiction of the vein map. Considering the hardware implementation, we have developed a prototype by embedding the camera module, near-infrared light sources, single-board computer, and the display screen. The device is ready for clinical testing that unfortunately could not be completed due to the Ethical clearance process that took longer than expected given the pandemic situation of the country.\n",
      "In the future, when the external parties permit, we plan to carry out the planned clinical testing and evaluation and thereby further improve the algorithms and fine-tune the device according to the feedback we get.\n",
      "We also will extend the research further, to identify Peripheral Vascular Diseases (PVD) based on the data collected through clinical trials, in the future.\n",
      "Publications\n",
      "Semester 7 report\n",
      "Semester 7 slides\n",
      "Semester 8 report\n",
      "Semester 8 slides\n",
      "Author 1, Author 2 and Author 3 “Research paper title” (2021). PDF.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Demo Video\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting online proctoring system https://cepdnaclk.github.io/e15-4yp-online-proctoring-system\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Visit Department Site\n",
      "Online Exam Proctoring System\n",
      "Team\n",
      "E/15/138, Mohamed Irfan, irfanmm96@gmail.com\n",
      "E/15/021, Mohamed Aslam, e15021@ce.pdn.ac.lk\n",
      "Supervisors\n",
      "Dr. Ziyan Maraikar, ziyanm@eng.pdn.ac.lk\n",
      "Dr. Upul Jayasinghe, upuljm@eng.pdn.ac.lk\n",
      "Mr. Mohamed Fawzan, fawzanm@gmail.com\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting sports action recognition https://cepdnaclk.github.io/e15-4yp-sports-action-recognition\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Objectively Measure Player Performanceon Olympic\n",
      "Weightlifting\n",
      "Team\n",
      "E/15/154, Chamin Jayasooriya, email\n",
      "E/15/179, Anandi Karunaratne, email\n",
      "Supervisors\n",
      "Dr. Rajitha Navarathna, email\n",
      "Mr. Sampath Deegalla, email\n",
      "Table of content\n",
      "Abstract\n",
      "Related works\n",
      "Methodology\n",
      "Experiment Setup and Implementation\n",
      "Results and Analysis\n",
      "Conclusion and Future Work\n",
      "Links\n",
      "Abstract\n",
      "This project introduces a novel method to measure the quality of the actions performed in Olympic weightlifting using human action recognition in videos. Human action recognition is a well-studied problem in computer vision and on the other hand action quality assessment is researched and experimented comparatively low. This is due to the lack of datasets that can be used to assess the quality of actions. In this research, we introduce a method to assess player techniques in weightlifting by using skeleton-based human action recognition. Furthermore, we introduce a new video dataset for action recognition in weightlifting which is annotated to frame level. We intended to develop a viable automated scoring system through action recognition that would be beneficial in the sports industry.\n",
      "Related works\n",
      "Action Quality Analysis in Weightlifting\n",
      "A very limited amount of work has been conducted on action quality analysis in weightlifting. Chatzitofis et al. (2013) has analyzed the biomechanics of human body and how it is applied to weightlifting. They have also extracted the data that is important to a weightlifting coach. These data includes the position, the angle, and the velocity of the weightlifting bar, the initial angle of the athlete’s knee, and the start time and the end time of the lift. For this, they have used a kinetic sensor to get depth data.\n",
      "Skeleton based Action Classification\n",
      "Classifying Actions with a Skeleton based Approach has captured the attention excessively in the past years.\n",
      "Li et al. (2019) introduces a new module named, A-link inference module which is an encoder-decoder structure. It can capture richer dependencies that current models might miss since they only capture local physical dependencies among joints. A-link inference model captures two main dependencies. 1. Action links, which are action-specific dependencies; and 2. Structural links. Combining these two, actional-structural graph convolution networks (AS-GCN) is proposed.\n",
      "Skeleton based action recognition has difficulties such as limited expressive power and generalization. Yan et al. (2018) addresses this problem by introducing a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN). This model is able to learn spatio-temporal patterns automatically and capable of generalization. This is validated on Kinetics and NTU-RGBD datasets.\n",
      "Methodology\n",
      "Dataset\n",
      "Since there are no existing weightlifting datasets, we have created our own dataset consisting of weightlifting video clips.\n",
      "For our dataset, videos were collected from the official Olympic YouTube channel. The selected videos include both men and women categories and both snatch and clean and jerk categories. The long video footages were trimmed down so that they only contain weightlifting events where only the player and the barbell is seen. Then we annotated the actions in a frequency of 5 fps.\n",
      "Action Classes\n",
      "As shown in Table I we can identify 11 action classes in weightlifting. There are 1570 of total video frames in the dataset containing all the actions as described in the Table II.\n",
      "Testing Data\n",
      "As for the testing purposes, we have used videos specifically with the medalists of different weight categories in 2016 Olympics as shown in the Table III.\n",
      "By using these data we have assumed that their techniques are more accurate. Hence we have used them for deriving optimal values for initial knee angle, bar angle\n",
      "which are used for our scoring model.\n",
      "Approach\n",
      "As we discussed earlier, we used the skeleton based approach to recognize the actions.\n",
      "The following figure shows the basic workflow of extracting and identifying actions done by humans in a video. For this, we have identified a suitable framework which estimates the poses of humans and represent using a skeleton showing joints of the human body. This framework is Openpose (references: Cao et al. (2019), Simon et al. (2017), Cao et al. (2019), Wei et al. (2016), Feiyu Chen). It was initially developed by researchers at Carnegie Mellon University. We have trained this model with our dataset in order to identify and classify actions.\n",
      "Fig.1 - Action Recognition Workflow\n",
      "After pose estimation is done, the features are extracted from the skeleton.\n",
      "We have identified that the position, the angle, and the velocity of the weightlifting bar, the initial angle of the athlete’s knee as well as the start time and the end time of the attempt are important for a weightlifting coach (references: Weightlifting Equipment and History - Olympic Sport History, Chatzitofis et al. (2013)). We have used the coordinates of the joints in the 2D image plane that are obtained from our model to calculate those information. The joints that are identifiable are shown in the below figure.\n",
      "Fig.2 - Joints identified using Openpose\n",
      "In simple terms, a weightlifting attempt is considered as a successful lift if a lifter can lift the bar above him and keep it balanced for a time. Therefore tracking the position, angle, and the velocity is important for a coach.\n",
      "Usually a player balances the bar symmetrically when he is lifting. Therefore we can assume that the player’s hands are at the same length from the center of the bar. Therefore, weightlifting bar position is calculated using joint 4 and joint 7.\n",
      "The angle between the bar and horizontal axis is important, because if the angle is too wide, it is harder for the player to balance the bar and it is likely the attempt will be unsuccessful. For this calculation we will be using the same joints we used for position calculation; 4 and 7.\n",
      "Velocity of the bar is another important factor for a coach. When a player lifts a bar, there is work (W) being done. (W) equals to F.d, where F is force given, and d is the distance moved. And as we know power (P) equals W/t where t is the time. Which gives us the following,\n",
      "where v is the velocity. While lifting, a player must give power as needed, not more or less. For velocity calculation, we will consider the bar positions of the current frame and the previous frame.\n",
      "The knee angle in the initial set up position is crucially important in weightlifting, because the success of the lift will depend on that. To calculate the initial knee angle, we will be using the coordinates of 11, 12, and 13 joints.\n",
      "Here, a is the vector passing through joint 11 and 12, and b is the vector passing though joint 12 and 13.\n",
      "We propose a scoring model where we can get a proper understanding of the accuracy of the techniques of the player. We assigned weights for the features we have extracted based on their importance and evaluate the accuracy of their action.\n",
      "For this, we followed the pseudo code described below in Algorithm.\n",
      "And the expected structure of the result is as follows.\n",
      "Overall score for the action\n",
      "Individual scores relevant to sub actions\n",
      "Details of the score calculation (which and how features affected to score\n",
      "Implementation\n",
      "We set up the environment on a high-performance server that has an Intel Xeon E5-1630 v3 CPU and an NVIDIA GK180GL [Tesla K40c] GPU\n",
      "to train the action recognition model.\n",
      "As we discussed earlier, for skeleton detection, Openpose framework was used, which is the Tensorflow variant of the initial Openpose framework. As mentioned, the skeleton detection library is built upon Tensorflow. For drawing skeletons and bounding boxes around human figures, OpenCV and Matplotlib libraries were used.\n",
      "The Openpose framework provides two models for skeleton detection; CMU and Mobilenet-thin. CMU model detects skeletons more accurately but at a slower speed when it is compared to Mobilenet-thin. For our experiments, we used the CMU model. The image (pre-processed video frames) resolution is 656x368 pixels. (Higher the input images’ resolution, higher the accuracy of the skeleton detection.)\n",
      "Then the features were extracted and pre-processed, and then the classification was done by MLPClassifier from Scikit-learn which is a neural network model. After this step, we have recognized actions and skeleton data of the player for each frame. Using these two information, we calculated angles and other required features for the technique evaluation algorithm.\n",
      "With those required parameters calculated, the action quality assessment can be done.\n",
      "Experiment Setup and Implementation\n",
      "For our final experiments and demonstrations, we used Openpose framework. In the first setup, Openpose is used to get the positions of the joints. Each person is tracked by calculating the Euclidean distance between the joints of two skeletons and matching two skeletons. Missing joints are filled using the joints’ relative position in the previous frame. Noise was added to the joint positions to try to augment data. A window size of 0.5s (5 frames) was used to extract features. The features of Body velocity, Normalized joint positions, and joint velocities were extracted. Then PCA was applied to reduce the feature dimension to 80. After that, it was classified by DNN of 3 layers of 50x50x50.\n",
      "After that, recognized actions for each frame is used to evaluate player techniques. Python, OpenCV and other helper libraries can be used to achieve this. Once the action for each frame of the video is identified, we evaluated techniques according to those identified actions. For example, if it is the initial position then we do not want to evaluate the player’s arms angles. In that position, we would rather need to know about knee angles. Therefore, we programmed our scoring algorithm in such a way where player’s technique is evaluated relevant to the current action. As mentioned in the Algorithm, we estimated a score for the quality of the action. If the player performs actions accurately in pre-defined techniquewise, then the player will get a higher score. At the end of the video, the player will get an overall score which is the weighted average of the scores earned for each sub-action.\n",
      "Data manipulation and Testing\n",
      "The video datasets were manipulated mainly by FFMPEG tool and OpenCV framework. For the training purposes, videos were collected from YouTube and some of the data were already collected by previous authors. The video data is preprocessed by trimming the videos (removing unnecessary parts of the video that are irrelevant to the target action) by using FFMPEG.\n",
      "Then the trimmed videos were converted into sequences of images using OpenCV and other python libraries such as NumPy, itertools, simplejson, etc. After that, for skeleton detection, Openpose framework was used, which is the Tensorflow variant of the initial Openpose framework. As mentioned, the skeleton detection library is built upon Tensorflow. For drawing skeletons and bounding boxes around human figures, OpenCV and Matplotlib libraries were used.\n",
      "The Openpose framework provides two models for skeleton detection; CMU and Mobilenet-thin. CMU model detects skeletons more accurately but at a slower speed when it is compared to Mobilenet-thin. For our experiments, we used the CMU model. The image (preprocessed video frames) resolution is 656x368 pixels. (Higher the input images’ resolution, higher the accuracy of the skeleton detection.)\n",
      "Then the features were extracted using Numpy and then the classification was done by MLPClassifier from Scikit-learn which is a neural network model. Then again the sequence of images was converted into the output video with labeled actions by OpenCV, Numpy, and other Python libraries.\n",
      "Pitfalls and workarounds\n",
      "Since we have been working on a CLI environment, getting video inputs and outputs to the local GUI cannot be done directly. Because of this, we could not test these frameworks using a webcam for live-action recognition. To overcome this issue, we have used Google cloud APIs (Drive API and YouTube Data API) and SSH, SCP protocols to manipulate data on the server.\n",
      "Further, the OpenPose framework does not perform well with the videos that include truncated and occluded human figures, rapid variations of camera angles, scale of the viewpoint and colour spectrum, brightness etc. Therefore to avoid erroneous results that would happen due to such reasons, we created our Weightlifting Dataset in which the video data does not have such properties.\n",
      "Since we do not estimate the angles of body joints in 3-dimensional space, the calculated angles may vary from the real values. But what we have done is using those angles to estimate a score which is a reasonable interpretation of the estimated angles. People can use that scores to evaluate players rather than raw angle values. To calculate the scores, we followed an experimental approach where we had to change parameters of the scoring algorithm many times to obtain an acceptable values for the scores.\n",
      "Results and Analysis\n",
      "Action Recognition Results\n",
      "Results of the action recognition model are shown in below Figure 3 and Table IV. We can see that the accuracy on test data is over 93\\%. This is due to the video dataset we chose for this task, which contains favourable properties for our action recognition model. By choosing training data in which human body occlusion, truncation are very minimum and other properties such as uniform scale, uniform brightness/contrast distribution, the human skeleton detection accuracy must have been improved. The dataset contains single person video frames and the background clutter is almost none.\n",
      "Fig.3 - Confusion Matrix for the Results of the Action Recognition Model\n",
      "Table IV - ACCURACY REPORT OF THE ACTION RECOGNITION MODEL\n",
      "Action Quality Assessment Results\n",
      "According to the algorithm we described in the above algorithm we assessed the whole lift and each sub-action. To get optimal values for comparison, we considered a video set of Olympic champions of the 2016 Olympics as the baseline data as shown in Table VI. Table V\n",
      "includes the player names with respect to the video sample number. Results obtained from those videos are shown in Figure .\n",
      "Table V - Sample Video Number and Relevant Player\n",
      "Table VI - Optimal values for Scoring Algorithm\n",
      "Fig.4 - Distribution of Angles in Olympic Medalists’ Videos Which Were Used to Determine Optimal Values for Scoring Algorithm\n",
      "Scoring Algorithm\n",
      "Using the values in Table VI we updated our scoring algorithm, and we applied it to calculate the scores of our previous dataset.\n",
      "Fig.5 - Initial knee angle and Obtained score distribution\n",
      "Fig.6 - Bar angle and Obtained score distribution\n",
      "In Figures 5 and 6 we can see how the score decreases with the deviation from the optimal value.\n",
      "The comparison of the scores of Olympic medalists’ videos and our dataset is given in Figure 7 and Figure 8.\n",
      "Fig.7 - Leg, Arm, Knee angle, Bar angle, and Overall scores of Olympic medalists\n",
      "Fig.8 - Leg, Arm, Knee angle, Bar angle, and Overall scores of the dataset\n",
      "By analyzing the overall scores for the weightlifting videos, we can see that our scoring algorithm has assigned scores for players’ actions as we expected with defined optimal values and weights for each sub-action. One can always re-configure the scoring algorithm values to determine what is best for their own evaluation. Here we have attempted to demonstrate the capability of our proposed method to evaluate players based on their action quality.\n",
      "As we have already mentioned, for a coach the velocity of lifting the bar of each player is important. We have used a graphical way to show the coach how the bar moves vertically, with respect to the frames in the video footage. (Figure 9 and 10)\n",
      "Fig.9 - Bar movement - Snatch\n",
      "Fig.10 - Bar movement - Clean and Jerk\n",
      "Figure 11 shows the differences between the bar movements of the snatch lift and the clean and jerk lift.\n",
      "Figure 12 compares the bar movements of two different Olympic players. The idea here is for a coach to get a general idea about the player. Therefore we did not focus on converting the data into metric units. Sport-persons can compare the bar movement with other players or with their previous lifts to improve their lifts. Hence this can be used as an assistive tool for training.\n",
      "Fig.11 - Comparison of bar movement - Snatch and Clean and Jerk\n",
      "Fig.12 - Comparison of bar movement - Snatch Men 94 kg and Snatch women 75 kg\n",
      "Conclusion and Future Work\n",
      "We have introduced a way to analyze the quality of a weightlifting player performance using just a video footage as the input. For this purpose we have identified the actions performed, extracted the required features for the relevant actions, and evaluated the quality of the action using those features.\n",
      "We have used Openpose, which is a 2D pose estimation model using skeleton based approach as our model. The model was trained using a weightlifting dataset created by us.\n",
      "The parameters for automatic action quality assessment algorithm can be further fine-tuned by following an empirical approach by involving sportspeople.\n",
      "Our intention was to develop a solution that can be used by anyone with a digital camera. Hence, the calculated angles were not accurate for direct usage. Another approach to address this problem is to use a 3D pose estimation model or to simultaneously process two videos obtained from the front angle and side angle, but that would limit the usage from the regular users.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting ipb https://cepdnaclk.github.io/e14-4yp-ipb\n",
      "\n",
      "\n",
      "IPB\n",
      "Automation of Intelligence Preparation of the Battleﬁeld\n",
      "August 2019 – July 2020\n",
      "Final Year research project - Group\n",
      "Python\n",
      "Flask\n",
      "Algorithm Development\n",
      "JavaScript\n",
      "Web Application Development\n",
      "Download Project Report With Full Details\n",
      "Abstarct\n",
      "In military operations armed forces have to get a better idea of the area in\n",
      "which they have to operate including terrain features, threats and avenues of\n",
      "approach.\n",
      "So they gather intelligence on the location, enemy, weather, vegetation,\n",
      "infrastructure and many such factors before making decisions. Intelligence\n",
      "Preparation of the Battleﬁeld (IPB) is the name given for that process of\n",
      "analyzing the situation and making decisions based on predictions. Usually this\n",
      "process happen manually by ofﬁcers using hard copy maps and it have number of\n",
      "inconveniences. In this paper, we implement and present a set of algorithms,\n",
      "tools and approaches for automating terrain analysis and decision making in\n",
      "Intelligence Preparation of the Battleﬁeld process and compare their results\n",
      "with a manual analysis.\n",
      "Team\n",
      "Hishan Indrajith\n",
      "Sathyanga Tharana\n",
      "Jayamal Jayamaha\n",
      "Project Supervisors\n",
      "Dr. Isuru Nawinne - Department of Computer\n",
      "Engineering, University of Peradeniya\n",
      "Dr. Janaka Alawatugoda - Department of Computer\n",
      "Engineering, University of Peradeniya\n",
      "Introduction\n",
      "IPB is a process that starts in advance of operations and continues during\n",
      "operations planning and execution. It provides guidelines for the gathering,\n",
      "analysis, and organization of intelligence. The purpose of this intelligence is\n",
      "to inform a commander’s decision process during the preparation for, and\n",
      "execution of a mission. Therefore IPB is a Command and staff tool which allows\n",
      "systematic and continuous analysis of the enemy and the battleﬁeld environment.\n",
      "It presents the results of the process in a graphical format. It is an\n",
      "integrated method of analysing Enemy, Ground and Friendly Forces factors in the\n",
      "Estimate.\n",
      "Basically there are four steps in IPB process. They are,\n",
      "Deﬁne the battleﬁeld environment\n",
      "Describe the battleﬁeld’s effects\n",
      "Evaluate the threat\n",
      "Determine threat COAs\n",
      "The resulting product of IPB is identiﬁcation of various areas of the battleﬁeld\n",
      "that affect Courses of Action (COAs). The four distinctive courses\n",
      "of action are,\n",
      "engagement areas\n",
      "battle positions\n",
      "inﬁltration lanes\n",
      "avenue of approach\n",
      "Any force that has the control of the key terrain has the military advantage.\n",
      "Key terrain areas cannot be deﬁned by geographical features alone. The\n",
      "evaluation of terrain features must be fused with information about weather,\n",
      "enemy asset types, friendly and enemy range of ﬁre, enemy doctrine and type of\n",
      "operation.\n",
      "The problem with current process is that IPB is done manually by intelligence\n",
      "ofﬁcers using hard copy maps on which they anotate various signiﬁcant areas,\n",
      "such as key terrain or defensible terrain. This manual process suffers from a\n",
      "number of inefﬁciencies as described below.\n",
      "No variable zooming in and out to obtain desired level of\n",
      "detail\n",
      "Annotating the maps is time consuming.\n",
      "Notations on maps get cluttered with the risk of being\n",
      "misread.\n",
      "Information could be disregarded or not used effectively in\n",
      "the process of the IPB.\n",
      "What We Did\n",
      "The research was basically spllited in to two major sections such that each\n",
      "section contain three milestones. The two sections was,\n",
      "Visual Support for Automating the Intelligence Preparation\n",
      "for Battlefield (IPB) Process\n",
      "Implement Automation of Intelligence Preparation for\n",
      "Battlefield\n",
      "So the six milestones for the project was,\n",
      "Web-based platform to display overlays on a map.\n",
      "Infrastructure to efficiently store data for overlays.\n",
      "Integrating the data storing mechanism with graphical user\n",
      "interface.\n",
      "A grid based combined obstacle overlay by collecting the\n",
      "vector overlays to a grid\n",
      "Generating the potential mobility corridors in the\n",
      "terrain\n",
      "Risk evaluation of corridors to predict the avenues of\n",
      "approach and key areas.\n",
      "Web-based platform to display overlays on a map\n",
      "As the IPB need a visual tool that allows military staff to add battlefield data\n",
      "in to the system and also visualize them as overlays, we needed to firstly\n",
      "develop a web based platform to add overlays and visualize them. So we firstly\n",
      "researched about a framework that we can use to do the map based functions.\n",
      "Simply from front-end side the application should work like a GIS software.\n",
      "Following technologies were chosen by us to be used fro the web platform.\n",
      "Leafletjs – Leaflet is the\n",
      "leading open-source JavaScript library for mobile-friendly interactive maps.\n",
      "Open\n",
      "street Maps – OpenStreetMap is a free editable map of the whole world\n",
      "that is being built by volunteers largely from scratch and released with an\n",
      "open-content license.\n",
      "Infrastructure to efficiently store data for overlays\n",
      "We needed to find a data storing mechanism and also a data format to store\n",
      "the overlay data. As the data in overlay are spatial data with attributes,\n",
      "We researched about the available methods to store such data.\n",
      "So the available options to store those data were using a vector\n",
      "format or a raster format.\n",
      "So as our web application was JS based, we choose GeoJSON\n",
      "which is a format for encoding a variety of geographic data structures.\n",
      "To store and provide the required overlay information relevant to\n",
      "battlefields, there should be a back-end application. As our future\n",
      "algorithms and models are based on python, we used Python\n",
      "Flask as the web framework for our back-end and the we decided to use\n",
      "REST architecture to build the back-end web service.\n",
      "Following were the attributes we defined for our overlays\n",
      "Building\n",
      "No of occupants\n",
      "Status\n",
      "Material\n",
      "Building Type\n",
      "No of stories\n",
      "Vegetation\n",
      "Vegetation Type (grassland, shrubland, woodland, medium\n",
      "density forest, high denisty forest, unknown)\n",
      "Water\n",
      "Water body type (water, river, reservoir, dock,\n",
      "wetland, unknown)\n",
      "Mark known points of shallow or deep\n",
      "Roads\n",
      "Road type (tertiary, track, unclassified, secondary,\n",
      "trunk, primary, motorway_link, trunk_link, primary_link, road,\n",
      "secondary_link, tertiary_link, motorway)\n",
      "Elevation\n",
      "Elevation : float value\n",
      "Integrating the data storing mechanism with graphical user interface\n",
      "Finally we had to integrate the back-end we developed using the data storing\n",
      "mechanism and data retrieving mechanisms with the front-end developed with\n",
      "map overlays\n",
      "So in our first section of the project, we implemented the web application\n",
      "tool to perform following major tasks.\n",
      "Create and save multiple battlefields(maps).\n",
      "Automatically generate the buildings, water, roads,\n",
      "elevation, vegetation overlays when a new battlefield is created.\n",
      "View a battlefield on user interface graphically with a\n",
      "map (Satellite or Topographical)\n",
      "View the overlays generated for the battlefield\n",
      "graphically on the map separately.\n",
      "Add new buildings, water bodies, vegetation areas,\n",
      "roads on the battlefield using a drawing tool\n",
      "Add values for the defined attributes of the newly\n",
      "drawn shape.\n",
      "Edit values of attributes of automatically generated\n",
      "geographical features.\n",
      "Remove geographical features of overlays.\n",
      "Save changes to be able to access later.\n",
      "All the information are stored in the backend.\n",
      "Following images are few screenshots from the tool.\n",
      "Creating the battlefield\n",
      "Generated overlays added on the map\n",
      "Adding data to an geographic feature\n",
      "Save the data insertion\n",
      "The architecture implemented for the system was basically a 3-Tier\n",
      "Architecture. Presentation layer being our web tool using LeafletJS,\n",
      "Application layer being the python web application using Flask and use REST\n",
      "web services to communicate with Presentation layer.\n",
      "Data layer is the filesystem which stores GeoJSON files in a hierarchical\n",
      "structure.\n",
      "Following diagram is the system architectural diagram.\n",
      "The auto generation of overlays happen in IPB Service Layer, where the\n",
      "available geographical data for Sri Lanka stored in the server are processed\n",
      "in order to produce the overlays of the given boundaries.\n",
      "We have obtained relevant digital geographical data for Sri Lanka and\n",
      "pre-processed them to suit the overlays we are considering.\n",
      "The Elevation data for Sri Lanka have been obtained from highest-resolution\n",
      "topographic data generated from NASA's Shuttle Radar\n",
      "Topography Mission (SRTM). We generated the island wide 25m contour\n",
      "lines using that DEM data and that is used for creating elevation overlay.\n",
      "Also we stored the raster DEM file in server for some other functions\n",
      "including trafficability calculation.\n",
      "OpenStreetMap data for Sri Lanka were obtained from https://download.geofabrik.de/asia/sri-lanka.html and\n",
      "processed to obtain overlay data for Sri Lanka.\n",
      "OSM Land Use data was used to obtain vegetation overlay\n",
      "by filtering vegetation and mapping their properties to our defined\n",
      "attributes.\n",
      "OSM Building data was processed to get building overlay\n",
      "such that their properties mapped into our defined building\n",
      "attributes.\n",
      "OSM water data was coverted into water overlay\n",
      "OSM road data was converted in to road overlay.\n",
      "A grid based combined obstacle overlay by collecting the vector overlays to\n",
      "a grid\n",
      "As we have built the overlays using a vector format with properties, we\n",
      "needed to convert those data overlays to grids of their properties as grid\n",
      "based analysis is used for the processing. We started from the elevation\n",
      "raster file of Sri Lanka obtained from SRTM dataset. In our program to get\n",
      "the combined obstacle overlay first step was to get the elevation grid. So\n",
      "our program was added the functionality to clip the Sri Lanka elevation\n",
      "raster file to the size of the battlefield firstly.\n",
      "The NASA’s Space Shuttle Radar Topography Mission (SRTM) DEM data's\n",
      "resolution is about 30 meters. It has pixels (cells) of grid approximately\n",
      "30m containing elevation data. See the image below.\n",
      "We needed to map these elevation data to a grid of cells of size 10 times\n",
      "smaller than SRTM data resolution for better accuracy as 30m is not a good\n",
      "resolution for ﬁnding mobility. So elevation data graph was resampled using\n",
      "bi-linear interpolation in order to reduce the resolution of the overlay\n",
      "grid size to about 3 meters. The elevation data raster overlay after\n",
      "resampling is shown in below.\n",
      "So the other overlay grids was also to be built to the same shape of the\n",
      "elevation grid obtained, such that they can be put one on other.\n",
      "So next from the elevation grid, an additional grid of slope was derived.\n",
      "The slope grid is produced such that slope at grid cell (x,y) is assigned\n",
      "the mean of the slope between (x,y) and each of the surrounding grid cells.\n",
      "Following Figure shows the generated slope overlay for above elevation\n",
      "example.\n",
      "Rasterization techniques were used to get the rater images of the building,\n",
      "water, road and vegetation overlays preserving their properties and those\n",
      "raster images of the overlays were converted to a numpy array for our\n",
      "processing. Following images will show the original map, building grid,\n",
      "water grid, vegetation grid and road grid obtained using our program\n",
      "respectively.\n",
      "Our target in this milestone was to obtain combined obstacle overlay by\n",
      "combining all these overlays in a suitable way to achieve our goal. So we\n",
      "constructed an overlay called trafficability grid combinning all those\n",
      "overlays (elevation, slope, building, vegetation, water, roads)\n",
      "Trafficability grid is a grid witch has cells representing squares on land,\n",
      "where each grid cell represent the trafficability of the cell. In another\n",
      "way each cell give a value defining how much it is difficult to troop\n",
      "maneuver withing that cell.\n",
      "We considered the electric flow model as a foundation of our algorithm to\n",
      "get trafficability grid. In electric current point of view, the electric\n",
      "current or the flow of electrons is determined by the resistance of the\n",
      "medium. The resistance is determined by the resistivity of the materials\n",
      "used in the medium.\n",
      "If the resistance per unit length is k, the resistance of\n",
      "l length medium becomes k x l.\n",
      "So for each property that we consider that would effect trafficability from\n",
      "the overlays, we defined a value denoting resistance per distance for troop\n",
      "maneuver. So the total resistance per distance for a given grid cell is the\n",
      "sum of all resistances per length of properties that belong to that cell.\n",
      "So the pseudocode for algorithm used in obtaining the trafficability using\n",
      "the resistance\n",
      "model is given below.\n",
      "function trafficability(coo):\n",
      "create empty grid trafficability\n",
      "elevation_min = minimum(coo.elevation)\n",
      "for each cell in coo:\n",
      "slope = cell.getSlope()\n",
      "isBuilding = cell.isBuildingHere()\n",
      "isWater = cell.isWaterHere()\n",
      "isRoad = cell.isRoadHere()\n",
      "vegetationLevel= cell.vegetation()\n",
      "relative_elevation = cell.getElevation() - elevation_min\n",
      "isBridge = isWater and isRoad\n",
      "resistivity_of_cell = relative_elevation\n",
      "if slope > max_slope_threshold:\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_heavy_slope\n",
      "if isRoad:\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_road\n",
      "else if isBridge:\n",
      "resistivity_of_cell = elevation + resistivity_bridge\n",
      "else if isBuilding:\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_building\n",
      "else if isWater:\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_water\n",
      "else if vegetationLevel == grassland\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_grassland\n",
      "else if vegetationLevel == shrubland\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_shrubland\n",
      "else if vegetationLevel == woodland\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_woodland\n",
      "else if vegetationLevel == medium density forest\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_medium_density_forest\n",
      "else if vegetationLevel == high density forest\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_high_density_forest\n",
      "else if vegetationLevel == unknown\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_unknown\n",
      "else:\n",
      "resistivity_of_cell = resistivity_of_cell + resistivity_vegetation_empty\n",
      "update corresponding cell in trafficability grid with resistivity_of_cell\n",
      "return trafficability\n",
      "So for the operation of this algorithm, we defined few attributes that\n",
      "describe the resistivity per length for different terrain features as below.\n",
      "max_slope_threshold = 0.4\n",
      "resistivity_vegetation_grassland = 30\n",
      "resistivity_vegetation_shrubland = 100\n",
      "resistivity_vegetation_woodland = 200\n",
      "resistivity_vegetation_medium_density_forest = 400\n",
      "resistivity_vegetation_high_density_forest = 600\n",
      "resistivity_vegetation_unknown = 200\n",
      "resistivity_vegetation_empty = 65\n",
      "resistivity_building = 1000\n",
      "resistivity_road = 1\n",
      "resistivity_bridge = 1\n",
      "resistivity_water = 10000\n",
      "resistivity_heavy_slope = 800\n",
      "These attributes were given assumed values based on the mobility in each\n",
      "situation.\n",
      "Generating the potential mobility corridors in the terrain\n",
      "So next we moved to generating potential mobility corridors that troops can\n",
      "move from a given starting point to an destination. The trafficability grid\n",
      "that was generated in last milestone, was used in determining the mobility\n",
      "corridors, or the avenues of approach. Trafficabilty grid represent a\n",
      "relative cost or a resistance of moving per a unit length, for each cell in\n",
      "grid. Here unit refer to width of a cell in the grid.\n",
      "To generate the potential mobility corridors, we experimented three\n",
      "approaches. Those were,\n",
      "Generalized Voronoi Diagram Method\n",
      "k-shortest paths algorithm\n",
      "Dijkstra's based path removing algorithm\n",
      "Generalized Voronoi Diagram Method\n",
      "The voronoi diagram method was to get mobility corridors from a voronoi\n",
      "diagram drawn for a GO-NO terrain map generated from trafficability\n",
      "grid.\n",
      "an example voronoi diagram\n",
      "Let P = {p1,p2,…,pn} be a set of n\n",
      "distinct points or sites in the plane. The Voronoi diagram of P is the\n",
      "subdivision of the plane into n cells, one for each site in P, with the\n",
      "property that a point q lies in the cell corresponding to a site pi if and\n",
      "only if dist(q, pi) < dist(q, pj) for each\n",
      "pj ∈ P with j ≠ i. If the sites are replaced\n",
      "with polygons, the above deﬁnition holds true with a more complex distance\n",
      "function that represents the minimum distance between a point and a polygon\n",
      "in the plane. Such a diagram for polygons instead of points is called the\n",
      "Generalized Voronoi Diagram (GVD). This can help to ﬁnd avenues of approach,\n",
      "and other important tactical features of terrain.\n",
      "Though the optimized algorithm for voronoi diagram is Fortune's algorithm with time complexity O(n log\n",
      "n), as we need to get the Generalized Voronoi Diagram for polygons, we\n",
      "used the basic algorithm with O(n2) for that.\n",
      "Following is the pseudocode for the generation of generalized voronoi\n",
      "diagram from GO NO-GO terrain grid.\n",
      "function voronoi(go_no_go_grid):\n",
      "create new grid border_grid\n",
      "for each no_go cell in go_no_go gird:\n",
      "if any neighbor cell is a go cell:\n",
      "mark cell as a border in border_grid\n",
      "create an array of array of cells (say cell_families) to store connected cells separately\n",
      "using a connected cell algorithm add connected cells to cell_families\n",
      "depth_map = grid of size go_no_go_grid\n",
      "color_map = grid of size go_no_go_grid\n",
      "put infinity to all cells in depth_map\n",
      "put zero to all cells in color_map\n",
      "family_id = 0\n",
      "for each family in cell_families:\n",
      "increment family_id by 1\n",
      "create a go_no_go grid sized grid which contain minimum geometric distance of each cell from the cells in the family, say it distance_map\n",
      "update the color_map, with family_id, only the cells where distance_map value < depth_map value\n",
      "update the depth_map , with distance_map value, only the cells where distance_map value < depth_map value\n",
      "create new grid voronoi_grid\n",
      "for each cell in color_map:\n",
      "if any neighbor cell is not equal to cell value:\n",
      "mark cell as a voronoi grid in voronoi_grid\n",
      "return voronoi_grid\n",
      "Following is the voronoi diagram resulted for a given battlefield.\n",
      "GVD drawn to the battlefield without restricted terrain(left) and with restricted terrain(right)\n",
      "So in this diagram is a\n",
      "network of paths, which gives many paths that avoids restricted NO-GO\n",
      "areas. Each edge of the voronoi graph corresponds to a path between two\n",
      "restricted NO-GO features. So basically voroni diagram gives an abstract\n",
      "set of paths that one can go avoiding only NO-GO areas. So we can\n",
      "select set of routes that join two positions from the network as below.\n",
      "set of paths selected using GVD\n",
      "But the problem in this\n",
      "method is that only the restricted terrain is considered for path\n",
      "generation. the other costs of mobility like cost from elevation,\n",
      "vegetation, roads, slope is not considered as the trafficability grid is\n",
      "mapped to a binary grid of GO, NO-Go and used here. So the accuracy is\n",
      "low as many data are not used.\n",
      "Considering the time\n",
      "complexity of the algorithm, the algorithm we used for generating this\n",
      "generalized voronoi algorithm has time complexity O(n2), assuming the NO-GO feature density is linearly proportional to number of cells(n) of a battlefield grid.\n",
      "We created 6 sample\n",
      "battlefields with different sizes in the same location, where it can be\n",
      "assumed as a uniform restricted terrain is there. Then we used the\n",
      "algorithm to compare time take for each.\n",
      "Following are the 6 sample battlefields created.\n",
      "See the times taken for the algorithm for different size grids below.\n",
      "The graphical representation\n",
      "of time taken for voronoi diagram vs number of cells is below.\n",
      "k-shortest paths algorithm\n",
      "The k shortest path routing\n",
      "problem is a generalization of the shortest path routing problem in a\n",
      "given network. It asks not only about a shortest path but also about\n",
      "next k−1 shortest paths (which may be longer than the shortest path).\n",
      "Our approach of finding k shortest paths in trafficability grid was\n",
      "actually finding the lowest cost paths, as the grid contain the cost\n",
      "values. We approached the k shortest paths problem by extending Dijkstra\n",
      "algorithm. We have to give start and end locations to find paths here\n",
      "first.\n",
      "Following is the pseudocode\n",
      "for the generation of paths using k-shortest paths algorithm from\n",
      "trafficability terrain grid.\n",
      "function kshortest(trafficability_grid, start_cell, end_cell):\n",
      "count = grid of zeros of size trafficability grid\n",
      "temp_path_list = queue to store temporary paths\n",
      "final_path_list = queue to store final paths\n",
      "add start cell to temp_path_list with cost 0\n",
      "while temp_path_list is not empty and count value for end_cell < k:\n",
      "current_shortest_path = get shortest path from temp_path_list\n",
      "remove current_shortest from temp_path_list\n",
      "current_destination = destination cell of current_shortest_path\n",
      "increment count value of current_destination by 1\n",
      "if current_destination == end_cell:\n",
      "add current_shortest to final_path_list\n",
      "if count value of current_destination <= k:\n",
      "for all neighbor cells of current_destination:\n",
      "current_path_copy = get a copy of current_shortest_path\n",
      "new_path = get_new_path(current_path_copy, r_change, c_change)\n",
      "let new_path be a new path formed by concatenating neighbor cell to current_shortest_path\n",
      "update cost of new_path by adding the cost of new part\n",
      "temp_path_list.append(new_path)\n",
      "return final_path_list\n",
      "So we generated 10 least\n",
      "cost paths taking k as 10, for the 6 sample battlefields marking their\n",
      "execution times.\n",
      "Following is an image of\n",
      "output paths obtained for battlefield 5.\n",
      "The problem in this result\n",
      "is that though there are several paths given as output in the result,\n",
      "they are actually represent a single path, just few small changes at few\n",
      "points are there. So those few changes make them the next least cost\n",
      "path. but there are not more different than the earlier path. But what\n",
      "we need is a set of paths that are different actually and go through a\n",
      "different area. So it is clear that k-shortest path algorithm doesn't\n",
      "give the best fit answer and we need not the next least cost paths, but\n",
      "the paths that are really different from others.\n",
      "The k shortest path problem\n",
      "is a problem where the complexity increases with k, number of cells, as\n",
      "well as distance between the two points given. For our time measurements\n",
      "we gave the start and end points as a corner to the middle of the\n",
      "battlefield approximately.\n",
      "Following is the table of times taken for the algorithm for different size grids.\n",
      "The graphical representation\n",
      "of time taken for k-shortest paths algorithm vs number of cells is\n",
      "below.\n",
      "Dijkstra's based path removing algorithm\n",
      "Our third approach was a\n",
      "dijkstra's algorithm based approach that include path segment removing\n",
      "and path correcting functions. Dijkstra's algorithm is a least cost or\n",
      "least distance finding algorithm between nodes in a graph, conceived by\n",
      "computer scientist Edsger W. Dijkstra in 1956.\n",
      "Basically for the\n",
      "trafficability grid, when performed Dijkstra's algorithm giving two\n",
      "points as start and end, outputs a path with the minimum cost, that one\n",
      "can go. But it just give one path and we need a set of different paths.\n",
      "After obtaining a shortest path, if we remove that path completely\n",
      "defining it as restricted, dijkstra's algorithm will next find another\n",
      "path that is completely independent from earlier path. They will not\n",
      "have common edges. But they can cross each other in places where both\n",
      "routes are in diagonal directions as in below figure.\n",
      "Then the set of paths give\n",
      "much different avenues of approaches as we need, but in cases where the\n",
      "route lie on common areas that both can use same path, that doesn't give\n",
      "the correct path and have multiple parallel paths. That happen as the\n",
      "paths coming next after the first path cannot use the same edges used by\n",
      "earlier paths. More importantly when the first path use a already\n",
      "available road in it, next path that need to use the road to some extent\n",
      "cannot use it and it will go in other areas close and parallel to road.\n",
      "See the below image that show the close and parallel path issue in this\n",
      "approach.\n",
      "Issue of having close and parallel paths (Left) and parts that need that issue to be corrected marked (Right)\n",
      "So a correction must be done\n",
      "to the close and parallel paths issue in common sections in routes. In\n",
      "the above image those places are circled with a red marker. So we\n",
      "developed a correction algorithm to correct that issue.\n",
      "When the paths generated\n",
      "were added to a grid, where cells belonging to paths have the cost\n",
      "defined in trafficability grid and other non path areas have a very high\n",
      "cost, the rasterized grid looks like below image.\n",
      "So in that grid view, the\n",
      "close and parallel, unwanted paths can be seen merged together as they\n",
      "are closer cells.\n",
      "Therefore in our correction\n",
      "algorithm, we made this grid and used dijkstra's algorithm again to this\n",
      "new grid to get least cost paths out of this faulty path set. Also this\n",
      "correction algorithm has a path section removing mechanism as well as a\n",
      "mechanism to identify which path section has to be removed before\n",
      "applying dijkstra's algorithm again to avoid resulting same path.\n",
      "In paths thickness is\n",
      "obtained for each cells using the number of surrounding path cells. When\n",
      "removing sections from the least cost path generated from new grid,\n",
      "first the segments with different thicknesses are splitted and we give\n",
      "priority to segments where, the path is thin (lowest wisth) and long\n",
      "(length with same thickness). Out of same width segments one with\n",
      "maximum length is chosen. Further the paths get splitted based on\n",
      "crossings as well, because in a crossing the number of surrounding path\n",
      "cells increase, hence taken as an increase of thickness.\n",
      "So following are the\n",
      "pseudo-codes for getting independent paths, path correction algorithm\n",
      "and obtaining sections to remove from paths respectively.\n",
      "Getting Independent Paths\n",
      "function independent_paths(trafficability_grid)\n",
      "max_factor = 5 // no paths of cost more than 5 times of initial path will be resulted\n",
      "create paths array to store paths\n",
      "lc_path = get least cost path for trafficability_grid using dijkstra's algorithm\n",
      "add lc_path to paths\n",
      "limit = max_factor * cost of lc_path // this is the cost limit for paths\n",
      "while true:\n",
      "mark cell of lc path as restricted in trafficability_grid except start and end cell\n",
      "lc_path = get least cost path for trafficability_grid using dijkstra's algorithm\n",
      "if cost of lc_path > limit:\n",
      "break while loop\n",
      "add path to path\n",
      "return correct_paths(paths, trafficability_grid) // correct the paths and return\n",
      "Path Correction Algorithm\n",
      "function correct_paths(paths, trafficability_grid)\n",
      "k = a very large value\n",
      "create array new_paths to store corrected paths\n",
      "create new grid of shape trafficability_grid and change all cell values to k (say new_grid)\n",
      "for each path in paths\n",
      "for all cells of the path:\n",
      "update new_grid with value from trafficability_grid\n",
      "for each path in paths\n",
      "lc_path = get least cost path for new_grid using dijkstra's algorithm\n",
      "add lc_path to new_paths\n",
      "section_to_remove = find_section_to_remove(lc_path, new_grid)\n",
      "mark cells of section_to_remove with k in new_grid\n",
      "return new_paths\n",
      "Obtaining Sections to remove from paths respectively\n",
      "find_section_to_remove(path, new_grid)\n",
      "k = very large value used in new_grid\n",
      "initially consider whole path as section to remove\n",
      "create array sections to store spllited sections\n",
      "threshold = 6 // initially cells with 6 or more neighboring non-path cells are considered as they are possible thinnest paths\n",
      "while sections is empty and threshold >= 0:\n",
      "inside_section = false\n",
      "length_of_section\n",
      "= 0\n",
      "start_cell_of_section = path[0]\n",
      "for cell in path:\n",
      "empty_count = number of neighboring cell with k // number of non-path neighbors\n",
      "if not inside_section and empty_count >= threshold:\n",
      "inside_section = True\n",
      "start_cell_of_section = cell\n",
      "length = 0\n",
      "if inside_section and empty_count >= threshold:\n",
      "length = length + 1\n",
      "if inside_section and empty_count < threshold:\n",
      "inside_section = False\n",
      "store start_cell_of_section as start, cell as end and length in sections array\n",
      "find the maximum length section from sections and assign to max_section\n",
      "threshold = threshold - 2\n",
      "return max_section\n",
      "So after applying the\n",
      "correction the paths for above example looked like following. Paths are\n",
      "shown in orange color.\n",
      "So this approach could be\n",
      "identified as a successful one, as the more unique and different avenues\n",
      "of approaches could be given as output. The routes that were given as\n",
      "output were basically similar paths that a person who is familiar with\n",
      "this area would choose.\n",
      "Limitation at choke points\n",
      "In this approach, a problem\n",
      "that we identified was, there is only a single path would be given as\n",
      "output through a choke point. Choke points are the places where troops\n",
      "have to maneuver through a very narrow area, where both the left and\n",
      "right sides are restricted areas. As example bridges, mountain passes,\n",
      "narrow areas between buildings etc.\n",
      "When generating paths, at\n",
      "initial state, when a path is there through a such choke point, though\n",
      "there can be another path which is not exactly similar to this path and\n",
      "has another approach but need to pass this choke point, it will not be\n",
      "given as output. The reason is to happen such a thing there should be\n",
      "close and parallel path segments for those two where there is should be\n",
      "common path. But that cannot happen as parallel and close paths cannot\n",
      "pass restricted part at choke point and the only pass through choke\n",
      "point has been occupied by first path. So to resolve this issue, if\n",
      "there is a choke point in the path generated, before generating the next\n",
      "independent path the pass through choke point must be unoccupied.\n",
      "Following is an image where\n",
      "paths are generated between two locations in Unversity of Peradeniya and\n",
      "the limitation of paths can be seen as there are two choke points here\n",
      "(Akbar bridge and Peradeniya bridge) and hence the potential avenues\n",
      "marked in light green color are not given in output. Paths in blue color\n",
      "are the computer generated paths.\n",
      "As described in above to\n",
      "resolve this issue, an modification was done to the 'Getting Independent\n",
      "Paths' algorithm. The identified choke points were made unoccupied\n",
      "after obtaining a path and before generating next independent path. For\n",
      "that instead of making the whole generated path restricted, the cells\n",
      "excluding choke points in the path were made restricted. So to find all\n",
      "choke points and remove path without choke points, an algorithm was\n",
      "developed and it's pseudo-code is as below.\n",
      "function non_choke_points(restricted_grid, path):\n",
      "front_cell = None\n",
      "back_cell = None\n",
      "create array non_chokes_point_set = to store cells which are not choke points\n",
      "for each cell in path:\n",
      "back_cell = front_cell\n",
      "front_cell = cell\n",
      "if back_cell is not None and front_cell is not None:\n",
      "v_d = front_cell[0] - back_cell[0]\n",
      "// get vertical displacement\n",
      "h_d = front_cell[1] - back_cell[1]\n",
      "// get horizontal displacement\n",
      "directions = None\n",
      "is_diagonal = False\n",
      "if (abs(h_d) - abs(v_d)) == 1:\n",
      "directions = (1, 0, -1, 0)\n",
      "else if (abs(h_d) - abs(v_d)) == -1:\n",
      "directions = (0, 1, 0, -1)\n",
      "else if(h_d * v_d) == 1:\n",
      "directions = (1, -1, -1, 1)\n",
      "is_diagonal = True\n",
      "else if(h_d * v_d) == -1:\n",
      "directions = (1, 1, -1, -1)\n",
      "is_diagonal = True\n",
      "is_choke = scan(restricted_grid, back_cell, directions, is_diagonal) // start scanning two sides\n",
      "if not is_choke:\n",
      "non_chokes_point_set.append(back_cell)\n",
      "return non_chokes_point_set\n",
      "function scan(restricted_grid, cell, directions, is_diagonal):\n",
      "choke_threshold = minimum distance to an obstacle for a cell to be a choke point\n",
      "restricted_1_found = False\n",
      "restricted_2_found = False\n",
      "distance_traveled = 0\n",
      "distance_step = 1\n",
      "if is_diagonal:\n",
      "distance_step = square root of 2\n",
      "while distance_traveled <= choke_threshold:\n",
      "distance_traveled = distance_traveled + distance_step\n",
      "current_cell1 = (cell[0] + directions[0], cell[1] + directions[1])\n",
      "current_cell2 = (cell[0] + directions[2], cell[1] + directions[3])\n",
      "if not restricted_1_found and restricted_grid[current_cell1] == 1:\n",
      "restricted_1_found = True\n",
      "if not restricted_2_found and restricted_grid[current_cell2] == 1:\n",
      "restricted_2_found = True\n",
      "if restricted_1_found and restricted_2_found:\n",
      "return True\n",
      "return False\n",
      "The scan function scan each\n",
      "cell in path in left and right directions up to the distance defined as\n",
      "choke_threshold to find a obstacle, it there are obstacles in both\n",
      "directions withing that limit, that cell is a choke point.\n",
      "We defined choke threshold\n",
      "as 4 units, that will approximately equal to 12 meters.\n",
      "So see the below image of\n",
      "computer generated output of above scenario after applying the fix to\n",
      "the 'Getting Independent Paths' algorithm.\n",
      "So now the result seems very similar to a human generated output.\n",
      "To do a time complexity\n",
      "comparison as in earlier approaches, we executed these algorithms for\n",
      "the 6 sample battlefields. As done in k-shortest path time comparison\n",
      "when choosing start and end, they were chosen such that they are one at a\n",
      "corner and other in center. Following is the table of times taken for\n",
      "the algorithm for different size grids.\n",
      "The graphical representation\n",
      "of time taken for k-shortest paths algorithm vs number of cells is\n",
      "below.\n",
      "Comparison of Three Approaches\n",
      "Below chart compares times\n",
      "taken by all three algorithms tested using six sample battlefields.\n",
      "The chart suggests that\n",
      "compared to time consumption, Dijkstra's based path removing algorithm\n",
      "is much time efficient than other two approaches. k-shortest path\n",
      "approach is not good as it's time consumption is much high as well as\n",
      "increase exponentially with number of cells.\n",
      "Following is a qualitative comparison between outputs of the three approaches.\n",
      "Generalized Voronoi Diagram Method\n",
      "k-shortest paths algorithm\n",
      "Dijkstra's based path removing algorithm\n",
      "Only GO,NO-GO terrain is used\n",
      "Trafficability grid is used with all features\n",
      "Trafficability grid is used with all features\n",
      "Paths does not depend on cost of traveling\n",
      "Paths depend on cost of traveling\n",
      "Paths depend on cost of traveling\n",
      "Different possible paths are resulted, but some mismatch is with paths paths are not spread, mostly same path with small differences is resulted\n",
      "Much spread can be seen in paths, actually different possible paths are resulted\n",
      "Time taken for algorithm is low (not the lowest)\n",
      "Heavy time consuption\n",
      "Very low time taken (it is the lowest out of three approaches)\n",
      "Considering all factors, we decide to use Dijkstra's based path removing algorithm.\n",
      "Risk evaluation of corridors to predict the avenues of approach and key\n",
      "areas\n",
      "As we get set of distinct\n",
      "easiest avenues that can be used for troop maneuver, there might be\n",
      "some risks in using the\n",
      "paths due to enemy locations.\n",
      "So in this milestone\n",
      "wedeveloped an algorithm to define the range of threats for\n",
      "the enemy locations\n",
      "annotatedby user and then use that range of threats to find\n",
      "threat for routes\n",
      "generated.The general approach to get a range of threat was,\n",
      "the threat decreasing a\n",
      "uniformamount when going away from the enemy location or building.\n",
      "So as we can definebuildings\n",
      "as enemy ones in our tool, the value must start decreasing from\n",
      "the wall ofthe building to\n",
      "outside. As our representation of terrain was using a grid of cells,\n",
      "wedefined two 2d arrays of\n",
      "the shape of terrain grid called Enemy threat grid and Threat\n",
      "decrement grid. In here\n",
      "Threat decrement grid has a value for each cell defining how much threat\n",
      "will loss in this cell. The amount is the loss of threat per grid cell\n",
      "unit.Using that we created the enemy threat grid that will finally have a\n",
      "value of threat foreach cell in the terrain. The value is between 0 and\n",
      "10.In here, what would decrease threat was only distance from the enemy\n",
      "building. Sothe threat decrement grid has uniform values. So the threat\n",
      "range that is resulted is a circular area around the building where\n",
      "threat last only to a maximum fixed distance from borders of the\n",
      "building.When a same cell in threat array get values from two threat\n",
      "locations, the maximum out of the threats at the cell due to all threat\n",
      "locations is kept.So the rasterized image of threat variation from an\n",
      "enemy building is as Following figure when only distance is considered.\n",
      "Following figure is the flow of the code we developed to get threat grid\n",
      "So the pseudo-code of the\n",
      "algorithm used to get the threat grid from a building whengiven the\n",
      "border_cell_list, which is the list of cells in the buildings border of\n",
      "it is given below\n",
      "function threat_grid(border_cell_list, threat_decrement_array)\n",
      "define starting threat for this building as T\n",
      "create new grid threat_range\n",
      "for each cell in border_cell_list:\n",
      "visited = new grid to store whether the cell visited or not\n",
      "q = new queue to store scanned cells with threat\n",
      "add cell to the q with threat T\n",
      "mark threat of cell in threat_range as T\n",
      "while q is not empty:\n",
      "current_cell = get cell with maximum threat cell from q\n",
      "remove current_cell from q\n",
      "mark current_cell as visited in visited\n",
      "let d is current_cell_threat_decrement\n",
      "d = threat_decrement_array_cell[current_cell]\n",
      "threat = threat_range[current_cell]\n",
      "for each unvisited neighbor cell of current_cell:\n",
      "let n is neighbor_cell_decrement\n",
      "n = threat_decrement_array_cell[neighbor]\n",
      "if neighbor is in diagonal direction:\n",
      "threat_decrement = square_root(2) * (d + n) /2\n",
      "else\n",
      "threat_decrement = d + n) /2\n",
      "neighbor_cell_threat = threat - threat_decrement\n",
      "if neighbor_cell_threat > threat_range[neighbor]:\n",
      "update threat_range with neighbor_cell_threat\n",
      "add neighbor to q\n",
      "return threat_range\n",
      "Then we studied how the\n",
      "terrain features would effect the threat and how to introduce those\n",
      "effects to our automated tool. From the features we have for terrain\n",
      "grid we identified following features would effect threat range of an\n",
      "enemy building.\n",
      "Enemy building height\n",
      "Height of surrounding buildings\n",
      "Level of vegetation\n",
      "High elevation than enemy building height in surround area\n",
      "Low elevation than enemy building ground\n",
      "So to add enemy building\n",
      "height to the code functionality we defined the starting threat T of the\n",
      "algorithm according to the enemy building height. As the threats will\n",
      "be mapped to range between 10 and 0 at the end, increasing starting\n",
      "threat at enemy building is not an issue.\n",
      "The best way to add the\n",
      "effect of surrounding features to the threat grid, we automatically\n",
      "change the Threat_decrement_array according to the features. As example,\n",
      "in the cells where there is a building, the threat decrement will be\n",
      "higher than normal cell.\n",
      "So we defined following\n",
      "attributes that affect threat decrement array and assingned some sample\n",
      "values for them and fine tuned the variables until a good result come.\n",
      "In a normal flat terrain\n",
      "with no features like building or vegetation given, threat from 1\n",
      "storied enemy building decrease uniformly up to 100m from border of the\n",
      "building.\n",
      "So the average width of a\n",
      "cell in our grid is approximately 3m, So the range is about 33 units.\n",
      "threat_decrement_building_max, this is the threat decrement at places\n",
      "where a building blocks visibility, normally it is a building with same\n",
      "number of stories or more than the enemy building.\n",
      "threat_decrement_grassland, this is the threat decrement at places where there is a grassland\n",
      "threat_decrement_shrubland, this is the threat decrement at places where there is a shrubland\n",
      "threat_decrement_medium_forest, this is the threat decrement at places where there is a medium_forest\n",
      "threat_decrement_high_forest, this is the threat decrement at places where there is a high_forest\n",
      "threat_decrement_elevation_increment, this is the value which the\n",
      "available threat decrement increase when the elevation is higher than\n",
      "the estimated building height\n",
      "threat_decrement_elevation_decrement , this is the value which the\n",
      "available threat decrement decrease when the elevation is lower than the\n",
      "enemy ground level.\n",
      "building_floor_height_average, this is the multiplying factor to get\n",
      "estimated building height from the number of stories of it.\n",
      "range_increment_per_floor, normally range of the single storied building\n",
      "is 33 units, but it increase when the number of stories of enemy\n",
      "building increase. This is the value in which the range increase per\n",
      "single storey.\n",
      "following Figures are images\n",
      "of the threat array generated in enemy buildings by changing the\n",
      "terrain features.\n",
      "When all buildings are\n",
      "single floor(LEFT), when top enemy building was made two story (MIDDLE) ,\n",
      "when a close building of it also made two story (RIGHT)\n",
      "When all buildings are two\n",
      "story, the threat range of enemy building is blocked by surrounding\n",
      "buildings as in first image. So when the enemy building is made a two\n",
      "stroy one, it's range of threat doesn't blocked by single floored\n",
      "buildings around. that is why the range has not changed in middle image.\n",
      "So when a nearby surround building also made two story as in right\n",
      "image, the range of enemy building will get effected from that.\n",
      "Below figure shows the\n",
      "variation of threat with elevation right side of the building, the\n",
      "elevation is high, it is higher than the height of the building, so the\n",
      "threat from building has been limited to right side. Also to left of the\n",
      "building, you can see there is an increase of threat. that is because\n",
      "the ground level to that side is lower than building ground level as\n",
      "well as the vegetation is grassland, that cause more spread of threat\n",
      "towards that side.\n",
      "Variation of threat with elevation\n",
      "Basically vegetation level\n",
      "effect threat range, in below figure to left side of the building, there\n",
      "is a heavy density forest, so the threat have been limited towards that\n",
      "side.\n",
      "Variation of threat with vegetation\n",
      "Finally obtaining the threat\n",
      "grid for the whole battlefield, we decided threats for the routes\n",
      "generated between given coordinates. So the paths were colored in IPB\n",
      "tool using the threats obtained for each routes as below. In the threat\n",
      "representation of the map, the colors change from green to red to\n",
      "represent threat from 0 to 10 respectively.\n",
      "Below is an image from IPB\n",
      "tool when potential mobility corridors were generated and paths are\n",
      "colored according to threat level due to the enemy locations marked in\n",
      "red.\n",
      "Comparison with Available Systems\n",
      "Google map directions\n",
      "Basically the platform\n",
      "normally used to find paths to travel from one place to another place is\n",
      "Google Map directions.\n",
      "Following figure shows the\n",
      "comparison of the avenues of approaches generated between two positions\n",
      "separated by a river and the Google direction result for those two\n",
      "positions.\n",
      "Comparison with Google\n",
      "direction, Our System generated paths (LEFT) Google Directions for\n",
      "vehicles(MIDDLE) and Google directions for walking(RIGHT)\n",
      "Basically direction API\n",
      "consider only available routes to generate the paths. Some times they\n",
      "give multiple paths possible but not to much deep level. So it doesn't\n",
      "consider the terrain features or any additional information we give on\n",
      "terrain in generation paths. Also it does not suggest paths to maneuver\n",
      "through non road areas. So in case of avenues of approaches our\n",
      "implementation is much successful towards obtaining avenues of\n",
      "approaches for troop maneuver.\n",
      "Comparison with result from a related works\n",
      "In [3] the researchers have\n",
      "developed algorithms to generate avenues of approaches for a small map\n",
      "using a trafficability array and generalized voronoi diagram. Also they\n",
      "have evaluated the avenues of approaches of that map by an subject\n",
      "matter experts (SME). So we recreated the map they have used in the\n",
      "research drawing similar terrain data.Then obtained avenues of\n",
      "approaches for the two locations they have used and then compared it\n",
      "with the result generated by their system and manual result by SME.\n",
      "Following figure shows the\n",
      "avenues of approaches for that map given by algorithms used by the\n",
      "researchers and the SME.\n",
      "Avenues of approaches by\n",
      "researcher's algorithms (LEFT) and subject matter expert(RIGHT), (C.\n",
      "Grindle, M. Lewis, R. Glinton, J. Giampapa, and K. Owens 2004, Fig. 5\n",
      "and 6, p. 4)\n",
      "Then following figure shows\n",
      "the our IPB tool generated avenues of approaches for the same map\n",
      "created by us on our tool.\n",
      "Avenues of approaches by our IPB tool\n",
      "So the avenues of approaches\n",
      "generated by our tool seems much similar to the avenues drawn by\n",
      "subject matter experts in the given research. There are basic three\n",
      "avenues suggested by the SME as well as our system. In the referenced\n",
      "research's output, only two avenues are suggested. Also our result\n",
      "contain risk estimation values for the avenues as well if enemy\n",
      "locations were annotated.\n",
      "Also the algorithm used by\n",
      "the referenced research is based on a voronoi diagram method. So that\n",
      "approach is giving a complex scenario when comes to larger maps as well\n",
      "as much time as concluded in \\autoref{f:label27}. So for larger maps\n",
      "with more details like buildings, water bodies the voronoi diagram\n",
      "become complex and give very high number of paths. So removing unwanted\n",
      "paths is difficult. So for each larger and smaller maps with any amount\n",
      "of features the approach taken by our algorithms is good.\n",
      "Conclusions and Future Works\n",
      "Building a tool for\n",
      "battlefield area evaluation, storing and visualizing information, and\n",
      "supporting decision making for troop maneuver planning is the primary\n",
      "objective of this project. In the IPB process also the objective is to\n",
      "build the combined obstacle overlay to use for troop locating and\n",
      "maneuver planning. Avenues of approach, Engagement areas, Defensible\n",
      "terrain are some final high level information obtained through the\n",
      "combined obstacle overlay. In this research we could develop algorithms\n",
      "and the tool to generate and display avenues of approach successfully.\n",
      "we looked at the low level\n",
      "environmental factors such as ground, and environment data. We developed\n",
      "a database of predefined terrain features data like building,\n",
      "elevation, vegetation, water and roads for any location. In this project\n",
      "we just included data for only Sri Lanka. So any default terrain data\n",
      "for a battlefield are automatically obtained by the tool. Then we build a\n",
      "mechanism to display in on the map as overlays. Also implemented method\n",
      "to put user defined features to overlays. We could developed a backend\n",
      "to store, edit and give the battlefield data separately. Using a REST\n",
      "API, we connected the backend with frontend IPB tool to enable\n",
      "operations on overlays.\n",
      "We obtained trafficability\n",
      "grid using a grid based model for processing overlay data. In the\n",
      "decision support development part we explored three different approaches\n",
      "to use trafficbilty grid to generate avenues of approach, which was a\n",
      "main requirement in IPB process. Finally we compared and further\n",
      "developed the best and more practical approach from those three. we\n",
      "finally developed the algorithms for the avenues of approach generation.\n",
      "Then We developed algorithms to find threat level for paths due to\n",
      "enemy. Finally we compared our output avenues with available paths\n",
      "generating platforms like Google maps and the avenues suggested by\n",
      "subject matter experts in related researches.\n",
      "As planned in milestones we\n",
      "implemented only avenues of approaches finding using trafficability\n",
      "grid. So there are few other high-level terrain information such as key\n",
      "terrain, defensible terrain and engagement areas. So as a future work\n",
      "those goals must be accomplished.\n",
      "Also there are few other\n",
      "terrain information that need to be fused with terrain data like weather\n",
      "and soil type. So we couldn't combine those data due to lack of those\n",
      "data. If those data also got fused, the we could obtain more accurate\n",
      "results. So that need to be done as a future target.\n",
      "Also when considering the\n",
      "threat from enemy we developed the algorithm to change the enemy range\n",
      "of threat according to elevation, vegetation, surrounding buildings and\n",
      "height of enemy building. So in future works, enemy must be more\n",
      "customized like several types of enemy like snipers, normal ones, scouts\n",
      "so on. Then that type also will effect the enemy range.\n",
      "Also currently we are\n",
      "obtaining the threat from enemy to the avenues. so in future version\n",
      "when there is a considerable high threat from a enemy location to a\n",
      "path, that path should be minimized to avoid that threat making a new\n",
      "path.\n",
      "References\n",
      "P.Skalický and\n",
      "T.Palasiewicz, “Intelligence preparation of the battlefield as a partof\n",
      "knowledge development,” 2017\n",
      "R. Glinton, S.\n",
      "Owens, J. Giampapa, K. Sycara, C. Grindle, and M. Lewis, “Terrain-based\n",
      "information fusion and inference,”Proc. Seventh Int. Conf. Inf.\n",
      "Fusion,FUSION 2004, vol. 1, pp. 338–345, 2004\n",
      "C. Grindle, M.\n",
      "Lewis, R. Glinton, J. Giampapa, and K. Owens, Sean Sycara, “Au-tomating\n",
      "Terrain Analysis: Algorithms for Intelligence Preparation of the\n",
      "Battlefield,”Proceedings of the Human Factors and Ergonomics Society\n",
      "Annual Meeting, vol. 48,no. 3, pp. 533–537, 2004\n",
      "C. J. James Donlon\n",
      "and K. D. Forbus, “Using a Geographic Information System forQualitative\n",
      "Spatial Reasoning about Trafficability,”Proc. QR99, pp. 1–11, 1999\n",
      "K. K. Rowel and H.\n",
      "Ranasinghe, “Impact of gis modelling in military operationalplanning..”\n",
      "E. D. Porter, “An overview of the army gis research program,” 1987\n",
      "W. Headquarters,\n",
      "Department of the Army, “Terrain analysis,”Encyclopedia ofGeographic\n",
      "Information Science, 1990.\n",
      "M. C. A. Agee,\n",
      "“INTELLIGENCE PREPARATION OF THE BATTLEFIELD(IPB),”Society, vol. 1387,\n",
      "no. 22, pp. 1383–1387, 1987\n",
      "U. W. Mark Meeder,\n",
      "Tobias Aebi, “The influence of slope on walking activity andthe\n",
      "pedestrian modal share,”20th EURO Working Group on Transportation\n",
      "Meeting,2017.\n",
      "D. E. Sidran,\n",
      "“TIGER: AN UNSUPERVISED MACHINE LEARNING TACTICALINFERENCE GENERATOR,”\n",
      "2009\n",
      "P. Svenson and H.\n",
      "Sidenbladh, “Determining possible avenues of approach usingANT,” 2003.\n",
      "© Team IPB\n",
      "\n",
      "\n",
      "Extracting Remotely Controlled CNC Robot https://cepdnaclk.github.io/e15-co326-Remotely-Controlled-CNC-Robot\n",
      "\n",
      "\n",
      "CNC base 3-axis remotely controlled pick and place robot\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "CNC base 3-axis remotely controlled pick and place robot\n",
      "Team\n",
      "Jaliyagoda A.J.N.M. (E/15/140)\n",
      "Karunarathna S.D.D.D. (E/15/173)\n",
      "Tennakoon T.M.P.B. (E/15/350)\n",
      "Table of Contents\n",
      "Introduction\n",
      "Specifications\n",
      "Methodology\n",
      "Design\n",
      "Links\n",
      "Introduction\n",
      "Over the past few decades technology has been evolving rapidly in so many aspects and fields to reach out to the human population in a more user-friendly manner. With these technological developments, new terms like “distance learning”, “remote laboratories”, “virtual learning environments” etc have emerged. However, labs have the greatest potential to overcome the bottleneck in distance education. The goal of Remote Laboratory implementation is to grant students access to laboratory equipment and cover physical laboratory exercises remotely.\n",
      "A programmable logic controller (PLC) is a special purpose industrial computer/controller that has been adapted to control manufacturing processes. Hence, PLC is widely used in manufacturing to organize complex tasks like security monitoring, automatic control production lines, and management of energy consumption. As a result, there is a great need for engineers with knowledge of PLC. High cost, limited equipment, and limited access to this equipment make it difficult to access everyone.\n",
      "Hence, connecting PLC with the remote laboratory enables educational institutions to offer programs to a much broader target group of potential students who under no circumstances are able to travel to and attend on-site sessions.\n",
      "In this project, we hope to develop a CNC (Computer Numerical Control) based pick and place arm, which will help to try different wiring arrangements in a PLC rig and try experiments one it remotely.\n",
      "Figure 1: An example of a Pick and Place CNC machine\n",
      "Figure 2: PLC Test Rig of the department of computer engineering\n",
      "Specifications\n",
      "Software Layer\n",
      "Web HMI with Javascript\n",
      "MQTT broker for communication\n",
      "Hardware Software Interface\n",
      "Using standard G-code language for machine control\n",
      "A firmware like Merlin/Gerber will be supposed to use\n",
      "Communication is done by USART protocol, with a baud rate of 115000bps\n",
      "Hardware Layer\n",
      "Nema17 standard stepper motors for motion control\n",
      "DRV8825 for stepper motor control\n",
      "Arduino Mega 2560 for motion planning\n",
      "Methodology\n",
      "It is constructed using the CNC technology, using Stepper motors with a combination of Screw and Bolt mechanism (for Y and Z axises) and Belt and Pulley mechanism (For X axis). Stepper motors are driven by DRV8825 Step stick drivers with microstepping of 1/16 mode. The microcontroller for the machine is Arduino Mega 2560, with the support of RAMPS 1.4 shield for additional hardware.\n",
      "The firmware we used is known as GRBL, a well known firmware which drives CNC machines using AVR family microcontrollers. We used GCODE to instruct the machine about movements in 3d space. The software named ‘Candle’ is used to control the machine from PC, and send machine commands as well as configuration commands.\n",
      "Communication protocol between HMI and the server needed careful consideration. The messages should be exchanged through the public internet and it should be lightweight since the messages need to arrive with minimum latency which could potentially disrupt the operation of the CNC machine. Therefore, the protocol should be able to handle unreliable networks. Also the messages only contain small commands that need to be passed to the hardware controller. Therefore, the message overhead should be minimum. And most importantly it should be able to handle multiple users. So students can work in groups controlling the PLC rig remotely. Considering all these requirements we used MQTT (Message Queue Telemetry Transport) as the message passing protocol. Because, MQTT is a lightweight message protocol that is based on a subscription-publishing model, in which publishers send messages to a server and this is who forwards messages to subscribers avoiding point-to-point connections between subscribers and publishers.\n",
      "Students can log into the remote platform using the HMI developed using JavaScript (along with HTML and CSS). Then they can use the HMI to send signals to control the CNC machine. The control messages get published to a MQTT broker. A server physically connected to the hardware controller subscribed to the MQTT broker receives the control messages. The control messages contain GCODE commands needed to control\n",
      "the machine. The server sends the G-CODE commands through a serial interface to the ATMEGA 2560 which runs the GRBL. GRBL converts the control signals to electronic signals and sends to the motor driver, which controls the three server motors. This moves the 3-axis of the CNC machine.\n",
      "Design\n",
      "Funding\n",
      "This project was funded by the Prof. Suhada Jayasuriya Project Support Fund through PEFAA https://pefaa.net/.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Analysis Tool for Industrial Images https://cepdnaclk.github.io/e17-co328-Analysis-Tool-for-Industrial-Images\n",
      "\n",
      "\n",
      "Analysis Tool for Industrial Images\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Analysis Tool for Industrial Images\n",
      "Team\n",
      "E/17/154, KARUNANAYAKE A.I, e17154@eng.pdn.ac.lk\n",
      "E/17/072, DISSANAYAKE D.M.D.R, e17072@eng.pdn.ac.lk\n",
      "E/17/380, WEERASOORIYA S.S, e17380@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Problem Overview\n",
      "Existing System\n",
      "Proposed System\n",
      "Links\n",
      "Problem Overview\n",
      "The injection molding manufacturing process is used for producing parts by injecting molten material into a mold.In our specific use case, we focus on plastic injection molding.One of the common problems in this process is when plastic residue gets stuck or left behind in the mold.Thus leading to damages to the mold , defects in products and ultimately resulting in unwanted business costs.\n",
      "Current Implementation\n",
      "The above issue is mainly handled by checking the molds manually on each iteration. This has become a heavy burden as it costs time and money to supply this labor at a high frequency . These machines are highly capable of working on full automatic but this issue has caused a significant overhead in the manufacturing process.As a solution, a device was built to capture images of the mold in near IR frequency to check for stuck particles. Currently, this is being implemented to mitigate this issue.The implementation is purely run to check for defects using an image processing algorithm with a given set of parameters.The problem here is that although this implementation has proven to be a better alternative there is a limitation at which how effective or how true the results from this device is Currently, the built device only gives out a binary output as positive a negative. Since there is a limitation for the flexibility of the used algorithm is these results do not always turn out to be true. Hence our focus is to elevate the performance of the implemented device to produce better results.\n",
      "Proposed System\n",
      "As a solution, we aim to provide a tool to provide statistical data representing to be used to show the effectiveness of the algorithm.Here we would change parameters such as threshold values for identifying particle sizes. For this we will be using the images captured from the device and manually labelled image sets. As a second part of the implementation, a dashboard to centrally view all the statistical data pertaining to different machines will be created. So that a better management of the facility can be maintained. With the proposed solution we will be able to improve the performance of the current implementation and as a result, improve the overall benefits. We will be able to have better confirmation of the errors / defects with higher assurance. We wil be able to minimize the cost of labour as the frequency of mold checks/ cleaning gets minimized and increase the overall output of the machines. The minimal maintenance cost wil be significantly lower than the high price to be paid for damaged molds. With the added improvement s to the device, the whole operation will ultimately be able to work on its maximum rated speed without any interference.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting ContactTracingApp https://cepdnaclk.github.io/e17-co328-ContactTracingApp\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "CONTACT TRACING APP\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Flood Forecasting System https://cepdnaclk.github.io/e17-co328-Flood-Forecasting-System\n",
      "\n",
      "\n",
      "Flood Forecasting System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Flood Forecasting System\n",
      "Team\n",
      "E/17/006, ALAHAKOON A.M.H.H, e17006@eng.pdn.ac.lk\n",
      "E/17/176, KUMARA W.M.E.S.K, e17176@eng.pdn.ac.lk\n",
      "E/17/338, SRIMAL R.M.L.C, e17338@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution\n",
      "Web Interface Overview\n",
      "Links\n",
      "Introduction\n",
      "Floods are the most destructive form of natural hazards in both local and global context.\n",
      "This is true in terms of both loss of life and property damage. Early flood forecasting can\n",
      "be used to identify potential areas of flooding in order to develop mitigatory planning and\n",
      "evacuation programs to remove people from such areas during flooding\n",
      "and also to implement suitable preventive measures to avoid damage to properties.\n",
      "In this project, our main objective is to build a flood forecasting system for Mi Oya river\n",
      "basin(Sri Lanka).Mi Oya Basin is heavily affected by seasonal flooding and droughts.\n",
      "As per the available data, floods in the Mi Oya basin are unleashed due to river overflow\n",
      "and reservoir spilling. Out of the several reservoirs located in the basin, Tabbowa and\n",
      "Inginimitiya are crucial in worsening the flood impacts as these two reservoirs are\n",
      "frequently spilling under adverse weather conditions. As such, the prevalence of a\n",
      "real-time flood forecasting model with the incorporation of the reservoir operations\n",
      "for the entire basin is essential to alleviate the flood induced impacts while\n",
      "preserving the optimum volume of water in the major reservoirs in the basin.\n",
      "Solution\n",
      "The proposed solution is to implement a simple data-driven or machine learning model to\n",
      "identify a direct mapping between the inputs(e.g., precipitation(P), temperature(T),\n",
      "potential evapotranspiration(PET), etc.) and outputs(In-flow level) without detailed\n",
      "consideration of the internal structure of the physical process. Also the system is\n",
      "consist of a web interface. The interface consists of three major modules as community\n",
      "view,control panel, and report. The warning messages are displayed with a map depicting\n",
      "the inundation extent in the community view, which is the interface for the public. Further,\n",
      "the community members are allowed to register their mobile numbers to receive warnings\n",
      "as SMS when such warnings are broadcasting at the disaster management center. A summary\n",
      "of past floods can be generated from the Report module for a required time period. Control\n",
      "panel provides access to the simulation module, gate operation module, flood warning\n",
      "dissemination module, access control module, etc. Only privileged users have access to the\n",
      "control panel. The figure below outlines the highlevel structure of the web application.\n",
      "Web Interface Overview\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Greenhouse Monitoring System https://cepdnaclk.github.io/e17-co328-Greenhouse-Monitoring-System\n",
      "\n",
      "\n",
      "Greenhouse Monitoring System\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Greenhouse Monitoring System Based on Image Spectral Data\n",
      "Team\n",
      "E/17/297, Rupasinghe T.T.V.N., e17297@eng.pdn.ac.lk\n",
      "E/17/206, Manohara H.T., e17206@eng.pdn.ac.lk\n",
      "E/17/148, Kalpana M. W. V., e17148@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Overview\n",
      "Problem Statement\n",
      "Solution\n",
      "Links\n",
      "Overview\n",
      "Greenhouse Monitoring System provides a platform to manage the Greenhouse by tracking the phases of plant harvest, identifying any plant disorder and tracking the plant growth by using the image spectral data of plants. The system is basically considered the key problems plant diseases, huge harvest wastage and unnecessary expensive maintenance in a greenhouse. So this system will make a high positive impact on maximizing the harvest and reduce maintenance cost in Greenhouses.\n",
      "Problem Statement\n",
      "Although the environmental conditions of plants are controlled, the temporal effects like temperature, humidity may not evenly balanced for each crop. Therefore, plants respond differently under those unbalanced environmental conditions. And, plants can have different kind of disorders. It leads to production failures in greenhouses. As well, the crop yield may not be harvested at the right moment. Because of that there would be a huge harvest wastage.\n",
      "In current greenhouses, the workers continuously observe the plant growth. In that case, workers will be tired and labor system would be inefficient. So, there would be an unnecessary higher cost for maintenance.\n",
      "Solution\n",
      "Plant diseases, huge harvest wastage and unnecessary expensive maintenance have been observed as the major issues in current Greenhouse Systems. These key problems simulated the development of image analysis and computer vision methods. That’s how the “greenhouse monitoring system based on image spectral data” came to the stage.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Greenhouse monitoring and controlling based on IOT sensor data https://cepdnaclk.github.io/e17-co328-Greenhouse-monitoring-and-controlling-based-on-IOT-sensor-data\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Greenhouse monitoring and controlling based on IOT/Sensor data\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "E/17/065, Kanishka dilhan, email\n",
      "E/17/312, Ishini udara, email\n",
      "E/17/240, Nadeesha diwakara, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting History of Music https://cepdnaclk.github.io/e17-co328-History-of-Music\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "History of Music\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Host Pathogen Interaction https://cepdnaclk.github.io/e17-co328-Host-Pathogen-Interaction\n",
      "\n",
      "\n",
      "BioWeb | Analazing microbiome data\n",
      "BioWeb\n",
      "Home\n",
      "About\n",
      "Pricing\n",
      "Team\n",
      "Contact\n",
      "Pages\n",
      "About Page\n",
      "Pricing Page\n",
      "Contact Page\n",
      "Blog Grid Page\n",
      "Blog Details Page\n",
      "Sign Up Page\n",
      "Sign In Page\n",
      "404 Page\n",
      "Sign In\n",
      "Sign Up\n",
      "Inference of host-microbe associations based on metagenomic data\n",
      "Toole provided the feature to analyze given microbiome data with the help of Machine learning and GUI .\n",
      "Web App Demo\n",
      "Star on Github\n",
      "Features\n",
      "Main Features Of Play\n",
      "There are many variations of passages of Lorem Ipsum available but the majority have suffered alteration in some form.\n",
      "Free and Open-Source\n",
      "Lorem Ipsum is simply dummy text of the printing and industry.\n",
      "Learn More\n",
      "Multipurpose Template\n",
      "Lorem Ipsum is simply dummy text of the printing and industry.\n",
      "Learn More\n",
      "High-quality Design\n",
      "Lorem Ipsum is simply dummy text of the printing and industry.\n",
      "Learn More\n",
      "All Essential Elements\n",
      "Lorem Ipsum is simply dummy text of the printing and industry.\n",
      "Learn More\n",
      "About Us\n",
      "Brilliant Toolkit to Build Nextgen Website Faster.\n",
      "The main ‘thrust' is to focus on educating attendees on how to best protect highly vulnerable business applications with interactive panel discussions and roundtables led by subject matter experts.\n",
      "The main ‘thrust' is to focus on educating attendees on how to best protect highly vulnerable business applications with interactive panel.\n",
      "Learn More\n",
      "Pricing Table\n",
      "Our Pricing Plan\n",
      "There are many variations of passages of Lorem Ipsum available but the majority have suffered alteration in some form.\n",
      "STARTING FROM\n",
      "$ 19.99/mo\n",
      "1 User\n",
      "All UI components\n",
      "Lifetime access\n",
      "Free updates\n",
      "Use on 1 (one) project\n",
      "3 Months support\n",
      "Purchase Now\n",
      "POPULAR\n",
      "STARTING FROM\n",
      "$ 19.99/mo\n",
      "5 User\n",
      "All UI components\n",
      "Lifetime access\n",
      "Free updates\n",
      "Use on 1 (one) project\n",
      "4 Months support\n",
      "Purchase Now\n",
      "STARTING FROM\n",
      "$ 70.99/mo\n",
      "1 User\n",
      "All UI components\n",
      "Lifetime access\n",
      "Free updates\n",
      "Use on unlimited project\n",
      "4 Months support\n",
      "Purchase Now\n",
      "FAQ\n",
      "Any Questions? Answered\n",
      "There are many variations of passages of Lorem Ipsum available but the majority have suffered alteration in some form.\n",
      "How to use TailGrids?\n",
      "It takes 2-3 weeks to get your first blog post ready. That includes the in-depth research & creation of your monthly content marketing strategy that we do before writing your first blog post, Ipsum available .\n",
      "How to download icons from LineIcons?\n",
      "It takes 2-3 weeks to get your first blog post ready. That includes the in-depth research & creation of your monthly content marketing strategy that we do before writing your first blog post, Ipsum available .\n",
      "Is GrayGrids part of UIdeck?\n",
      "It takes 2-3 weeks to get your first blog post ready. That includes the in-depth research & creation of your monthly content marketing strategy that we do before writing your first blog post, Ipsum available .\n",
      "Can I use this template for commercial project?\n",
      "It takes 2-3 weeks to get your first blog post ready. That includes the in-depth research & creation of your monthly content marketing strategy that we do before writing your first blog post, Ipsum available .\n",
      "Do you have plan to releasing Play Pro?\n",
      "It takes 2-3 weeks to get your first blog post ready. That includes the in-depth research & creation of your monthly content marketing strategy that we do before writing your first blog post, Ipsum available .\n",
      "Where and how to host this template?\n",
      "It takes 2-3 weeks to get your first blog post ready. That includes the in-depth research & creation of your monthly content marketing strategy that we do before writing your first blog post, Ipsum available .\n",
      "Testimonials\n",
      "What our Client Say\n",
      "There are many variations of passages of Lorem Ipsum available but the majority have suffered alteration in some form.\n",
      "“Our members are so impressed. It's intuitive. It's clean. It's distraction free. If you're building a community.\n",
      "Sabo Masties\n",
      "Founder @ Rolex\n",
      "“Our members are so impressed. It's intuitive. It's clean. It's distraction free. If you're building a community.\n",
      "Margin Gesmu\n",
      "Founder @ UI Hunter\n",
      "“Our members are so impressed. It's intuitive. It's clean. It's distraction free. If you're building a community.\n",
      "William Smith\n",
      "Founder @ Trorex\n",
      "Some Of Our Clients\n",
      "Our Team\n",
      "Meet Our Team\n",
      "There are many variations of passages of Lorem Ipsum available but the majority have suffered alteration in some form.\n",
      "Adveen Desuza\n",
      "UI Designer\n",
      "Jezmin uniya\n",
      "Product Designer\n",
      "Andrieo Gloree\n",
      "App Developer\n",
      "Jackie Sanders\n",
      "Content Writer\n",
      "CONTACT US\n",
      "Let's talk about\n",
      "Love to hear from you!\n",
      "Our Location\n",
      "401 Broadway, 24th Floor, Orchard Cloud View, London\n",
      "How Can We Help?\n",
      "info@yourdomain.com\n",
      "contact@yourdomain.com\n",
      "Send us a Message\n",
      "Full Name*\n",
      "Email*\n",
      "Phone*\n",
      "Message*\n",
      "Send Message\n",
      "We create digital experiences for brands and companies by using\n",
      "technology.\n",
      "About Us\n",
      "Home\n",
      "Features\n",
      "About\n",
      "Testimonial\n",
      "Features\n",
      "How it works\n",
      "Privacy policy\n",
      "Terms of Service\n",
      "Refund policy\n",
      "Our Products\n",
      "LineIcons\n",
      "Ecommerce HTML\n",
      "Ayro UI\n",
      "PlainAdmin\n",
      "Partners\n",
      "Privacy policy\n",
      "Legal notice\n",
      "Terms of service\n",
      "Designed and Developed by\n",
      "TailGrids and UIdeck\n",
      "\n",
      "\n",
      "Extracting NGS Data AnalysingToolkit https://cepdnaclk.github.io/e17-co328-NGS-Data-AnalysingToolkit\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Oral Cavity Region Detection https://cepdnaclk.github.io/e17-co328-Oral-Cavity-Region-Detection\n",
      "\n",
      "\n",
      "Oral Cavity Region Detection Tool\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Oral Cavity Region Detection Tool\n",
      "Team\n",
      "e17058, Devindi G.A.I, e17058@eng.pdn.ac.lk\n",
      "e17090, Francis F.B.A.H, e17090@eng.pdn.ac.lk\n",
      "e17190, Liyanage S.N, e17190@eng.pdn.ac.lk\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Software Design\n",
      "Testing\n",
      "Conclusion\n",
      "Links\n",
      "Introduction\n",
      "This project contains a web-based application that can be used to upload images of the oral cavity and identify the known regions which are normal. For example: The tool will process an image uploaded by the clinician and apply masks to easily recognize a specific region of the oral cavity which does not indicate any abnormality.\n",
      "Why\n",
      "If known regions are quickly detected using a methodology, without patient having to endure prolonged invasions to the oral cavity, the dentists can easily identify the abnormal regions and pay more attention to the undetected oral lesions/ suspected regions in a matter of seconds.\n",
      "On the other hand, AI detection systems that are used to detect oral cancers require oral cavity images with only the lesion component. Therefore, the output masks of our tool can be used to filter out the lesion part and feed it to the cancer detection tools.\n",
      "Solution Architecture\n",
      "Software Design\n",
      "User Interface\n",
      "See the prototype\n",
      "of the web interface. (in progess)\n",
      "Use Case Diagram\n",
      "Testing\n",
      "Conclusion\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Prediction of risks associated with mass corona vaccination https://cepdnaclk.github.io/e17-co328-Prediction-of-risks-associated-with-mass-corona-vaccination\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Skim Sequencing Analysis https://cepdnaclk.github.io/e17-co328-Skim-Sequencing-Analysis\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Analysis Software for Next Generation Skim Sequencing\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "E/17/018, Imesh Balasuriya, email\n",
      "E/17/194, Madhushan Ramalingam, email\n",
      "E/17/296, Ravisha Rupasinghe, email\n",
      "Table of Contents\n",
      "Analysis Software for Next Generation Skim Sequencing\n",
      "Team\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Movie Review System https://cepdnaclk.github.io/e16-co328-Movie-Review-System\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Project Publication Platform https://cepdnaclk.github.io/e16-co328-Project-Publication-Platform\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Publication Platform\n",
      "Team\n",
      "E/16/078, Thilini Deshika, email\n",
      "E/16/168, Sudam Kalpage, email\n",
      "E/16/275, Hashan Eranga, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "Website based platform for inventors and students to publish their projects and attract investment to continue their projects to the production stage.\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Student Management System https://cepdnaclk.github.io/e16-co328-Student-Management-System\n",
      "\n",
      "\n",
      "Student Management System | e16-co328-Student-Management-System\n",
      "e16-co328-Student-Management-System\n",
      "Student Management System\n",
      "Student App\n",
      "Desging diagrams\n",
      "Interaction perspective - use case diagram\n",
      "left - teachers app\n",
      "right - students app\n",
      "Structural perspective - class diagram\n",
      "left - teachers app\n",
      "right - students app\n",
      "Behavioral\n",
      "perspective - Activity diagram\n",
      "Databse design - ER diagram\n",
      "\n",
      "\n",
      "Extracting Zero Trash https://cepdnaclk.github.io/e15-co328-Zero-Trash\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Zero Trash\n",
      "Team\n",
      "E/15/140, Jaliyagoda A.J.N.M., nuwanjaliyagoda@eng.pdn.ac.lk\n",
      "E/15/173, Karunarathne S.D.D.D, dinelkadilshani95@gmail.com\n",
      "E/15/350, Tennakoon T.M.P.B., pasan96tennakoon@gmail.com\n",
      "Table of Contents\n",
      "Introduction\n",
      "Solution Architecture\n",
      "Design\n",
      "Deployments\n",
      "Testing\n",
      "Links\n",
      "Introduction\n",
      "In today’s increasingly congested world, it is difficult to imagine the absence of waste. Waste generation levels are rising. In 2019 alone, the world’s cities produced 2 billion tons of solid waste. With increasing urbanization and population growth, annual waste generation is expected to grow by 70% in 2050.\n",
      "Although richer nations like the U.S.A and Japan produce more waste than countries like Sri Lanka, the problems of waste management are different in the developing world. Unlike developed nations, we do not have a well-organized means of controlling waste. Garbage is rarely collected on a regular basis, as municipalities are often underfunded. The lack of status and poor salaries associated with the job of garbage collection also creates a system where employees are not trained or able to manage an effective system.\n",
      "Zero Trash provides a communication platform between its users and garbage collectors which did not exist (at least not successfully) in Sri Lanka. This could have huge implications for both lessening the cost of collecting garbage and aiding in the recycling process, as well as ensuring that materials that would otherwise end up in a landfill are transported to the appropriate recycling centers. This will increase the income for garbage collectors while providing householders with an additional income.\n",
      "Solution Architecture\n",
      "Frontend Web Applications for Clients\n",
      "For Users and Collectors. Users should be able to sign in to it and place pickup requests for trash collections and maintain their contact information.\n",
      "RESTful API Server\n",
      "This will provide data and services to the Frontend application using HTTP GET and POST requests. Every request is authenticated using a bearer authentication token, which is issued to users when login into the system.\n",
      "Web Application for Management\n",
      "For management and monitoring purposes. System owners can sign in and see the progress of the system, accept and manage trash collector activities, communicate with customers, and see the summary of trash collected between certain periods.\n",
      "Design\n",
      "ER Diagram:\n",
      "A User Case Diagram:\n",
      "Deployments\n",
      "Frontend component is based on client side processing and it can be stored as a static web page on a server. React framework provides an option for build and develop the content using Development mode and after the component is ready for Deployment, it allows to collect all the HTML, JS and CSS files, bundle them and export the site as a package for Live Production.\n",
      "We used git with Github for development and it allows build workflows for automation of the project deployment. So we used the Workflow for React applications and once a pull request or commit happens to the master branch, it can automatically build the code for the production environment.\n",
      "Since we have not commercialized our project yet, we used the feature provided by GitHub for static web page hosts, named GitHub Pages. Our workflow can automatically upload the latest production build into the GitHub page we have created. This will help us to follow the DevOps practice known as CI/CD\n",
      "Testing\n",
      "Unit Testing was mainly focused on front end web application which is exposed to the customers. Unit tests were done using Jest and Enzyme libraries. Following areas were considered when writing unit tests\n",
      "Object Rendering\n",
      "API endpoint handling\n",
      "Styling\n",
      "Input validation with states\n",
      "Transferring of props\n",
      "Links\n",
      "Project Repository\n",
      "Project Report\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting SL Number Plate Detection Group A https://cepdnaclk.github.io/e17-co543-SL-Number-Plate-Detection-Group-A\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Project Title\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "eNumber, Name, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Other Sub Topics\n",
      "Links\n",
      "Introduction\n",
      "description of the real world problem and solution, impact\n",
      "Other Sub Topics\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting Pera Knowledge Portal https://cepdnaclk.github.io/e15-2yp-Pera-Knowledge-Portal\n",
      "\n",
      "\n",
      "Projects | Department of Computer Engineering\n",
      "Projects - Department of Computer Engineering\n",
      "University of Peradeniya, Sri Lanka\n",
      "Pera Knowledge Portal\n",
      "Team\n",
      "E/15/140, Jaliyagoda A.J.N.M., nuwanjaliyagoda@eng.pdn.ac.lk\n",
      "E/15/173, Karunarathne S.D.D.D, dinelkadilshani95@gmail.com\n",
      "E/15/350, Tennakoon T.M.P.B., pasan96tennakoon@gmail.com\n",
      "Introduction\n",
      "Our project aims to create a database of Research papers, Project Reports, Thesis’ done in University of Peradeniya. Since there is no current database where we keep the project reports other than the hard copies themselves, it is not possible for a person outside the university to access these reports. We created a platform where anyone in the university can upload their respective reports into a database which can be used by anyone; inside or outside the university, to access and read through. Anyone who is a member of the University of Peradeniya can use the CMS platform we have created to register on Pera Knowledge Portal. Members of our website can upload a pdf document of the documentation (Research Paper, Project Report, Thesis) they wish to be published. Knowledge Portal platform extracts the texts from pdf documents and indexed them in our database. Which gives the documentation to be searched even by the content of pdf documents. Anyone inside or outside the university can use the search engine we have provided to search these documents. Pera knowledge Portal search engine is able to produce accurate search results and give the most relatable documents according to the search text by the user.\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "Back to top\n",
      "\n",
      "\n",
      "Extracting finite element based structural non linear analysis https://cepdnaclk.github.io/e15-2yp-finite-element-based-structural-non-linear-analysis\n",
      "\n",
      "\n",
      "finite-element-based-structural-non-linear-analysis | e15-2yp-finite-element-based-structural-non-linear-analysis\n",
      "e15-2yp-finite-element-based-structural-non-linear-analysis\n",
      "finite-element-based-structural-non-linear-analysis\n",
      "Introduction\n",
      "This is an attempt to implement a CLI tool for the following paper.\n",
      "M.C.M. Rajapakse, K.K. Wijesundara, R. Nascimbene, C.S. Bandara, R. Dissanayake, Accounting axial-moment-shear interaction for force-based fiber modeling of RC frames, Engineering Structures, Volume 184, 2019, Pages 15-36,ISSN 0141-0296,\n",
      "https://doi.org/10.1016/j.engstruct.2019.01.075.\n",
      "People: [Pubudu Premathilaka], [Suneth Samarasinghe]\n",
      "Advised by: Dr. Kushan Wijesundara and [Sameera Hippola)\n",
      "Project summary\n",
      "Civil engineering structure modelling\n",
      "Elementwise local stiffness matrix calculation generation.\n",
      "Structure’s global stiffnexx matrix calculation.\n",
      "Load matrix generation.\n",
      "Lieanr system oprations.\n",
      "Linear system representation : dense and sparse\n",
      "Linear system solving: Gauss ellimination on dense and sparse matrices, iterative numerical techniques.\n",
      "Backtracking to translate the linear system solution to civil engineering structure.\n",
      "The main objective of this project was to find the time and memroy efficient way of computing the results.\n",
      "Please note\n",
      "This work was done as a partial requirement for CO328 Software Engineering) course. **This implementation consists of the linear and non linear region analysis **\n",
      "\n",
      "\n",
      "Extracting dynamic background cancellation in videos https://cepdnaclk.github.io/e14-2yp-dynamic-background-cancellation-in-videos\n",
      "\n",
      "\n",
      "Dynamic Background Cancellation | e14-2yp-dynamic-background-cancellation-in-videos\n",
      "e14-2yp-dynamic-background-cancellation-in-videos\n",
      "Dynamic Background Cancellation\n",
      "Dynamic background cancellation is a fundamental problem in video processing. Eventhough estimating the foreground is trivial in static background conditions, estimating the foreground can be tricky when the background is dynamic as well.\n",
      "In this project we try differrent approaches to detect the background and foreground in a video. We start with classical approaches and try to evaluate their pros and cons. Finally, we propose the most suitable combination of video processing operations to get the most accurate results.\n",
      "Algorithms\n",
      "PBAS Pixel based adaptive segmentation\n",
      "GMM Gaussian mixture model\n",
      "EM Expectatation maximization algorithm\n",
      "AGMM Adaptive gaussian mixture model\n",
      "FCMM Free Cylindrical mixture model\n",
      "AFCMM Adaptive free cylinder mixture model\n",
      "HVS Hierarchial video segmentation\n",
      "RPCA Robust Principle Component Analysis\n",
      "Morphological filtering\n",
      "SCC Strongly connected component analysis\n",
      "Technologies\n",
      "Python (Numpy, Scipy, Matplotlib)\n",
      "Matlab\n",
      "OpenCV\n",
      "People\n",
      "This project was done by Gihan Jayatilaka, Harshana Weligampola and Suren Sritharan as a course project for CO227 (Computer Engineering Project). The project was supervised by Dr. Dhammika Elkaduwe, Dr. Roshan Godaliyadda, Dr. Parakrama Ekanayeka and Dr. Vijitha Herath.\n",
      "Gihan, Harshana, Suren and Dr.Elkaduwa are from Department of Computer Engineering, Faculty of Engineering, University of Peradeniya. Dr.Godaliyadda, Dr.Ekanayeka, and Dr.Herath are from Department of Electrical and Electronics Engineering, Faculty of Engineering, University of Peradeniya\n",
      "Links\n",
      "Teambitecode.com page\n",
      "Report\n",
      "\n",
      "\n",
      "Extracting RISCV Pipeline CPU Implimentation Group2 https://cepdnaclk.github.io/e16-co502-RISCV-Pipeline-CPU-Implimentation-Group2\n",
      "\n",
      "\n",
      "RISC V Pipeline Processor\n",
      "Jun03\n",
      "Welcome to Our Risc V Pipeline Processor!\n",
      "Categories\n",
      "Memory systems and cache\n",
      "(1)\n",
      "Control Unit (4)\n",
      "Arithmatic and logic unit\n",
      "(1)\n",
      "Register file (4)\n",
      "Pipeline stages (1)\n",
      "Hazards (4)\n",
      "Calendar\n",
      "July 2021\n",
      "M\n",
      "T\n",
      "W\n",
      "T\n",
      "F\n",
      "S\n",
      "S\n",
      "« Jun\n",
      "Aug »\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Instruction Implementation\n",
      "R Type\n",
      "S Type\n",
      "J Type\n",
      "B Type\n",
      "I Type\n",
      "U Type\n",
      "©2011 Butterfly . All Rights Reserved.\n",
      "•\n",
      "Design by TEMPLATED   •\n",
      "Icons by FAMFAMFAM. Valid XHTML   •   Valid CSS\n",
      "\n",
      "\n",
      "Extracting RISCV pipeline cpu implementation group04 https://cepdnaclk.github.io/e16-co502-RISCV-pipeline-cpu-implementation-group04\n",
      "\n",
      "\n",
      "e16-co502-RISCV-pipeline-cpu-implementation-group04 | This is Advance Computer Architecture project of implementing Piplined Proccesor according to the RISC-V Instruction set\n",
      "e16-co502-RISCV-pipeline-cpu-implementation-group04\n",
      "RISCV Pipeline Proccesor Impementation\n",
      "This is a sample image, to show how to add images to your page. To learn more options, please refer this\n",
      "Team\n",
      "E/16/319, Vindula Rathnayke, email\n",
      "E/16/320, Subhash Rathnayke, email\n",
      "Table of Contents\n",
      "Introduction\n",
      "Pipeline Diagram\n",
      "Instruction Encoding System\n",
      "Links\n",
      "Introduction\n",
      "This is Advance Computer Architecture project of implementing Piplined Proccesor according to the 32bit\n",
      "RISC-V Instruction set. There containing all type of instructions.\n",
      "Pipeline Diagram with Datapath\n",
      "### Control Signals\n",
      "Register Read Flag\n",
      "Register write Flag\n",
      "Memory to register Flag\n",
      "Memory write Flag\n",
      "Branch Flag\n",
      "ALU opcode\n",
      "Register destination Flag\n",
      "ALU source Flag\n",
      "Instruction Encoding System\n",
      "…..\n",
      "Links\n",
      "Project Repository\n",
      "Project Page\n",
      "Department of Computer Engineering\n",
      "University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting RV32IM NoC implementation https://cepdnaclk.github.io/e16-co502-RV32IM-NoC-implementation\n",
      "\n",
      "\n",
      "Home - RV32IM Network on Chip Design and Implementation\n",
      "Home | RV32IM Network on Chip Design and Implementation\n",
      "Link\n",
      "Search\n",
      "Menu\n",
      "Expand\n",
      "Document\n",
      "HomeNodesCommunicationRoutersMain Memory and Memory Controller\n",
      "This site uses Just the Docs, a documentation theme for Jekyll.\n",
      "Project Repository on GitHub\n",
      "RV32IM Network on Chip Design and Implementation\n",
      "Table of Contents\n",
      "Introduction Pipeline Datapath Team Supervisors Links\n",
      "Introduction\n",
      "Under extended features we designed a Network of Chip to interconnect 16 RV32IM CPU instances using a mesh network. Mesh network is used by the CPU instances to communicate with other CPU instances and to access the main memory through the memory controllers. Figure 1 shows the basic design of the NoC. As shown in Figure 1, the main hardware components of the NoC,\n",
      "Nodes Routers Main memory Memory Controller\n",
      "GitHub Repository\n",
      "Overview of the Network on Chip\n",
      "Team\n",
      "E/16/069, Damsy De Silve, email E/16/094, Shirly Ekanayake, email E/16/276, Buddhi Perera, email\n",
      "Supervisors\n",
      "Dr. Isuru Navinna Dr. Mahanama Wickramasinghe\n",
      "Links\n",
      "Project Repository Project Page Department of Computer Engineering University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting RV32IM pipeline implementation group1 https://cepdnaclk.github.io/e16-co502-RV32IM-pipeline-implementation-group1\n",
      "\n",
      "\n",
      "Home - RV32IM Pipeline Implementation\n",
      "Home | RV32IM Pipeline Implementation\n",
      "Link\n",
      "Search\n",
      "Menu\n",
      "Expand\n",
      "Document\n",
      "HomeHardware UnitsControl Unit Control Signals Generated by the Control Unit\n",
      "Control Unit Design\n",
      "Instructions and the Control Signals ALURegister FileBranch and Jump Detection UnitImmediate Value Generation UnitProgram Counter RegisterMultiplexersProgram Counter Incrimeting AdderPipeline RegisterMemory HierarchyData CacheData MemoryInstruction CacheInstruction MemoryTiming and Simulation DelaysSimulation Delays of Hardware UnitsClock Cycle PeriodHazard Detection and Handling HazardsTypes of HazardsHandling Data HazardsForwarding‌ ‌unit‌ ‌HardwareHandling Control HazardsPipeline Datapath with Forwarding MechanismIntegrated CPUTesting\n",
      "This site uses Just the Docs, a documentation theme for Jekyll.\n",
      "Project Repository on GitHub\n",
      "RV32IM Pipeline Implementation\n",
      "Table of Contents\n",
      "Introduction Pipeline Datapath Team Supervisors Links\n",
      "Introduction\n",
      "The objective of this project was to design and implement a 5 stage pipeline CPU to support the RISC-V instruction architecture. This pipeline CPU supports the entire RV32IM ISA which contains 45 instructions. The designed pipeline CPU was implemented using behavioral modeling in verilogHDL and icarus Verilog was used compile and simulate. gtkWave was used to observe the behavior. GitHub Repository\n",
      "Pipeline Datapath\n",
      "Team\n",
      "E/16/069, Damsy De Silve, email E/16/094, Shirly Ekanayake, email E/16/276, Buddhi Perera, email\n",
      "Supervisors\n",
      "Dr. Isuru Navinna Dr. Mahanama Wickramasinghe\n",
      "Links\n",
      "Project Repository Project Page Department of Computer Engineering University of Peradeniya\n",
      "\n",
      "\n",
      "Extracting RV32IM pipeline implementation group3 https://cepdnaclk.github.io/e16-co502-RV32IM-pipeline-implementation-group3\n",
      "\n",
      "\n",
      "RISC-V 32 bit CPU\n",
      "RISC-V 32 bit CPU\n",
      "Home\n",
      "Blog\n",
      "planning\n",
      "Posted On July 2nd, 2021 .\n",
      "Instructions and encoding.\n",
      "Datapath and control, hardware units and signals.\n",
      "Continue Reading →\n",
      "ALU and Register file\n",
      "Posted On July 3rd, 2021 .\n",
      "ALU\n",
      "Register file.\n",
      "Other hardware units.\n",
      "Continue Reading →\n",
      "control unit\n",
      "Posted On July 7th, 2021 .\n",
      "Analysis of the controll unit behaviour to different instructions\n",
      "Finalizing the convention of the multi-bit control signals outputs.\n",
      "Continue Reading →\n",
      "Intergration & Testing\n",
      "Posted On July 24th, 2021 .\n",
      "Intergrating all the units together.\n",
      "Hazzard handling is done with assembler for now.\n",
      "Continue Reading →\n",
      "Hazard Hanndling\n",
      "Posted On August 24th, 2021 .\n",
      "Implemented two fowarding units in stage3 and stage4.\n",
      "Implemented a flushing unit to flush the data in pipeline registers in stage1 and stage2\n",
      "Continue Reading →\n",
      "Phase2: Shared Memory MPSoC\n",
      "Posted On October 22th, 2021 .\n",
      "Implemented a Shared MPSoC system that uses a snoop bus and snoop controller to handle data sharing\n",
      "Implemented a chache with a state machine based on the MESI protocol\n",
      "Continue Reading →\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from shutil import which\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "# Create Options object\n",
    "chrome_options = Options()\n",
    "# Add argument to Options to use headless browser\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "chrome_path = which(\"chromedriver\")\n",
    "\n",
    "# Add options argument to Chrome driver to use headless browser\n",
    "driver = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)\n",
    "\n",
    "projects = pd.read_csv(\"data/projects_details.csv\")\n",
    "\n",
    "# csv_file = open(\"data/projects_pages_details.csv\", \"w\", encoding='utf-8', newline='')\n",
    "# writer = csv.writer(csv_file)\n",
    "\n",
    "# writer.writerow([\"title\", \"page_url\", \"description\"])\n",
    "\n",
    "\n",
    "for project in projects.values:\n",
    "    title = project[0]\n",
    "    url = project[6]\n",
    "\n",
    "    url = url.strip()\n",
    "    if url == \"#\":\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n\\nExtracting {title} {url}\\n\\n\")\n",
    "\n",
    "    driver.get(url)\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, features=\"html.parser\")\n",
    "\n",
    "    file = open(\"data/\" + title + \".txt\", \"w\", encoding='utf-8')\n",
    "\n",
    "    # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    # get text\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "\n",
    "    print(text)\n",
    "    # writer.writerow([title, url, text])\n",
    "    file.write(text)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cepdnaclk.github.io/e15-3yp-A-GUI-for-controlling-and-supervising-multiple-robots-remotely\n",
      "https://cepdnaclk.github.io/e15-3yp-An-Efficient-System-For-Waste-Collection\n",
      "https://cepdnaclk.github.io/e15-3yp-An-automated-system-for-monitoring-and-controlling-the-water-supply-to-a-large-farmland\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Bike-Sharing-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Book-Management-System-Automated-Book-Carrying-Robot\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Vehicle-Parking-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Automated-Water-Quality-Monitoring-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Automatic-Door-Lock-System\n",
      "https://cepdnaclk.github.io/e15-3yp-E-Checkup\n",
      "https://cepdnaclk.github.io/e15-3yp-Embedded-system-for-detecting-adverse-gases\n",
      "https://cepdnaclk.github.io/e15-3yp-Fire-Detection-and-Alert-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Health-Watch\n",
      "https://cepdnaclk.github.io/e15-3yp-Hydroponics-Automation-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Intelligent-Road-Traffic-Control-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Monitoring-and-Tracking-System-for-Transportation-of-Pharmaceuticals\n",
      "https://cepdnaclk.github.io/e15-3yp-Personal-Physical-Trainer-PPT\n",
      "https://cepdnaclk.github.io/e15-3yp-Safer-Travel-Utility-SaVy\n",
      "https://cepdnaclk.github.io/e15-3yp-Smart-Educational-Management-System\n",
      "https://cepdnaclk.github.io/e15-3yp-Smart-Mirror\n",
      "https://cepdnaclk.github.io/e15-3yp-Smart-Monitoring-and-Automated-Controlling-System-for-an-Aquarium\n",
      "https://cepdnaclk.github.io/e14-3yp-Air-Quality-Monitoring-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Attendance-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Bike-Sharing-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Electricity-Billing-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Fishing-Bot\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Greenhouse-Fertilizing-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Automated-Monitoring-of-Hospital-Patients\n",
      "https://cepdnaclk.github.io/e14-3yp-Automatic-Speed-Trap\n",
      "https://cepdnaclk.github.io/e14-3yp-Bus-tracking-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Control-System-for-Heliostat-Solar-Power-Plants\n",
      "https://cepdnaclk.github.io/e14-3yp-Networked-and-Automated-Weather-Monitoring-and-Alerting-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Real-Time-Water-Qualtiy-Measurement-System\n",
      "https://cepdnaclk.github.io/e14-3yp-River-water-level-and-speed-monitoring-and-alert-system\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Breathalyzer-Test\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Shopping-Cart\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Warehouse-Monitoring-for-Paddy-Storage\n",
      "https://cepdnaclk.github.io/e14-3yp-Smart-Waste-Disposal-Monitoring-System\n",
      "https://cepdnaclk.github.io/e14-3yp-Telepresence-Robot\n",
      "https://cepdnaclk.github.io/e14-3yp-Train-Movement-Tracking-and-Level-Crossing-Safety-Control\n",
      "https://cepdnaclk.github.io/e14-3yp-sleep-apnea-detection\n",
      "https://cepdnaclk.github.io/e17-3yp-Covid-Tracer\n",
      "https://cepdnaclk.github.io/e17-3yp-E-Parking-System\n",
      "https://cepdnaclk.github.io/e17-3yp-Landmine-Detector\n",
      "https://cepdnaclk.github.io/e17-3yp-Milk-Testing-and-Collecting-System\n",
      "https://cepdnaclk.github.io/e17-3yp-Remote-Gatekeeping-System\n",
      "https://cepdnaclk.github.io/e17-3yp-Secure-Food-Delivery\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Cradle\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Locker\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Pet-Feeder\n",
      "https://cepdnaclk.github.io/e17-3yp-Smart-Pour\n",
      "https://cepdnaclk.github.io/e17-3yp-Wild-Life-Tracker\n",
      "https://cepdnaclk.github.io/e17-3yp-maker-mate\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-billiard\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-keyboard-tutoring-system\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-medical-diagnostics\n",
      "https://cepdnaclk.github.io/e17-3yp-remote-proctoring-system\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-apartment-security-system\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-garbage-collection\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-home\n",
      "https://cepdnaclk.github.io/e17-3yp-smart-shopping-cart\n",
      "https://cepdnaclk.github.io/e16-3yp-agribot\n",
      "https://cepdnaclk.github.io/e16-3yp-automated-railway-ticketing-system\n",
      "https://cepdnaclk.github.io/e16-3yp-automatic-fish-tank-control-system\n",
      "https://cepdnaclk.github.io/e16-3yp-chessMATE\n",
      "https://cepdnaclk.github.io/e16-3yp-computerized-timetabling-and-attendance-marking-system\n",
      "https://cepdnaclk.github.io/e16-3yp-digital-signage-based-user-targeted-advertising\n",
      "https://cepdnaclk.github.io/e16-3yp-full-body-motion-tracking-system\n",
      "https://cepdnaclk.github.io/e16-3yp-gas-level-indicator-and-leakage-detector\n",
      "https://cepdnaclk.github.io/e16-3yp-obstacle-bots-for-swarm-robots\n",
      "https://cepdnaclk.github.io/e16-3yp-qurantine-tracker\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-door-lock\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-infared-shooting-sport\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-meeting-automaton\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-payment-system\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-pharmaceutical-warehousing\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-pill-manager\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-shopping-cart-with-automatic-bill-system\n",
      "https://cepdnaclk.github.io/e16-3yp-smart-vending-machine\n",
      "https://cepdnaclk.github.io/e16-3yp-waiterbot-system\n",
      "https://cepdnaclk.github.io/e16-3yp-water-quality-monitoring-and-usage-monitoring-system\n",
      "https://cepdnaclk.github.io/e15-4yp-Accelerating-Adaptive-Banded-Event-Alignment-Algorithm-with-OpenCL-on-FPGA\n",
      "https://cepdnaclk.github.io/e15-4yp-Brain-Computer-Interface-for-controlling-virtual-objects\n",
      "https://cepdnaclk.github.io/e15-4yp-Doppelganger-Cartoon\n",
      "https://cepdnaclk.github.io/e15-4yp-Explainable-Machine-Learning-for-Real-World-Resource-Constrained-Problems\n",
      "https://cepdnaclk.github.io/e15-4yp-Hand-Gesture-Recognition-using-sEMG\n",
      "https://cepdnaclk.github.io/e15-4yp-Identifying-keywords-in-legal-articles-using-ML-techniques\n",
      "https://cepdnaclk.github.io/e15-4yp-Microservice-Based-Edge-Computing-Architecture\n",
      "https://cepdnaclk.github.io/e15-4yp-Mixed-Reality-based-Simulation-Platform-for-Swarm-Robotics\n",
      "https://cepdnaclk.github.io/e15-4yp-Optimizing-Mitochondria-Genome-Assembly-And-Annotation-With-Skim-Sequencing-Data\n",
      "https://cepdnaclk.github.io/e15-4yp-Optimizing-chloroplast-genome-assembly-and-annotation-with-skim-sequencing-data\n",
      "https://cepdnaclk.github.io/e15-4yp-Pipeline-for-Isolation-of-Fast-evolving-ITS-Regions-from-Skim-Sequencing-Data\n",
      "https://cepdnaclk.github.io/e15-4yp-Real-Time-Data-processing-and-AI-for-Distributed-IoT\n",
      "https://cepdnaclk.github.io/e15-4yp-Real-Time-Emotion-Recognition-using-Electrocardiogram-Analysis\n",
      "https://cepdnaclk.github.io/e15-4yp-Revealing-miRNA-Biomarkers-for-Alzheimer-s-Disease-using-NGS\n",
      "#\n",
      "https://cepdnaclk.github.io/e15-4yp-anonymous-authentication\n",
      "https://cepdnaclk.github.io/e15-4yp-cricket-analysis\n",
      "https://cepdnaclk.github.io/e15-4yp-human-behavior-prediction-using-cctv\n",
      "https://cepdnaclk.github.io/e15-4yp-nearIR-spectroscopy\n",
      "https://cepdnaclk.github.io/e15-4yp-online-proctoring-system\n",
      "https://cepdnaclk.github.io/e15-4yp-sports-action-recognition\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "https://cepdnaclk.github.io/e14-4yp-ipb\n",
      "#\n",
      "https://cepdnaclk.github.io/e15-co326-Remotely-Controlled-CNC-Robot\n",
      "https://cepdnaclk.github.io/e17-co328-Analysis-Tool-for-Industrial-Images\n",
      "#\n",
      "https://cepdnaclk.github.io/e17-co328-ContactTracingApp\n",
      "#\n",
      "https://cepdnaclk.github.io/e17-co328-Flood-Forecasting-System\n",
      "https://cepdnaclk.github.io/e17-co328-Greenhouse-Monitoring-System\n",
      "https://cepdnaclk.github.io/e17-co328-Greenhouse-monitoring-and-controlling-based-on-IOT-sensor-data\n",
      "https://cepdnaclk.github.io/e17-co328-History-of-Music\n",
      "https://cepdnaclk.github.io/e17-co328-Host-Pathogen-Interaction\n",
      "https://cepdnaclk.github.io/e17-co328-NGS-Data-AnalysingToolkit\n",
      "https://cepdnaclk.github.io/e17-co328-Oral-Cavity-Region-Detection\n",
      "#\n",
      "https://cepdnaclk.github.io/e17-co328-Prediction-of-risks-associated-with-mass-corona-vaccination\n",
      "https://cepdnaclk.github.io/e17-co328-Skim-Sequencing-Analysis\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "https://cepdnaclk.github.io/e16-co328-Movie-Review-System\n",
      "#\n",
      "https://cepdnaclk.github.io/e16-co328-Project-Publication-Platform\n",
      "https://cepdnaclk.github.io/e16-co328-Student-Management-System\n",
      "#\n",
      "#\n",
      "https://cepdnaclk.github.io/e15-co328-Zero-Trash\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "https://cepdnaclk.github.io/e17-co543-SL-Number-Plate-Detection-Group-A\n",
      "https://cepdnaclk.github.io/e15-2yp-Pera-Knowledge-Portal\n",
      "https://cepdnaclk.github.io/e15-2yp-finite-element-based-structural-non-linear-analysis\n",
      "https://cepdnaclk.github.io/e14-2yp-dynamic-background-cancellation-in-videos\n",
      "#\n",
      "#\n",
      "https://cepdnaclk.github.io/e16-co502-RISCV-Pipeline-CPU-Implimentation-Group2\n",
      "https://cepdnaclk.github.io/e16-co502-RISCV-pipeline-cpu-implementation-group04\n",
      "https://cepdnaclk.github.io/e16-co502-RV32IM-NoC-implementation\n",
      "https://cepdnaclk.github.io/e16-co502-RV32IM-pipeline-implementation-group1\n",
      "https://cepdnaclk.github.io/e16-co502-RV32IM-pipeline-implementation-group3\n",
      "#\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "for project in projects.values:\n",
    "    print(project[6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}